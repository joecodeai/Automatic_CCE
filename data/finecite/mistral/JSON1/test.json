[
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "person",
                "sitting",
                "on",
                "a",
                "horse.",
                "he",
                "is",
                "holding",
                "a",
                "horse",
                "thread",
                "and",
                "he",
                "is",
                "wearing",
                "a",
                "cap.",
                "there",
                "are",
                "flags,",
                "board",
                "on",
                "the",
                "left",
                "side.",
                "we",
                "can",
                "see",
                "in",
                "the",
                "background",
                "sky,",
                "trees.",
                "Contrastive",
                "Learning",
                "Recently,",
                "contrastive",
                "learning",
                "has",
                "been",
                "widely",
                "studied",
                "in",
                "unsupervised",
                "representation",
                "learning",
                "for",
                "vision,",
                "#REF",
                ",",
                "language",
                "#REF",
                ",",
                "or",
                "multi-modal",
                "#REF",
                ".",
                "The",
                "goal",
                "is",
                "to",
                "learn",
                "semantic",
                "representation",
                "between",
                "two",
                "views",
                "by",
                "allowing",
                "the",
                "positive",
                "sample",
                "to",
                "be",
                "similar",
                "(in",
                "semantic",
                "space)",
                "and",
                "negatives",
                "to",
                "be",
                "dissimilar",
                "semantically",
                "simultaneously.",
                "CLIP",
                "#REF",
                "and",
                "MIL-NCE",
                "#TARGET_REF",
                "has",
                "demonstrated",
                "the",
                "effectiveness",
                "for",
                "learning",
                "the",
                "semantic",
                "mapping",
                "between",
                "vision",
                "and",
                "language.",
                "Previous",
                "attempts",
                "mainly",
                "exploit",
                "the",
                "InfoNCE",
                "#REF",
                "objective",
                "to",
                "maximize",
                "a",
                "lower",
                "bound",
                "of",
                "the",
                "mutual",
                "information.",
                "This",
                "paper",
                "extends",
                "the",
                "multimodal",
                "contrastive",
                "learning",
                "between",
                "the",
                "trace",
                "in",
                "the",
                "image",
                "and",
                "captioning",
                "sentence.",
                "In",
                "the",
                "same",
                "image,",
                "they",
                "correspond",
                "to",
                "each",
                "other",
                "semantically.",
                "This",
                "motivates",
                "us",
                "to",
                "design",
                "a",
                "contrastive",
                "loss",
                "for",
                "better",
                "2022",
                "alignment",
                "between",
                "the",
                "trace",
                "and",
                "language."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There is a person sitting on a horse. he is holding a horse thread and he is wearing a cap. there are flags, board on the left side. we can see in the background sky, trees. Contrastive Learning Recently, contrastive learning has been widely studied in unsupervised representation learning for vision, #REF , language #REF , or multi-modal #REF . The goal is to learn semantic representation between two views by allowing the positive sample to be similar (in semantic space) and negatives to be dissimilar semantically simultaneously. CLIP #REF and MIL-NCE #TARGET_REF has demonstrated the effectiveness for learning the semantic mapping between vision and language. Previous attempts mainly exploit the InfoNCE #REF objective to maximize a lower bound of the mutual information. This paper extends the multimodal contrastive learning between the trace in the image and captioning sentence. In the same image, they correspond to each other semantically. This motivates us to design a contrastive loss for better 2022 alignment between the trace and language.",
        "output": "{\"INFORMATION\": [\"MIL-NCE #TARGET_REF has demonstrated the effectiveness for learning the semantic mapping between vision and language.\"], \"PERCEPTION\": [\"The goal is to learn semantic representation between two views by allowing the positive sample to be similar\", \"and negatives to be dissimilar semantically simultaneously.\"], \"BACKGROUND\": [\"(in semantic space)\", \"CLIP #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "the",
                "OPUS",
                "#TARGET_REF",
                "parallel",
                "movie",
                "subtitle",
                "corpus",
                "of",
                "subtitles",
                "collected",
                "from",
                "opensubtitles.org",
                "as",
                "a",
                "multi-domain",
                "proxy.",
                "As",
                "the",
                "movies",
                "we",
                "use",
                "for",
                "source",
                "data",
                "cover",
                "several",
                "different",
                "genres",
                "and,",
                "although",
                "scripted,",
                "represents",
                "real",
                "human",
                "language",
                "used",
                "in",
                "a",
                "multitude",
                "of",
                "situations",
                "similar",
                "to",
                "many",
                "social",
                "media",
                "platforms."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use the OPUS #TARGET_REF parallel movie subtitle corpus of subtitles collected from opensubtitles.org as a multi-domain proxy. As the movies we use for source data cover several different genres and, although scripted, represents real human language used in a multitude of situations similar to many social media platforms.",
        "output": "{\"INFORMATION\": [\"OPUS #TARGET_REF parallel movie subtitle corpus of subtitles collected from opensubtitles.org\"], \"PERCEPTION\": [\"We use the\", \"as a multi-domain proxy.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper,",
                "we",
                "developed",
                "a",
                "semi-supervised",
                "strategy",
                "to",
                "detect",
                "toxic",
                "comments",
                "in",
                "the",
                "Brazilian",
                "Portuguese",
                "language.",
                "Semi-supervision",
                "is",
                "the",
                "problem",
                "of",
                "learning",
                "from",
                "labeled",
                "and",
                "unlabeled",
                "data",
                "#TARGET_REF",
                ",",
                "in",
                "which",
                "given",
                "a",
                "point",
                "set",
                "X",
                "=",
                "{x",
                "1",
                ",",
                "...,",
                "x",
                "l",
                ",",
                "x",
                "l+1",
                ",",
                "...,",
                "x",
                "n",
                "}",
                "and",
                "a",
                "label",
                "set",
                "L",
                "=",
                "{1,",
                "...,",
                "c},",
                "the",
                "first",
                "l",
                "points",
                "have",
                "labels",
                "{y",
                "1",
                ",",
                "...,",
                "y",
                "l",
                "}",
                "∈",
                "L",
                "and",
                "the",
                "remaining",
                "points",
                "are",
                "unlabeled",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "In this paper, we developed a semi-supervised strategy to detect toxic comments in the Brazilian Portuguese language. Semi-supervision is the problem of learning from labeled and unlabeled data #TARGET_REF , in which given a point set X = {x 1 , ..., x l , x l+1 , ..., x n } and a label set L = {1, ..., c}, the first l points have labels {y 1 , ..., y l } ∈ L and the remaining points are unlabeled #REF .",
        "output": "{\"INFORMATION\": [\"Semi-supervision is the problem of learning from labeled and unlabeled data #TARGET_REF , in which given a point set X = {x 1 , ..., x l , x l+1 , ..., x n } and a label set L = {1, ..., c}, the first l points have labels {y 1 , ..., y l } \\u2208 L\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"and the remaining points are unlabeled #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "practice,",
                "the",
                "separation",
                "of",
                "question",
                "encoding",
                "and",
                "passage",
                "encoding",
                "is",
                "desirable,",
                "so",
                "that",
                "the",
                "dense",
                "representations",
                "of",
                "all",
                "passages",
                "can",
                "be",
                "precomputed",
                "for",
                "efficient",
                "retrieval.",
                "Here,",
                "we",
                "adopt",
                "two",
                "independent",
                "neural",
                "networks",
                "initialized",
                "from",
                "pre-trained",
                "LMs",
                "for",
                "the",
                "two",
                "encoders",
                "E",
                "q",
                "(•)",
                "and",
                "E",
                "p",
                "(•)",
                "separately,",
                "and",
                "take",
                "the",
                "representations",
                "at",
                "the",
                "first",
                "token",
                "(e.g.,",
                "#TARGET_REF",
                "symbol",
                "in",
                "BERT)",
                "as",
                "the",
                "output",
                "for",
                "encoding."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "In practice, the separation of question encoding and passage encoding is desirable, so that the dense representations of all passages can be precomputed for efficient retrieval. Here, we adopt two independent neural networks initialized from pre-trained LMs for the two encoders E q (•) and E p (•) separately, and take the representations at the first token (e.g., #TARGET_REF symbol in BERT) as the output for encoding.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF symbol in BERT)\"], \"PERCEPTION\": [\"the separation of question encoding and passage encoding is desirable, so that the dense representations of all passages can be precomputed for efficient retrieval.\", \"we adopt two independent neural networks initialized from pre-trained LMs for the two encoders E q (\\u2022) and E p (\\u2022) separately, and take the representations at the first token\", \"as the output for encoding.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "same",
                "approach",
                "is",
                "applied",
                "on",
                "diacritic",
                "model",
                "instead",
                "of",
                "using",
                "character",
                "information",
                "we",
                "use",
                "diacritics",
                "and",
                "instead",
                "of",
                "using",
                "C-Bi-LSTM",
                "we",
                "use",
                "D-Bi-LSTM.",
                "We",
                "extract",
                "the",
                "forward",
                "and",
                "backward",
                "outputs",
                "of",
                "the",
                "trained",
                "D-Bi-LSTM",
                "as",
                "individually-trained",
                "diacritic",
                "embeddings.",
                "It",
                "is",
                "worth",
                "noting",
                "that",
                "both",
                "of",
                "these",
                "models",
                "are",
                "trained",
                "on",
                "diacritized",
                "version",
                "of",
                "the",
                "datasets.",
                "Also",
                "it",
                "is",
                "important",
                "to",
                "mention",
                "that",
                "the",
                "output",
                "from",
                "this",
                "step",
                "are",
                "weights",
                "to",
                "initialize",
                "the",
                "character",
                "and",
                "diacritic",
                "embedding",
                "layers",
                "in",
                "the",
                "combination",
                "model",
                "and",
                "both",
                "of",
                "these",
                "sets",
                "of",
                "weights",
                "have",
                "been",
                "trained",
                "individually",
                "in",
                "separate",
                "models.",
                "The",
                "justification",
                "of",
                "this",
                "step",
                "can",
                "be",
                "found",
                "in",
                "Section",
                "(",
                "6)",
                "#TARGET_REF",
                "where",
                "the",
                "experiments",
                "showed",
                "that",
                "training",
                "these",
                "embeddings",
                "separately",
                "and",
                "using",
                "them",
                "as",
                "individually-trained",
                "embedding",
                "in",
                "the",
                "final",
                "model",
                "improves",
                "the",
                "performance."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The same approach is applied on diacritic model instead of using character information we use diacritics and instead of using C-Bi-LSTM we use D-Bi-LSTM. We extract the forward and backward outputs of the trained D-Bi-LSTM as individually-trained diacritic embeddings. It is worth noting that both of these models are trained on diacritized version of the datasets. Also it is important to mention that the output from this step are weights to initialize the character and diacritic embedding layers in the combination model and both of these sets of weights have been trained individually in separate models. The justification of this step can be found in Section ( 6) #TARGET_REF where the experiments showed that training these embeddings separately and using them as individually-trained embedding in the final model improves the performance.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF where the experiments showed that training these embeddings separately and using them as individually-trained embedding in the final model improves the performance.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The justification of this step can be found in Section ( 6)\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "work,",
                "we",
                "introduce",
                "a",
                "framework",
                "to",
                "automatically",
                "identify",
                "spurious",
                "correlations",
                "exploited",
                "by",
                "the",
                "model,",
                "sometimes",
                "also",
                "denoted",
                "as",
                "\"shortcuts\"",
                "in",
                "prior",
                "work",
                "#REF",
                "1",
                ",",
                "at",
                "a",
                "large",
                "scale.",
                "Our",
                "proposed",
                "framework",
                "differs",
                "from",
                "existing",
                "literature",
                "with",
                "a",
                "focus",
                "more",
                "on",
                "automatic",
                "shortcut",
                "identification,",
                "instead",
                "of",
                "pre-defining",
                "a",
                "limited",
                "set",
                "of",
                "shortcuts",
                "or",
                "learning",
                "from",
                "human",
                "annotations",
                "(Table",
                "1).",
                "Our",
                "framework",
                "works",
                "as",
                "follows:",
                "given",
                "a",
                "task",
                "and",
                "a",
                "trained",
                "model,",
                "we",
                "first",
                "utilize",
                "interpretability",
                "methods,",
                "e.g.,",
                "attention",
                "scores",
                "#REF",
                "and",
                "integrated",
                "gradient",
                "#REF",
                "which",
                "are",
                "commonly",
                "used",
                "for",
                "interpreting",
                "model's",
                "decisions,",
                "to",
                "automatically",
                "extract",
                "tokens",
                "that",
                "the",
                "model",
                "deems",
                "as",
                "important",
                "for",
                "task",
                "label",
                "Objective",
                "Approach",
                "for",
                "shortcut",
                "identification",
                "#TARGET_REF",
                "Robustness",
                "against",
                "known",
                "shortcuts",
                "Pre-defined",
                "#REF",
                "Robustness",
                "against",
                "known",
                "shortcuts",
                "Pre-defined",
                "#REF",
                "Robustness",
                "against",
                "unknown",
                "shortcuts",
                "A",
                "low-capacity",
                "model",
                "to",
                "specifically",
                "learn",
                "shortcuts",
                "#REF",
                "prediction.",
                "We",
                "then",
                "introduce",
                "two",
                "extra",
                "steps",
                "to",
                "further",
                "categorize",
                "the",
                "extracted",
                "tokens",
                "to",
                "be",
                "\"genuine\"",
                "or",
                "\"spurious\".",
                "We",
                "utilize",
                "a",
                "cross-dataset",
                "analysis",
                "to",
                "identify",
                "tokens",
                "that",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "\"shortcut\"."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this work, we introduce a framework to automatically identify spurious correlations exploited by the model, sometimes also denoted as \"shortcuts\" in prior work #REF 1 , at a large scale. Our proposed framework differs from existing literature with a focus more on automatic shortcut identification, instead of pre-defining a limited set of shortcuts or learning from human annotations (Table 1). Our framework works as follows: given a task and a trained model, we first utilize interpretability methods, e.g., attention scores #REF and integrated gradient #REF which are commonly used for interpreting model's decisions, to automatically extract tokens that the model deems as important for task label Objective Approach for shortcut identification #TARGET_REF Robustness against known shortcuts Pre-defined #REF Robustness against known shortcuts Pre-defined #REF Robustness against unknown shortcuts A low-capacity model to specifically learn shortcuts #REF prediction. We then introduce two extra steps to further categorize the extracted tokens to be \"genuine\" or \"spurious\". We utilize a cross-dataset analysis to identify tokens that are more likely to be \"shortcut\".",
        "output": "{\"INFORMATION\": [\"shortcut identification #TARGET_REF\"], \"PERCEPTION\": [\"given a task and a trained model, we first utilize interpretability methods,\", \"to automatically extract tokens that the model deems as important for task label Objective Approach for\"], \"BACKGROUND\": [\"e.g., attention scores #REF and integrated gradient #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "a",
                "Rapid",
                "Serial",
                "Visual",
                "Presentation",
                "(RSVP)",
                "paradigm,",
                "sentences",
                "were",
                "presented",
                "one",
                "word",
                "at",
                "a",
                "time,",
                "on",
                "average",
                "every",
                "≈",
                "240",
                "ms,",
                "in",
                "a",
                "white",
                "monospace",
                "font",
                "on",
                "a",
                "grey",
                "background",
                "approximately",
                "in",
                "the",
                "centre",
                "of",
                "the",
                "screen,",
                "at",
                "the",
                "optimal",
                "viewing",
                "position",
                "#TARGET_REF",
                ".",
                "Each",
                "word",
                "subtended",
                "a",
                "horizontal",
                "angle",
                "0.76",
                "•",
                "to",
                "the",
                "left",
                "and",
                "11.81",
                "•",
                "to",
                "the",
                "right",
                "from",
                "the",
                "centre.",
                "Sentences",
                "were",
                "separated",
                "by",
                "500",
                "ms",
                "of",
                "a",
                "white",
                "central",
                "fixation",
                "cross",
                "(see",
                "Figure",
                "1).",
                "On",
                "approximately",
                "20%",
                "of",
                "the",
                "sentences",
                "in",
                "each",
                "session,",
                "the",
                "participant",
                "was",
                "prompted",
                "to",
                "verbalise",
                "the",
                "previous",
                "sentence",
                "back",
                "to",
                "the",
                "experimenter.",
                "An",
                "accuracy",
                "score",
                "of",
                "93%",
                "across",
                "all",
                "sessions",
                "confirmed",
                "that",
                "the",
                "participant",
                "successfully",
                "attended",
                "the",
                "sentences.",
                "Stimuli",
                "were",
                "presented",
                "using",
                "PsychoPy",
                "#REF",
                "on",
                "an",
                "LCD",
                "monitor",
                "with",
                "a",
                "resolution",
                "of",
                "1920x1080",
                "pixels",
                "and",
                "60",
                "Hz",
                "refresh",
                "rate.",
                "The",
                "subject's",
                "head",
                "was",
                "stabilised",
                "with",
                "a",
                "chin-rest.",
                "Gilching,",
                "Germany).",
                "Channel",
                "impedances",
                "were",
                "kept",
                "below",
                "15",
                "kΩ.",
                "Data",
                "were",
                "preprocessed",
                "using",
                "MNE-Python",
                "#REF",
                ".",
                "Individual",
                "EEG",
                "sessions",
                "were",
                "band-pass",
                "filtered",
                "between",
                "1-40",
                "Hz,",
                "downsampled",
                "to",
                "250",
                "Hz",
                "and",
                "re-referenced",
                "to",
                "average",
                "reference.",
                "Noisy",
                "channels",
                "were",
                "determined",
                "based",
                "on",
                "visual",
                "inspection",
                "and",
                "interpolated.",
                "Non-neuronal",
                "components",
                "(e.g.",
                "ocular,",
                "muscular,",
                "electrical)",
                "were",
                "removed",
                "via",
                "Independent",
                "Component",
                "Analysis",
                "(ICA)",
                "individually",
                "for",
                "each",
                "recording",
                "session",
                "(an",
                "average",
                "of",
                "4",
                "components",
                "were",
                "removed",
                "per",
                "EEG",
                "session)."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In a Rapid Serial Visual Presentation (RSVP) paradigm, sentences were presented one word at a time, on average every ≈ 240 ms, in a white monospace font on a grey background approximately in the centre of the screen, at the optimal viewing position #TARGET_REF . Each word subtended a horizontal angle 0.76 • to the left and 11.81 • to the right from the centre. Sentences were separated by 500 ms of a white central fixation cross (see Figure 1). On approximately 20% of the sentences in each session, the participant was prompted to verbalise the previous sentence back to the experimenter. An accuracy score of 93% across all sessions confirmed that the participant successfully attended the sentences. Stimuli were presented using PsychoPy #REF on an LCD monitor with a resolution of 1920x1080 pixels and 60 Hz refresh rate. The subject's head was stabilised with a chin-rest. Gilching, Germany). Channel impedances were kept below 15 kΩ. Data were preprocessed using MNE-Python #REF . Individual EEG sessions were band-pass filtered between 1-40 Hz, downsampled to 250 Hz and re-referenced to average reference. Noisy channels were determined based on visual inspection and interpolated. Non-neuronal components (e.g. ocular, muscular, electrical) were removed via Independent Component Analysis (ICA) individually for each recording session (an average of 4 components were removed per EEG session).",
        "output": "{\"INFORMATION\": [\"In a Rapid Serial Visual Presentation (RSVP) paradigm, sentences were presented one word at a time, on average every \\u2248 240 ms, in a white monospace font on a grey background approximately in the centre of the screen, at the optimal viewing position #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Each word subtended a horizontal angle 0.76 \\u2022 to the left and 11.81 \\u2022 to the right from the centre. Sentences were separated by 500 ms of a white central fixation cross (see Figure 1).\"]}"
    },
    {
        "gold": {
            "text": [
                "End-to-end",
                "automatic",
                "speech",
                "recognition",
                "(E2E",
                "ASR),",
                "which",
                "transcribes",
                "speech",
                "using",
                "a",
                "single",
                "neural",
                "network",
                "(NN),",
                "has",
                "recently",
                "gained",
                "traction",
                "#TARGET_REF",
                ".",
                "Existing",
                "E2E",
                "ASR",
                "models",
                "generate",
                "audio",
                "transcripts",
                "by",
                "sequentially",
                "producing",
                "likely",
                "graphemes,",
                "or",
                "multi-graphemic",
                "units,",
                "from",
                "which",
                "lexical",
                "items",
                "of",
                "a",
                "language",
                "can",
                "be",
                "recovered.",
                "However,",
                "other",
                "linguistic",
                "annotations",
                "such",
                "as",
                "phonemic",
                "transcripts,",
                "part-of-speech",
                "(POS)",
                "tags,",
                "or",
                "word",
                "boundaries,",
                "help",
                "understand",
                "the",
                "underlying",
                "audio",
                "characteristics",
                "#REF",
                ".",
                "Such",
                "linguistic",
                "annotations",
                "are",
                "especially",
                "important",
                "in",
                "natural",
                "language",
                "processing",
                "(NLP)",
                "tasks",
                "done",
                "on",
                "audio",
                "!!",
                "!",
                "\"",
                "!\"!",
                "#",
                "\"",
                "#\"!",
                "#",
                "$",
                "#",
                "\"",
                "$",
                "!",
                "\"!",
                "\"",
                "!\"#",
                "#",
                "\"",
                "#\"#",
                "#",
                "$",
                "#",
                "\"",
                "$",
                "\"",
                "\"#",
                "\"",
                "#",
                "\"",
                "#",
                "\"",
                "#",
                "\"",
                "#",
                "$",
                "#",
                "\"",
                "#",
                "\""
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "End-to-end automatic speech recognition (E2E ASR), which transcribes speech using a single neural network (NN), has recently gained traction #TARGET_REF . Existing E2E ASR models generate audio transcripts by sequentially producing likely graphemes, or multi-graphemic units, from which lexical items of a language can be recovered. However, other linguistic annotations such as phonemic transcripts, part-of-speech (POS) tags, or word boundaries, help understand the underlying audio characteristics #REF . Such linguistic annotations are especially important in natural language processing (NLP) tasks done on audio !! ! \" !\"! # \" #\"! # $ # \" $ ! \"! \" !\"# # \" #\"# # $ # \" $ \" \"# \" # \" # \" # \" # $ # \" # \"",
        "output": "{\"INFORMATION\": [\"End-to-end automatic speech recognition (E2E ASR), which transcribes speech using a single neural network (NN),\"], \"PERCEPTION\": [\"has recently gained traction #TARGET_REF .\"], \"BACKGROUND\": [\"Existing E2E ASR models generate audio transcripts by sequentially producing likely graphemes, or multi-graphemic units, from which lexical items of a language can be recovered.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper,",
                "we",
                "focus",
                "on",
                "measuring",
                "and",
                "mitigating",
                "gender-biased",
                "language",
                "in",
                "machine-generated",
                "job",
                "ads,",
                "a",
                "use",
                "case",
                "of",
                "large-scale",
                "language",
                "models",
                "which",
                "risks",
                "representational",
                "and",
                "allocational",
                "harms",
                "#REF",
                ".",
                "Representational",
                "harms",
                "come",
                "from",
                "the",
                "conditioning",
                "of",
                "a",
                "job's",
                "suitability",
                "to",
                "a",
                "given",
                "individual",
                "based",
                "on",
                "their",
                "gender.",
                "When",
                "jobs",
                "are",
                "valued",
                "unequally",
                "(either",
                "by",
                "financial,",
                "social",
                "or",
                "intellectual",
                "status),",
                "this,",
                "in",
                "turn,",
                "can",
                "reinforce",
                "gendered",
                "power",
                "hierarchies",
                "and",
                "negative",
                "societal",
                "divisions.",
                "Gender-biased",
                "language",
                "may",
                "result",
                "in",
                "an",
                "unequal",
                "distribution",
                "of",
                "job",
                "applications",
                "if",
                "it",
                "dissuades",
                "gender-diverse",
                "candidates",
                "from",
                "applying",
                "#REF",
                ".",
                "Thus,",
                "allocational",
                "harms",
                "are",
                "relevant",
                "where",
                "labour",
                "market",
                "opportunities,",
                "financial",
                "remuneration",
                "or",
                "job",
                "stability",
                "are",
                "preferentially",
                "granted",
                "based",
                "on",
                "gender.",
                "We",
                "know",
                "from",
                "prior",
                "NLP",
                "research",
                "that",
                "GPT",
                "models",
                "reflect",
                "occupational",
                "stereotypes",
                "in",
                "society",
                "#TARGET_REF",
                ",",
                "confirming",
                "the",
                "risk",
                "of",
                "representational",
                "harm,",
                "but",
                "not",
                "how",
                "this",
                "translates",
                "into",
                "allocational",
                "harms",
                "in",
                "applied",
                "settings.",
                "To",
                "measure",
                "bias,",
                "our",
                "experiment",
                "employs",
                "lists",
                "of",
                "gender-coded",
                "words.",
                "These",
                "lists",
                "are",
                "potentially",
                "in",
                "themselves",
                "biased,",
                "having",
                "been",
                "defined",
                "by",
                "a",
                "research",
                "group",
                "under",
                "a",
                "particular",
                "cultural",
                "bias",
                "or",
                "as",
                "the",
                "result",
                "of",
                "biased",
                "data.",
                "To",
                "mitigate",
                "this",
                "concern,",
                "we",
                "use",
                "multiple",
                "measures",
                "to",
                "cover",
                "the",
                "blind",
                "spots",
                "or",
                "specific",
                "biases",
                "present",
                "in",
                "any",
                "single",
                "list.",
                "However,",
                "our",
                "proposed",
                "metric",
                "may",
                "better",
                "capture",
                "the",
                "most",
                "obvious,",
                "text-level",
                "aspects",
                "of",
                "gender-biased",
                "language",
                "and",
                "will",
                "be",
                "less",
                "effective",
                "to",
                "find",
                "covert,",
                "but",
                "equally",
                "as",
                "damaging,",
                "forms",
                "of",
                "gender",
                "bias",
                "in",
                "job",
                "ads,",
                "or",
                "job",
                "search",
                "more",
                "broadly."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this paper, we focus on measuring and mitigating gender-biased language in machine-generated job ads, a use case of large-scale language models which risks representational and allocational harms #REF . Representational harms come from the conditioning of a job's suitability to a given individual based on their gender. When jobs are valued unequally (either by financial, social or intellectual status), this, in turn, can reinforce gendered power hierarchies and negative societal divisions. Gender-biased language may result in an unequal distribution of job applications if it dissuades gender-diverse candidates from applying #REF . Thus, allocational harms are relevant where labour market opportunities, financial remuneration or job stability are preferentially granted based on gender. We know from prior NLP research that GPT models reflect occupational stereotypes in society #TARGET_REF , confirming the risk of representational harm, but not how this translates into allocational harms in applied settings. To measure bias, our experiment employs lists of gender-coded words. These lists are potentially in themselves biased, having been defined by a research group under a particular cultural bias or as the result of biased data. To mitigate this concern, we use multiple measures to cover the blind spots or specific biases present in any single list. However, our proposed metric may better capture the most obvious, text-level aspects of gender-biased language and will be less effective to find covert, but equally as damaging, forms of gender bias in job ads, or job search more broadly.",
        "output": "{\"INFORMATION\": [\"GPT models reflect occupational stereotypes in society #TARGET_REF , confirming the risk of representational harm, but not how this translates into allocational harms in applied settings.\"], \"PERCEPTION\": [\"We know from prior NLP research that\"], \"BACKGROUND\": [\"Gender-biased language may result in an unequal distribution of job applications if it dissuades gender-diverse candidates from applying #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Offensive",
                "language",
                "can",
                "include",
                "various",
                "categories",
                "such",
                "as",
                "threats,",
                "vilification,",
                "insults,",
                "calumniation,",
                "discrimination",
                "and",
                "swearing",
                "#TARGET_REF",
                ".",
                "Detection",
                "of",
                "such",
                "language",
                "is",
                "necessary",
                "for",
                "ease",
                "of",
                "moderation",
                "of",
                "content",
                "on",
                "social",
                "media.",
                "Despite",
                "their",
                "popularity,",
                "toxicity",
                "detection",
                "tasks",
                "have",
                "focused",
                "majorly",
                "on",
                "sequence",
                "classification,",
                "rather",
                "than",
                "sequence",
                "tagging.",
                "Finding",
                "which",
                "spans",
                "make",
                "a",
                "comment",
                "or",
                "document",
                "toxic",
                "in",
                "nature",
                "is",
                "crucial",
                "in",
                "explaining",
                "the",
                "reasons",
                "behind",
                "their",
                "toxicity.",
                "Additionally,",
                "such",
                "attributions",
                "would",
                "allow",
                "for",
                "more",
                "efficient",
                "semi-automated",
                "quality-based",
                "moderation",
                "of",
                "content,",
                "especially",
                "for",
                "verbose",
                "documents,",
                "in",
                "comparison",
                "to",
                "quantitative",
                "toxicity",
                "scores."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Offensive language can include various categories such as threats, vilification, insults, calumniation, discrimination and swearing #TARGET_REF . Detection of such language is necessary for ease of moderation of content on social media. Despite their popularity, toxicity detection tasks have focused majorly on sequence classification, rather than sequence tagging. Finding which spans make a comment or document toxic in nature is crucial in explaining the reasons behind their toxicity. Additionally, such attributions would allow for more efficient semi-automated quality-based moderation of content, especially for verbose documents, in comparison to quantitative toxicity scores.",
        "output": "{\"INFORMATION\": [\"Offensive language can include various categories such as threats, vilification, insults, calumniation, discrimination and swearing #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Detection of such language is necessary for ease of moderation of content on social media.\", \"Finding which spans make a comment or document toxic in nature is crucial in explaining the reasons behind their toxicity.\"]}"
    },
    {
        "gold": {
            "text": [
                "Generating",
                "multiple",
                "valid",
                "outputs",
                "given",
                "a",
                "source",
                "sequence",
                "has",
                "a",
                "wide",
                "range",
                "of",
                "applications,",
                "such",
                "as",
                "machine",
                "translation",
                "#REF",
                ",",
                "paraphrase",
                "generation",
                "#REF",
                ",",
                "question",
                "generation",
                "#TARGET_REF",
                ",",
                "dialogue",
                "system",
                "#REF",
                ",",
                "and",
                "story",
                "generation",
                "#REF",
                ".",
                "For",
                "example,",
                "in",
                "machine",
                "translation,",
                "there",
                "are",
                "often",
                "many",
                "plausible",
                "and",
                "semantically",
                "equivalent",
                "translations",
                "due",
                "to",
                "information",
                "asymmetry",
                "between",
                "different",
                "languages",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Generating multiple valid outputs given a source sequence has a wide range of applications, such as machine translation #REF , paraphrase generation #REF , question generation #TARGET_REF , dialogue system #REF , and story generation #REF . For example, in machine translation, there are often many plausible and semantically equivalent translations due to information asymmetry between different languages #REF .",
        "output": "{\"INFORMATION\": [\"question generation #TARGET_REF ,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Generating multiple valid outputs given a source sequence has a wide range of applications, such as machine translation #REF , paraphrase generation #REF ,\", \"dialogue system #REF , and story generation #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "t",
                ",",
                "x",
                "t",
                ")|1",
                "≤",
                "t",
                "≤",
                "n",
                "d",
                "},",
                "let",
                "{b",
                "t",
                "|1",
                "≤",
                "t",
                "≤",
                "n",
                "d",
                "}be",
                "the",
                "dialogue",
                "state",
                "for",
                "each",
                "turn,",
                "where",
                "b",
                "t",
                "∈",
                "{0,",
                "1}",
                "N",
                "b",
                "and",
                "N",
                "b",
                "is",
                "the",
                "number",
                "of",
                "all",
                "slot-value",
                "pairs.",
                "Dialogue",
                "state",
                "tracking",
                "is",
                "usually",
                "formulated",
                "as",
                "a",
                "multilabel",
                "learning",
                "problem",
                "where",
                "the",
                "state",
                "at",
                "turn",
                "t",
                "predicted",
                "by",
                "modeling",
                "the",
                "conditional",
                "distribution",
                "p(bt",
                "|c",
                "t",
                ")",
                "=",
                "p(b",
                "t",
                "|u",
                "t",
                ",",
                "x",
                "t−1",
                ",",
                "b",
                "t−1",
                "),",
                "where",
                "b",
                "t−1",
                "is",
                "the",
                "dialogue",
                "state",
                "in",
                "the",
                "previous",
                "turn.",
                "To",
                "model",
                "this",
                "conditional",
                "distribution,",
                "a",
                "state",
                "tracking",
                "model",
                "p",
                "B",
                "(u",
                "t",
                ",",
                "x",
                "t−1",
                ",",
                "b",
                "t−1",
                ")",
                "mainly",
                "employs",
                "an",
                "utterance",
                "en-coder,",
                "a",
                "context",
                "encoder",
                "to",
                "work",
                "with",
                "a",
                "slot-value",
                "predictor",
                "that",
                "estimates",
                "whether",
                "a",
                "slot-value",
                "pair",
                "should",
                "be",
                "included",
                "in",
                "the",
                "dialogue",
                "states",
                "#TARGET_REF",
                ".",
                "Specifically,",
                "the",
                "predictor",
                "takes",
                "as",
                "input",
                "a",
                "slot-value",
                "pair",
                "(s",
                "i",
                ",",
                "e",
                "i",
                "),",
                "and",
                "the",
                "encoded",
                "utterances",
                "h",
                "utt",
                "∈",
                "R",
                "D",
                "and",
                "context",
                "h",
                "ctx",
                "∈",
                "R",
                "D",
                "from",
                "the",
                "utterance",
                "encoder",
                "f",
                "utt",
                "(u",
                "t",
                ",",
                "x",
                "t−1",
                ")",
                "and",
                "context",
                "encoder",
                "f",
                "ctx",
                "(b",
                "t−1",
                ")",
                "respectively,",
                "and",
                "D",
                "is",
                "the",
                "hidden",
                "dimension.",
                "The",
                "prediction",
                "is",
                "then",
                "performed",
                "by",
                "aggregating",
                "the",
                "results",
                "of",
                "slot-value",
                "predictor",
                "f",
                "val",
                "(h",
                "utt",
                ",",
                "h",
                "ctx",
                ",",
                "(s",
                "i",
                ",",
                "e",
                "i",
                "))",
                "for",
                "the",
                "complete",
                "N",
                "b",
                "slotvalue",
                "pairs.",
                "We",
                "optimize",
                "the",
                "state",
                "tracking",
                "model",
                "using",
                "the",
                "cross-entropy",
                "loss:L",
                "=",
                "d",
                "i",
                "t=1:n",
                "d",
                "−",
                "log(b",
                "t",
                "•p",
                "B",
                "(u",
                "t",
                ",",
                "x",
                "t−1",
                ",",
                "c",
                "t−1",
                "))",
                "(4)where",
                "the",
                "parameters",
                "of",
                "p",
                "B",
                ",",
                "which",
                "include",
                "f",
                "utt",
                ",",
                "f",
                "ctx",
                ",",
                "and",
                "f",
                "val",
                ",",
                "are",
                "jointly",
                "trained."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "t , x t )|1 ≤ t ≤ n d }, let {b t |1 ≤ t ≤ n d }be the dialogue state for each turn, where b t ∈ {0, 1} N b and N b is the number of all slot-value pairs. Dialogue state tracking is usually formulated as a multilabel learning problem where the state at turn t predicted by modeling the conditional distribution p(bt |c t ) = p(b t |u t , x t−1 , b t−1 ), where b t−1 is the dialogue state in the previous turn. To model this conditional distribution, a state tracking model p B (u t , x t−1 , b t−1 ) mainly employs an utterance en-coder, a context encoder to work with a slot-value predictor that estimates whether a slot-value pair should be included in the dialogue states #TARGET_REF . Specifically, the predictor takes as input a slot-value pair (s i , e i ), and the encoded utterances h utt ∈ R D and context h ctx ∈ R D from the utterance encoder f utt (u t , x t−1 ) and context encoder f ctx (b t−1 ) respectively, and D is the hidden dimension. The prediction is then performed by aggregating the results of slot-value predictor f val (h utt , h ctx , (s i , e i )) for the complete N b slotvalue pairs. We optimize the state tracking model using the cross-entropy loss:L = d i t=1:n d − log(b t •p B (u t , x t−1 , c t−1 )) (4)where the parameters of p B , which include f utt , f ctx , and f val , are jointly trained.",
        "output": "{\"INFORMATION\": [\"a slot-value predictor that estimates whether a slot-value pair should be included in the dialogue states #TARGET_REF .\"], \"PERCEPTION\": [\"To model this conditional distribution, a state tracking model p B (u t , x t\\u22121 , b t\\u22121 ) mainly employs an utterance en-coder, a context encoder to work with\"], \"BACKGROUND\": [\"Specifically, the predictor takes as input a slot-value pair (s i , e i ), and the encoded utterances h utt \\u2208 R D and context h ctx \\u2208 R D from the utterance encoder f utt (u t , x t\\u22121 ) and context encoder f ctx (b t\\u22121 ) respectively, and D is the hidden dimension.\"]}"
    },
    {
        "gold": {
            "text": [
                "where",
                "h",
                "v",
                "and",
                "h",
                "r",
                "are",
                "node",
                "embedding",
                "and",
                "relation",
                "embedding.",
                "We",
                "define",
                "the",
                "compositional",
                "operation",
                "as",
                "ϕ(h",
                "u",
                ",",
                "h",
                "r",
                ")",
                "=",
                "h",
                "u",
                "−h",
                "r",
                "inspired",
                "by",
                "the",
                "TransE",
                "#TARGET_REF",
                ".",
                "The",
                "relation",
                "embedding",
                "is",
                "also",
                "updated",
                "via",
                "another",
                "linear",
                "transformation:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "where h v and h r are node embedding and relation embedding. We define the compositional operation as ϕ(h u , h r ) = h u −h r inspired by the TransE #TARGET_REF . The relation embedding is also updated via another linear transformation:",
        "output": "{\"INFORMATION\": [\"the TransE #TARGET_REF .\"], \"PERCEPTION\": [\"We define the compositional operation as \\u03d5(h u , h r ) = h u \\u2212h r inspired by\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "ArXiv",
                "open-sources",
                "the",
                "LaTeX",
                "version",
                "of",
                "their",
                "articles,",
                "when",
                "available.",
                "In",
                "order",
                "to",
                "make",
                "our",
                "Symlink",
                "dataset",
                "open-access",
                "to",
                "the",
                "whole",
                "community,",
                "we",
                "crawled",
                "the",
                "metadata",
                "of",
                "these",
                "articles",
                "and",
                "only",
                "selected",
                "articles",
                "under",
                "the",
                "CC",
                "BY",
                "license.",
                "Once",
                "obtained",
                "the",
                "LaTeX",
                "project,",
                "we",
                "extracted",
                "all",
                "the",
                "paragraphs",
                "from",
                "the",
                ".tex",
                "files.",
                "We",
                "filtered",
                "out",
                "all",
                "short",
                "paragraphs",
                "with",
                "less",
                "than",
                "50",
                "words",
                "and",
                "paragraphs",
                "without",
                "symbols.",
                "Since",
                "a",
                "formula",
                "can",
                "be",
                "composed",
                "in",
                "multiple",
                "ways",
                "such",
                "as",
                "inline",
                "formulae",
                "(between",
                "$",
                "$),",
                "displayed",
                "formulae",
                "(between",
                "$$",
                "$$),",
                "or",
                "using",
                "commands",
                "e.g.",
                "array,",
                "to",
                "keep",
                "the",
                "original",
                "TeX",
                "format",
                "of",
                "the",
                "formulae,",
                "all",
                "of",
                "these",
                "math",
                "objects",
                "are",
                "masked",
                "before",
                "tokenization.",
                "Then,",
                "we",
                "used",
                "the",
                "SciBERT",
                "tokenizer",
                "#TARGET_REF",
                "to",
                "tokenize",
                "the",
                "text.",
                "The",
                "original",
                "math",
                "object",
                "is",
                "then",
                "restored.",
                "As",
                "we",
                "observed",
                "that",
                "many",
                "papers",
                "have",
                "nested",
                "math",
                "objects,",
                "we",
                "deleted",
                "all",
                "the",
                "nested",
                "objects,",
                "hence,",
                "having",
                "non-nested",
                "LaTeX",
                "data.",
                "This",
                "is",
                "helpful",
                "as",
                "it",
                "makes",
                "the",
                "LaTeX",
                "documents",
                "more",
                "similar",
                "to",
                "the",
                "ones",
                "generated",
                "by",
                "the",
                "PDF-to-LaTeX",
                "tools,",
                "which",
                "do",
                "not",
                "contain",
                "nested",
                "objects."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "ArXiv open-sources the LaTeX version of their articles, when available. In order to make our Symlink dataset open-access to the whole community, we crawled the metadata of these articles and only selected articles under the CC BY license. Once obtained the LaTeX project, we extracted all the paragraphs from the .tex files. We filtered out all short paragraphs with less than 50 words and paragraphs without symbols. Since a formula can be composed in multiple ways such as inline formulae (between $ $), displayed formulae (between $$ $$), or using commands e.g. array, to keep the original TeX format of the formulae, all of these math objects are masked before tokenization. Then, we used the SciBERT tokenizer #TARGET_REF to tokenize the text. The original math object is then restored. As we observed that many papers have nested math objects, we deleted all the nested objects, hence, having non-nested LaTeX data. This is helpful as it makes the LaTeX documents more similar to the ones generated by the PDF-to-LaTeX tools, which do not contain nested objects.",
        "output": "{\"INFORMATION\": [\"the SciBERT tokenizer #TARGET_REF\"], \"PERCEPTION\": [\"we used\", \"to tokenize the text. The original math object is then restored.\"], \"BACKGROUND\": [\"Since a formula can be composed in multiple ways such as inline formulae (between $ $), displayed formulae (between $$ $$), or using commands\"]}"
    },
    {
        "gold": {
            "text": [
                "Taking",
                "inspiration",
                "from",
                "gradient",
                "checkpointing",
                "#TARGET_REF",
                ",",
                "we",
                "observe",
                "that",
                "if",
                "the",
                "inputs",
                "Q",
                "C",
                ",",
                "K,",
                "V",
                "are",
                "available",
                "during",
                "the",
                "backward",
                "pass,",
                "we",
                "can",
                "re-compute",
                "o",
                "C",
                "and",
                "then",
                "use",
                "the",
                "produced",
                "intermediate",
                "activations",
                "to",
                "computed",
                "(Q",
                "C",
                ")",
                "from",
                "d",
                "(o",
                "C",
                ").",
                "Once",
                "d",
                "(Q",
                "C)",
                "is",
                "computed,",
                "we",
                "can",
                "again",
                "discard",
                "the",
                "intermediate",
                "activations",
                "and",
                "gradients",
                "produced",
                "during",
                "this",
                "step",
                "and",
                "move",
                "on",
                "to",
                "the",
                "next",
                "chunk.",
                "This",
                "ensures",
                "that",
                "the",
                "peak",
                "memory",
                "usage",
                "during",
                "the",
                "backward",
                "pass",
                "through",
                "the",
                "attention",
                "layer",
                "is",
                "bounded",
                "by",
                "the",
                "memory",
                "required",
                "to",
                "backpropagate",
                "through",
                "a",
                "single",
                "chunk."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Taking inspiration from gradient checkpointing #TARGET_REF , we observe that if the inputs Q C , K, V are available during the backward pass, we can re-compute o C and then use the produced intermediate activations to computed (Q C ) from d (o C ). Once d (Q C) is computed, we can again discard the intermediate activations and gradients produced during this step and move on to the next chunk. This ensures that the peak memory usage during the backward pass through the attention layer is bounded by the memory required to backpropagate through a single chunk.",
        "output": "{\"INFORMATION\": [\"gradient checkpointing\"], \"PERCEPTION\": [\"Taking inspiration from\"], \"BACKGROUND\": [\"we observe that if the inputs Q C , K, V are available during the backward pass, we can re-compute o C and then use the produced intermediate activations to computed (Q C ) from d (o C ). Once d (Q C) is computed, we can again discard the intermediate activations and gradients produced during this step and move on to the next chunk.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Joint:",
                "we",
                "concatenate",
                "the",
                "training",
                "examples",
                "from",
                "Quoref",
                "and",
                "CoNLL-to-QA",
                "converted",
                "11",
                "The",
                "only",
                "difference",
                "of",
                "TASE",
                "in",
                "our",
                "experiments",
                "and",
                "the",
                "reported",
                "results",
                "in",
                "#TARGET_REF",
                "is",
                "the",
                "number",
                "of",
                "training",
                "epochs.",
                "For",
                "a",
                "fair",
                "comparison,",
                "we",
                "train",
                "all",
                "models",
                "for",
                "the",
                "same",
                "number",
                "of",
                "iterations."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Joint: we concatenate the training examples from Quoref and CoNLL-to-QA converted 11 The only difference of TASE in our experiments and the reported results in #TARGET_REF is the number of training epochs. For a fair comparison, we train all models for the same number of iterations.",
        "output": "{\"INFORMATION\": [\"results in #TARGET_REF\"], \"PERCEPTION\": [\"we concatenate the training examples from Quoref and CoNLL-to-QA converted 11 The only difference of TASE in our experiments and the reported\", \"is the number of training epochs.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "answer",
                "these",
                "questions,",
                "we",
                "first",
                "establish",
                "in",
                "section",
                "2",
                "a",
                "state-of-the-art",
                "that",
                "is",
                "meant",
                "to",
                "be",
                "broad",
                "enough",
                "to",
                "have",
                "a",
                "shallow",
                "overview",
                "depicting",
                "the",
                "ins",
                "and",
                "outs",
                "and",
                "issues",
                "around",
                "the",
                "usability",
                "of",
                "Transformer-based",
                "models",
                "whose",
                "breadcrumb",
                "trail",
                "is",
                "the",
                "issue",
                "of",
                "resources.",
                "Then,",
                "we",
                "present",
                "in",
                "the",
                "section",
                "3",
                "the",
                "recent",
                "progress",
                "of",
                "the",
                "questionanswering",
                "task,",
                "through",
                "the",
                "use",
                "of",
                "these",
                "latest",
                "models.",
                "In",
                "sections",
                "4",
                "and",
                "5",
                "we",
                "introduce",
                "our",
                "model",
                "and",
                "present",
                "our",
                "experiments",
                "on",
                "the",
                "usability",
                "of",
                "Transformers",
                "models",
                "in",
                "a",
                "question-answering",
                "task",
                "for",
                "#REF",
                "and",
                "PIAF",
                "#REF",
                "corpora.",
                "We",
                "propose",
                "to",
                "address",
                "the",
                "instability",
                "relating",
                "to",
                "data",
                "scarcity",
                "by",
                "investigating",
                "various",
                "training",
                "strategies",
                "with",
                "data",
                "augmentation,",
                "hyperparameters",
                "optimization",
                "and",
                "cross-lingual",
                "transfer.",
                "Finally,",
                "we",
                "present",
                "a",
                "new",
                "compact",
                "model",
                "for",
                "French",
                "based",
                "on",
                "ALBERT",
                "#TARGET_REF",
                "1",
                ",",
                "and",
                "compare",
                "it",
                "to",
                "existing",
                "monolingual",
                "and",
                "multilingual",
                "models,",
                "large",
                "and",
                "compact,",
                "under",
                "constrained",
                "conditions",
                "(notably",
                "on",
                "learning",
                "data)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3
            ]
        },
        "input": "To answer these questions, we first establish in section 2 a state-of-the-art that is meant to be broad enough to have a shallow overview depicting the ins and outs and issues around the usability of Transformer-based models whose breadcrumb trail is the issue of resources. Then, we present in the section 3 the recent progress of the questionanswering task, through the use of these latest models. In sections 4 and 5 we introduce our model and present our experiments on the usability of Transformers models in a question-answering task for #REF and PIAF #REF corpora. We propose to address the instability relating to data scarcity by investigating various training strategies with data augmentation, hyperparameters optimization and cross-lingual transfer. Finally, we present a new compact model for French based on ALBERT #TARGET_REF 1 , and compare it to existing monolingual and multilingual models, large and compact, under constrained conditions (notably on learning data).",
        "output": "{\"INFORMATION\": [\"ALBERT #TARGET_REF\"], \"PERCEPTION\": [\"we present a new compact model for French based on\", \"1 , and compare it to existing monolingual and multilingual models, large and compact, under constrained conditions\"], \"BACKGROUND\": [\"(notably on learning data).\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "caption",
                "generation",
                "backbone",
                "is",
                "a",
                "transformerbased",
                "encoder-decoder",
                "proposed",
                "by",
                "#TARGET_REF",
                ",",
                "which",
                "mainly",
                "employs",
                "a",
                "multi-head",
                "attention",
                "mechanism",
                "and",
                "achieves",
                "top-tier",
                "performance",
                "in",
                "many",
                "sequential",
                "related",
                "tasks.",
                "Here,",
                "we",
                "highlight",
                "several",
                "task-oriented",
                "modifications."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The caption generation backbone is a transformerbased encoder-decoder proposed by #TARGET_REF , which mainly employs a multi-head attention mechanism and achieves top-tier performance in many sequential related tasks. Here, we highlight several task-oriented modifications.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF , which mainly employs a multi-head attention mechanism and achieves top-tier performance in many sequential related tasks.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The caption generation backbone is a transformerbased encoder-decoder proposed by\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "new",
                "lexico-structural",
                "transfer",
                "approach",
                "is",
                "more",
                "similar",
                "to",
                "the",
                "interlingua",
                "approach",
                "in",
                "that",
                "they",
                "both",
                "have",
                "a",
                "predicate-argument",
                "structure",
                "representation",
                "of",
                "the",
                "meaning",
                "of",
                "the",
                "sentence,",
                "which",
                "gives",
                "them",
                "roughly",
                "equivalent",
                "semantic",
                "depth.",
                "Another",
                "similarity",
                "is",
                "that",
                "the",
                "new",
                "transfer",
                "approach",
                "can",
                "also",
                "combine",
                "lexical",
                "items",
                "from",
                "several",
                "languages",
                "together",
                "into",
                "a",
                "single",
                "transfer",
                "lexicon",
                "entry,",
                "greatly",
                "simplifying",
                "the",
                "task",
                "of",
                "adding",
                "the",
                "mapping",
                "to",
                "a",
                "new",
                "language",
                "#TARGET_REF",
                ".",
                "An",
                "important",
                "remaining",
                "difference",
                "is",
                "that",
                "the",
                "interlingua",
                "approach",
                "would",
                "claim",
                "that",
                "a",
                "single",
                "predicate-argument",
                "structure",
                "can",
                "serve",
                "as",
                "a",
                "common",
                "representation",
                "for",
                "many",
                "languages,",
                "whereas",
                "the",
                "transfer",
                "approach",
                "allows",
                "for",
                "language-specific",
                "predicate-argument",
                "structures..",
                "A",
                "fundamental",
                "assumption",
                "of",
                "either",
                "approach,",
                "and",
                "the",
                "most",
                "important",
                "similarity,",
                "is",
                "that",
                "these",
                "classifications",
                "can",
                "be",
                "made",
                "based",
                "on",
                "distinguished",
                "semantic",
                "features,",
                "and",
                "that",
                "these",
                "semantic",
                "features",
                "will",
                "be",
                "relevant",
                "to",
                "classification",
                "schemes",
                "in",
                "other",
                "languages.",
                "Whether",
                "the",
                "classification",
                "schemes",
                "serve",
                "as",
                "a",
                "means",
                "of",
                "associating",
                "a",
                "single",
                "logical",
                "form",
                "composed",
                "of",
                "semantic",
                "primitives",
                "with",
                "many",
                "lexical",
                "items,",
                "as",
                "in",
                "the",
                "LCS",
                "approach,",
                "or",
                "as",
                "a",
                "means",
                "of",
                "enriching",
                "a",
                "set",
                "of",
                "logical",
                "forms",
                "with",
                "a",
                "collection",
                "of",
                "semantic",
                "features,",
                "the",
                "classifications",
                "still",
                "have",
                "to",
                "be",
                "determined,",
                "and",
                "the",
                "associations",
                "with",
                "semantic",
                "features",
                "have",
                "to",
                "be",
                "made.",
                "The",
                "rest",
                "of",
                "this",
                "paper",
                "discusses",
                "specific",
                "issues",
                "with",
                "respect",
                "to",
                "the",
                "association",
                "of",
                "semantic",
                "features",
                "with",
                "the",
                "classifications",
                "in",
                "English",
                "verbs."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The new lexico-structural transfer approach is more similar to the interlingua approach in that they both have a predicate-argument structure representation of the meaning of the sentence, which gives them roughly equivalent semantic depth. Another similarity is that the new transfer approach can also combine lexical items from several languages together into a single transfer lexicon entry, greatly simplifying the task of adding the mapping to a new language #TARGET_REF . An important remaining difference is that the interlingua approach would claim that a single predicate-argument structure can serve as a common representation for many languages, whereas the transfer approach allows for language-specific predicate-argument structures.. A fundamental assumption of either approach, and the most important similarity, is that these classifications can be made based on distinguished semantic features, and that these semantic features will be relevant to classification schemes in other languages. Whether the classification schemes serve as a means of associating a single logical form composed of semantic primitives with many lexical items, as in the LCS approach, or as a means of enriching a set of logical forms with a collection of semantic features, the classifications still have to be determined, and the associations with semantic features have to be made. The rest of this paper discusses specific issues with respect to the association of semantic features with the classifications in English verbs.",
        "output": "{\"INFORMATION\": [\"the new transfer approach can also combine lexical items from several languages together into a single transfer lexicon entry, greatly simplifying the task of adding the mapping to a new language #TARGET_REF .\"], \"PERCEPTION\": [\"The new lexico-structural transfer approach is more similar to the interlingua approach\", \"Another similarity is that\", \"An important remaining difference is that the interlingua approach would claim that a single predicate-argument structure can serve as a common representation for many languages, whereas the transfer approach allows for language-specific predicate-argument structures..\"], \"BACKGROUND\": [\"A fundamental assumption of either approach, and the most important similarity, is that these classifications can be made based on distinguished semantic features, and that these semantic features will be relevant to classification schemes in other languages.\"]}"
    },
    {
        "gold": {
            "text": [
                "Both",
                "the",
                "encoder",
                "and",
                "decoder",
                "are",
                "six-layer",
                "Transformer",
                "#TARGET_REF",
                ",",
                "the",
                "number",
                "of",
                "heads",
                "of",
                "Multi-Head",
                "Attention",
                "is",
                "8,",
                "the",
                "token",
                "embedding",
                "dimension",
                "is",
                "512,",
                "and",
                "the",
                "ratio",
                "of",
                "Dropout",
                "is",
                "0.1.",
                "Adam",
                "(Kingma",
                "and",
                "Ba,",
                "2015)",
                "was",
                "used",
                "as",
                "the",
                "optimization",
                "method",
                "for",
                "parameters",
                "during",
                "training.",
                "The",
                "learning",
                "rate",
                "of",
                "Adam",
                "was",
                "set",
                "to",
                "0.001.",
                "Hyperparameters",
                "λ,",
                "which",
                "adjust",
                "the",
                "frequency",
                "of",
                "ITF",
                "model",
                "and",
                "INF",
                "model,",
                "were",
                "set",
                "as",
                "0.2,",
                "0.4,",
                "0.6,",
                "or",
                "0.8.",
                "The",
                "INF",
                "model",
                "uses",
                "bi-gram",
                "as",
                "its",
                "n-gram",
                "function."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Both the encoder and decoder are six-layer Transformer #TARGET_REF , the number of heads of Multi-Head Attention is 8, the token embedding dimension is 512, and the ratio of Dropout is 0.1. Adam (Kingma and Ba, 2015) was used as the optimization method for parameters during training. The learning rate of Adam was set to 0.001. Hyperparameters λ, which adjust the frequency of ITF model and INF model, were set as 0.2, 0.4, 0.6, or 0.8. The INF model uses bi-gram as its n-gram function.",
        "output": "{\"INFORMATION\": [\"Both the encoder and decoder are six-layer Transformer #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "RNN-NLU",
                "#TARGET_REF",
                ")",
                "is",
                "an",
                "attention-based",
                "bi-directional",
                "recurrent",
                "neural",
                "network",
                "model",
                "that",
                "jointly",
                "predicts",
                "the",
                "current",
                "slot",
                "and",
                "the",
                "intent",
                "at",
                "each",
                "time",
                "step",
                "using",
                "shared",
                "hidden",
                "states",
                "and",
                "attention."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• RNN-NLU #TARGET_REF ) is an attention-based bi-directional recurrent neural network model that jointly predicts the current slot and the intent at each time step using shared hidden states and attention.",
        "output": "{\"INFORMATION\": [\"RNN-NLU #TARGET_REF ) is an attention-based bi-directional recurrent neural network model that jointly predicts the current slot and the intent at each time step using shared hidden states and attention.\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "For",
                "our",
                "contextual",
                "word",
                "embeddings,",
                "we",
                "use",
                "fastText",
                "embeddings",
                "for",
                "English",
                "#REF",
                "which",
                "are",
                "pretrained",
                "on",
                "common-Crawl",
                "and",
                "the",
                "Wikipedia",
                "corpus.",
                "FastText",
                "embeddings",
                "are",
                "also",
                "used",
                "for",
                "Hindi,",
                "French,",
                "Spanish",
                "and",
                "Italian",
                "word",
                "representations",
                "#TARGET_REF",
                ".",
                "The",
                "bi-LSTM",
                "trains",
                "on",
                "a",
                "fixed",
                "300",
                "hidden",
                "dimensions",
                "for",
                "all",
                "the",
                "bi-LSTMs",
                "in",
                "the",
                "architecture."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For our contextual word embeddings, we use fastText embeddings for English #REF which are pretrained on common-Crawl and the Wikipedia corpus. FastText embeddings are also used for Hindi, French, Spanish and Italian word representations #TARGET_REF . The bi-LSTM trains on a fixed 300 hidden dimensions for all the bi-LSTMs in the architecture.",
        "output": "{\"INFORMATION\": [\"Italian word representations\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"FastText embeddings are also used for Hindi, French, Spanish\"]}"
    },
    {
        "gold": {
            "text": [
                "However,",
                "MMB's",
                "attitude",
                "to",
                "these",
                "primitives",
                "was",
                "very",
                "unlike",
                "that",
                "of",
                "other",
                "peddlers",
                "of",
                "conceptual",
                "primitives",
                "or",
                "languages",
                "of",
                "thought:",
                "at",
                "no",
                "point",
                "did",
                "she",
                "suggest,",
                "in",
                "the",
                "way",
                "that",
                "became",
                "fashionable",
                "later",
                "in",
                "cognitive",
                "science,",
                "that",
                "the",
                "primitive",
                "names",
                "constituted",
                "some",
                "sort",
                "of",
                "language",
                "in",
                "the",
                "mind",
                "or",
                "brain",
                "#TARGET_REF",
                "or",
                "that,",
                "although",
                "they",
                "appeared",
                "to",
                "be",
                "English,",
                "the",
                "primitives",
                "like",
                "'Move'",
                "and",
                "'Do'",
                "were",
                "really",
                "the",
                "names",
                "of",
                "underlying",
                "entities",
                "that",
                "were",
                "not",
                "in",
                "any",
                "particular",
                "language",
                "at",
                "all.",
                "This",
                "kind",
                "of",
                "naive",
                "imperialism",
                "of",
                "English",
                "has",
                "been",
                "the",
                "bane",
                "of",
                "linguistics",
                "for",
                "many",
                "years,",
                "and",
                "shows,",
                "by",
                "contrast,",
                "the",
                "far",
                "greater",
                "sophistication",
                "of",
                "the",
                "structuralism",
                "that",
                "preceded",
                "it."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "However, MMB's attitude to these primitives was very unlike that of other peddlers of conceptual primitives or languages of thought: at no point did she suggest, in the way that became fashionable later in cognitive science, that the primitive names constituted some sort of language in the mind or brain #TARGET_REF or that, although they appeared to be English, the primitives like 'Move' and 'Do' were really the names of underlying entities that were not in any particular language at all. This kind of naive imperialism of English has been the bane of linguistics for many years, and shows, by contrast, the far greater sophistication of the structuralism that preceded it.",
        "output": "{\"INFORMATION\": [\"brain #TARGET_REF\"], \"PERCEPTION\": [\"although they appeared to be English, the primitives like 'Move' and 'Do' were really the names of underlying entities that were not in any particular language at all.\"], \"BACKGROUND\": [\"MMB's attitude to these primitives was very unlike that of other peddlers of conceptual primitives or languages of thought: at no point did she suggest, in the way that became fashionable later in cognitive science, that the primitive names constituted some sort of language in the mind or\", \"or that,\"]}"
    },
    {
        "gold": {
            "text": [
                "the",
                "32",
                "configurations",
                "detailed",
                "above.",
                "This",
                "results",
                "in",
                "1304",
                "distinct",
                "clues",
                "in",
                "English,",
                "and",
                "1399",
                "in",
                "Hungarian.",
                "For",
                "evaluation,",
                "we",
                "create",
                "an",
                "online",
                "game,",
                "where",
                "human",
                "players",
                "get",
                "a",
                "board",
                "with",
                "one",
                "of",
                "the",
                "corresponding",
                "clues",
                "randomly,",
                "and",
                "have",
                "to",
                "choose",
                "the",
                "given",
                "number",
                "of",
                "words",
                "from",
                "the",
                "board",
                "which",
                "they",
                "think",
                "the",
                "clue",
                "refers",
                "to.",
                "The",
                "players",
                "do",
                "not",
                "know",
                "how",
                "the",
                "agents",
                "work,",
                "and",
                "to",
                "avoid",
                "that",
                "through",
                "the",
                "game",
                "they",
                "learn",
                "it",
                "at",
                "the",
                "end",
                "of",
                "the",
                "round",
                "they",
                "only",
                "see",
                "the",
                "color",
                "of",
                "their",
                "chosen",
                "words.",
                "We",
                "collected",
                "443",
                "rounds",
                "played",
                "in",
                "English,",
                "and",
                "1365",
                "in",
                "Hungarian.",
                "This",
                "way,",
                "we",
                "have",
                "31.5",
                "rounds",
                "on",
                "average",
                "to",
                "evaluate",
                "English",
                "configurations,",
                "and",
                "64",
                "rounds",
                "for",
                "Hungarian.",
                "For",
                "one",
                "board,",
                "players",
                "on",
                "average",
                "spent",
                "39",
                "seconds",
                "on",
                "guessing",
                "in",
                "English,",
                "while",
                "37",
                "seconds",
                "in",
                "Hungarian.",
                "We",
                "note",
                "that",
                "the",
                "players",
                "of",
                "the",
                "Hungarian",
                "game",
                "were",
                "most",
                "likely",
                "Hungarian",
                "native",
                "speakers,",
                "while",
                "the",
                "same",
                "cannot",
                "be",
                "said",
                "about",
                "the",
                "English",
                "game,",
                "therefore",
                "we",
                "consider",
                "the",
                "Hungarian",
                "data",
                "more",
                "reliable.",
                "Similar",
                "to",
                "#TARGET_REF",
                ",",
                "we",
                "compute",
                "the",
                "precision",
                "of",
                "the",
                "agents",
                "asP@targets",
                "=",
                "|I",
                "n",
                "∩",
                "U",
                "|",
                "n",
                ",where",
                "I",
                "n",
                "is",
                "the",
                "set",
                "of",
                "the",
                "targeted",
                "words,",
                "and",
                "U",
                "is",
                "the",
                "set",
                "of",
                "words",
                "chosen",
                "by",
                "the",
                "players.",
                "However,",
                "the",
                "scoring",
                "functions",
                "optimize",
                "clue",
                "words",
                "to",
                "stay",
                "away",
                "from",
                "red",
                "words,",
                "but",
                "not",
                "from",
                "non-targeted",
                "blue",
                "words,",
                "which",
                "might",
                "be",
                "almost",
                "as",
                "related",
                "to",
                "the",
                "clue",
                "as",
                "the",
                "targeted",
                "ones.",
                "If",
                "the",
                "user",
                "chooses",
                "such",
                "an",
                "untargeted",
                "word,",
                "the",
                "agent",
                "still",
                "performs",
                "well.",
                "So",
                "we",
                "define",
                "P@all,P@all",
                "=",
                "|A",
                "∩",
                "U",
                "|",
                "n",
                ",where",
                "A",
                "is",
                "the",
                "set",
                "of",
                "all",
                "good",
                "(blue)",
                "words.",
                "In",
                "Table",
                "3",
                "and",
                "Table",
                "4,",
                "we",
                "show",
                "the",
                "mean",
                "precision",
                "of",
                "the",
                "players'",
                "guesses",
                "on",
                "the",
                "clues",
                "of",
                "each",
                "agent."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "the 32 configurations detailed above. This results in 1304 distinct clues in English, and 1399 in Hungarian. For evaluation, we create an online game, where human players get a board with one of the corresponding clues randomly, and have to choose the given number of words from the board which they think the clue refers to. The players do not know how the agents work, and to avoid that through the game they learn it at the end of the round they only see the color of their chosen words. We collected 443 rounds played in English, and 1365 in Hungarian. This way, we have 31.5 rounds on average to evaluate English configurations, and 64 rounds for Hungarian. For one board, players on average spent 39 seconds on guessing in English, while 37 seconds in Hungarian. We note that the players of the Hungarian game were most likely Hungarian native speakers, while the same cannot be said about the English game, therefore we consider the Hungarian data more reliable. Similar to #TARGET_REF , we compute the precision of the agents asP@targets = |I n ∩ U | n ,where I n is the set of the targeted words, and U is the set of words chosen by the players. However, the scoring functions optimize clue words to stay away from red words, but not from non-targeted blue words, which might be almost as related to the clue as the targeted ones. If the user chooses such an untargeted word, the agent still performs well. So we define P@all,P@all = |A ∩ U | n ,where A is the set of all good (blue) words. In Table 3 and Table 4, we show the mean precision of the players' guesses on the clues of each agent.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF ,\"], \"PERCEPTION\": [\"Similar to\", \"we compute the precision of the agents asP@targets = |I n \\u2229 U | n ,where I n is the set of the targeted words, and U is the set of words chosen by the players.\"], \"BACKGROUND\": [\"However, the scoring functions optimize clue words to stay away from red words, but not from non-targeted blue words, which might be almost as related to the clue as the targeted ones.\"]}"
    },
    {
        "gold": {
            "text": [
                "An",
                "important",
                "desideratum",
                "of",
                "natural",
                "language",
                "generation",
                "(NLG)",
                "is",
                "to",
                "produce",
                "outputs",
                "that",
                "are",
                "not",
                "only",
                "correct",
                "but",
                "also",
                "diverse",
                "#REF",
                ".",
                "The",
                "term",
                "\"diversity\"",
                "in",
                "NLG",
                "is",
                "defined",
                "as",
                "the",
                "ability",
                "of",
                "a",
                "generative",
                "model",
                "to",
                "create",
                "a",
                "set",
                "of",
                "possible",
                "outputs",
                "that",
                "are",
                "each",
                "valid",
                "given",
                "the",
                "input",
                "and",
                "vary",
                "as",
                "widely",
                "as",
                "possible",
                "in",
                "terms",
                "of",
                "content,",
                "language",
                "style,",
                "and",
                "word",
                "variability",
                "#REF",
                ".",
                "This",
                "research",
                "problem",
                "is",
                "also",
                "referred",
                "as",
                "one-to-many",
                "generation",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1
            ]
        },
        "input": "An important desideratum of natural language generation (NLG) is to produce outputs that are not only correct but also diverse #REF . The term \"diversity\" in NLG is defined as the ability of a generative model to create a set of possible outputs that are each valid given the input and vary as widely as possible in terms of content, language style, and word variability #REF . This research problem is also referred as one-to-many generation #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"one-to-many generation #TARGET_REF .\"], \"PERCEPTION\": [\"This research problem is also referred as\"], \"BACKGROUND\": [\"The term \\\"diversity\\\" in NLG is defined as the ability of a generative model to create a set of possible outputs that are each valid given the input and vary as widely as possible in terms of content, language style, and word variability #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "investigate",
                "what",
                "logical",
                "mechanisms",
                "govern",
                "argumentative",
                "relations,",
                "we",
                "hypothesize",
                "that",
                "governing",
                "mechanisms",
                "should",
                "be",
                "able",
                "to",
                "classify",
                "the",
                "relations",
                "without",
                "directly",
                "training",
                "on",
                "relationlabeled",
                "data.",
                "Thus,",
                "we",
                "first",
                "compile",
                "a",
                "set",
                "of",
                "rules",
                "specifying",
                "logical",
                "and",
                "theory-informed",
                "mechanisms",
                "that",
                "signal",
                "the",
                "support",
                "and",
                "attack",
                "relations",
                "(",
                "§3).",
                "The",
                "rules",
                "are",
                "grouped",
                "into",
                "four",
                "mechanisms:",
                "factual",
                "consistency,",
                "sentiment",
                "coherence,",
                "causal",
                "relation,",
                "and",
                "normative",
                "relation.",
                "These",
                "rules",
                "are",
                "combined",
                "via",
                "probabilistic",
                "soft",
                "logic",
                "(PSL)",
                "#TARGET_REF",
                "to",
                "estimate",
                "the",
                "optimal",
                "argumentative",
                "relations",
                "between",
                "statements.",
                "We",
                "operationalize",
                "each",
                "mechanism",
                "by",
                "training",
                "semantic",
                "modules",
                "on",
                "public",
                "datasets",
                "so",
                "that",
                "the",
                "modules",
                "reflect",
                "real-world",
                "knowledge",
                "necessary",
                "for",
                "reasoning",
                "(",
                "§4).",
                "For",
                "normative",
                "relation,",
                "we",
                "build",
                "a",
                "necessary",
                "dataset",
                "via",
                "rich",
                "annotation",
                "of",
                "the",
                "normative",
                "argumentation",
                "schemes",
                "argument",
                "from",
                "consequences",
                "and",
                "practical",
                "reasoning",
                "#REF",
                ",",
                "by",
                "developing",
                "a",
                "novel",
                "and",
                "reliable",
                "annotation",
                "protocol",
                "(",
                "§5)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To investigate what logical mechanisms govern argumentative relations, we hypothesize that governing mechanisms should be able to classify the relations without directly training on relationlabeled data. Thus, we first compile a set of rules specifying logical and theory-informed mechanisms that signal the support and attack relations ( §3). The rules are grouped into four mechanisms: factual consistency, sentiment coherence, causal relation, and normative relation. These rules are combined via probabilistic soft logic (PSL) #TARGET_REF to estimate the optimal argumentative relations between statements. We operationalize each mechanism by training semantic modules on public datasets so that the modules reflect real-world knowledge necessary for reasoning ( §4). For normative relation, we build a necessary dataset via rich annotation of the normative argumentation schemes argument from consequences and practical reasoning #REF , by developing a novel and reliable annotation protocol ( §5).",
        "output": "{\"INFORMATION\": [\"probabilistic soft logic (PSL) #TARGET_REF\"], \"PERCEPTION\": [\"These rules are combined via\", \"to estimate the optimal argumentative relations between statements.\"], \"BACKGROUND\": [\"The rules are grouped into four mechanisms:\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "term",
                "toxic",
                "comment",
                "is",
                "commonly",
                "found",
                "in",
                "literature",
                "as",
                "harmful",
                "speech,",
                "hate",
                "speech,",
                "or",
                "offensive",
                "language.",
                "Toxic",
                "comment",
                "may",
                "be",
                "viewed",
                "as",
                "negative",
                "online",
                "behaviors,",
                "i.e.,",
                "comments",
                "that",
                "are",
                "rude,",
                "disrespectful,",
                "may",
                "contain",
                "hate",
                "speech,",
                "or",
                "otherwise",
                "likely",
                "to",
                "make",
                "someone",
                "leave",
                "a",
                "discussion",
                "1",
                ".",
                "#TARGET_REF",
                "define",
                "hate",
                "speech",
                "as",
                "any",
                "communication",
                "that",
                "disparages",
                "a",
                "person",
                "or",
                "a",
                "group",
                "based",
                "on",
                "some",
                "characteristic",
                "such",
                "as",
                "race,",
                "color,",
                "ethnicity,",
                "gender,",
                "sexual",
                "orientation,",
                "nationality,",
                "religion,",
                "or",
                "other",
                "characteristics.",
                "Also,",
                "it",
                "may",
                "occur",
                "with",
                "different",
                "linguistic",
                "styles,",
                "even",
                "in",
                "subtle",
                "forms",
                "or",
                "when",
                "humour",
                "is",
                "used",
                "#REF",
                ".",
                "It",
                "is",
                "important",
                "to",
                "highlight",
                "that",
                "fighting",
                "these",
                "types",
                "of",
                "comments",
                "is",
                "of",
                "utmost",
                "importance",
                "since",
                "they",
                "are",
                "a",
                "crime",
                "in",
                "several",
                "countries."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The term toxic comment is commonly found in literature as harmful speech, hate speech, or offensive language. Toxic comment may be viewed as negative online behaviors, i.e., comments that are rude, disrespectful, may contain hate speech, or otherwise likely to make someone leave a discussion 1 . #TARGET_REF define hate speech as any communication that disparages a person or a group based on some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics. Also, it may occur with different linguistic styles, even in subtle forms or when humour is used #REF . It is important to highlight that fighting these types of comments is of utmost importance since they are a crime in several countries.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF define hate speech as any communication that disparages a person or a group based on some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics.\"], \"PERCEPTION\": [\"It is important to highlight that fighting these types of comments is of utmost importance since they are a crime in several countries.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "the",
                "BERT",
                "model",
                "#TARGET_REF",
                ","
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "• the BERT model #TARGET_REF ,",
        "output": "{\"INFORMATION\": [\"the BERT model #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Generalisability",
                "While",
                "we",
                "have",
                "established",
                "methods",
                "for",
                "measuring",
                "and",
                "mitigating",
                "binary",
                "gender",
                "bias,",
                "we",
                "have",
                "not",
                "achieved",
                "the",
                "same",
                "for",
                "nonbinary",
                "genders",
                "nor",
                "for",
                "any",
                "other",
                "protected",
                "characteristics",
                "defined",
                "in",
                "the",
                "Equality",
                "Act",
                "2010",
                "#TARGET_REF",
                ".",
                "Practitioners",
                "tackling",
                "more",
                "varied",
                "presentations",
                "of",
                "identity-directed",
                "bias",
                "may",
                "be",
                "less",
                "able",
                "to",
                "find",
                "pre-existing",
                "lists",
                "of",
                "biased",
                "words",
                "to",
                "define",
                "bias",
                "measurements."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Generalisability While we have established methods for measuring and mitigating binary gender bias, we have not achieved the same for nonbinary genders nor for any other protected characteristics defined in the Equality Act 2010 #TARGET_REF . Practitioners tackling more varied presentations of identity-directed bias may be less able to find pre-existing lists of biased words to define bias measurements.",
        "output": "{\"INFORMATION\": [\"the Equality Act 2010 #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Generalisability While we have established methods for measuring and mitigating binary gender bias, we have not achieved the same for nonbinary genders nor for any other protected characteristics defined in\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "alleviate",
                "the",
                "issue,",
                "we",
                "add",
                "a",
                "special",
                "tag",
                "for",
                "the",
                "BT",
                "data",
                "#TARGET_REF",
                ".",
                "With",
                "BT[t],",
                "we",
                "send",
                "a",
                "signal",
                "to",
                "the",
                "model",
                "that",
                "it",
                "is",
                "processing",
                "synthetic",
                "data,",
                "and",
                "thus,",
                "it",
                "may",
                "not",
                "hurt",
                "the",
                "learning",
                "over",
                "the",
                "real",
                "data.",
                "Table",
                "2",
                "(rows",
                "(c,g))",
                "shows",
                "the",
                "results."
            ],
            "context": [
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To alleviate the issue, we add a special tag for the BT data #TARGET_REF . With BT[t], we send a signal to the model that it is processing synthetic data, and thus, it may not hurt the learning over the real data. Table 2 (rows (c,g)) shows the results.",
        "output": "{\"INFORMATION\": [\"BT data #TARGET_REF .\"], \"PERCEPTION\": [\"we add a special tag for the\", \"we send a signal to the model that it is processing synthetic data, and thus, it may not hurt the learning over the real data.\"], \"BACKGROUND\": [\"To alleviate the issue,\", \"With BT[t],\"]}"
    },
    {
        "gold": {
            "text": [
                "Although",
                "first",
                "suggested",
                "by",
                "Kay",
                "#REF",
                ",",
                "the",
                "alternative",
                "idea",
                "of",
                "an",
                "MT",
                "system",
                "for",
                "a",
                "monolingual",
                "user",
                "seems",
                "only",
                "to",
                "have",
                "really",
                "been",
                "followed",
                "up",
                "about",
                "five",
                "years",
                "ago,",
                "when",
                "several",
                "proposals",
                "for",
                "interactive",
                "MT",
                "for",
                "monolingual",
                "users",
                "were",
                "apparently",
                "initiated",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                0,
                0
            ]
        },
        "input": "Although first suggested by Kay #REF , the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when several proposals for interactive MT for monolingual users were apparently initiated #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"several proposals for interactive MT for monolingual users\"], \"PERCEPTION\": [\"the alternative idea of an MT system for a monolingual user seems only to have really been followed up about five years ago, when\", \"were apparently initiated\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "There",
                "have",
                "been",
                "great",
                "advances",
                "in",
                "argument",
                "mining-classifying",
                "the",
                "argumentative",
                "relation",
                "between",
                "statements",
                "as",
                "support,",
                "attack,",
                "or",
                "neutral.",
                "Recent",
                "research",
                "has",
                "focused",
                "on",
                "training",
                "complex",
                "neural",
                "networks",
                "on",
                "large",
                "labeled",
                "data.",
                "However,",
                "the",
                "behavior",
                "of",
                "such",
                "models",
                "remains",
                "obscure,",
                "and",
                "recent",
                "studies",
                "found",
                "evidence",
                "that",
                "those",
                "models",
                "may",
                "rely",
                "on",
                "spurious",
                "statistics",
                "of",
                "training",
                "data",
                "#TARGET_REF",
                "and",
                "superficial",
                "cues",
                "irrelevant",
                "to",
                "the",
                "meaning",
                "of",
                "statements,",
                "such",
                "as",
                "discourse",
                "markers",
                "#REF",
                ".",
                "Hence,",
                "in",
                "this",
                "work,",
                "we",
                "turn",
                "to",
                "an",
                "interpretable",
                "method",
                "to",
                "investigate",
                "logical",
                "relations",
                "between",
                "statements,",
                "such",
                "as",
                "causal",
                "relations",
                "and",
                "factual",
                "contradiction.",
                "Such",
                "relations",
                "have",
                "been",
                "underemphasized",
                "in",
                "earlier",
                "studies",
                "#REF",
                ",",
                "possibly",
                "because",
                "their",
                "operationalization",
                "was",
                "unreliable",
                "then.",
                "Now",
                "that",
                "computational",
                "semantics",
                "is",
                "fast",
                "developing,",
                "our",
                "work",
                "takes",
                "a",
                "first",
                "step",
                "to",
                "computationally",
                "investigate",
                "how",
                "logical",
                "mechanisms",
                "contribute",
                "to",
                "building",
                "argumentative",
                "relations",
                "between",
                "statements",
                "and",
                "to",
                "classification",
                "accuracy",
                "with",
                "and",
                "without",
                "training",
                "on",
                "labeled",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There have been great advances in argument mining-classifying the argumentative relation between statements as support, attack, or neutral. Recent research has focused on training complex neural networks on large labeled data. However, the behavior of such models remains obscure, and recent studies found evidence that those models may rely on spurious statistics of training data #TARGET_REF and superficial cues irrelevant to the meaning of statements, such as discourse markers #REF . Hence, in this work, we turn to an interpretable method to investigate logical relations between statements, such as causal relations and factual contradiction. Such relations have been underemphasized in earlier studies #REF , possibly because their operationalization was unreliable then. Now that computational semantics is fast developing, our work takes a first step to computationally investigate how logical mechanisms contribute to building argumentative relations between statements and to classification accuracy with and without training on labeled data.",
        "output": "{\"INFORMATION\": [\"those models may rely on spurious statistics of training data #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Recent research has focused on training complex neural networks on large labeled data. However, the behavior of such models remains obscure, and recent studies found evidence that\", \"and superficial cues irrelevant to the meaning of statements, such as discourse markers #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Encoding:",
                "All",
                "the",
                "information",
                "explicitly",
                "represented",
                "in",
                "the",
                "source",
                "texts",
                "is",
                "encoded",
                "following",
                "essentially",
                "the",
                "CES",
                "(Corpus",
                "Encoding",
                "Standard)",
                "designed",
                "by",
                "EAGLES,",
                "on",
                "the",
                "basis",
                "of",
                "the",
                "Text",
                "Encoding",
                "Initiative",
                "(TEI)",
                "guidelines",
                "#REF",
                ".",
                "250,000",
                "running",
                "words",
                "are",
                "tagged",
                "at",
                "the",
                "morphosyntactic",
                "level,",
                "following",
                "the",
                "EAGLES",
                "guidelines",
                "#TARGET_REF",
                ",",
                "instantiated",
                "by",
                "each",
                "PAROLE",
                "partner",
                "for",
                "his",
                "own",
                "language."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Encoding: All the information explicitly represented in the source texts is encoded following essentially the CES (Corpus Encoding Standard) designed by EAGLES, on the basis of the Text Encoding Initiative (TEI) guidelines #REF . 250,000 running words are tagged at the morphosyntactic level, following the EAGLES guidelines #TARGET_REF , instantiated by each PAROLE partner for his own language.",
        "output": "{\"INFORMATION\": [\"EAGLES guidelines #TARGET_REF ,\"], \"PERCEPTION\": [\"250,000 running words are tagged at the morphosyntactic level, following the\", \"instantiated by each PAROLE partner for his own language.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "illustrate",
                "the",
                "same",
                "point,",
                "#TARGET_REF",
                "carried",
                "out",
                "a",
                "comparison",
                "between",
                "the",
                "vocabulary",
                "found",
                "in",
                "a",
                "college",
                "dictionary",
                "(Webster's",
                "7th)",
                "and",
                "a",
                "text",
                "corpus",
                "(New",
                "York",
                "Times",
                "News",
                "Service)",
                "and",
                "noted",
                "that",
                "the",
                "overlap",
                "was",
                "only",
                "23%",
                "of",
                "the",
                "total",
                "vocabulary",
                "in",
                "either",
                "source.",
                "Three",
                "quarters",
                "of",
                "the",
                "41%",
                "which",
                "only",
                "occurred",
                "in",
                "the",
                "corpus",
                "could",
                "be",
                "accounted",
                "for",
                "in",
                "terms",
                "of",
                "inflection,",
                "hyphenation",
                "at",
                "the",
                "end",
                "of",
                "a",
                "line,",
                "proper",
                "nouns,",
                "and",
                "obvious",
                "misspellings.",
                "Assuming",
                "that",
                "inflection",
                "is",
                "accounted",
                "for",
                "by",
                "a",
                "rule",
                "system,",
                "hyphenation",
                "is",
                "covered",
                "in",
                "a",
                "trivial",
                "pre-processing",
                "step,",
                "and",
                "misspellings",
                "are",
                "treated",
                "separately,",
                "proper",
                "nouns",
                "constitute",
                "an",
                "important",
                "source",
                "of",
                "incompleteness.",
                "What",
                "happens",
                "with",
                "the",
                "remaining",
                "quarter?",
                "Amsler",
                "states",
                "that",
                "these",
                "cases",
                "cannot",
                "be",
                "classified",
                "without",
                "individual",
                "inspection."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To illustrate the same point, #TARGET_REF carried out a comparison between the vocabulary found in a college dictionary (Webster's 7th) and a text corpus (New York Times News Service) and noted that the overlap was only 23% of the total vocabulary in either source. Three quarters of the 41% which only occurred in the corpus could be accounted for in terms of inflection, hyphenation at the end of a line, proper nouns, and obvious misspellings. Assuming that inflection is accounted for by a rule system, hyphenation is covered in a trivial pre-processing step, and misspellings are treated separately, proper nouns constitute an important source of incompleteness. What happens with the remaining quarter? Amsler states that these cases cannot be classified without individual inspection.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF carried out a comparison between the vocabulary found in a college dictionary (Webster's 7th) and a text corpus (New York Times News Service) and noted that the overlap was only 23% of the total vocabulary in either source.\"], \"PERCEPTION\": [\"To illustrate the same point,\"], \"BACKGROUND\": [\"Three quarters of the 41% which only occurred in the corpus could be accounted for in terms of inflection, hyphenation at the end of a line, proper nouns, and obvious misspellings.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "performed",
                "decoding",
                "based",
                "on",
                "(i)",
                "EEG",
                "for",
                "single-trials",
                "(i.e.",
                "no",
                "averaging),",
                "(ii)",
                "EEG",
                "averaged",
                "across",
                "three",
                "and",
                "(iii)",
                "ten",
                "trials.",
                "Averaging",
                "EEG",
                "signals",
                "across",
                "trials",
                "increases",
                "the",
                "signal",
                "to",
                "noise",
                "ratio",
                "of",
                "the",
                "'samples'",
                "#REF",
                ",",
                "but",
                "ignores",
                "true",
                "variability",
                "across",
                "EEG",
                "data",
                "from",
                "different",
                "words",
                "of",
                "the",
                "same",
                "category",
                "#TARGET_REF",
                ".",
                "For",
                "training",
                "(resp.",
                "dev)",
                "set",
                "we",
                "generated",
                "the",
                "same",
                "number",
                "of",
                "samples",
                "for",
                "3",
                "and",
                "10",
                "trial",
                "averages",
                "as",
                "for",
                "the",
                "single",
                "trial",
                "test",
                "(resp.",
                "dev)",
                "sets",
                "via",
                "boostrapping.",
                "For",
                "the",
                "test",
                "set,",
                "we",
                "averaged",
                "data",
                "without",
                "replacement,",
                "so",
                "that",
                "examples",
                "can",
                "be",
                "entered",
                "as",
                "independent",
                "data",
                "points",
                "in",
                "statistical",
                "tests.",
                "Hence,",
                "the",
                "number",
                "of",
                "samples",
                "in",
                "the",
                "test",
                "set",
                "(but",
                "not",
                "in",
                "the",
                "training",
                "or",
                "dev",
                "sets)",
                "is",
                "smaller",
                "for",
                "3",
                "and",
                "10",
                "trial",
                "averages",
                "than",
                "single",
                "trials",
                "(Table",
                "3)."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We performed decoding based on (i) EEG for single-trials (i.e. no averaging), (ii) EEG averaged across three and (iii) ten trials. Averaging EEG signals across trials increases the signal to noise ratio of the 'samples' #REF , but ignores true variability across EEG data from different words of the same category #TARGET_REF . For training (resp. dev) set we generated the same number of samples for 3 and 10 trial averages as for the single trial test (resp. dev) sets via boostrapping. For the test set, we averaged data without replacement, so that examples can be entered as independent data points in statistical tests. Hence, the number of samples in the test set (but not in the training or dev sets) is smaller for 3 and 10 trial averages than single trials (Table 3).",
        "output": "{\"INFORMATION\": [\"different words of the same category #TARGET_REF\"], \"PERCEPTION\": [\"We performed decoding based on\"], \"BACKGROUND\": [\"(i) EEG for single-trials (i.e. no averaging), (ii) EEG averaged across three and (iii) ten trials. Averaging EEG signals across trials increases the signal to noise ratio of the 'samples' #REF , but ignores true variability across EEG data from\"]}"
    },
    {
        "gold": {
            "text": [
                "With",
                "the",
                "regularization",
                "values,",
                "we",
                "fed",
                "several",
                "machine",
                "learning",
                "algorithms",
                "to",
                "identify",
                "and",
                "predict",
                "toxic",
                "comments.",
                "We",
                "experimented",
                "Multi",
                "Layer",
                "Perceptron,",
                "Naïve",
                "Bayes,",
                "Decision",
                "Tree,",
                "Support",
                "Vector",
                "Machine,",
                "and",
                "Gradient",
                "Boosting",
                "from",
                "the",
                "Scikit-Learn",
                "library",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "With the regularization values, we fed several machine learning algorithms to identify and predict toxic comments. We experimented Multi Layer Perceptron, Naïve Bayes, Decision Tree, Support Vector Machine, and Gradient Boosting from the Scikit-Learn library #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"the Scikit-Learn library #TARGET_REF .\"], \"PERCEPTION\": [\"We experimented Multi Layer Perceptron, Na\\u00efve Bayes, Decision Tree, Support Vector Machine, and Gradient Boosting from\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "create",
                "entity",
                "representations",
                "of",
                "a",
                "mention",
                "span",
                "m",
                "and",
                "a",
                "context",
                "s",
                "using",
                "ELMo",
                "#REF",
                "and",
                "BERT",
                "#TARGET_REF",
                ".",
                "We",
                "largely",
                "follow",
                "the",
                "embedding",
                "procedure",
                "of",
                "#REF",
                ".",
                "Their",
                "downstream",
                "models",
                "use",
                "trainable",
                "weights",
                "to",
                "combine",
                "the",
                "vectors",
                "from",
                "the",
                "pre-trained",
                "model",
                "layers,",
                "we",
                "use",
                "this",
                "in",
                "the",
                "baselines",
                "as",
                "well",
                "except",
                "for",
                "the",
                "results",
                "in",
                "Table",
                "4",
                "and",
                "for",
                "ELMo.",
                "Note",
                "that",
                "we",
                "do",
                "not",
                "fine",
                "tune",
                "the",
                "ELMo",
                "and",
                "BERT",
                "parameters",
                "of",
                "the",
                "baselines,",
                "since",
                "our",
                "focus",
                "is",
                "on",
                "general",
                "entity",
                "representations",
                "that",
                "can",
                "work",
                "off-the-shelf",
                "rather",
                "than",
                "task",
                "specific",
                "entity",
                "representations.",
                "Our",
                "approach",
                "does",
                "not",
                "use",
                "task",
                "specific",
                "fine",
                "tuning",
                "either.",
                "ELMO",
                "We",
                "run",
                "ELMo",
                "on",
                "the",
                "entire",
                "sentence",
                "s",
                "and",
                "combine",
                "the",
                "three",
                "layer",
                "outputs",
                "using",
                "uniform",
                "weights.",
                "Then,",
                "we",
                "average",
                "contextualized",
                "vectors",
                "of",
                "the",
                "mention",
                "span",
                "m",
                "to",
                "obtain",
                "the",
                "entity",
                "representation."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We create entity representations of a mention span m and a context s using ELMo #REF and BERT #TARGET_REF . We largely follow the embedding procedure of #REF . Their downstream models use trainable weights to combine the vectors from the pre-trained model layers, we use this in the baselines as well except for the results in Table 4 and for ELMo. Note that we do not fine tune the ELMo and BERT parameters of the baselines, since our focus is on general entity representations that can work off-the-shelf rather than task specific entity representations. Our approach does not use task specific fine tuning either. ELMO We run ELMo on the entire sentence s and combine the three layer outputs using uniform weights. Then, we average contextualized vectors of the mention span m to obtain the entity representation.",
        "output": "{\"INFORMATION\": [\"BERT #TARGET_REF .\"], \"PERCEPTION\": [\"We create entity representations of a mention span m and a context s using\", \"Note that we do not fine tune the ELMo and BERT parameters of the baselines, since our focus is on general entity representations that can work off-the-shelf rather than task specific entity representations.\"], \"BACKGROUND\": [\"ELMo #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "has",
                "been",
                "active",
                "research",
                "in",
                "NLP",
                "to",
                "understand",
                "different",
                "mechanisms",
                "of",
                "argumentation",
                "computationally.",
                "Argumentative",
                "relations",
                "have",
                "been",
                "found",
                "to",
                "be",
                "associated",
                "with",
                "various",
                "statistics,",
                "such",
                "as",
                "discourse",
                "markers",
                "#REF",
                ",",
                "sentiment",
                "#REF",
                ",",
                "and",
                "use",
                "of",
                "negating",
                "words",
                "#REF",
                ".",
                "Further,",
                "as",
                "framing",
                "plays",
                "an",
                "important",
                "role",
                "in",
                "debates",
                "#TARGET_REF",
                ",",
                "different",
                "stances",
                "for",
                "a",
                "topic",
                "emphasize",
                "different",
                "points,",
                "resulting",
                "in",
                "strong",
                "thematic",
                "correlations",
                "#REF",
                ".",
                "Such",
                "thematic",
                "associations",
                "have",
                "been",
                "exploited",
                "in",
                "stance",
                "detection",
                "and",
                "dis/agreement",
                "classification.",
                "Stance",
                "detection",
                "#REF",
                "aims",
                "to",
                "classify",
                "a",
                "statement",
                "as",
                "pro",
                "or",
                "con",
                "with",
                "respect",
                "to",
                "a",
                "topic,",
                "while",
                "dis/agreement",
                "classification",
                "#REF",
                "aims",
                "to",
                "decide",
                "whether",
                "two",
                "statements",
                "are",
                "from",
                "the",
                "same",
                "or",
                "opposite",
                "stance(s)",
                "for",
                "a",
                "given",
                "topic.",
                "Topics",
                "are",
                "usually",
                "discrete,",
                "and",
                "models",
                "often",
                "learn",
                "thematic",
                "correlations",
                "between",
                "a",
                "topic",
                "and",
                "a",
                "stance",
                "#REF",
                ".",
                "Our",
                "work",
                "is",
                "slightly",
                "different",
                "as",
                "we",
                "classify",
                "the",
                "direct",
                "support",
                "or",
                "attack",
                "relation",
                "between",
                "two",
                "natural",
                "statements."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There has been active research in NLP to understand different mechanisms of argumentation computationally. Argumentative relations have been found to be associated with various statistics, such as discourse markers #REF , sentiment #REF , and use of negating words #REF . Further, as framing plays an important role in debates #TARGET_REF , different stances for a topic emphasize different points, resulting in strong thematic correlations #REF . Such thematic associations have been exploited in stance detection and dis/agreement classification. Stance detection #REF aims to classify a statement as pro or con with respect to a topic, while dis/agreement classification #REF aims to decide whether two statements are from the same or opposite stance(s) for a given topic. Topics are usually discrete, and models often learn thematic correlations between a topic and a stance #REF . Our work is slightly different as we classify the direct support or attack relation between two natural statements.",
        "output": "{\"INFORMATION\": [\"Further, as framing plays an important role in debates #TARGET_REF , different stances for a topic emphasize different points, resulting in strong thematic correlations #REF\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Memory-based",
                "MT",
                "is",
                "an",
                "idea",
                "of",
                "viewing",
                "MT",
                "as",
                "a",
                "memory",
                "activity.",
                "For",
                "example,",
                "parsing",
                "is",
                "considered",
                "as",
                "a",
                "memory-search",
                "process",
                "which",
                "identifies",
                "similar",
                "cases",
                "in",
                "the",
                "past",
                "from",
                "the",
                "memory,",
                "and",
                "to",
                "provide",
                "interpretation",
                "based",
                "on",
                "the",
                "identified",
                "case.",
                "It",
                "can",
                "be",
                "considered",
                "as",
                "an",
                "application",
                "of",
                "Memory-Based",
                "Reasoning",
                "(MBR)",
                "#REF",
                "and",
                "Case-Based",
                "Reasoning",
                "(CBR)",
                "#TARGET_REF",
                "to",
                "NLP.",
                "This",
                "view,",
                "however,",
                "counters",
                "to",
                "traditional",
                "idea",
                "to",
                "view",
                "NLP",
                "as",
                "an",
                "extensive",
                "rule",
                "application",
                "process",
                "to",
                "build",
                "up",
                "meaning",
                "representation.",
                "Some",
                "models",
                "has",
                "been",
                "proposed",
                "in",
                "this",
                "direction,",
                "such",
                "as",
                "Direct",
                "Memory",
                "Access",
                "Parsing",
                "(DMAP)",
                "#REF",
                "and",
                "ΦDMDIALOG",
                "#REF",
                ".",
                "Independently,",
                "the",
                "idea",
                "of",
                "using",
                "examples",
                "for",
                "translation",
                "has",
                "been",
                "proposed",
                "by",
                "#REF",
                ",",
                "and",
                "some",
                "experimental",
                "results",
                "has",
                "been",
                "reported",
                "recently",
                "#REF",
                "and",
                "#REF",
                ".",
                "Recently,",
                "such",
                "an",
                "approach",
                "is",
                "gaining",
                "increasing",
                "attention",
                "due",
                "to",
                "the",
                "problems",
                "in",
                "the",
                "traditional",
                "machine",
                "translation",
                "approach:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Memory-based MT is an idea of viewing MT as a memory activity. For example, parsing is considered as a memory-search process which identifies similar cases in the past from the memory, and to provide interpretation based on the identified case. It can be considered as an application of Memory-Based Reasoning (MBR) #REF and Case-Based Reasoning (CBR) #TARGET_REF to NLP. This view, however, counters to traditional idea to view NLP as an extensive rule application process to build up meaning representation. Some models has been proposed in this direction, such as Direct Memory Access Parsing (DMAP) #REF and ΦDMDIALOG #REF . Independently, the idea of using examples for translation has been proposed by #REF , and some experimental results has been reported recently #REF and #REF . Recently, such an approach is gaining increasing attention due to the problems in the traditional machine translation approach:",
        "output": "{\"INFORMATION\": [\"Case-Based Reasoning (CBR) #TARGET_REF\"], \"PERCEPTION\": [\"Memory-based MT is an idea of viewing MT as a memory activity.\", \"It can be considered as\", \"This view,\", \"counters to traditional idea to view NLP as an extensive rule application process to build up meaning representation.\"], \"BACKGROUND\": [\"parsing is considered as a memory-search process which identifies similar cases in the past from the memory, and to provide interpretation based on the identified case.\", \"an application of Memory-Based Reasoning (MBR) #REF and\", \"to NLP.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "advantages",
                "of",
                "EBMT",
                "are",
                "that",
                "translation",
                "quality",
                "is",
                "assured,",
                "because",
                "the",
                "example",
                "translations",
                "are",
                "real.",
                "The",
                "system",
                "knows",
                "its",
                "limitations:",
                "if",
                "a",
                "suitable",
                "example",
                "cannot",
                "be",
                "found,",
                "the",
                "system",
                "will",
                "not",
                "translate",
                "on",
                "a",
                "word-for-word",
                "basis",
                "as",
                "in",
                "rule-based",
                "MT.",
                "This",
                "approach",
                "does",
                "not",
                "depend",
                "on",
                "structure",
                "preservation",
                "as",
                "a",
                "first",
                "choice",
                "(cf.",
                "#TARGET_REF",
                ",",
                "p.84),",
                "and",
                "perhaps",
                "most",
                "interesting",
                "of",
                "all,",
                "it",
                "is",
                "easy",
                "to",
                "extend",
                "an",
                "EBMT",
                "system:",
                "we",
                "simply",
                "add",
                "more",
                "examples",
                "to",
                "the",
                "database.",
                "Unlike",
                "in",
                "rule-based",
                "MT,",
                "there",
                "is",
                "not",
                "the",
                "overhead",
                "of",
                "'entropy'",
                "of",
                "performance,",
                "where",
                "the",
                "addition",
                "of",
                "a",
                "new",
                "rule",
                "has",
                "unforeseen",
                "repercussions",
                "on",
                "the",
                "rest",
                "of",
                "the",
                "system,",
                "which",
                "sometimes",
                "do",
                "not",
                "surface",
                "until",
                "many",
                "months",
                "after",
                "the",
                "change",
                "was",
                "made,",
                "and",
                "therefore",
                "are",
                "extremely",
                "difficult",
                "to",
                "trace."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The advantages of EBMT are that translation quality is assured, because the example translations are real. The system knows its limitations: if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT. This approach does not depend on structure preservation as a first choice (cf. #TARGET_REF , p.84), and perhaps most interesting of all, it is easy to extend an EBMT system: we simply add more examples to the database. Unlike in rule-based MT, there is not the overhead of 'entropy' of performance, where the addition of a new rule has unforeseen repercussions on the rest of the system, which sometimes do not surface until many months after the change was made, and therefore are extremely difficult to trace.",
        "output": "{\"INFORMATION\": [\"This approach does not depend on structure preservation as a first choice (cf. #TARGET_REF , p.84),\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"if a suitable example cannot be found, the system will not translate on a word-for-word basis as in rule-based MT.\"]}"
    },
    {
        "gold": {
            "text": [
                "proc�",
                "of",
                "supervised",
                "training",
                "based",
                "on",
                "computing",
                "the",
                "frequency",
                "with",
                "which",
                "transitions",
                "are",
                "traversed",
                "in",
                "a",
                "corpus",
                "of",
                "parse",
                "histories.",
                "The",
                "result",
                "is",
                "a",
                "probabilistic",
                "parser",
                "which,",
                "unlike",
                "a",
                "PCFG,",
                "is",
                "capable",
                "of",
                "probabilistically",
                "discriminating",
                "derivations",
                "which",
                "differ",
                "only",
                "in",
                "terms",
                "of",
                "order",
                "of",
                "application",
                "of",
                "the",
                "same",
                "set",
                "of",
                "CF",
                "backbone",
                "rules,",
                "due",
                "to",
                "the",
                "parse",
                "context",
                "defined",
                "by",
                "the",
                "LR",
                "table.",
                "Experiments",
                "with",
                "this",
                "s",
                "ys",
                "tem",
                "revealed",
                "three",
                "major",
                "problems",
                "which",
                "our",
                "current",
                "research",
                "is",
                "addressing.",
                "Firstly,",
                "although",
                "the",
                "system",
                "is",
                "able",
                "to",
                "rank",
                "parses",
                "with",
                "a",
                "75%",
                "chance",
                "that",
                "the",
                "correct",
                "anal",
                "ys",
                "is",
                "will",
                "be",
                "the",
                "most",
                "highly",
                "ranked,",
                "further",
                "improvement",
                "will",
                "require",
                "a",
                "'lexicalised'",
                "system",
                "in",
                "which",
                "(minimally)",
                "probabilities",
                "are",
                "associated",
                "with",
                "alternative",
                "subcategorisation",
                "possibilities",
                "of",
                "individual",
                "lexical",
                "items.",
                "Currently,",
                "the",
                "relative",
                "frequency",
                "of",
                "subcategorisation",
                "possibilities",
                "for",
                "individual",
                "lexical",
                "items",
                "is",
                "not",
                "recorded",
                "in",
                "wide-coverage",
                "lexicons,",
                "such",
                "as",
                "ANLT",
                "or",
                "COMLEX",
                "#REF",
                ".",
                "Secondly,",
                "removal",
                "of",
                "punctuation",
                "from",
                "the",
                "input",
                "(after",
                "segmentation",
                "int.o",
                "text",
                "sentences)",
                "worsens",
                "performance",
                "as",
                "punctuation",
                "both",
                "reduces",
                "syntactic",
                "ambiguity",
                "#REF",
                "relations",
                "between",
                "text",
                "units",
                "#REF",
                ".",
                "Thirdly,",
                "the",
                "largest",
                "source",
                "of",
                "error",
                "on",
                "unseen",
                "input",
                "is",
                "the",
                "omission",
                "of",
                "appropriate",
                "subcategorisation",
                "values",
                "for",
                "lexical",
                "items",
                "(mostly",
                "verbs)",
                ",",
                "preventing",
                "the",
                "system",
                "from",
                "finding",
                "the",
                "correct",
                "analysis.",
                "The",
                "current",
                "coverage",
                "of",
                "this",
                "system",
                "on",
                "a",
                "general",
                "corpus",
                "(e.g.",
                "Brown",
                "or",
                "LOB)",
                "is",
                "estimated",
                "to",
                "be",
                "around",
                "20%",
                "by",
                "#TARGET_REF",
                ".",
                "We",
                "have",
                "developed",
                "a",
                "variant",
                "probabilistic",
                "LR",
                "parser",
                "which",
                "does",
                "not",
                "rely",
                "on",
                "subcategorisation",
                "and",
                "uses",
                "punctuation",
                "to",
                "reduce",
                "ambiguity.",
                "The",
                "anal",
                "ys",
                "es",
                "produced",
                "by",
                "this",
                "parser",
                "could",
                "be",
                "utilised",
                "for",
                "phrase-finding",
                "applications,",
                "recovery",
                "of",
                "subcategorisation",
                "frames,",
                "and",
                "other",
                "'intermediate'",
                "level",
                "parsing",
                "problems."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "proc� of supervised training based on computing the frequency with which transitions are traversed in a corpus of parse histories. The result is a probabilistic parser which, unlike a PCFG, is capable of probabilistically discriminating derivations which differ only in terms of order of application of the same set of CF backbone rules, due to the parse context defined by the LR table. Experiments with this s ys tem revealed three major problems which our current research is addressing. Firstly, although the system is able to rank parses with a 75% chance that the correct anal ys is will be the most highly ranked, further improvement will require a 'lexicalised' system in which (minimally) probabilities are associated with alternative subcategorisation possibilities of individual lexical items. Currently, the relative frequency of subcategorisation possibilities for individual lexical items is not recorded in wide-coverage lexicons, such as ANLT or COMLEX #REF . Secondly, removal of punctuation from the input (after segmentation int.o text sentences) worsens performance as punctuation both reduces syntactic ambiguity #REF relations between text units #REF . Thirdly, the largest source of error on unseen input is the omission of appropriate subcategorisation values for lexical items (mostly verbs) , preventing the system from finding the correct analysis. The current coverage of this system on a general corpus (e.g. Brown or LOB) is estimated to be around 20% by #TARGET_REF . We have developed a variant probabilistic LR parser which does not rely on subcategorisation and uses punctuation to reduce ambiguity. The anal ys es produced by this parser could be utilised for phrase-finding applications, recovery of subcategorisation frames, and other 'intermediate' level parsing problems.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The current coverage of this system on a general corpus (e.g. Brown or LOB) is estimated to be around 20% by\"]}"
    },
    {
        "gold": {
            "text": [
                "Datasets",
                "created",
                "for",
                "sentiment",
                "analysis",
                "have",
                "been",
                "available",
                "for",
                "researchers",
                "since",
                "at",
                "least",
                "the",
                "early",
                "2000s",
                "#REF",
                ".",
                "Such",
                "datasets",
                "generally",
                "use",
                "a",
                "binary",
                "or",
                "ternary",
                "annotation",
                "scheme",
                "(positive,",
                "negative",
                "+",
                "neutral)",
                "(e.g.",
                "#REF",
                ")",
                "and",
                "have",
                "traditionally",
                "been",
                "based",
                "on",
                "review",
                "data",
                "such",
                "as,",
                "e.g.",
                "Amazon",
                "product",
                "reviews,",
                "or",
                "movie",
                "reviews",
                "#REF",
                ".",
                "Many,",
                "if",
                "not",
                "most,",
                "emotion",
                "datasets",
                "on",
                "the",
                "other",
                "hand",
                "use",
                "Twitter",
                "as",
                "a",
                "source",
                "and",
                "individual",
                "tweets",
                "as",
                "level",
                "of",
                "granularity",
                "#TARGET_REF",
                ".",
                "In",
                "the",
                "case",
                "of",
                "emotion",
                "datasets,",
                "the",
                "emotion",
                "taxonomies",
                "used",
                "are",
                "often",
                "based",
                "on",
                "#REF",
                "and",
                "#REF",
                "(which",
                "is",
                "partially",
                "based",
                "on",
                "Ekman)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Datasets created for sentiment analysis have been available for researchers since at least the early 2000s #REF . Such datasets generally use a binary or ternary annotation scheme (positive, negative + neutral) (e.g. #REF ) and have traditionally been based on review data such as, e.g. Amazon product reviews, or movie reviews #REF . Many, if not most, emotion datasets on the other hand use Twitter as a source and individual tweets as level of granularity #TARGET_REF . In the case of emotion datasets, the emotion taxonomies used are often based on #REF and #REF (which is partially based on Ekman).",
        "output": "{\"INFORMATION\": [\"as a source and individual tweets as level of granularity\"], \"PERCEPTION\": [\"emotion datasets on the other hand use Twitter\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "existing",
                "self-supervised",
                "VLP",
                "approaches",
                "can",
                "be",
                "largely",
                "categorized",
                "into",
                "two",
                "groups:",
                "the",
                "twostep",
                "pretraining",
                "and",
                "the",
                "end-to-end",
                "pretraining,",
                "depending",
                "on",
                "whether",
                "they",
                "rely",
                "on",
                "visual",
                "object",
                "embeddings",
                "as",
                "input",
                "for",
                "the",
                "Transformer.",
                "Two-step",
                "Pretraining",
                "firstly",
                "employ",
                "an",
                "off-theshelf",
                "object",
                "detector",
                "to",
                "convert",
                "an",
                "image",
                "into",
                "a",
                "set",
                "of",
                "object",
                "embeddings,",
                "and",
                "then",
                "feed",
                "them",
                "into",
                "a",
                "Transformer",
                "jointly",
                "with",
                "text",
                "embeddings",
                "to",
                "generate",
                "their",
                "multi-modal",
                "representations.",
                "Hence",
                "their",
                "visual",
                "feature",
                "networks",
                "are",
                "not",
                "optimized",
                "during",
                "both",
                "pretraining",
                "&amp,",
                "finetuning",
                "stage.",
                "Most",
                "of",
                "these",
                "methods,",
                "such",
                "as",
                "LXMERT",
                "#REF",
                ",ViLBert",
                "#TARGET_REF",
                ",",
                "VL-Bert",
                "#REF",
                ",",
                "Unicoder-VL",
                "#REF",
                "and",
                "UNITER",
                "#REF",
                ",",
                "adopt",
                "BERT-like",
                "objectives",
                "to",
                "train",
                "their",
                "networks,",
                "which",
                "include",
                "Masked",
                "Language",
                "Modeling",
                "(MLM),",
                "Masked",
                "Vision",
                "Modeling",
                "(MVM)",
                "and",
                "Image-Text",
                "Matching",
                "(ITM).",
                "In",
                "addition,",
                "VILLA",
                "#REF",
                "develops",
                "an",
                "advanced",
                "adversarial",
                "pretraining",
                "and",
                "finetuning",
                "strategy",
                "to",
                "improve",
                "generalization",
                "ability.",
                "OSCAR",
                "#REF",
                "and",
                "VINVL",
                "#REF",
                "introduce",
                "object",
                "labels",
                "to",
                "bridge",
                "different",
                "modalities",
                "and",
                "revisit",
                "the",
                "importance",
                "of",
                "visual",
                "features.",
                "Ernie-ViL",
                "#REF",
                "exploits",
                "structured",
                "knowledge",
                "in",
                "the",
                "text",
                "and",
                "constructs",
                "scene",
                "graph",
                "prediction",
                "tasks",
                "to",
                "learn",
                "joint",
                "representations.",
                "UNIMO",
                "#REF",
                "proposes",
                "a",
                "unified",
                "model",
                "to",
                "leverage",
                "large-scale",
                "free",
                "text",
                "corpus,",
                "image",
                "collections,",
                "and",
                "image-text",
                "pairs",
                "simultaneously",
                "through",
                "a",
                "contrastive",
                "learning",
                "task.",
                "Despite",
                "their",
                "strong",
                "performances,",
                "those",
                "methods",
                "are",
                "limited",
                "by",
                "the",
                "object",
                "detector",
                "and",
                "neglect",
                "visual",
                "cues",
                "outside",
                "of",
                "object",
                "regions,",
                "often",
                "leading",
                "to",
                "mistakes",
                "in",
                "downstream",
                "tasks."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The existing self-supervised VLP approaches can be largely categorized into two groups: the twostep pretraining and the end-to-end pretraining, depending on whether they rely on visual object embeddings as input for the Transformer. Two-step Pretraining firstly employ an off-theshelf object detector to convert an image into a set of object embeddings, and then feed them into a Transformer jointly with text embeddings to generate their multi-modal representations. Hence their visual feature networks are not optimized during both pretraining &amp, finetuning stage. Most of these methods, such as LXMERT #REF ,ViLBert #TARGET_REF , VL-Bert #REF , Unicoder-VL #REF and UNITER #REF , adopt BERT-like objectives to train their networks, which include Masked Language Modeling (MLM), Masked Vision Modeling (MVM) and Image-Text Matching (ITM). In addition, VILLA #REF develops an advanced adversarial pretraining and finetuning strategy to improve generalization ability. OSCAR #REF and VINVL #REF introduce object labels to bridge different modalities and revisit the importance of visual features. Ernie-ViL #REF exploits structured knowledge in the text and constructs scene graph prediction tasks to learn joint representations. UNIMO #REF proposes a unified model to leverage large-scale free text corpus, image collections, and image-text pairs simultaneously through a contrastive learning task. Despite their strong performances, those methods are limited by the object detector and neglect visual cues outside of object regions, often leading to mistakes in downstream tasks.",
        "output": "{\"INFORMATION\": [\",ViLBert #TARGET_REF ,\"], \"PERCEPTION\": [\"Most of these methods, such as\", \"to train their networks, which include Masked Language Modeling (MLM), Masked Vision Modeling (MVM) and Image-Text Matching (ITM).\"], \"BACKGROUND\": [\"LXMERT #REF\", \"VL-Bert #REF , Unicoder-VL #REF and UNITER #REF , adopt BERT-like objectives\"]}"
    },
    {
        "gold": {
            "text": [
                "One",
                "can",
                "create",
                "a",
                "graph",
                "(Bel-Enguix,",
                "2014),",
                "and",
                "its",
                "transformation",
                "to",
                "a",
                "word",
                "embedding",
                "model",
                "#TARGET_REF",
                ",",
                "specifically",
                "for",
                "modeling",
                "associations,",
                "but",
                "these",
                "require",
                "difficult-to-obtain",
                "association",
                "data.",
                "This",
                "would",
                "be",
                "a",
                "high",
                "resource",
                "requirement",
                "and",
                "would",
                "make",
                "it",
                "difficult",
                "to",
                "apply",
                "such",
                "methods",
                "in",
                "various",
                "languages."
            ],
            "context": [
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "One can create a graph (Bel-Enguix, 2014), and its transformation to a word embedding model #TARGET_REF , specifically for modeling associations, but these require difficult-to-obtain association data. This would be a high resource requirement and would make it difficult to apply such methods in various languages.",
        "output": "{\"INFORMATION\": [\"a word embedding model #TARGET_REF ,\"], \"PERCEPTION\": [\"One can create\", \"its transformation to\", \"specifically for modeling associations, but these require difficult-to-obtain association data. This would be a high resource requirement and would make it difficult to apply such methods in various languages.\"], \"BACKGROUND\": [\"a graph (Bel-Enguix, 2014), and\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "definition",
                "generation",
                "dataset,",
                "we",
                "directly",
                "use",
                "the",
                "OD",
                "dataset",
                "published",
                "by",
                "#TARGET_REF",
                ".",
                "The",
                "training",
                "set",
                "has",
                "33,128",
                "words",
                "and",
                "97,855",
                "entries.",
                "Each",
                "entry",
                "consists",
                "of",
                "a",
                "triplet",
                "of",
                "(w",
                "*",
                ",",
                "c,",
                "d",
                "com",
                ").",
                "For",
                "testing,",
                "we",
                "align",
                "the",
                "words",
                "and",
                "context",
                "in",
                "OD",
                "with",
                "the",
                "definitions",
                "in",
                "OALD",
                "through",
                "manual",
                "annotation.",
                "The",
                "annotated",
                "test",
                "set",
                "includes",
                "3,881",
                "words",
                "and",
                "5,111",
                "entries,",
                "which",
                "is",
                "used",
                "for",
                "automatic",
                "evaluation",
                "in",
                "experiments.",
                "Each",
                "entry",
                "in",
                "the",
                "test",
                "set",
                "has",
                "both",
                "golden",
                "complex",
                "and",
                "simple",
                "definitions",
                "from",
                "OD",
                "and",
                "OALD,",
                "respectively.",
                "Detailed",
                "statistics",
                "are",
                "listed",
                "in",
                "Table",
                "1."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For the definition generation dataset, we directly use the OD dataset published by #TARGET_REF . The training set has 33,128 words and 97,855 entries. Each entry consists of a triplet of (w * , c, d com ). For testing, we align the words and context in OD with the definitions in OALD through manual annotation. The annotated test set includes 3,881 words and 5,111 entries, which is used for automatic evaluation in experiments. Each entry in the test set has both golden complex and simple definitions from OD and OALD, respectively. Detailed statistics are listed in Table 1.",
        "output": "{\"INFORMATION\": [\"the OD dataset published by #TARGET_REF . The training set has 33,128 words and 97,855 entries. Each entry consists of a triplet of (w * , c, d com ).\"], \"PERCEPTION\": [\"For the definition generation dataset, we directly use\", \"For testing, we align the words and context in OD with the definitions in OALD through manual annotation.\"], \"BACKGROUND\": [\"Each entry in the test set has both golden complex and simple definitions from OD and OALD, respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "b",
                "b",
                "«",
                "¾",
                "´",
                "¿µ:",
                "S",
                "A",
                "c",
                "¬",
                "½",
                "´",
                "¿µ:",
                "A",
                "A",
                "£",
                "NA",
                "b",
                "«",
                "¿",
                "´",
                "¿µ:",
                "A",
                "A",
                "b",
                "«",
                "´",
                "¿µ:",
                "A",
                "NA",
                "a",
                "bFigure",
                "7:",
                "Abstract",
                "Syntax",
                "Tree",
                "and",
                "pattern",
                "trees",
                "of",
                "programming",
                "languages,",
                "the",
                "sort",
                "of",
                "pattern",
                "trees",
                "that",
                "are",
                "allowed",
                "are",
                "only",
                "groupings",
                "of",
                "contiguous",
                "nodes,",
                "in",
                "effect,",
                "tree",
                "parsing",
                "is",
                "allowed",
                "with",
                "a",
                "tree",
                "grammar",
                "consisting",
                "of",
                "trees",
                "of",
                "possibly",
                "multiple",
                "levels",
                "and",
                "allowing",
                "only",
                "concatenation:",
                "this",
                "is",
                "equivalent",
                "to",
                "a",
                "TSG.",
                "Consider",
                "an",
                "AST",
                "in",
                "Figure",
                "7",
                "(ignoring",
                "the",
                "annotations",
                "on",
                "the",
                "nodes,",
                "in",
                "parentheses),",
                "and",
                "take",
                "for",
                "pattern",
                "trees",
                "only",
                "those",
                "initial",
                "trees",
                "of",
                "Figure",
                "7",
                "(«",
                "½",
                "«",
                ").",
                "It",
                "can",
                "be",
                "seen",
                "that",
                "the",
                "AST",
                "can",
                "be",
                "decomposed",
                "in",
                "several",
                "ways,",
                "for",
                "example",
                "by",
                "the",
                "set",
                "of",
                "pattern",
                "trees",
                "«",
                "¾",
                "«",
                "¿",
                "«",
                "¿",
                "«",
                "or",
                "the",
                "set",
                "«",
                "¾",
                "«",
                "¿",
                "«",
                ".",
                "If",
                "the",
                "numbers",
                "in",
                "parentheses",
                "after",
                "the",
                "labels",
                "(",
                ")",
                "are",
                "considered",
                "as",
                "costs,",
                "an",
                "optimal",
                "decomposition",
                "can",
                "be",
                "determined",
                "(here,",
                "«",
                "¾",
                "«",
                "¿",
                "«",
                ").",
                "Now",
                "in",
                "Section",
                "4.2",
                "we",
                "develop",
                "an",
                "algorithm",
                "based",
                "on",
                "this",
                "which",
                "allows",
                "an",
                "input",
                "AST",
                "(for",
                "us,",
                "a",
                "derivation",
                "or",
                "dependency",
                "structure,",
                "for",
                "example)",
                "to",
                "be",
                "broken",
                "into",
                "component",
                "non-contiguous",
                "'trees'",
                "efficiently.",
                "From",
                "a",
                "theoretical",
                "point",
                "of",
                "view",
                "this",
                "is",
                "interesting,",
                "as",
                "the",
                "expectation",
                "would",
                "be",
                "that",
                "some",
                "more",
                "complex",
                "mechanism",
                "would",
                "be",
                "necessary,",
                "in",
                "much",
                "the",
                "same",
                "way",
                "that",
                "allowing",
                "stretching",
                "of",
                "paired",
                "characters",
                "in",
                "strings",
                "(say,",
                "in",
                "the",
                "language",
                "of",
                "nested",
                "strings",
                "Ò",
                "Ò",
                "Ò",
                "¼",
                ",",
                "where",
                "the",
                "th",
                "is",
                "matched",
                "with",
                "the",
                "´Ò",
                "•",
                "½",
                "µ",
                "th",
                ")",
                "cannot",
                "be",
                "performed",
                "by",
                "a",
                "finite",
                "state",
                "automaton",
                "but",
                "requires",
                "a",
                "pushdown",
                "automaton",
                "through",
                "the",
                "addition",
                "of",
                "a",
                "stack,",
                "here,",
                "it",
                "might",
                "be",
                "expected",
                "that",
                "a",
                "stack",
                "is",
                "similarly",
                "necessary",
                "to",
                "keep",
                "track",
                "of",
                "the",
                "unbounded",
                "elements."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "b b « ¾ ´ ¿µ: S A c ¬ ½ ´ ¿µ: A A £ NA b « ¿ ´ ¿µ: A A b « ´ ¿µ: A NA a bFigure 7: Abstract Syntax Tree and pattern trees of programming languages, the sort of pattern trees that are allowed are only groupings of contiguous nodes, in effect, tree parsing is allowed with a tree grammar consisting of trees of possibly multiple levels and allowing only concatenation: this is equivalent to a TSG. Consider an AST in Figure 7 (ignoring the annotations on the nodes, in parentheses), and take for pattern trees only those initial trees of Figure 7 (« ½ « ). It can be seen that the AST can be decomposed in several ways, for example by the set of pattern trees « ¾ « ¿ « ¿ « or the set « ¾ « ¿ « . If the numbers in parentheses after the labels ( ) are considered as costs, an optimal decomposition can be determined (here, « ¾ « ¿ « ). Now in Section 4.2 we develop an algorithm based on this which allows an input AST (for us, a derivation or dependency structure, for example) to be broken into component non-contiguous 'trees' efficiently. From a theoretical point of view this is interesting, as the expectation would be that some more complex mechanism would be necessary, in much the same way that allowing stretching of paired characters in strings (say, in the language of nested strings Ò Ò Ò ¼ , where the th is matched with the ´Ò • ½ µ th ) cannot be performed by a finite state automaton but requires a pushdown automaton through the addition of a stack, here, it might be expected that a stack is similarly necessary to keep track of the unbounded elements.",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "All",
                "the",
                "collected",
                "data",
                "were",
                "originally",
                "posted",
                "in",
                "the",
                "period",
                "of",
                "March",
                "-June",
                "2020.",
                "During",
                "this",
                "time,",
                "Vietnam",
                "was",
                "facing",
                "a",
                "second",
                "wave",
                "of",
                "Covid-19",
                "with",
                "a",
                "drastic",
                "increase",
                "from",
                "20",
                "to",
                "355",
                "cases",
                "#REF",
                ".",
                "The",
                "spread",
                "of",
                "Covid-19",
                "results",
                "in",
                "an",
                "'infodemic'",
                "in",
                "which",
                "misleading",
                "information",
                "is",
                "disseminated",
                "rapidly",
                "especially",
                "on",
                "social",
                "media",
                "#TARGET_REF",
                ".",
                "Hence,",
                "this",
                "period",
                "is",
                "a",
                "potential",
                "source",
                "of",
                "fake",
                "news.",
                "Besides",
                "Covid-19,",
                "the",
                "items",
                "in",
                "our",
                "dataset",
                "cover",
                "a",
                "wide",
                "range",
                "of",
                "domains",
                "including",
                "entertainment,",
                "sport,",
                "finance",
                "and",
                "healthcare.",
                "The",
                "result",
                "of",
                "the",
                "data",
                "collection",
                "stage",
                "is",
                "10,007",
                "items",
                "that",
                "are",
                "prepared",
                "for",
                "the",
                "annotation",
                "process."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "All the collected data were originally posted in the period of March -June 2020. During this time, Vietnam was facing a second wave of Covid-19 with a drastic increase from 20 to 355 cases #REF . The spread of Covid-19 results in an 'infodemic' in which misleading information is disseminated rapidly especially on social media #TARGET_REF . Hence, this period is a potential source of fake news. Besides Covid-19, the items in our dataset cover a wide range of domains including entertainment, sport, finance and healthcare. The result of the data collection stage is 10,007 items that are prepared for the annotation process.",
        "output": "{\"INFORMATION\": [\"The spread of Covid-19 results in an 'infodemic' in which misleading information is disseminated rapidly especially on social media #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"All the collected data were originally posted in the period of March -June 2020.\", \"Hence, this period is a potential source of fake news. Besides Covid-19, the items in our dataset cover a wide range of domains including entertainment, sport, finance and healthcare.\"]}"
    },
    {
        "gold": {
            "text": [
                "Since",
                "PLMs",
                "can",
                "process",
                "multiple",
                "input",
                "sentences,",
                "we",
                "add",
                "a",
                "query",
                "sentence",
                "before",
                "the",
                "context",
                "to",
                "emphasize",
                "the",
                "words",
                "(e.g.",
                "river)",
                "that",
                "need",
                "to",
                "be",
                "predicted",
                "and",
                "the",
                "corpus",
                "(e.g.",
                "Bible)",
                "they",
                "come",
                "from.",
                "We",
                "add",
                "special",
                "tokens",
                "[CLS]",
                "and",
                "[SEP]",
                "to",
                "separate",
                "the",
                "query",
                "and",
                "the",
                "context",
                "as",
                "shown",
                "in",
                "Figure",
                "2.",
                "BERT",
                "first",
                "tokenizes",
                "the",
                "input",
                "contents",
                "and",
                "then",
                "generates",
                "contextualized",
                "vector",
                "representations",
                "for",
                "each",
                "token",
                "in",
                "multiple",
                "hidden",
                "layers.",
                "We",
                "focus",
                "on",
                "the",
                "output",
                "of",
                "only",
                "the",
                "first",
                "position",
                "that",
                "we",
                "passed",
                "the",
                "special",
                "[CLS]",
                "token",
                "to.",
                "The",
                "last",
                "k",
                "hidden",
                "layers",
                "are",
                "selected",
                "to",
                "get",
                "the",
                "final",
                "representation",
                "of",
                "token",
                "[CLS]",
                "through",
                "a",
                "weighted",
                "calculation",
                "function",
                "as",
                "below,x",
                "[CLS]",
                "=",
                "k",
                "i=1",
                "W",
                "i",
                "x",
                "[CLS]iwhere",
                "W",
                "i",
                "is",
                "the",
                "learning",
                "weight",
                "for",
                "each",
                "hidden",
                "layer.",
                "The",
                "calculated",
                "representation",
                "is",
                "then",
                "fed",
                "into",
                "a",
                "dense",
                "layer,",
                "and",
                "the",
                "technique",
                "of",
                "multi-sample",
                "dropout",
                "#TARGET_REF",
                "is",
                "utilized",
                "to",
                "accelerate",
                "training",
                "and",
                "finally",
                "obtain",
                "the",
                "predicted",
                "complexity",
                "scores.",
                "The",
                "loss",
                "function",
                "can",
                "be",
                "chosen",
                "among",
                "several",
                "options",
                "including",
                "Mean",
                "Square",
                "Error",
                "(MSE),",
                "Root",
                "Mean",
                "Square",
                "Error",
                "(RMSE),",
                "and",
                "Mean",
                "Absolute",
                "Error",
                "(MAE)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Since PLMs can process multiple input sentences, we add a query sentence before the context to emphasize the words (e.g. river) that need to be predicted and the corpus (e.g. Bible) they come from. We add special tokens [CLS] and [SEP] to separate the query and the context as shown in Figure 2. BERT first tokenizes the input contents and then generates contextualized vector representations for each token in multiple hidden layers. We focus on the output of only the first position that we passed the special [CLS] token to. The last k hidden layers are selected to get the final representation of token [CLS] through a weighted calculation function as below,x [CLS] = k i=1 W i x [CLS]iwhere W i is the learning weight for each hidden layer. The calculated representation is then fed into a dense layer, and the technique of multi-sample dropout #TARGET_REF is utilized to accelerate training and finally obtain the predicted complexity scores. The loss function can be chosen among several options including Mean Square Error (MSE), Root Mean Square Error (RMSE), and Mean Absolute Error (MAE).",
        "output": "{\"INFORMATION\": [\"multi-sample dropout #TARGET_REF\"], \"PERCEPTION\": [\"The calculated representation is then fed into a dense layer, and the technique of\", \"is utilized to accelerate training and finally obtain the predicted complexity scores.\"], \"BACKGROUND\": [\"The last k hidden layers are selected to get the final representation of token [CLS] through a weighted calculation function as below,x\"]}"
    },
    {
        "gold": {
            "text": [
                "Recent",
                "studies",
                "show",
                "that",
                "NLP",
                "models",
                "are",
                "vulnerable",
                "to",
                "adversarial",
                "perturbations.",
                "A",
                "seemingly",
                "\"invariance",
                "transformation\"",
                "(a.k.a.",
                "adversarial",
                "perturbation)",
                "such",
                "as",
                "synonym",
                "substitutions",
                "#TARGET_REF",
                "or",
                "syntax-guided",
                "paraphrasing",
                "#REF",
                "can",
                "alter",
                "the",
                "prediction.",
                "To",
                "mitigate",
                "the",
                "model",
                "vulnerability,",
                "robust",
                "training",
                "methods",
                "have",
                "been",
                "proposed",
                "and",
                "shown",
                "effective",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Recent studies show that NLP models are vulnerable to adversarial perturbations. A seemingly \"invariance transformation\" (a.k.a. adversarial perturbation) such as synonym substitutions #TARGET_REF or syntax-guided paraphrasing #REF can alter the prediction. To mitigate the model vulnerability, robust training methods have been proposed and shown effective #REF .",
        "output": "{\"INFORMATION\": [\"synonym substitutions #TARGET_REF\"], \"PERCEPTION\": [\"Recent studies show that NLP models are vulnerable to adversarial perturbations. A seemingly \\\"invariance transformation\\\"\", \"such as\", \"can alter the prediction.\"], \"BACKGROUND\": [\"(a.k.a. adversarial perturbation)\", \"or syntax-guided paraphrasing #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Previous",
                "annotation",
                "tasks",
                "have",
                "shown",
                "that",
                "even",
                "with",
                "binary",
                "or",
                "ternary",
                "classification",
                "schemes,",
                "human",
                "annotators",
                "agree",
                "only",
                "about",
                "70-80%",
                "of",
                "the",
                "time",
                "and",
                "the",
                "more",
                "categories",
                "there",
                "are,",
                "the",
                "harder",
                "it",
                "becomes",
                "for",
                "annotators",
                "to",
                "agree",
                "#TARGET_REF",
                ".",
                "For",
                "example,",
                "when",
                "creating",
                "the",
                "DENS",
                "dataset",
                "#REF",
                ",",
                "only",
                "21%",
                "of",
                "their",
                "annotations",
                "had",
                "consensus",
                "between",
                "all",
                "annotators",
                "with",
                "73.5%",
                "having",
                "to",
                "resort",
                "to",
                "majority",
                "agreement,",
                "and",
                "a",
                "further",
                "5.5%",
                "could",
                "not",
                "be",
                "agreed",
                "upon",
                "and",
                "were",
                "left",
                "to",
                "expert",
                "annotators",
                "to",
                "be",
                "resolved."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Previous annotation tasks have shown that even with binary or ternary classification schemes, human annotators agree only about 70-80% of the time and the more categories there are, the harder it becomes for annotators to agree #TARGET_REF . For example, when creating the DENS dataset #REF , only 21% of their annotations had consensus between all annotators with 73.5% having to resort to majority agreement, and a further 5.5% could not be agreed upon and were left to expert annotators to be resolved.",
        "output": "{\"INFORMATION\": [\"even with binary or ternary classification schemes, human annotators agree only about 70-80% of the time and the more categories there are, the harder it becomes for annotators to agree #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Previous annotation tasks have shown that\"]}"
    },
    {
        "gold": {
            "text": [
                "Robust",
                "models",
                "(first-order).",
                "With",
                "the",
                "same",
                "setup",
                "as",
                "base",
                "models,",
                "we",
                "apply",
                "robust",
                "training",
                "methods",
                "to",
                "improve",
                "the",
                "resistance",
                "to",
                "word",
                "substitution",
                "attacks.",
                "#REF",
                "provide",
                "a",
                "provably",
                "robust",
                "training",
                "method",
                "through",
                "Interval",
                "Bound",
                "Propagation",
                "(IBP,",
                "#TARGET_REF",
                ")",
                "for",
                "all",
                "word",
                "substitutions",
                "on",
                "BoW,",
                "CNN",
                "and",
                "LSTM.",
                "#REF",
                "provide",
                "a",
                "provably",
                "robust",
                "training",
                "method",
                "on",
                "general",
                "computational",
                "graphs",
                "through",
                "a",
                "combination",
                "of",
                "forward",
                "and",
                "backward",
                "linear",
                "bound",
                "propagation,",
                "and",
                "the",
                "resulting",
                "3-layer",
                "Transformer",
                "is",
                "robust",
                "to",
                "up",
                "to",
                "6",
                "word",
                "substitutions.",
                "For",
                "both",
                "works",
                "we",
                "use",
                "the",
                "same",
                "set",
                "of",
                "counter-fitted",
                "synonyms",
                "provided",
                "in",
                "#REF",
                ".",
                "We",
                "skip",
                "BERT-base",
                "due",
                "to",
                "the",
                "lack",
                "of",
                "an",
                "effective",
                "robust",
                "training",
                "method."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Robust models (first-order). With the same setup as base models, we apply robust training methods to improve the resistance to word substitution attacks. #REF provide a provably robust training method through Interval Bound Propagation (IBP, #TARGET_REF ) for all word substitutions on BoW, CNN and LSTM. #REF provide a provably robust training method on general computational graphs through a combination of forward and backward linear bound propagation, and the resulting 3-layer Transformer is robust to up to 6 word substitutions. For both works we use the same set of counter-fitted synonyms provided in #REF . We skip BERT-base due to the lack of an effective robust training method.",
        "output": "{\"INFORMATION\": [\"Interval Bound Propagation (IBP, #TARGET_REF )\"], \"PERCEPTION\": [\"#REF provide a provably robust training method through\", \"for all word substitutions on BoW, CNN and LSTM.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "X.",
                "We",
                "discuss",
                "further",
                "details",
                "of",
                "the",
                "data",
                "preparation",
                "in",
                "Section",
                "3.2.",
                "Letting",
                "y",
                "*",
                "i",
                "denote",
                "elements",
                "of",
                "the",
                "collapsed",
                "single-sequence",
                "representation",
                "s",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "s",
                "S",
                ",",
                "the",
                "joint",
                "log-likelihood",
                "(Eq.",
                "(",
                "3))",
                "can",
                "be",
                "written",
                "asL",
                "=",
                "log",
                "p(y",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "y",
                "K",
                "|X)",
                "=",
                "M",
                "*",
                "m=1",
                "log",
                "p(y",
                "*",
                "m",
                "|y",
                "*",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "y",
                "*",
                "m−1",
                ",",
                "X)",
                ".",
                "(9)Note",
                "that",
                "this",
                "form",
                "is",
                "almost",
                "equivalent",
                "to",
                "the",
                "single",
                "sequence",
                "objective",
                "function",
                "in",
                "Eq.",
                "(",
                "1)",
                "except",
                "for",
                "the",
                "variable",
                "y",
                "*",
                "m",
                "takes",
                "values",
                "from",
                "the",
                "union",
                "of",
                "the",
                "K",
                "symbol",
                "sets",
                "that",
                "represent",
                "the",
                "K",
                "output",
                "sequences",
                "and",
                "the",
                "length",
                "of",
                "this",
                "sequenceM",
                "*",
                "=",
                "K",
                "k=1",
                "M",
                "k",
                ",",
                "is",
                "the",
                "sum",
                "of",
                "the",
                "lengths",
                "of",
                "the",
                "K",
                "output",
                "sequences.This",
                "framework",
                "has",
                "various",
                "benefits",
                "compared",
                "with",
                "the",
                "existing",
                "frameworks",
                "described",
                "in",
                "Section",
                "2.",
                "Similar",
                "to",
                "the",
                "O2O",
                "model",
                "trained",
                "with",
                "the",
                "conditional",
                "chain",
                "mapping",
                "in",
                "Section",
                "2.2.2,",
                "this",
                "framework",
                "does",
                "not",
                "assume",
                "the",
                "conditional",
                "independence",
                "between",
                "output",
                "labels",
                "and",
                "has",
                "the",
                "flexibility",
                "to",
                "model",
                "the",
                "dependency",
                "between",
                "words/morphemes",
                "and",
                "linguistic",
                "annotations.",
                "Related",
                "works",
                "are",
                "using",
                "the",
                "O2O",
                "model,",
                "e.g.,",
                "#TARGET_REF",
                ",",
                "but",
                "they",
                "are",
                "based",
                "on",
                "CTC",
                "and",
                "do",
                "not",
                "consider",
                "such",
                "an",
                "explicit",
                "output",
                "dependency.",
                "Also,",
                "the",
                "proposed",
                "method",
                "using",
                "Transformer",
                "can",
                "preserve",
                "a",
                "relationship",
                "between",
                "the",
                "word/morpheme",
                "and",
                "the",
                "corresponding",
                "linguistic",
                "annotations",
                "across",
                "the",
                "sequence",
                "based",
                "on",
                "the",
                "aligned",
                "representation",
                "s",
                "i",
                "in",
                "Eq.",
                "(",
                "8).",
                "Finally,",
                "this",
                "framework",
                "is",
                "equivalent",
                "to",
                "the",
                "original",
                "single-sequence",
                "objective",
                "function,",
                "and",
                "we",
                "can",
                "use",
                "an",
                "existing",
                "strong",
                "sequence-to-sequence",
                "model",
                "(transformer",
                "in",
                "this",
                "paper)",
                "without",
                "any",
                "modifications",
                "of",
                "the",
                "algorithm.",
                "The",
                "only",
                "process",
                "is",
                "to",
                "prepare",
                "the",
                "collapsed",
                "single",
                "sequence",
                "composed",
                "of",
                "s",
                "i",
                ",",
                "which",
                "is",
                "discussed",
                "in",
                "the",
                "next",
                "section."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "X. We discuss further details of the data preparation in Section 3.2. Letting y * i denote elements of the collapsed single-sequence representation s 1 , . . . , s S , the joint log-likelihood (Eq. ( 3)) can be written asL = log p(y 1 , . . . , y K |X) = M * m=1 log p(y * m |y * 1 , . . . , y * m−1 , X) . (9)Note that this form is almost equivalent to the single sequence objective function in Eq. ( 1) except for the variable y * m takes values from the union of the K symbol sets that represent the K output sequences and the length of this sequenceM * = K k=1 M k , is the sum of the lengths of the K output sequences.This framework has various benefits compared with the existing frameworks described in Section 2. Similar to the O2O model trained with the conditional chain mapping in Section 2.2.2, this framework does not assume the conditional independence between output labels and has the flexibility to model the dependency between words/morphemes and linguistic annotations. Related works are using the O2O model, e.g., #TARGET_REF , but they are based on CTC and do not consider such an explicit output dependency. Also, the proposed method using Transformer can preserve a relationship between the word/morpheme and the corresponding linguistic annotations across the sequence based on the aligned representation s i in Eq. ( 8). Finally, this framework is equivalent to the original single-sequence objective function, and we can use an existing strong sequence-to-sequence model (transformer in this paper) without any modifications of the algorithm. The only process is to prepare the collapsed single sequence composed of s i , which is discussed in the next section.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF ,\"], \"PERCEPTION\": [\"but they are based on CTC and do not consider such an explicit output dependency.\"], \"BACKGROUND\": [\"the O2O model, e.g.,\"]}"
    },
    {
        "gold": {
            "text": [
                "vComp[oo][oo-y]",
                "1",
                "_",
                "[E,",
                "h",
                "I",
                "C➔",
                "Y4•,",
                ",",
                "1",
                ",",
                "p,q",
                "I",
                "D,",
                "r,",
                "s]",
                "Earley",
                "-",
                "[E,",
                "h",
                "I",
                "A[oo]",
                "➔",
                "Y1",
                "B[oo",
                "1",
                "]",
                "•",
                "Y2",
                ",'Y'",
                ",",
                "i",
                ",",
                "k",
                "I",
                "D",
                ",",
                "r,",
                "s]As",
                "an",
                "alternative",
                "approach,",
                "Boullier",
                "#TARGET_REF",
                "defines",
                "the",
                "shared",
                "forest",
                "for",
                "a",
                "LIG",
                "g",
                "=",
                "(Vr,",
                "VN",
                ",",
                "Vi,",
                "P,",
                "S)",
                "and",
                "an",
                "input",
                "string",
                "w",
                "by",
                "means",
                "of",
                "a",
                "linear",
                "derivation",
                "grammar,",
                "a",
                "context-free",
                "grammar",
                "recognizing",
                "the",
                "language",
                "defined",
                "by",
                "the",
                "sequences",
                "of",
                "LIG",
                "of",
                "g",
                "that",
                "could",
                "be",
                "used",
                "to",
                "derive",
                "w.",
                "Previously",
                "to",
                "the",
                "construction",
                "of",
                "the",
                "linear",
                "derivation",
                "grammar,",
                "we",
                "must",
                "compute",
                "the",
                "transitive",
                "closure",
                "for",
                "a",
                "set",
                "of",
                "relations",
                "on",
                "V",
                "N",
                "x",
                "V",
                "N."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "vComp[oo][oo-y] 1 _ [E, h I C➔ Y4•, , 1 , p,q I D, r, s] Earley - [E, h I A[oo] ➔ Y1 B[oo 1 ] • Y2 ,'Y' , i , k I D , r, s]As an alternative approach, Boullier #TARGET_REF defines the shared forest for a LIG g = (Vr, VN , Vi, P, S) and an input string w by means of a linear derivation grammar, a context-free grammar recognizing the language defined by the sequences of LIG of g that could be used to derive w. Previously to the construction of the linear derivation grammar, we must compute the transitive closure for a set of relations on V N x V N.",
        "output": "{\"INFORMATION\": [\"Boullier #TARGET_REF defines the shared forest for a LIG g = (Vr, VN , Vi, P, S) and an input string w by means of a linear derivation grammar, a context-free grammar recognizing the language defined by the sequences of LIG of g that could be used to derive w.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"s]As an alternative approach,\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "understand",
                "whether",
                "existing",
                "models",
                "can",
                "accurately",
                "perform",
                "such",
                "relative",
                "comparisons,",
                "we",
                "conducted",
                "a",
                "preliminary",
                "study",
                "on",
                "pre-trained",
                "BART",
                "#TARGET_REF",
                ",",
                "first",
                "generating",
                "two",
                "candidate",
                "summaries",
                "from",
                "the",
                "model",
                "and",
                "observing",
                "whether",
                "a",
                "higher",
                "probability",
                "is",
                "assigned",
                "to",
                "the",
                "candidate",
                "with",
                "a",
                "higher",
                "ROUGE",
                "#REF",
                "score.",
                "As",
                "Tab.",
                "1",
                "shows,",
                "the",
                "accuracy",
                "is",
                "far",
                "from",
                "ideal.",
                "This",
                "is",
                "likely",
                "due",
                "to",
                "the",
                "fact",
                "that",
                "MLE",
                "training",
                "only",
                "encourages",
                "the",
                "model",
                "to",
                "assign",
                "high",
                "probability",
                "to",
                "the",
                "reference",
                "summary,",
                "and",
                "is",
                "agnostic",
                "about",
                "any",
                "relative",
                "comparison",
                "between",
                "non-reference",
                "summaries.",
                "However,",
                "we",
                "argue",
                "that",
                "it",
                "is",
                "also",
                "important",
                "for",
                "the",
                "order",
                "of",
                "model",
                "scores",
                "to",
                "be",
                "coordinated",
                "with",
                "the",
                "actual",
                "quality",
                "metrics",
                "by",
                "which",
                "the",
                "summaries",
                "will",
                "be",
                "evaluated",
                "-higher",
                "model",
                "scores",
                "should",
                "indicate",
                "better",
                "quality",
                "summaries.",
                "In",
                "the",
                "following",
                "we",
                "will",
                "refer",
                "to",
                "models",
                "that",
                "have",
                "such",
                "scores",
                "as",
                "\"coordinated\"",
                "for",
                "conciseness."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To understand whether existing models can accurately perform such relative comparisons, we conducted a preliminary study on pre-trained BART #TARGET_REF , first generating two candidate summaries from the model and observing whether a higher probability is assigned to the candidate with a higher ROUGE #REF score. As Tab. 1 shows, the accuracy is far from ideal. This is likely due to the fact that MLE training only encourages the model to assign high probability to the reference summary, and is agnostic about any relative comparison between non-reference summaries. However, we argue that it is also important for the order of model scores to be coordinated with the actual quality metrics by which the summaries will be evaluated -higher model scores should indicate better quality summaries. In the following we will refer to models that have such scores as \"coordinated\" for conciseness.",
        "output": "{\"INFORMATION\": [\"BART #TARGET_REF ,\"], \"PERCEPTION\": [\"we conducted a preliminary study on pre-trained\", \"first generating two candidate summaries from the model and observing whether a higher probability is assigned to the candidate with a higher ROUGE #REF score.\"], \"BACKGROUND\": [\"To understand whether existing models can accurately perform such relative comparisons,\"]}"
    },
    {
        "gold": {
            "text": [
                "Previous",
                "works",
                "on",
                "FEVEROUS",
                "generally",
                "convert",
                "all",
                "evidence",
                "pieces",
                "into",
                "either",
                "plain",
                "text",
                "#REF",
                "or",
                "several",
                "tables",
                "#TARGET_REF",
                ".",
                "However,",
                "format",
                "conversions",
                "inevitably",
                "lose",
                "rich",
                "context",
                "information",
                "for",
                "the",
                "converted",
                "evidence,",
                "thus",
                "may",
                "mislead",
                "the",
                "subsequent",
                "encoding",
                "and",
                "interaction",
                "steps.",
                "For",
                "example,",
                "in",
                "Figure",
                "1,",
                "the",
                "entire",
                "top",
                "two",
                "rows",
                "are",
                "indispensable",
                "to",
                "understand",
                "the",
                "table",
                "cell",
                "Won.",
                "It",
                "is",
                "difficult",
                "to",
                "identify",
                "all",
                "related",
                "context",
                "cells",
                "and",
                "design",
                "a",
                "general",
                "conversion",
                "method",
                "to",
                "render",
                "them",
                "into",
                "sentences,",
                "but",
                "these",
                "connections",
                "can",
                "be",
                "easily",
                "caught",
                "by",
                "pre-trained",
                "table",
                "models",
                "#REF",
                ".",
                "On",
                "the",
                "other",
                "side,",
                "identifying/re-organizing",
                "crucial",
                "elements",
                "in",
                "a",
                "sentence",
                "to",
                "construct",
                "a",
                "table",
                "is",
                "also",
                "challenging.",
                "Simply",
                "inserting",
                "a",
                "whole",
                "sentence",
                "in",
                "a",
                "table",
                "cell",
                "#REF",
                "will",
                "make",
                "the",
                "new",
                "cells",
                "much",
                "larger",
                "(and",
                "unique)",
                "than",
                "normal",
                "ones,",
                "thus",
                "can",
                "not",
                "make",
                "the",
                "most",
                "of",
                "general",
                "pre-trained",
                "table",
                "models",
                "#REF",
                "as",
                "we",
                "expect."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Previous works on FEVEROUS generally convert all evidence pieces into either plain text #REF or several tables #TARGET_REF . However, format conversions inevitably lose rich context information for the converted evidence, thus may mislead the subsequent encoding and interaction steps. For example, in Figure 1, the entire top two rows are indispensable to understand the table cell Won. It is difficult to identify all related context cells and design a general conversion method to render them into sentences, but these connections can be easily caught by pre-trained table models #REF . On the other side, identifying/re-organizing crucial elements in a sentence to construct a table is also challenging. Simply inserting a whole sentence in a table cell #REF will make the new cells much larger (and unique) than normal ones, thus can not make the most of general pre-trained table models #REF as we expect.",
        "output": "{\"INFORMATION\": [\"works on FEVEROUS generally convert all evidence pieces into\", \"several tables #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"either plain text #REF or\", \"format conversions inevitably lose rich context information for the converted evidence,\"]}"
    },
    {
        "gold": {
            "text": [
                "From",
                "a",
                "technical",
                "point",
                "of",
                "view,",
                "the",
                "domain",
                "of",
                "inflectional",
                "morphology",
                "is",
                "a",
                "rather",
                "well-explored",
                "area,",
                "in",
                "which",
                "most",
                "efforts",
                "are",
                "devoted",
                "to",
                "development",
                "rather",
                "than",
                "research.",
                "Techniques",
                "used",
                "are",
                "based",
                "on",
                "finite-state",
                "transducers",
                "as",
                "used",
                "originally",
                "in",
                "two-level",
                "morphology,",
                "cf.",
                "#TARGET_REF",
                "for",
                "an",
                "overview.",
                "Research",
                "concentrates",
                "to",
                "a",
                "large",
                "extent",
                "on",
                "complicated",
                "phenomena",
                "such",
                "as",
                "Arabic",
                "nonlinear",
                "morphology.",
                "10",
                "Transferring",
                "the",
                "finite-state",
                "approach",
                "from",
                "inflection",
                "to",
                "word",
                "formation",
                "does",
                "not",
                "by",
                "itself",
                "cause",
                "many",
                "additional",
                "problems,",
                "but",
                "it",
                "does",
                "exacerbate",
                "a",
                "number",
                "of",
                "well-known",
                "problems",
                "of",
                "finite-state",
                "mechanisms:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "From a technical point of view, the domain of inflectional morphology is a rather well-explored area, in which most efforts are devoted to development rather than research. Techniques used are based on finite-state transducers as used originally in two-level morphology, cf. #TARGET_REF for an overview. Research concentrates to a large extent on complicated phenomena such as Arabic nonlinear morphology. 10 Transferring the finite-state approach from inflection to word formation does not by itself cause many additional problems, but it does exacerbate a number of well-known problems of finite-state mechanisms:",
        "output": "{\"INFORMATION\": [\"cf. #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Techniques used are based on finite-state transducers as used originally in two-level morphology,\", \"for an overview.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "Italian,",
                "we",
                "train",
                "and",
                "test",
                "solely",
                "on",
                "the",
                "Ita-TimeBank,",
                "whereas",
                "the",
                "current",
                "state",
                "of",
                "the",
                "art",
                "system",
                "trained",
                "on",
                "an",
                "augmented",
                "Ita-TimeBank",
                "#TARGET_REF",
                ",",
                "which",
                "was",
                "enriched",
                "with",
                "more",
                "labeled",
                "data.",
                "Similarly,",
                "in",
                "French,",
                "we",
                "use",
                "the",
                "established",
                "French",
                "TimeBank,",
                "while",
                "experiments",
                "in",
                "French",
                "so",
                "far",
                "have",
                "been",
                "on",
                "self-annotated",
                "#REF",
                "or",
                "TimeML",
                "corpora",
                "#REF",
                ".",
                "Since",
                "these",
                "repositories",
                "of",
                "augmented",
                "data",
                "were",
                "not",
                "available",
                "to",
                "us",
                "at",
                "the",
                "time",
                "of",
                "writing",
                "this",
                "paper,",
                "the",
                "values",
                "reflect",
                "the",
                "same.",
                "However,",
                "it",
                "is",
                "to",
                "be",
                "noted",
                "that",
                "our",
                "system",
                "does",
                "provide",
                "an",
                "accuracy",
                "that",
                "is",
                "close",
                "to",
                "the",
                "currently",
                "reported",
                "stateof-the-art",
                "even",
                "in",
                "the",
                "absence",
                "of",
                "language",
                "specific",
                "features,",
                "explaining",
                "the",
                "fact",
                "that",
                "sub-word",
                "information",
                "is",
                "necessary",
                "for",
                "event",
                "detection",
                "in",
                "Italian",
                "and",
                "French",
                "as",
                "well."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For Italian, we train and test solely on the Ita-TimeBank, whereas the current state of the art system trained on an augmented Ita-TimeBank #TARGET_REF , which was enriched with more labeled data. Similarly, in French, we use the established French TimeBank, while experiments in French so far have been on self-annotated #REF or TimeML corpora #REF . Since these repositories of augmented data were not available to us at the time of writing this paper, the values reflect the same. However, it is to be noted that our system does provide an accuracy that is close to the currently reported stateof-the-art even in the absence of language specific features, explaining the fact that sub-word information is necessary for event detection in Italian and French as well.",
        "output": "{\"INFORMATION\": [\"Ita-TimeBank #TARGET_REF ,\"], \"PERCEPTION\": [\"For Italian, we train and test solely on the Ita-TimeBank,\"], \"BACKGROUND\": [\"whereas the current state of the art system trained on an augmented\", \"which was enriched with more labeled data.\"]}"
    },
    {
        "gold": {
            "text": [
                "Adjectives",
                "are",
                "primarily",
                "used",
                "for",
                "modification",
                "of",
                "nouns.",
                "They",
                "have",
                "lexical",
                "organization",
                "and",
                "semantic",
                "properties",
                "that",
                "are",
                "not",
                "shared",
                "by",
                "other",
                "modifiers",
                "and",
                "are",
                "unique",
                "to",
                "them",
                "#TARGET_REF",
                ".",
                "The",
                "selected",
                "sense",
                "of",
                "the",
                "adjective",
                "sorry",
                "in",
                "WordNet",
                "has",
                "the",
                "gloss",
                "as",
                "feeling",
                "or",
                "expressing",
                "regret",
                "or",
                "sorrow",
                "or",
                "a",
                "sense",
                "of",
                "loss",
                "over",
                "something",
                "done",
                "or",
                "undone.",
                "The",
                "see",
                "also",
                "relation",
                "for",
                "this",
                "is",
                "the",
                "adjective",
                "penitent,",
                "repentant,",
                "which",
                "means",
                "feeling",
                "or",
                "expressing",
                "remorse",
                "for",
                "misdeeds.",
                "Thus,",
                "the",
                "underlying",
                "semantic",
                "connotation",
                "of",
                "the",
                "word",
                "is",
                "a",
                "feeling",
                "or",
                "an",
                "emotional",
                "state.",
                "An",
                "example",
                "of",
                "this",
                "is",
                "the",
                "sentence",
                "in",
                "the",
                "apology",
                "number",
                "3",
                "which",
                "states-We",
                "are",
                "truly",
                "sorry",
                "for",
                "this",
                "and",
                "will",
                "ensure",
                "that",
                "this",
                "never",
                "happens",
                "again.",
                "Here",
                "the",
                "use",
                "of",
                "sorry",
                "refers",
                "to",
                "the",
                "feelings",
                "expressed",
                "by",
                "the",
                "offender.",
                "In",
                "our",
                "dataset,",
                "out",
                "of",
                "the",
                "18",
                "communications,",
                "7",
                "have",
                "the",
                "use",
                "of",
                "sorry.",
                "In",
                "these",
                "7",
                "letters",
                "it",
                "is",
                "used",
                "12",
                "times."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Adjectives are primarily used for modification of nouns. They have lexical organization and semantic properties that are not shared by other modifiers and are unique to them #TARGET_REF . The selected sense of the adjective sorry in WordNet has the gloss as feeling or expressing regret or sorrow or a sense of loss over something done or undone. The see also relation for this is the adjective penitent, repentant, which means feeling or expressing remorse for misdeeds. Thus, the underlying semantic connotation of the word is a feeling or an emotional state. An example of this is the sentence in the apology number 3 which states-We are truly sorry for this and will ensure that this never happens again. Here the use of sorry refers to the feelings expressed by the offender. In our dataset, out of the 18 communications, 7 have the use of sorry. In these 7 letters it is used 12 times.",
        "output": "{\"INFORMATION\": [\"They have lexical organization and semantic properties that are not shared by other modifiers and are unique to them #TARGET_REF .\"], \"PERCEPTION\": [\"The selected sense of the adjective sorry in WordNet has the gloss as feeling or expressing regret or sorrow or a sense of loss over something done or undone. The see also relation for this is the adjective penitent, repentant, which means feeling or expressing remorse for misdeeds.\", \"the underlying semantic connotation of the word is a feeling or an emotional state.\"], \"BACKGROUND\": [\"Adjectives are primarily used for modification of nouns.\", \"An example of this is the sentence in the apology number 3 which states-We are truly sorry for this and will ensure that this never happens again.\"]}"
    },
    {
        "gold": {
            "text": [
                "With",
                "a",
                "slight",
                "abuse",
                "of",
                "notations,",
                "we",
                "use",
                "p",
                "B",
                "(x",
                "t−1",
                ")",
                "to",
                "denote",
                "p",
                "B",
                "(u",
                "t",
                ",",
                "x",
                "t−1",
                ",",
                "c",
                "t−1",
                ").",
                "We",
                "formulate",
                "the",
                "training",
                "loss",
                "for",
                "self-supervised",
                "task",
                "as:L",
                "mem",
                "=",
                "d",
                "i",
                "−",
                "log(b",
                "t",
                "•",
                "p",
                "B",
                "(",
                "l(x",
                "t−1",
                ")))",
                "−",
                "KL(p",
                "B",
                "(x",
                "t−1",
                ")||p",
                "B",
                "(",
                "l(x",
                "t−1",
                "))",
                "(9)where",
                "KL",
                "is",
                "Kullback-Leibler",
                "divergence,",
                "and",
                "l(x",
                "t−1",
                "))",
                "is",
                "the",
                "natural",
                "language",
                "action",
                "obtained",
                "via",
                "the",
                "memory",
                "component.",
                "This",
                "loss",
                "enforces",
                "the",
                "learned",
                "action",
                "representations",
                "to",
                "restore",
                "both",
                "the",
                "ground",
                "truth",
                "and",
                "predicted",
                "state",
                "transitions.",
                "Note",
                "that",
                "the",
                "natural",
                "language",
                "actions",
                "are",
                "sampled",
                "from",
                "categorical",
                "distributions,",
                "which",
                "is",
                "nondifferentiable.",
                "To",
                "get",
                "gradients",
                "for",
                "the",
                "memory",
                "component",
                "during",
                "back-propagation,",
                "we",
                "apply",
                "a",
                "continuous",
                "approximation,",
                "i.e.,",
                "using",
                "gumbelsoftmax",
                "trick",
                "instead",
                "to",
                "conduct",
                "sampling",
                "#TARGET_REF",
                ",",
                "to",
                "enable",
                "end-to-end",
                "differentiability."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "With a slight abuse of notations, we use p B (x t−1 ) to denote p B (u t , x t−1 , c t−1 ). We formulate the training loss for self-supervised task as:L mem = d i − log(b t • p B ( l(x t−1 ))) − KL(p B (x t−1 )||p B ( l(x t−1 )) (9)where KL is Kullback-Leibler divergence, and l(x t−1 )) is the natural language action obtained via the memory component. This loss enforces the learned action representations to restore both the ground truth and predicted state transitions. Note that the natural language actions are sampled from categorical distributions, which is nondifferentiable. To get gradients for the memory component during back-propagation, we apply a continuous approximation, i.e., using gumbelsoftmax trick instead to conduct sampling #TARGET_REF , to enable end-to-end differentiability.",
        "output": "{\"INFORMATION\": [\"instead to conduct sampling #TARGET_REF\"], \"PERCEPTION\": [\"To get gradients for the memory component during back-propagation, we apply\", \"continuous approximation, i.e., using gumbelsoftmax trick\"], \"BACKGROUND\": [\", to enable end-to-end differentiability.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "closely",
                "related",
                "linguistic",
                "concept",
                "and",
                "an",
                "established",
                "task",
                "in",
                "the",
                "last",
                "decade",
                "is",
                "bridging",
                "anaphora",
                "resolution",
                "#TARGET_REF",
                ".",
                "Both",
                "bridging",
                "anaphora",
                "resolution",
                "and",
                "NP",
                "Enrichment",
                "relate",
                "entities",
                "mentioned",
                "in",
                "the",
                "text",
                "via",
                "non-identity",
                "relations.",
                "However,",
                "there",
                "are",
                "a",
                "number",
                "of",
                "major",
                "differences",
                "between",
                "bridging",
                "and",
                "NP",
                "Enrichment.",
                "These",
                "differences",
                "are",
                "summarized",
                "in",
                "Table",
                "8,",
                "and",
                "expanded",
                "upon",
                "in",
                "what",
                "follows."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A closely related linguistic concept and an established task in the last decade is bridging anaphora resolution #TARGET_REF . Both bridging anaphora resolution and NP Enrichment relate entities mentioned in the text via non-identity relations. However, there are a number of major differences between bridging and NP Enrichment. These differences are summarized in Table 8, and expanded upon in what follows.",
        "output": "{\"INFORMATION\": [\"anaphora resolution\"], \"PERCEPTION\": [\"A closely related linguistic concept and an established task in the last decade is bridging\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Considering",
                "the",
                "inevitable",
                "expense",
                "in",
                "format",
                "conversion,",
                "we",
                "believe",
                "that",
                "each",
                "evidence",
                "in",
                "its",
                "original",
                "format",
                "can",
                "contribute",
                "necessary",
                "information",
                "to",
                "final",
                "verification,",
                "thus",
                "should",
                "be",
                "better",
                "encoded",
                "in",
                "its",
                "original",
                "format.",
                "This",
                "further",
                "indicates",
                "that",
                "we",
                "should",
                "design",
                "both",
                "sentence-to-table",
                "and",
                "table(cell)-to-sentence",
                "conversion",
                "methods",
                "to",
                "obtain",
                "all",
                "evidence",
                "in",
                "both",
                "formats,",
                "and",
                "maintain",
                "two",
                "parallel",
                "encoders",
                "to",
                "absorb",
                "the",
                "two",
                "formats,",
                "respectively.",
                "An",
                "advantage",
                "of",
                "doing",
                "so",
                "is",
                "to",
                "maximally",
                "encourage",
                "early",
                "interaction,",
                "which",
                "proves",
                "more",
                "effective",
                "than",
                "pair-wise",
                "encoding",
                "#REF",
                "When",
                "converting",
                "table",
                "evidence",
                "into",
                "sentences,",
                "previous",
                "works",
                "either",
                "convert",
                "table",
                "cells",
                "to",
                "a",
                "concatenation",
                "of",
                "key-value",
                "pairs",
                "#REF",
                ",",
                "or",
                "construct",
                "sentences",
                "in",
                "a",
                "coordinate-description",
                "style",
                "#TARGET_REF",
                ".",
                "They",
                "pay",
                "less",
                "attention",
                "to",
                "the",
                "conventional",
                "organization",
                "of",
                "tables",
                "structures.",
                "We",
                "observe",
                "that,",
                "in",
                "a",
                "table,",
                "the",
                "column",
                "headers",
                "usually",
                "represent",
                "the",
                "types/properties",
                "and",
                "the",
                "row",
                "headers",
                "often",
                "denote",
                "entities",
                "or",
                "scopes.",
                "We",
                "argue",
                "that",
                "one",
                "should",
                "consider",
                "these",
                "conventions",
                "to",
                "convert",
                "a",
                "table",
                "cell",
                "evidence",
                "into",
                "more",
                "natural",
                "sentences,",
                "and",
                "later",
                "pretrained",
                "language",
                "models",
                "will",
                "be",
                "able",
                "to",
                "better",
                "capture",
                "the",
                "contextualized",
                "semantics",
                "of",
                "the",
                "table",
                "cells",
                "from",
                "generated",
                "sentences.",
                "On",
                "the",
                "other",
                "hand,",
                "existing",
                "pre-trained",
                "table",
                "models",
                "are",
                "trained",
                "to",
                "analyze",
                "one",
                "table",
                "at",
                "one",
                "time,",
                "while",
                "previous",
                "evidence",
                "conversion",
                "methods",
                "produce",
                "several",
                "small",
                "tables",
                "for",
                "one",
                "instance.",
                "It",
                "would",
                "be",
                "necessary",
                "to",
                "properly",
                "organize",
                "all",
                "evidence",
                "in",
                "one",
                "table",
                "so",
                "that",
                "pre-trained",
                "table",
                "models",
                "can",
                "allow",
                "the",
                "most",
                "interactions",
                "among",
                "all",
                "evidence",
                "pieces."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Considering the inevitable expense in format conversion, we believe that each evidence in its original format can contribute necessary information to final verification, thus should be better encoded in its original format. This further indicates that we should design both sentence-to-table and table(cell)-to-sentence conversion methods to obtain all evidence in both formats, and maintain two parallel encoders to absorb the two formats, respectively. An advantage of doing so is to maximally encourage early interaction, which proves more effective than pair-wise encoding #REF When converting table evidence into sentences, previous works either convert table cells to a concatenation of key-value pairs #REF , or construct sentences in a coordinate-description style #TARGET_REF . They pay less attention to the conventional organization of tables structures. We observe that, in a table, the column headers usually represent the types/properties and the row headers often denote entities or scopes. We argue that one should consider these conventions to convert a table cell evidence into more natural sentences, and later pretrained language models will be able to better capture the contextualized semantics of the table cells from generated sentences. On the other hand, existing pre-trained table models are trained to analyze one table at one time, while previous evidence conversion methods produce several small tables for one instance. It would be necessary to properly organize all evidence in one table so that pre-trained table models can allow the most interactions among all evidence pieces.",
        "output": "{\"INFORMATION\": [\"When converting table evidence into sentences, previous works\", \"construct sentences in a coordinate-description style #TARGET_REF .\"], \"PERCEPTION\": [\"They pay less attention to the conventional organization of tables structures.\", \"We argue that one should consider these conventions to convert a table cell evidence into more natural sentences, and later pretrained language models will be able to better capture the contextualized semantics of the table cells from generated sentences.\"], \"BACKGROUND\": [\"we should design\", \"table(cell)-to-sentence conversion methods to obtain all evidence\", \"either convert table cells to a concatenation of key-value pairs #REF , or\", \"We observe that, in a table, the column headers usually represent the types/properties and the row headers often denote entities or scopes.\"]}"
    },
    {
        "gold": {
            "text": [
                "Furthermore,",
                "when",
                "the",
                "environment",
                "is",
                "noisy,",
                "or",
                "the",
                "communication",
                "partner",
                "suffers",
                "from",
                "a",
                "motor",
                "or",
                "cognitive",
                "impairment,",
                "multimodal",
                "integration",
                "plays",
                "a",
                "more",
                "critical",
                "role.",
                "Noise",
                "in",
                "communication",
                "can",
                "originate",
                "from",
                "various",
                "sources.",
                "It",
                "can",
                "be",
                "linguistic",
                "noise",
                "(e.g.",
                "spelling",
                "mistakes,",
                "complex",
                "attachments),",
                "visual",
                "ambiguities",
                "(e.g.",
                "clutter",
                "in",
                "the",
                "environment,",
                "occlusions)",
                "or",
                "an",
                "acoustic",
                "noise.",
                "Instead",
                "of",
                "waiting",
                "for",
                "clarification,",
                "combining",
                "the",
                "uncertain",
                "information",
                "from",
                "the",
                "linguistic",
                "channel",
                "with",
                "information",
                "from",
                "the",
                "other",
                "ones",
                "increases",
                "the",
                "fluency",
                "and",
                "the",
                "effectiveness",
                "of",
                "the",
                "communication",
                "#REF",
                ".",
                "One",
                "of",
                "the",
                "most",
                "well-known",
                "examples",
                "to",
                "this",
                "phenomenon",
                "is",
                "the",
                "cocktail",
                "party",
                "effect,",
                "that",
                "highlights",
                "the",
                "human",
                "ability",
                "to",
                "focus",
                "on",
                "one",
                "particular",
                "source",
                "while",
                "inhibiting",
                "the",
                "noisy",
                "ones.",
                "When",
                "the",
                "informativeness",
                "of",
                "one",
                "modality",
                "is",
                "reduced",
                "due",
                "to",
                "environmental",
                "conditions,",
                "the",
                "human",
                "language",
                "processing",
                "system",
                "can",
                "successfully",
                "adjust",
                "itself",
                "by",
                "relying",
                "less",
                "on",
                "the",
                "unclear",
                "modality",
                "and",
                "using",
                "other",
                "cues",
                "in",
                "the",
                "environment.",
                "In",
                "this",
                "specific",
                "scenario,",
                "other",
                "informative",
                "cues",
                "provide",
                "more",
                "reliable",
                "information",
                "compared",
                "to",
                "the",
                "noisy",
                "linguistic",
                "input.",
                "These",
                "cues",
                "can",
                "come",
                "from",
                "the",
                "surrounding",
                "environment",
                "and",
                "from",
                "the",
                "communicational",
                "partners,",
                "and",
                "include",
                "eye-gaze",
                "direction",
                "or",
                "representational",
                "gestures",
                "combined",
                "with",
                "their",
                "referential",
                "link",
                "to",
                "the",
                "entities",
                "in",
                "the",
                "environment.",
                "Eye-tracking",
                "is",
                "attracting",
                "considerable",
                "interest",
                "in",
                "many",
                "assistive",
                "technologies",
                "such",
                "as",
                "educational",
                "VR",
                "systems",
                "that",
                "provide",
                "embodied",
                "learning",
                "environments",
                "or",
                "driver",
                "monitoring",
                "systems.",
                "The",
                "use",
                "of",
                "eye-tracking",
                "in",
                "daily",
                "technological",
                "products",
                "such",
                "as",
                "mobile",
                "phones,",
                "laptops",
                "and",
                "virtual",
                "reality",
                "headsets",
                "is",
                "increasing",
                "day",
                "by",
                "day",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "incorporating",
                "eye-movements",
                "in",
                "our",
                "language",
                "comprehension",
                "models",
                "is",
                "an",
                "inevitable",
                "outcome",
                "of",
                "these",
                "latest",
                "developments,",
                "and",
                "this",
                "makes",
                "the",
                "systematic",
                "research",
                "on",
                "the",
                "combination",
                "of",
                "this",
                "modality",
                "with",
                "others",
                "very",
                "crucial."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Furthermore, when the environment is noisy, or the communication partner suffers from a motor or cognitive impairment, multimodal integration plays a more critical role. Noise in communication can originate from various sources. It can be linguistic noise (e.g. spelling mistakes, complex attachments), visual ambiguities (e.g. clutter in the environment, occlusions) or an acoustic noise. Instead of waiting for clarification, combining the uncertain information from the linguistic channel with information from the other ones increases the fluency and the effectiveness of the communication #REF . One of the most well-known examples to this phenomenon is the cocktail party effect, that highlights the human ability to focus on one particular source while inhibiting the noisy ones. When the informativeness of one modality is reduced due to environmental conditions, the human language processing system can successfully adjust itself by relying less on the unclear modality and using other cues in the environment. In this specific scenario, other informative cues provide more reliable information compared to the noisy linguistic input. These cues can come from the surrounding environment and from the communicational partners, and include eye-gaze direction or representational gestures combined with their referential link to the entities in the environment. Eye-tracking is attracting considerable interest in many assistive technologies such as educational VR systems that provide embodied learning environments or driver monitoring systems. The use of eye-tracking in daily technological products such as mobile phones, laptops and virtual reality headsets is increasing day by day #TARGET_REF . Therefore, incorporating eye-movements in our language comprehension models is an inevitable outcome of these latest developments, and this makes the systematic research on the combination of this modality with others very crucial.",
        "output": "{\"INFORMATION\": [\"The use of eye-tracking in daily technological products such as mobile phones, laptops and virtual reality headsets is increasing day by day #TARGET_REF .\"], \"PERCEPTION\": [\"incorporating eye-movements in our language comprehension models is an inevitable outcome of these latest developments,\"], \"BACKGROUND\": [\"Eye-tracking is attracting considerable interest in many assistive technologies such as educational VR systems\"]}"
    },
    {
        "gold": {
            "text": [
                "When",
                "S",
                "attacks",
                "C,",
                "they",
                "may",
                "express",
                "opposite",
                "sentiments",
                "toward",
                "the",
                "same",
                "target,",
                "whereas",
                "they",
                "may",
                "express",
                "the",
                "same",
                "sentiment",
                "if",
                "S",
                "supports",
                "C",
                "#TARGET_REF",
                "R4:",
                "SentiConflict(S,",
                "C)",
                "→",
                "Attack(S,",
                "C),",
                "R5:",
                "SentiCoherent(S,",
                "C)",
                "→",
                "Support(S,",
                "C)",
                "s.t.",
                "SentiConflict(S,",
                "C)",
                "=",
                "max",
                "i,j",
                "P",
                "(t",
                "S",
                "i",
                "=",
                "t",
                "C",
                "j",
                ")",
                "P",
                "(s",
                "S",
                "i",
                "=",
                "pos)P",
                "(s",
                "C",
                "j",
                "=",
                "neg)",
                "+P",
                "(s",
                "S",
                "i",
                "=",
                "neg)P",
                "(s",
                "C",
                "j",
                "=",
                "pos)",
                ",",
                "SentiCoherent(S,",
                "C)",
                "=",
                "max",
                "i,j",
                "P",
                "(t",
                "S",
                "i",
                "=",
                "t",
                "C",
                "j",
                ")",
                "P",
                "(s",
                "S",
                "i",
                "=",
                "pos)P",
                "(s",
                "C",
                "j",
                "=",
                "pos)",
                "+P",
                "(s",
                "S",
                "i",
                "=",
                "neg)P",
                "(s",
                "C",
                "j",
                "=",
                "neg)",
                ".In",
                "this",
                "work,",
                "targets",
                "are",
                "all",
                "noun",
                "phrases",
                "and",
                "verb",
                "phrases",
                "in",
                "C",
                "and",
                "S.",
                "P",
                "(t",
                "S",
                "i",
                "=",
                "t",
                "C",
                "j",
                ")",
                "is",
                "computed",
                "by",
                "a",
                "textual",
                "entailment",
                "module",
                "(",
                "§4.1),",
                "and",
                "P",
                "(s",
                "S",
                "i",
                ")",
                "and",
                "P",
                "(s",
                "C",
                "j",
                ")",
                "by",
                "a",
                "target-based",
                "sentiment",
                "classifier",
                "(",
                "§4.2)."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "When S attacks C, they may express opposite sentiments toward the same target, whereas they may express the same sentiment if S supports C #TARGET_REF R4: SentiConflict(S, C) → Attack(S, C), R5: SentiCoherent(S, C) → Support(S, C) s.t. SentiConflict(S, C) = max i,j P (t S i = t C j ) P (s S i = pos)P (s C j = neg) +P (s S i = neg)P (s C j = pos) , SentiCoherent(S, C) = max i,j P (t S i = t C j ) P (s S i = pos)P (s C j = pos) +P (s S i = neg)P (s C j = neg) .In this work, targets are all noun phrases and verb phrases in C and S. P (t S i = t C j ) is computed by a textual entailment module ( §4.1), and P (s S i ) and P (s C j ) by a target-based sentiment classifier ( §4.2).",
        "output": "{\"INFORMATION\": [\"they may express the same sentiment if S supports C #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"When S attacks C, they may express opposite sentiments toward the same target,\"]}"
    },
    {
        "gold": {
            "text": [
                "Peru",
                "offers",
                "a",
                "rich",
                "diversity",
                "context",
                "for",
                "machine",
                "translation",
                "research",
                "with",
                "47",
                "native",
                "languages",
                "#REF",
                ".",
                "All",
                "of",
                "them",
                "are",
                "highly",
                "distinguishing",
                "from",
                "Castilian",
                "Spanish,",
                "the",
                "primary",
                "1",
                "Available",
                "in:",
                "https://github.com/aoncevay/mt-peru",
                "official",
                "language",
                "in",
                "the",
                "country",
                "and",
                "the",
                "one",
                "spoken",
                "by",
                "the",
                "majority",
                "of",
                "the",
                "population.",
                "However,",
                "from",
                "the",
                "computational",
                "perspective,",
                "all",
                "of",
                "these",
                "languages",
                "do",
                "not",
                "have",
                "enough",
                "resources,",
                "such",
                "as",
                "monolingual",
                "or",
                "parallel",
                "texts,",
                "and",
                "most",
                "of",
                "them",
                "are",
                "considered",
                "endangered",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "Peru offers a rich diversity context for machine translation research with 47 native languages #REF . All of them are highly distinguishing from Castilian Spanish, the primary 1 Available in: https://github.com/aoncevay/mt-peru official language in the country and the one spoken by the majority of the population. However, from the computational perspective, all of these languages do not have enough resources, such as monolingual or parallel texts, and most of them are considered endangered #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"languages\", \"are considered endangered #TARGET_REF\"], \"PERCEPTION\": [\"most of them\"], \"BACKGROUND\": [\"Peru offers a rich diversity context for machine translation research with 47 native languages #REF\", \"from the computational perspective, all of these\", \"do not have enough resources,\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Homophily,",
                "i.e.,",
                "the",
                "tendency",
                "of",
                "users",
                "in",
                "a",
                "social",
                "space",
                "forge",
                "ties",
                "with",
                "others",
                "who",
                "are",
                "similar",
                "to",
                "them",
                "in",
                "socially",
                "significant",
                "ways",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• Homophily, i.e., the tendency of users in a social space forge ties with others who are similar to them in socially significant ways #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"Homophily, i.e., the tendency of users in a social space forge ties with others who are similar to them in socially significant ways #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Job",
                "Selection",
                "Collecting",
                "and",
                "generating",
                "job",
                "ads",
                "for",
                "all",
                "possible",
                "jobs",
                "is",
                "prohibitively",
                "timely",
                "and",
                "costly.",
                "Hence,",
                "we",
                "restrict",
                "our",
                "experiments",
                "to",
                "a",
                "sample",
                "of",
                "15",
                "jobs",
                "selected",
                "via",
                "three",
                "criteria:",
                "(1)",
                "prevalence,",
                "jobs",
                "with",
                "a",
                "sufficiently",
                "large",
                "labour",
                "force",
                "in",
                "the",
                "UK",
                "(N",
                "≥",
                "40,000),",
                "(2)",
                "relevance,",
                "jobs",
                "which",
                "have",
                "a",
                "sufficiently",
                "large",
                "number",
                "of",
                "real-world",
                "job",
                "ads",
                "on",
                "a",
                "popular",
                "online",
                "forum",
                "(N",
                "≥",
                "1,000)",
                "and",
                "(3)",
                "bias,",
                "jobs",
                "which",
                "represent",
                "the",
                "most",
                "male-biased,",
                "female-biased",
                "and",
                "neutral",
                "parts",
                "of",
                "GPT-3's",
                "prior",
                "distribution",
                "in",
                "how",
                "frequently",
                "certain",
                "jobs",
                "are",
                "associated",
                "with",
                "a",
                "given",
                "gender.",
                "To",
                "apply",
                "these",
                "criteria,",
                "we",
                "first",
                "filter",
                "jobs",
                "in",
                "the",
                "UK",
                "economy",
                "by",
                "prevalence",
                "and",
                "relevance",
                "#TARGET_REF",
                ".",
                "Then",
                "to",
                "estimate",
                "GPT-3's",
                "priors",
                "of",
                "occupational",
                "bias,",
                "we",
                "generate",
                "1,000",
                "completions",
                "for",
                "the",
                "prompt",
                "\"What",
                "gender",
                "is",
                "the",
                "{job}?",
                "The",
                "{job}",
                "is",
                "a",
                "[token]\",",
                "where",
                "a",
                "completion",
                "could",
                "be:",
                "\"What",
                "gender",
                "is",
                "the",
                "plumber?"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Job Selection Collecting and generating job ads for all possible jobs is prohibitively timely and costly. Hence, we restrict our experiments to a sample of 15 jobs selected via three criteria: (1) prevalence, jobs with a sufficiently large labour force in the UK (N ≥ 40,000), (2) relevance, jobs which have a sufficiently large number of real-world job ads on a popular online forum (N ≥ 1,000) and (3) bias, jobs which represent the most male-biased, female-biased and neutral parts of GPT-3's prior distribution in how frequently certain jobs are associated with a given gender. To apply these criteria, we first filter jobs in the UK economy by prevalence and relevance #TARGET_REF . Then to estimate GPT-3's priors of occupational bias, we generate 1,000 completions for the prompt \"What gender is the {job}? The {job} is a [token]\", where a completion could be: \"What gender is the plumber?",
        "output": "{\"INFORMATION\": [\"relevance #TARGET_REF\"], \"PERCEPTION\": [\"we first filter jobs in the UK economy by prevalence and\"], \"BACKGROUND\": [\"Job Selection Collecting and generating job ads for all possible jobs is prohibitively timely and costly. Hence, we restrict our experiments to a sample of 15 jobs selected via three criteria:\", \"To apply these criteria,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "originality",
                "of",
                "WM",
                "lies",
                "in",
                "its",
                "approach",
                "to",
                "reusability.",
                "Ten",
                "#TARGET_REF",
                "present",
                "this",
                "approach",
                "in",
                "terms",
                "of",
                "the",
                "diagram",
                "in",
                "Fig.",
                "1."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The originality of WM lies in its approach to reusability. Ten #TARGET_REF present this approach in terms of the diagram in Fig. 1.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The originality of WM lies in its approach to reusability. Ten\", \"present this approach in terms of the diagram in Fig. 1.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "situation",
                "leads",
                "us",
                "to",
                "consider",
                "the",
                "potential",
                "application",
                "of",
                "shallow",
                "semantic",
                "parsing",
                "and",
                "semantic",
                "role",
                "labeling",
                "models",
                "to",
                "SMT,",
                "in",
                "ways",
                "that",
                "might",
                "reduce",
                "role",
                "confusion",
                "errors",
                "in",
                "the",
                "translation",
                "output.",
                "Within",
                "the",
                "lexical",
                "semantics",
                "community,",
                "increasingly",
                "sophisticated",
                "models",
                "for",
                "shallow",
                "semantic",
                "parsing",
                "are",
                "being",
                "developed.",
                "Such",
                "semantic",
                "parsers,",
                "which",
                "automatically",
                "label",
                "the",
                "predicates",
                "and",
                "arguments",
                "(roles)",
                "of",
                "the",
                "various",
                "semantic",
                "frames",
                "in",
                "a",
                "sentence,",
                "could",
                "automatically",
                "identify",
                "inconsistent",
                "semantic",
                "frame",
                "and",
                "role",
                "mappings",
                "between",
                "the",
                "input",
                "source",
                "sentences",
                "and",
                "their",
                "output",
                "translations.",
                "This",
                "approach",
                "is",
                "supported",
                "by",
                "the",
                "results",
                "of",
                "#TARGET_REF",
                ",",
                "which",
                "reported",
                "that",
                "(for",
                "the",
                "Chinese-English",
                "language",
                "pair)",
                "approximately",
                "84%",
                "of",
                "semantic",
                "role",
                "mappings",
                "remained",
                "consistent",
                "cross-lingually",
                "across",
                "sentence",
                "translations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "This situation leads us to consider the potential application of shallow semantic parsing and semantic role labeling models to SMT, in ways that might reduce role confusion errors in the translation output. Within the lexical semantics community, increasingly sophisticated models for shallow semantic parsing are being developed. Such semantic parsers, which automatically label the predicates and arguments (roles) of the various semantic frames in a sentence, could automatically identify inconsistent semantic frame and role mappings between the input source sentences and their output translations. This approach is supported by the results of #TARGET_REF , which reported that (for the Chinese-English language pair) approximately 84% of semantic role mappings remained consistent cross-lingually across sentence translations.",
        "output": "{\"INFORMATION\": [\"which reported that (for the Chinese-English language pair) approximately 84% of semantic role mappings remained consistent cross-lingually across sentence translations.\"], \"PERCEPTION\": [\"This approach is supported by the results of #TARGET_REF ,\"], \"BACKGROUND\": [\"Within the lexical semantics community, increasingly sophisticated models for shallow semantic parsing are being developed. Such semantic parsers,\", \"could automatically identify inconsistent semantic frame and role mappings between the input source sentences and their output translations.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "most",
                "common",
                "method",
                "of",
                "measuring",
                "the",
                "quality",
                "of",
                "a",
                "MT",
                "metric",
                "is",
                "correlation",
                "with",
                "human",
                "judgments",
                "#TARGET_REF",
                ",",
                "however,",
                "these",
                "correlations",
                "provide",
                "little",
                "information",
                "regard-ing",
                "when",
                "and",
                "why",
                "an",
                "MT",
                "metric",
                "differs",
                "from",
                "human",
                "judgment.",
                "In",
                "this",
                "paper,",
                "we",
                "consider",
                "three",
                "ways",
                "of",
                "examining",
                "MT",
                "metric",
                "quality,",
                "with",
                "the",
                "aim",
                "of",
                "determining",
                "the",
                "failure",
                "cases",
                "of",
                "MT",
                "metrics."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The most common method of measuring the quality of a MT metric is correlation with human judgments #TARGET_REF , however, these correlations provide little information regard-ing when and why an MT metric differs from human judgment. In this paper, we consider three ways of examining MT metric quality, with the aim of determining the failure cases of MT metrics.",
        "output": "{\"INFORMATION\": [\"correlation with human judgments #TARGET_REF\"], \"PERCEPTION\": [\"we consider three ways of examining MT metric quality,\"], \"BACKGROUND\": [\"these correlations provide little information regard-ing when and why an MT metric differs from human judgment.\", \"with the aim of determining the failure cases of MT metrics.\"]}"
    },
    {
        "gold": {
            "text": [
                "Previous",
                "research",
                "has",
                "demonstrated",
                "that",
                "some",
                "demographic",
                "settings",
                "are",
                "inherently",
                "more",
                "abusive",
                "than",
                "others.",
                "For",
                "example,",
                "a",
                "study",
                "by",
                "#REF",
                "mapped",
                "the",
                "locations",
                "of",
                "hateful",
                "tweets",
                "across",
                "the",
                "United",
                "States",
                "to",
                "uncover",
                "the",
                "regions",
                "where",
                "people",
                "use",
                "hate",
                "speech",
                "the",
                "most.",
                "They",
                "observed",
                "that",
                "areas",
                "with",
                "low",
                "diversity",
                "use",
                "more",
                "derogatory",
                "slurs",
                "against",
                "racial",
                "and",
                "sexual",
                "minorities.",
                "A",
                "separate",
                "line",
                "of",
                "work",
                "by",
                "#TARGET_REF",
                "concluded",
                "that",
                "male-only",
                "discussion",
                "groups",
                "on",
                "the",
                "Internet",
                "use",
                "more",
                "coarse",
                "and",
                "abusive",
                "language",
                "than",
                "female-only",
                "groups.",
                "These",
                "works",
                "indicate",
                "that",
                "demographic",
                "settings",
                "can",
                "be",
                "predictive",
                "of",
                "the",
                "(abusive)",
                "nature",
                "of",
                "comments",
                "orig-inating",
                "from",
                "within",
                "them.",
                "User",
                "and",
                "community",
                "information",
                "constitutes",
                "a",
                "direct",
                "and",
                "simple",
                "way",
                "of",
                "capturing",
                "the",
                "demographic",
                "setting",
                "of",
                "a",
                "comment."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Previous research has demonstrated that some demographic settings are inherently more abusive than others. For example, a study by #REF mapped the locations of hateful tweets across the United States to uncover the regions where people use hate speech the most. They observed that areas with low diversity use more derogatory slurs against racial and sexual minorities. A separate line of work by #TARGET_REF concluded that male-only discussion groups on the Internet use more coarse and abusive language than female-only groups. These works indicate that demographic settings can be predictive of the (abusive) nature of comments orig-inating from within them. User and community information constitutes a direct and simple way of capturing the demographic setting of a comment.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF concluded that male-only discussion groups on the Internet use more coarse and abusive language than female-only groups.\"], \"PERCEPTION\": [\"These works indicate that demographic settings can be predictive of the (abusive) nature of comments orig-inating from within them.\"], \"BACKGROUND\": [\"the locations of hateful tweets across the United States to uncover the regions where people use hate speech the most.\", \"areas with low diversity use more derogatory slurs against racial and sexual minorities. A separate line of work by\"]}"
    },
    {
        "gold": {
            "text": [
                "Besides,",
                "leveraging",
                "knowledge",
                "graph",
                "is",
                "not",
                "the",
                "only",
                "way",
                "to",
                "promote",
                "content",
                "diversity",
                "as",
                "it",
                "is",
                "a",
                "highly",
                "knowledge-intensive",
                "task.",
                "Many",
                "existing",
                "knowledge-enhanced",
                "methods",
                "#TARGET_REF",
                "can",
                "be",
                "used",
                "to",
                "acquire",
                "different",
                "external",
                "knowledge",
                "for",
                "producing",
                "diverse",
                "outputs,",
                "e.g.,",
                "taking",
                "different",
                "retrieved",
                "documents",
                "as",
                "conditions",
                "for",
                "generator."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Besides, leveraging knowledge graph is not the only way to promote content diversity as it is a highly knowledge-intensive task. Many existing knowledge-enhanced methods #TARGET_REF can be used to acquire different external knowledge for producing diverse outputs, e.g., taking different retrieved documents as conditions for generator.",
        "output": "{\"INFORMATION\": [\"Many existing knowledge-enhanced methods #TARGET_REF can be used to acquire different external knowledge for producing diverse outputs, e.g., taking different retrieved documents as conditions for generator.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"leveraging knowledge graph is not the only way to promote content diversity as it is a highly knowledge-intensive task.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "table",
                "1",
                "we",
                "have",
                "gathered",
                "some",
                "of",
                "the",
                "most",
                "significant",
                "emotion",
                "datasets",
                "in",
                "relation",
                "to",
                "this",
                "study.",
                "The",
                "table",
                "lists",
                "the",
                "paper",
                "in",
                "which",
                "the",
                "dataset",
                "was",
                "released",
                "(study),",
                "what",
                "the",
                "source",
                "data",
                "that",
                "was",
                "used",
                "was",
                "(source),",
                "what",
                "model",
                "was",
                "used",
                "to",
                "obtain",
                "the",
                "best",
                "evaluation",
                "scores",
                "(model),",
                "the",
                "number",
                "of",
                "categories",
                "used",
                "for",
                "annotation",
                "(cat),",
                "whether",
                "the",
                "system",
                "was",
                "multilabel",
                "or",
                "not",
                "(multi),",
                "and",
                "the",
                "macro",
                "f1",
                "scores",
                "and",
                "accuracy",
                "score",
                "as",
                "reported",
                "by",
                "the",
                "paper",
                "(macro",
                "f1",
                "and",
                "accuracy",
                "respectively).",
                "Some",
                "papers",
                "only",
                "reported",
                "a",
                "micro",
                "f1",
                "and",
                "no",
                "macro",
                "f1",
                "score.",
                "These",
                "scores",
                "have",
                "been",
                "marked",
                "with",
                "a",
                "µ.",
                "The",
                "datasets",
                "in",
                "table",
                "1",
                "differ",
                "from",
                "each",
                "so",
                "much",
                "in",
                "content,",
                "structure,",
                "and",
                "manner",
                "of",
                "annotation",
                "that",
                "direct",
                "comparisons",
                "are",
                "hard",
                "to",
                "make.",
                "Typically,",
                "the",
                "fewer",
                "the",
                "number",
                "of",
                "categories,",
                "the",
                "easier",
                "the",
                "classification",
                "task",
                "and",
                "the",
                "higher",
                "the",
                "evaluation",
                "scores.",
                "It",
                "stands",
                "to",
                "reason",
                "that",
                "the",
                "easier",
                "it",
                "is",
                "to",
                "detect",
                "emotions",
                "in",
                "the",
                "source",
                "data,",
                "the",
                "easier",
                "it",
                "is",
                "for",
                "annotators",
                "to",
                "identify",
                "and",
                "agree",
                "upon",
                "annotation",
                "labels",
                "and",
                "therefore",
                "it",
                "becomes",
                "easier",
                "for",
                "the",
                "system",
                "or",
                "model",
                "to",
                "correctly",
                "classify",
                "the",
                "test",
                "data",
                "as",
                "well.",
                "The",
                "outlier",
                "in",
                "these",
                "datasets",
                "is",
                "EmoNet",
                "#TARGET_REF",
                "which",
                "achieved",
                "astonishing",
                "accuracies",
                "by",
                "using",
                "665",
                "different",
                "hashtags",
                "to",
                "automatically",
                "categorize",
                "1.6",
                "million",
                "tweets",
                "into",
                "24",
                "categories",
                "(Plutchik's",
                "8",
                "at",
                "3",
                "different",
                "intensities),",
                "unfortunately",
                "neither",
                "the",
                "dataset",
                "or",
                "their",
                "model",
                "has",
                "been",
                "made",
                "available",
                "for",
                "closer",
                "inspection."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "In table 1 we have gathered some of the most significant emotion datasets in relation to this study. The table lists the paper in which the dataset was released (study), what the source data that was used was (source), what model was used to obtain the best evaluation scores (model), the number of categories used for annotation (cat), whether the system was multilabel or not (multi), and the macro f1 scores and accuracy score as reported by the paper (macro f1 and accuracy respectively). Some papers only reported a micro f1 and no macro f1 score. These scores have been marked with a µ. The datasets in table 1 differ from each so much in content, structure, and manner of annotation that direct comparisons are hard to make. Typically, the fewer the number of categories, the easier the classification task and the higher the evaluation scores. It stands to reason that the easier it is to detect emotions in the source data, the easier it is for annotators to identify and agree upon annotation labels and therefore it becomes easier for the system or model to correctly classify the test data as well. The outlier in these datasets is EmoNet #TARGET_REF which achieved astonishing accuracies by using 665 different hashtags to automatically categorize 1.6 million tweets into 24 categories (Plutchik's 8 at 3 different intensities), unfortunately neither the dataset or their model has been made available for closer inspection.",
        "output": "{\"INFORMATION\": [\"EmoNet #TARGET_REF\"], \"PERCEPTION\": [\"The datasets\", \"differ from each so much in content, structure, and manner of annotation that direct comparisons are hard to make.\", \"The outlier in these datasets is\", \"which achieved astonishing accuracies by using 665 different hashtags to automatically categorize 1.6 million tweets into 24 categories (Plutchik's 8 at 3 different intensities), unfortunately neither the dataset or their model has been made available for closer inspection.\"], \"BACKGROUND\": [\"in table 1\"]}"
    },
    {
        "gold": {
            "text": [
                "Generative",
                "language",
                "models",
                "are",
                "getting",
                "bigger:",
                "from",
                "ELMo's",
                "release",
                "in",
                "2018",
                "with",
                "94M",
                "parameters",
                "#REF",
                "to",
                "Megatron-Turing",
                "NLG",
                "in",
                "2022",
                "with",
                "530Bn",
                "#REF",
                ",",
                "there",
                "has",
                "been",
                "approximately",
                "a",
                "tenfold",
                "annual",
                "increase",
                "in",
                "parameters.",
                "The",
                "growing",
                "capabilities",
                "of",
                "these",
                "models",
                "have",
                "supported",
                "their",
                "adoption",
                "in",
                "many",
                "downstream",
                "tasks,",
                "from",
                "text",
                "summarisation",
                "#TARGET_REF",
                "and",
                "weather",
                "reporting",
                "#REF",
                "to",
                "writing",
                "code",
                "#REF",
                ".",
                "However,",
                "there",
                "are",
                "various",
                "associated",
                "risks,",
                "such",
                "as",
                "privacy",
                "erosion,",
                "copyright",
                "infringement,",
                "environmental",
                "harms",
                "and",
                "negative",
                "stereotyping",
                "of",
                "social",
                "groups",
                "#REF",
                ".",
                "We",
                "focus",
                "on",
                "the",
                "latter",
                "of",
                "these",
                "risks,",
                "specifically",
                "the",
                "problem",
                "of",
                "gender",
                "bias",
                "with",
                "respect",
                "to",
                "occupation.",
                "*",
                "Equal",
                "contribution."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Generative language models are getting bigger: from ELMo's release in 2018 with 94M parameters #REF to Megatron-Turing NLG in 2022 with 530Bn #REF , there has been approximately a tenfold annual increase in parameters. The growing capabilities of these models have supported their adoption in many downstream tasks, from text summarisation #TARGET_REF and weather reporting #REF to writing code #REF . However, there are various associated risks, such as privacy erosion, copyright infringement, environmental harms and negative stereotyping of social groups #REF . We focus on the latter of these risks, specifically the problem of gender bias with respect to occupation. * Equal contribution.",
        "output": "{\"INFORMATION\": [\"The growing capabilities of these models have supported their adoption in\", \"text summarisation #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Generative language models are getting bigger:\", \"many downstream tasks, from\", \"and weather reporting #REF to writing code #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "utilize",
                "a",
                "standard",
                "Transformer",
                "#TARGET_REF",
                "as",
                "our",
                "generation",
                "model.",
                "It",
                "takes",
                "the",
                "concatenation",
                "of",
                "the",
                "sequence",
                "x",
                "and",
                "all",
                "the",
                "selected",
                "concepts",
                "v",
                "1",
                ",",
                "...,",
                "v",
                "N",
                "as",
                "input",
                "and",
                "auto-regressively",
                "generates",
                "the",
                "outputs",
                "y.",
                "We",
                "adopt",
                "the",
                "cross-entropy",
                "loss,",
                "which",
                "can",
                "be",
                "written",
                "as:L",
                "generation",
                "=",
                "−",
                "log",
                "p(y|x,",
                "v",
                "1",
                ",",
                "•",
                "•",
                "•",
                ",",
                "v",
                "N",
                ")",
                "(5)",
                "=",
                "−",
                "|y|",
                "t=1",
                "log",
                "p(y",
                "t",
                "|x,",
                "v",
                "1",
                ",",
                "•",
                "•",
                "•",
                ",",
                "v",
                "N",
                ",",
                "y",
                "&lt,t",
                ").Note",
                "that",
                "since",
                "the",
                "selected",
                "concepts",
                "do",
                "not",
                "have",
                "a",
                "rigorous",
                "order,",
                "we",
                "only",
                "apply",
                "positional",
                "encodings",
                "(used",
                "in",
                "Transformer)",
                "to",
                "the",
                "input",
                "sequence",
                "x."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We utilize a standard Transformer #TARGET_REF as our generation model. It takes the concatenation of the sequence x and all the selected concepts v 1 , ..., v N as input and auto-regressively generates the outputs y. We adopt the cross-entropy loss, which can be written as:L generation = − log p(y|x, v 1 , • • • , v N ) (5) = − |y| t=1 log p(y t |x, v 1 , • • • , v N , y &lt,t ).Note that since the selected concepts do not have a rigorous order, we only apply positional encodings (used in Transformer) to the input sequence x.",
        "output": "{\"INFORMATION\": [\"standard Transformer\", \"as our generation model.\"], \"PERCEPTION\": [\"We utilize a\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "At",
                "a",
                "high",
                "level,",
                "the",
                "entire",
                "premise",
                "of",
                "our",
                "work",
                "is",
                "the",
                "point",
                "of",
                "multi-stage",
                "ranking,",
                "in",
                "that",
                "the",
                "architecture",
                "evolved",
                "to",
                "achieve",
                "a",
                "good",
                "balance",
                "between",
                "effectiveness",
                "and",
                "efficiency",
                "in",
                "end-to-end",
                "retrieval.",
                "Motivated",
                "by",
                "the",
                "observation,",
                "dating",
                "back",
                "more",
                "than",
                "a",
                "decade,",
                "that",
                "effective",
                "techniques",
                "are",
                "often",
                "computationally",
                "expensive,",
                "multi-stage",
                "retrieval",
                "architectures",
                "control",
                "latency",
                "by",
                "applying",
                "expensive",
                "techniques",
                "over",
                "only",
                "the",
                "most",
                "promising",
                "candidates",
                "#REF",
                ".",
                "This",
                "is",
                "often",
                "operationalized",
                "as",
                "optimizing",
                "for",
                "recall",
                "in",
                "the",
                "earlier",
                "stages",
                "of",
                "the",
                "pipeline.",
                "Specifically",
                "in",
                "the",
                "context",
                "of",
                "transformers,",
                "multi-stage",
                "neural",
                "pipelines",
                "have",
                "been",
                "explored",
                "in",
                "the",
                "past",
                "by",
                "many",
                "researchers",
                "#REF",
                ".",
                "The",
                "key",
                "difference",
                "in",
                "our",
                "work",
                "is",
                "the",
                "(re-)introduction",
                "of",
                "\"traditional\"",
                "feature-based",
                "learning-to-rank",
                "approaches",
                "alongside",
                "neural",
                "models.",
                "This",
                "aligns",
                "with",
                "our",
                "broader",
                "goal",
                "of",
                "investigating",
                "how",
                "learning",
                "to",
                "rank",
                "might",
                "contribute",
                "to",
                "modern",
                "retrieval",
                "approaches",
                "dominated",
                "by",
                "neural",
                "models.",
                "The",
                "computational",
                "costs",
                "associated",
                "with",
                "ranking",
                "using",
                "pretrained",
                "transformers",
                "can",
                "be",
                "reduced",
                "in",
                "various",
                "ways.",
                "We",
                "can",
                "accelerate",
                "inference",
                "using",
                "smaller",
                "or",
                "simpler",
                "models.",
                "#REF",
                "use",
                "distillation",
                "to",
                "transfer",
                "knowledge",
                "captured",
                "in",
                "a",
                "larger",
                "model",
                "into",
                "a",
                "smaller",
                "model,",
                "achieving",
                "substantial",
                "speedups",
                "with",
                "minimal",
                "effectiveness",
                "loss.",
                "#REF",
                "propose",
                "a",
                "simpler",
                "transformer",
                "model",
                "to",
                "capture",
                "contextual",
                "information",
                "that",
                "trades",
                "effectiveness",
                "for",
                "much",
                "faster",
                "inference.",
                "Additional",
                "examples",
                "of",
                "this",
                "approach",
                "include",
                "#REF",
                ".",
                "An",
                "alternative",
                "is",
                "to",
                "introduce",
                "early-exit",
                "optimizations,",
                "as",
                "in",
                "#REF",
                "and",
                "#TARGET_REF",
                ".",
                "Further",
                "speedups",
                "can",
                "be",
                "gained",
                "by",
                "making",
                "modifications",
                "to",
                "the",
                "backbone",
                "transformer",
                "model,",
                "as",
                "in",
                "#REF",
                ".",
                "The",
                "key",
                "point",
                "is",
                "that",
                "our",
                "proposed",
                "LTR",
                "filtering",
                "module",
                "achieves",
                "speedups",
                "in",
                "a",
                "manner",
                "that",
                "is",
                "orthogonal",
                "to",
                "the",
                "methods",
                "discussed",
                "here,",
                "which",
                "focus",
                "on",
                "directly",
                "accelerating",
                "transformer",
                "inference.",
                "Thus,",
                "these",
                "approaches",
                "can",
                "be",
                "combined",
                "with",
                "our",
                "method",
                "for",
                "even",
                "greater",
                "efficiency",
                "gains."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "At a high level, the entire premise of our work is the point of multi-stage ranking, in that the architecture evolved to achieve a good balance between effectiveness and efficiency in end-to-end retrieval. Motivated by the observation, dating back more than a decade, that effective techniques are often computationally expensive, multi-stage retrieval architectures control latency by applying expensive techniques over only the most promising candidates #REF . This is often operationalized as optimizing for recall in the earlier stages of the pipeline. Specifically in the context of transformers, multi-stage neural pipelines have been explored in the past by many researchers #REF . The key difference in our work is the (re-)introduction of \"traditional\" feature-based learning-to-rank approaches alongside neural models. This aligns with our broader goal of investigating how learning to rank might contribute to modern retrieval approaches dominated by neural models. The computational costs associated with ranking using pretrained transformers can be reduced in various ways. We can accelerate inference using smaller or simpler models. #REF use distillation to transfer knowledge captured in a larger model into a smaller model, achieving substantial speedups with minimal effectiveness loss. #REF propose a simpler transformer model to capture contextual information that trades effectiveness for much faster inference. Additional examples of this approach include #REF . An alternative is to introduce early-exit optimizations, as in #REF and #TARGET_REF . Further speedups can be gained by making modifications to the backbone transformer model, as in #REF . The key point is that our proposed LTR filtering module achieves speedups in a manner that is orthogonal to the methods discussed here, which focus on directly accelerating transformer inference. Thus, these approaches can be combined with our method for even greater efficiency gains.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF .\"], \"PERCEPTION\": [\"An alternative is to introduce early-exit optimizations, as in #REF and\"], \"BACKGROUND\": [\"#REF propose a simpler transformer model to capture contextual information that trades effectiveness for much faster inference.\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "current",
                "need",
                "for",
                "accurate",
                "ROI",
                "analysis",
                "schemes",
                "for",
                "LSPs.",
                "As",
                "#TARGET_REF",
                "discuss,",
                "LSPs",
                "that",
                "have",
                "not",
                "incorporated",
                "MT",
                "in",
                "their",
                "internal",
                "workflow",
                "by",
                "2015",
                "will",
                "be",
                "facing",
                "the",
                "risk",
                "of",
                "bankruptcy.",
                "Moreover,",
                "both",
                "researchers",
                "and",
                "professionals",
                "agree",
                "it",
                "is",
                "out",
                "of",
                "the",
                "question",
                "whether",
                "LSPs",
                "should",
                "implement",
                "the",
                "usage",
                "of",
                "MT",
                "in",
                "their",
                "respective",
                "businesses",
                "or",
                "not.",
                "The",
                "question",
                "has",
                "shifted",
                "to",
                "how",
                "LSPs",
                "can",
                "profit",
                "from",
                "the",
                "usage",
                "of",
                "MT",
                "internally",
                "and",
                "harvest",
                "the",
                "proven",
                "benefits."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There is a current need for accurate ROI analysis schemes for LSPs. As #TARGET_REF discuss, LSPs that have not incorporated MT in their internal workflow by 2015 will be facing the risk of bankruptcy. Moreover, both researchers and professionals agree it is out of the question whether LSPs should implement the usage of MT in their respective businesses or not. The question has shifted to how LSPs can profit from the usage of MT internally and harvest the proven benefits.",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [], \"BACKGROUND\": [\"As #TARGET_REF discuss, LSPs that have not incorporated MT in their internal workflow by 2015 will be facing the risk of bankruptcy.\"]}"
    },
    {
        "gold": {
            "text": [
                "It",
                "has",
                "been",
                "widely",
                "observed",
                "that",
                "the",
                "negative",
                "impacts",
                "of",
                "such",
                "errors",
                "on",
                "the",
                "utility",
                "of",
                "the",
                "translation",
                "are",
                "inadequately",
                "reflected",
                "by",
                "evaluation",
                "metrics",
                "based",
                "on",
                "lexical",
                "criteria.",
                "The",
                "accuracy",
                "of",
                "translation",
                "lexical",
                "choice",
                "has",
                "reached",
                "increasingly",
                "satisfactory",
                "levels-at",
                "least",
                "for",
                "largely",
                "literal",
                "genres",
                "such",
                "as",
                "newswire",
                "-which",
                "helps",
                "boost",
                "lexically",
                "oriented",
                "scores",
                "such",
                "as",
                "BLEU",
                "#REF",
                "or",
                "METEOR",
                "#TARGET_REF",
                "despite",
                "serious",
                "role",
                "confusion",
                "errors",
                "in",
                "the",
                "translations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "It has been widely observed that the negative impacts of such errors on the utility of the translation are inadequately reflected by evaluation metrics based on lexical criteria. The accuracy of translation lexical choice has reached increasingly satisfactory levels-at least for largely literal genres such as newswire -which helps boost lexically oriented scores such as BLEU #REF or METEOR #TARGET_REF despite serious role confusion errors in the translations.",
        "output": "{\"INFORMATION\": [\"METEOR #TARGET_REF\"], \"PERCEPTION\": [\"The accuracy of translation lexical choice has reached increasingly satisfactory levels-at least for largely literal genres such as newswire -which helps boost lexically oriented scores\", \"despite serious role confusion errors in the translations.\"], \"BACKGROUND\": [\"It has been widely observed that the negative impacts of such errors on the utility of the translation are inadequately reflected by evaluation metrics based on lexical criteria.\", \"such as BLEU #REF or\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "specification",
                "phase",
                "of",
                "the",
                "project",
                "the",
                "formal",
                "representation",
                "of",
                "the",
                "\"conceptual",
                "core\"",
                "of",
                "the",
                "lexicons",
                "was",
                "designed,",
                "and",
                "the",
                "basic",
                "structured",
                "set",
                "of",
                "\"meaning-types\"",
                "-i.e.",
                "the",
                "core",
                "ontology",
                "-to",
                "be",
                "used",
                "as",
                "a",
                "common",
                "starting",
                "point",
                "and",
                "a",
                "shared",
                "device",
                "to",
                "build",
                "the",
                "harmonised",
                "language",
                "specific",
                "semantic",
                "lexicons",
                "was",
                "defined",
                "(see",
                "#TARGET_REF",
                ".",
                "Such",
                "a",
                "task",
                "has",
                "tackled",
                "questions",
                "that",
                "are",
                "at",
                "the",
                "core",
                "of",
                "lexical",
                "semantics",
                "research.",
                "The",
                "development",
                "of",
                "twelve",
                "harmonised",
                "semantic",
                "lexicons",
                "requires",
                "strong",
                "mechanisms",
                "for",
                "guaranteeing",
                "uniformity",
                "and",
                "consistency",
                "of",
                "the",
                "representations.",
                "These",
                "mechanisms,",
                "in",
                "turn,",
                "guarantee",
                "that",
                "within",
                "the",
                "same",
                "language",
                "consistent",
                "formal",
                "devices",
                "apply",
                "cross-domain",
                "and",
                "cross-categorially.",
                "Finally,",
                "the",
                "multilingual",
                "component",
                "translates",
                "into",
                "the",
                "requirement",
                "of",
                "identifying",
                "elements",
                "of",
                "the",
                "semantic",
                "vocabulary",
                "for",
                "structuring",
                "word",
                "meaning",
                "which",
                "are",
                "at",
                "the",
                "same",
                "time",
                "independent",
                "from",
                "any",
                "individual",
                "language",
                "but",
                "able",
                "to",
                "capture",
                "linguistically",
                "useful",
                "generalisations",
                "for",
                "different",
                "NLP",
                "tasks."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the specification phase of the project the formal representation of the \"conceptual core\" of the lexicons was designed, and the basic structured set of \"meaning-types\" -i.e. the core ontology -to be used as a common starting point and a shared device to build the harmonised language specific semantic lexicons was defined (see #TARGET_REF . Such a task has tackled questions that are at the core of lexical semantics research. The development of twelve harmonised semantic lexicons requires strong mechanisms for guaranteeing uniformity and consistency of the representations. These mechanisms, in turn, guarantee that within the same language consistent formal devices apply cross-domain and cross-categorially. Finally, the multilingual component translates into the requirement of identifying elements of the semantic vocabulary for structuring word meaning which are at the same time independent from any individual language but able to capture linguistically useful generalisations for different NLP tasks.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"the formal representation of the \\\"conceptual core\\\" of the lexicons was designed, and the basic structured set of \\\"meaning-types\\\" -i.e. the core ontology -to be used as a common starting point and a shared device to build the harmonised language specific semantic lexicons was defined (see\", \"Such a task has tackled questions that are at the core of lexical semantics research.\"]}"
    },
    {
        "gold": {
            "text": [
                "Concerning",
                "the",
                "use",
                "of",
                "examples",
                "for",
                "generation",
                "by",
                "'recombination',",
                "since",
                "the",
                "system",
                "is",
                "example-based,",
                "the",
                "issue",
                "here",
                "is",
                "not",
                "so",
                "much",
                "generation",
                "from",
                "representations",
                "-which",
                "are",
                "largely",
                "given",
                "a",
                "priori",
                "by",
                "the",
                "corpus",
                "of",
                "examples",
                "-but",
                "the",
                "capability",
                "of",
                "such",
                "a",
                "mechanism",
                "to",
                "generate",
                "texts",
                "which",
                "are",
                "not",
                "directly",
                "represented",
                "in",
                "the",
                "database",
                "of",
                "examples.",
                "The",
                "general",
                "advantages",
                "of",
                "example-based",
                "natural",
                "language",
                "processing",
                "have",
                "already",
                "been",
                "discussed.",
                "However,",
                "it",
                "is",
                "very",
                "much",
                "appreciated",
                "that",
                "in",
                "order",
                "for",
                "example-based",
                "systems",
                "to",
                "have",
                "any",
                "real",
                "degree",
                "of",
                "flexibility",
                "they",
                "must",
                "be",
                "afforded",
                "some",
                "degree",
                "of",
                "generative",
                "capacity",
                "above",
                "and",
                "beyond",
                "that",
                "supported",
                "by",
                "'static'",
                "individual",
                "examples.",
                "This",
                "increased",
                "flexibility",
                "is",
                "gained",
                "by",
                "matching",
                "against",
                "subcomponents",
                "of",
                "more",
                "than",
                "one",
                "example",
                "across",
                "the",
                "example",
                "database.",
                "This",
                "may",
                "occur",
                "when",
                "an",
                "input",
                "text",
                "does",
                "not",
                "match",
                "against",
                "one",
                "complete",
                "example",
                "but",
                "several",
                "examples",
                "match",
                "against",
                "parts",
                "of",
                "the",
                "input.",
                "Obviously",
                "it",
                "is",
                "important",
                "not",
                "to",
                "reject",
                "the",
                "input",
                "text",
                "outright",
                "as",
                "'ill-formed'",
                "in",
                "some",
                "way,",
                "but",
                "attempt",
                "to",
                "generate",
                "a",
                "corresponding",
                "'clone'",
                "(",
                "#TARGET_REF",
                ")",
                "of",
                "the",
                "input",
                "based",
                "on",
                "the",
                "highest",
                "scoring",
                "matches",
                "returned",
                "by",
                "the",
                "matching",
                "process.",
                "There",
                "is",
                "a",
                "need",
                "for",
                "information",
                "to",
                "guide",
                "this",
                "process,",
                "and",
                "this",
                "information",
                "comes",
                "from",
                "the",
                "intentional",
                "model",
                "and",
                "domain",
                "knowledge."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Concerning the use of examples for generation by 'recombination', since the system is example-based, the issue here is not so much generation from representations -which are largely given a priori by the corpus of examples -but the capability of such a mechanism to generate texts which are not directly represented in the database of examples. The general advantages of example-based natural language processing have already been discussed. However, it is very much appreciated that in order for example-based systems to have any real degree of flexibility they must be afforded some degree of generative capacity above and beyond that supported by 'static' individual examples. This increased flexibility is gained by matching against subcomponents of more than one example across the example database. This may occur when an input text does not match against one complete example but several examples match against parts of the input. Obviously it is important not to reject the input text outright as 'ill-formed' in some way, but attempt to generate a corresponding 'clone' ( #TARGET_REF ) of the input based on the highest scoring matches returned by the matching process. There is a need for information to guide this process, and this information comes from the intentional model and domain knowledge.",
        "output": "{\"INFORMATION\": [\"attempt to generate a corresponding 'clone' ( #TARGET_REF ) of the input based on the highest scoring matches returned by the matching process.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Obviously it is important not to reject the input text outright as 'ill-formed' in some way,\", \"There is a need for information to guide this process, and this information comes from the intentional model and domain knowledge.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "two",
                "recent",
                "models",
                "from",
                "the",
                "Quoref",
                "leaderboard:",
                "RoBERTa",
                "#REF",
                "and",
                "TASE",
                "(Segal",
                "et",
                "al.,",
                "2020),",
                "from",
                "which",
                "TASE",
                "has",
                "the",
                "state-ofthe-art",
                "results.",
                "We",
                "use",
                "RoBERTa-large",
                "from",
                "Hug-gingFace",
                "#TARGET_REF",
                ".",
                "TASE",
                "casts",
                "MRC",
                "as",
                "a",
                "sequence",
                "tagging",
                "problem",
                "to",
                "handle",
                "questions",
                "with",
                "multi-span",
                "answers.",
                "It",
                "assigns",
                "a",
                "tag",
                "to",
                "every",
                "token",
                "of",
                "the",
                "context",
                "indicating",
                "whether",
                "the",
                "token",
                "is",
                "a",
                "part",
                "of",
                "the",
                "answer.",
                "We",
                "use",
                "the",
                "TASE",
                "IO",
                "+SSE",
                "setup",
                "that",
                "is",
                "a",
                "combination",
                "of",
                "their",
                "multi-span",
                "architecture",
                "and",
                "single-span",
                "extraction",
                "with",
                "IO",
                "tagging.We",
                "use",
                "the",
                "same",
                "configuration",
                "and",
                "hyper-parameters",
                "for",
                "TASE",
                "IO",
                "+SSE",
                "as",
                "described",
                "in",
                "#REF",
                ".",
                "We",
                "train",
                "all",
                "models",
                "for",
                "two",
                "epochs",
                "in",
                "all",
                "experiments.",
                "11",
                "We",
                "use",
                "the",
                "F1",
                "score",
                "that",
                "calculates",
                "the",
                "number",
                "of",
                "shared",
                "words",
                "between",
                "predictions",
                "and",
                "gold",
                "answers",
                "for",
                "evaluation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use two recent models from the Quoref leaderboard: RoBERTa #REF and TASE (Segal et al., 2020), from which TASE has the state-ofthe-art results. We use RoBERTa-large from Hug-gingFace #TARGET_REF . TASE casts MRC as a sequence tagging problem to handle questions with multi-span answers. It assigns a tag to every token of the context indicating whether the token is a part of the answer. We use the TASE IO +SSE setup that is a combination of their multi-span architecture and single-span extraction with IO tagging.We use the same configuration and hyper-parameters for TASE IO +SSE as described in #REF . We train all models for two epochs in all experiments. 11 We use the F1 score that calculates the number of shared words between predictions and gold answers for evaluation.",
        "output": "{\"INFORMATION\": [\"RoBERTa-large from Hug-gingFace #TARGET_REF .\"], \"PERCEPTION\": [\"We use\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Recently,",
                "#REF",
                "and",
                "#REF",
                "have",
                "shown",
                "that",
                "multilingual",
                "models",
                "underperformed,",
                "when",
                "applied",
                "on",
                "poorly",
                "endowed",
                "languages.",
                "Additionally,",
                "as",
                "mentioned",
                "in",
                "subsection",
                "2.1,",
                "recent",
                "works",
                "#TARGET_REF",
                "have",
                "highlighted",
                "the",
                "limitation",
                "of",
                "Transformer-based",
                "transfer",
                "learning",
                "with",
                "strong",
                "instabilities",
                "arising",
                "from",
                "the",
                "small-scale",
                "learning."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Recently, #REF and #REF have shown that multilingual models underperformed, when applied on poorly endowed languages. Additionally, as mentioned in subsection 2.1, recent works #TARGET_REF have highlighted the limitation of Transformer-based transfer learning with strong instabilities arising from the small-scale learning.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF have highlighted the limitation of Transformer-based transfer learning with strong instabilities arising from the small-scale learning.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"as mentioned in subsection 2.1, recent works\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "empower",
                "the",
                "generation",
                "model",
                "to",
                "produce",
                "multiple",
                "reasonable",
                "outputs,",
                "we",
                "employ",
                "a",
                "mixture",
                "of",
                "expert",
                "(MoE)",
                "module",
                "to",
                "model",
                "uncertainty",
                "and",
                "generate",
                "diverse",
                "outputs.",
                "While",
                "the",
                "MoE",
                "models",
                "have",
                "primarily",
                "been",
                "explored",
                "as",
                "a",
                "means",
                "of",
                "increasing",
                "model",
                "capacity,",
                "they",
                "are",
                "also",
                "being",
                "used",
                "to",
                "boost",
                "diverse",
                "generation",
                "process",
                "#TARGET_REF",
                ".",
                "Formally,",
                "the",
                "MoE",
                "module",
                "introduces",
                "a",
                "multinomial",
                "latent",
                "variable",
                "z",
                "∈",
                "{1,",
                "•",
                "•",
                "•",
                ",",
                "K},",
                "and",
                "decomposes",
                "the",
                "marginal",
                "likelihood",
                "as",
                "follows:p(y|x,",
                "G",
                "x",
                ")",
                "=",
                "K",
                "z=1",
                "p(z|x,",
                "G",
                "x",
                ")p(y|z,",
                "x,",
                "G",
                "x",
                ").",
                "(7)Training.",
                "We",
                "minimize",
                "the",
                "loss",
                "function",
                "(in",
                "Eq.(",
                "6))",
                "using",
                "the",
                "MoE",
                "decomposition,∇",
                "log",
                "p(y|x,",
                "G",
                "x",
                ")",
                "(8)",
                "=",
                "K",
                "z=1",
                "p(z|x,",
                "y,",
                "G",
                "x",
                ")",
                "•",
                "∇",
                "log",
                "p(y,",
                "z|x,",
                "G",
                "x",
                "),and",
                "train",
                "the",
                "model",
                "with",
                "the",
                "EM",
                "algorithm",
                "#REF",
                ".",
                "Ideally,",
                "we",
                "would",
                "like",
                "different",
                "experts",
                "to",
                "specialize",
                "in",
                "different",
                "reasoning",
                "abilities",
                "so",
                "that",
                "they",
                "can",
                "generate",
                "diverse",
                "outputs.",
                "The",
                "specialization",
                "of",
                "experts",
                "means",
                "that",
                "given",
                "the",
                "input,",
                "only",
                "one",
                "element",
                "in",
                "{p(y,",
                "z|x,",
                "G",
                "x",
                ")}",
                "K",
                "z=1",
                "should",
                "dominate",
                "in",
                "value",
                "#REF",
                ".",
                "To",
                "encourage",
                "this,",
                "we",
                "employ",
                "a",
                "hard",
                "mixture",
                "model",
                "to",
                "maximize",
                "max",
                "z",
                "p(y,",
                "z|x,",
                "G",
                "x",
                ")",
                "by",
                "assigning",
                "full",
                "responsibility",
                "to",
                "the",
                "expert",
                "with",
                "the",
                "largest",
                "joint",
                "probability.",
                "Training",
                "proceeds",
                "via",
                "hard-EM",
                "can",
                "be",
                "written",
                "as:"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To empower the generation model to produce multiple reasonable outputs, we employ a mixture of expert (MoE) module to model uncertainty and generate diverse outputs. While the MoE models have primarily been explored as a means of increasing model capacity, they are also being used to boost diverse generation process #TARGET_REF . Formally, the MoE module introduces a multinomial latent variable z ∈ {1, • • • , K}, and decomposes the marginal likelihood as follows:p(y|x, G x ) = K z=1 p(z|x, G x )p(y|z, x, G x ). (7)Training. We minimize the loss function (in Eq.( 6)) using the MoE decomposition,∇ log p(y|x, G x ) (8) = K z=1 p(z|x, y, G x ) • ∇ log p(y, z|x, G x ),and train the model with the EM algorithm #REF . Ideally, we would like different experts to specialize in different reasoning abilities so that they can generate diverse outputs. The specialization of experts means that given the input, only one element in {p(y, z|x, G x )} K z=1 should dominate in value #REF . To encourage this, we employ a hard mixture model to maximize max z p(y, z|x, G x ) by assigning full responsibility to the expert with the largest joint probability. Training proceeds via hard-EM can be written as:",
        "output": "{\"INFORMATION\": [\"MoE models have\", \"been explored as a means of increasing model capacity,\", \"being used to boost diverse generation process #TARGET_REF .\"], \"PERCEPTION\": [\"While the\", \"primarily\", \"they are also\"], \"BACKGROUND\": [\"To empower the generation model to produce multiple reasonable outputs, we employ a mixture of expert (MoE) module to model uncertainty and generate diverse outputs.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Coordinated",
                "behavior",
                "or",
                "brigading,",
                "i.e.,",
                "when",
                "users",
                "with",
                "similar",
                "beliefs",
                "act",
                "in",
                "a",
                "coordinated",
                "manner",
                "in",
                "a",
                "social",
                "space",
                "towards",
                "some",
                "common",
                "objective",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "• Coordinated behavior or brigading, i.e., when users with similar beliefs act in a coordinated manner in a social space towards some common objective #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"Coordinated behavior or brigading, i.e., when users with similar beliefs act in a coordinated manner in a social space towards some common objective #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "compare",
                "with",
                "the",
                "following",
                "baselines",
                "that",
                "do",
                "not",
                "consider",
                "conditioned",
                "generation:",
                "(1)",
                "Seqto-Seq",
                "#REF",
                "implemented",
                "based",
                "on",
                "transformer",
                "#REF",
                ",",
                "(2)",
                "TSCP",
                "#REF",
                ",",
                "and",
                "two",
                "baselines",
                "that",
                "adopt",
                "latent",
                "action",
                "learning",
                "for",
                "conditioned",
                "generation:",
                "(3)",
                "LaRL",
                "#REF",
                ",",
                "(4)",
                "MALA",
                "#REF",
                ".",
                "Note",
                "that",
                "for",
                "these",
                "two",
                "approaches,",
                "we",
                "experiment",
                "with",
                "both",
                "discrete",
                "and",
                "continuous",
                "latent",
                "action",
                "representations.",
                "We",
                "also",
                "compare",
                "the",
                "full",
                "model",
                "MASP",
                "with",
                "its",
                "two",
                "variants:",
                "(1)",
                "Post-hoc",
                "Saliency",
                "obtains",
                "action",
                "representations",
                "via",
                "the",
                "importance",
                "attribution",
                "technique",
                "as",
                "#TARGET_REF",
                ",",
                "(2)",
                "Memory-based",
                "Saliency",
                "employs",
                "the",
                "same",
                "memory",
                "component",
                "as",
                "MASP",
                "but",
                "trained",
                "without",
                "the",
                "pseudo",
                "parallel",
                "corpus."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We compare with the following baselines that do not consider conditioned generation: (1) Seqto-Seq #REF implemented based on transformer #REF , (2) TSCP #REF , and two baselines that adopt latent action learning for conditioned generation: (3) LaRL #REF , (4) MALA #REF . Note that for these two approaches, we experiment with both discrete and continuous latent action representations. We also compare the full model MASP with its two variants: (1) Post-hoc Saliency obtains action representations via the importance attribution technique as #TARGET_REF , (2) Memory-based Saliency employs the same memory component as MASP but trained without the pseudo parallel corpus.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF ,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Post-hoc Saliency obtains action representations via the importance attribution technique as\"]}"
    },
    {
        "gold": {
            "text": [
                "(1)",
                "we",
                "compare",
                "extracted",
                "entity-attribute",
                "pairs",
                "to",
                "those",
                "extracted",
                "by",
                "the",
                "previous",
                "state-ofthe-art",
                "Biperpedia",
                "#TARGET_REF",
                "and",
                "(",
                "2)",
                "we",
                "report",
                "precision",
                "over",
                "a",
                "small",
                "set",
                "of",
                "longtail",
                "entityattribute",
                "pairs",
                "that",
                "did",
                "not",
                "appear",
                "in",
                "our",
                "distant",
                "supervision."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "(1) we compare extracted entity-attribute pairs to those extracted by the previous state-ofthe-art Biperpedia #TARGET_REF and ( 2) we report precision over a small set of longtail entityattribute pairs that did not appear in our distant supervision.",
        "output": "{\"INFORMATION\": [\"Biperpedia #TARGET_REF\"], \"PERCEPTION\": [\"(1) we compare extracted entity-attribute pairs to those extracted by the previous state-ofthe-art\", \"and ( 2) we report precision over a small set of longtail entityattribute pairs that did not appear in our distant supervision.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "disentangle",
                "dataset",
                "shift",
                "and",
                "evidence",
                "ambiguity",
                "of",
                "the",
                "data",
                "splitting",
                "strategy,",
                "we",
                "apply",
                "RDS",
                "stochastic",
                "choice",
                "reward",
                "mechanism",
                "#TARGET_REF",
                "to",
                "create",
                "public",
                "training,",
                "public-and",
                "private",
                "testing",
                "sets.",
                "Figure",
                "3",
                "illustrates",
                "the",
                "learning",
                "dynamic",
                "towards",
                "the",
                "goal."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To disentangle dataset shift and evidence ambiguity of the data splitting strategy, we apply RDS stochastic choice reward mechanism #TARGET_REF to create public training, public-and private testing sets. Figure 3 illustrates the learning dynamic towards the goal.",
        "output": "{\"INFORMATION\": [\"RDS stochastic choice reward mechanism #TARGET_REF to create public training, public-and private testing sets.\"], \"PERCEPTION\": [\"To disentangle dataset shift and evidence ambiguity of the data splitting strategy, we apply\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "\"It",
                "is",
                "well",
                "known",
                "that",
                "Western",
                "Languages",
                "are",
                "50%",
                "redundant.",
                "Experiment",
                "shows",
                "that",
                "if",
                "an",
                "average",
                "person",
                "guesses",
                "the",
                "successive",
                "words",
                "in",
                "a",
                "completely",
                "unknown",
                "sentence",
                "he",
                "has",
                "to",
                "be",
                "told",
                "only",
                "half",
                "of",
                "them.",
                "Experiment",
                "shows",
                "that",
                "this",
                "also",
                "applies",
                "to",
                "guessing",
                "the",
                "successive",
                "word-ideas",
                "in",
                "a",
                "foreign",
                "language.",
                "How",
                "can",
                "this",
                "fact",
                "be",
                "used",
                "in",
                "machine",
                "translation\"",
                "#TARGET_REF",
                ")."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1
            ]
        },
        "input": "\"It is well known that Western Languages are 50% redundant. Experiment shows that if an average person guesses the successive words in a completely unknown sentence he has to be told only half of them. Experiment shows that this also applies to guessing the successive word-ideas in a foreign language. How can this fact be used in machine translation\" #TARGET_REF ).",
        "output": "{\"INFORMATION\": [\"#TARGET_REF ).\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Experiment shows that this also applies to guessing the successive word-ideas in a foreign language. How can this fact be used in machine translation\\\"\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "Russian-English",
                "portion",
                "of",
                "this",
                "study,",
                "we",
                "selected",
                "as",
                "source",
                "texts",
                "a",
                "subset",
                "of",
                "the",
                "texts",
                "from",
                "the",
                "2014",
                "Workshop",
                "on",
                "Statistical",
                "Machine",
                "Translation",
                "(WMT-14)",
                "shared",
                "translation",
                "task",
                "#TARGET_REF",
                ".",
                "Source",
                "texts",
                "were",
                "news",
                "articles",
                "covering",
                "world",
                "news",
                "events",
                "in",
                "late",
                "2013."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "For the Russian-English portion of this study, we selected as source texts a subset of the texts from the 2014 Workshop on Statistical Machine Translation (WMT-14) shared translation task #TARGET_REF . Source texts were news articles covering world news events in late 2013.",
        "output": "{\"INFORMATION\": [\"the texts from the 2014 Workshop on Statistical Machine Translation (WMT-14) shared translation task #TARGET_REF . Source texts were news articles covering world news events in late 2013.\"], \"PERCEPTION\": [\"For the Russian-English portion of this study, we selected as source texts a subset of\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "pairing",
                "two",
                "TAGs",
                "for",
                "MT,",
                "syntax-semantics",
                "mapping",
                "or",
                "paraphrase,",
                "under",
                "the",
                "redefinition",
                "of",
                "Synchronous",
                "TAG",
                "in",
                "#TARGET_REF",
                "there",
                "must",
                "be",
                "an",
                "isomorphism",
                "between",
                "the",
                "derivations",
                "of",
                "two",
                "strings",
                "to",
                "be",
                "paired.",
                "In",
                "TAG,",
                "for",
                "each",
                "DERIVED",
                "TREE",
                "derived",
                "from",
                "smaller",
                "elementary",
                "trees,",
                "there",
                "is",
                "a",
                "corresponding",
                "DERIVATION",
                "TREE",
                "which",
                "describes",
                "the",
                "history",
                "of",
                "the",
                "derivation.",
                "This",
                "derivation",
                "tree",
                "has",
                "a",
                "number",
                "of",
                "similarities",
                "to",
                "dependency",
                "trees,",
                "but",
                "is",
                "not",
                "exactly",
                "the",
                "same",
                "#REF",
                ".",
                "In",
                "general",
                "there",
                "will",
                "not",
                "be",
                "an",
                "isomorphism",
                "between",
                "two",
                "such",
                "trees",
                "for",
                "any",
                "of",
                "the",
                "above",
                "applications,",
                "hence",
                "Shieber's",
                "proposed",
                "extension",
                "to",
                "allow",
                "\"bounded",
                "subderivation\"",
                "(which",
                "correspond",
                "to",
                "gCNs",
                "in",
                "the",
                "context",
                "of",
                "derivation",
                "trees).",
                "However,",
                "he",
                "also",
                "notes",
                "the",
                "possibility,",
                "further",
                "explored",
                "in",
                "#REF",
                ",",
                "that",
                "the",
                "pairing",
                "of",
                "gNCNs",
                "will",
                "be",
                "necessary.",
                "An",
                "example",
                "taken",
                "from",
                "the",
                "latter",
                "is",
                "in",
                "(2).",
                "teeth.",
                "The",
                "doctor",
                "wants",
                "to",
                "be",
                "able",
                ".",
                ".",
                ".",
                "to",
                "examine",
                "his",
                "teeth."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In pairing two TAGs for MT, syntax-semantics mapping or paraphrase, under the redefinition of Synchronous TAG in #TARGET_REF there must be an isomorphism between the derivations of two strings to be paired. In TAG, for each DERIVED TREE derived from smaller elementary trees, there is a corresponding DERIVATION TREE which describes the history of the derivation. This derivation tree has a number of similarities to dependency trees, but is not exactly the same #REF . In general there will not be an isomorphism between two such trees for any of the above applications, hence Shieber's proposed extension to allow \"bounded subderivation\" (which correspond to gCNs in the context of derivation trees). However, he also notes the possibility, further explored in #REF , that the pairing of gNCNs will be necessary. An example taken from the latter is in (2). teeth. The doctor wants to be able . . . to examine his teeth.",
        "output": "{\"INFORMATION\": [\"the redefinition of Synchronous TAG in #TARGET_REF\"], \"PERCEPTION\": [\"In pairing two TAGs for MT,\", \"under\", \"there must be an isomorphism between the derivations of two strings to be paired.\"], \"BACKGROUND\": [\"syntax-semantics mapping or paraphrase,\", \"In TAG, for each DERIVED TREE derived from smaller elementary trees, there is a corresponding DERIVATION TREE which describes the history of the derivation.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "predicting",
                "the",
                "similarity",
                "scores,",
                "a",
                "separate",
                "model",
                "is",
                "used",
                "for",
                "each",
                "of",
                "the",
                "languages",
                "BERT-Base",
                "#TARGET_REF",
                "for",
                "English,",
                "BERTimbau",
                "for",
                "Portuguese,",
                "and",
                "Bertinho-Base",
                "for",
                "Galician.",
                "The",
                "created",
                "BERTRAM",
                "embeddings",
                "for",
                "each",
                "of",
                "the",
                "idioms",
                "found",
                "within",
                "the",
                "task",
                "are",
                "added",
                "into",
                "the",
                "embedding",
                "matrix",
                "of",
                "the",
                "relevant",
                "model.",
                "These",
                "models",
                "are",
                "used",
                "within",
                "a",
                "Sentence",
                "BERT",
                "#REF",
                "setup,",
                "implemented",
                "using",
                "the",
                "SentenceTransformers",
                "library,",
                "which",
                "consists",
                "of",
                "a",
                "siamese",
                "network",
                "structure",
                "that",
                "uses",
                "mean",
                "squared",
                "error",
                "over",
                "the",
                "cosine",
                "similarities",
                "of",
                "the",
                "input",
                "sentences",
                "as",
                "it's",
                "loss",
                "function.",
                "This",
                "allows",
                "us",
                "to",
                "use",
                "the",
                "contextualised",
                "embedding",
                "outputs",
                "of",
                "our",
                "BERT",
                "networks",
                "to",
                "find",
                "cosine",
                "similarity",
                "between",
                "a",
                "given",
                "pair",
                "of",
                "sentences."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For predicting the similarity scores, a separate model is used for each of the languages BERT-Base #TARGET_REF for English, BERTimbau for Portuguese, and Bertinho-Base for Galician. The created BERTRAM embeddings for each of the idioms found within the task are added into the embedding matrix of the relevant model. These models are used within a Sentence BERT #REF setup, implemented using the SentenceTransformers library, which consists of a siamese network structure that uses mean squared error over the cosine similarities of the input sentences as it's loss function. This allows us to use the contextualised embedding outputs of our BERT networks to find cosine similarity between a given pair of sentences.",
        "output": "{\"INFORMATION\": [\"BERT-Base #TARGET_REF for English,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"For predicting the similarity scores, a separate model is used for each of the languages\", \"BERTimbau for Portuguese, and Bertinho-Base for Galician.\"]}"
    },
    {
        "gold": {
            "text": [
                "Some",
                "emotions",
                "are",
                "also",
                "more",
                "closely",
                "correlated.",
                "In",
                "Plutchik's",
                "wheel",
                "#TARGET_REF",
                ")",
                "related",
                "emotions",
                "are",
                "placed",
                "on",
                "the",
                "same",
                "dyad",
                "so",
                "that",
                "for",
                "example",
                "for",
                "anger",
                "as",
                "a",
                "core",
                "emotion,",
                "there",
                "is",
                "also",
                "rage",
                "that",
                "is",
                "more",
                "intense,",
                "but",
                "highly",
                "correlated",
                "with",
                "anger,",
                "and",
                "annoyance",
                "which",
                "is",
                "less",
                "intense,",
                "but",
                "equally",
                "correlated.",
                "In",
                "this",
                "way",
                "it",
                "is",
                "also",
                "possible",
                "to",
                "map",
                "more",
                "distinct",
                "categories",
                "of",
                "emotions",
                "onto",
                "larger",
                "wholes,",
                "in",
                "this",
                "case",
                "rage",
                "and",
                "annoyance",
                "could",
                "be",
                "mapped",
                "to",
                "anger,",
                "or",
                "even",
                "more",
                "coarsely",
                "to",
                "negative.",
                "This",
                "approach",
                "has",
                "been",
                "employed",
                "by",
                "for",
                "example",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Some emotions are also more closely correlated. In Plutchik's wheel #TARGET_REF ) related emotions are placed on the same dyad so that for example for anger as a core emotion, there is also rage that is more intense, but highly correlated with anger, and annoyance which is less intense, but equally correlated. In this way it is also possible to map more distinct categories of emotions onto larger wholes, in this case rage and annoyance could be mapped to anger, or even more coarsely to negative. This approach has been employed by for example #REF .",
        "output": "{\"INFORMATION\": [\"Plutchik's wheel #TARGET_REF ) related emotions are placed on the same dyad\"], \"PERCEPTION\": [\"In\"], \"BACKGROUND\": [\"Some emotions are also more closely correlated.\", \"for anger as a core emotion, there is also rage that is more intense, but highly correlated with anger, and annoyance which is less intense, but equally correlated.\"]}"
    },
    {
        "gold": {
            "text": [
                "Named",
                "Entity",
                "Disambiguation",
                "(NED)",
                "We",
                "use",
                "the",
                "standard",
                "English",
                "CoNLL-YAGO",
                "benchmark",
                "#REF",
                "preprocessed",
                "by",
                "#REF",
                ".",
                "For",
                "each",
                "entity",
                "mention,",
                "at",
                "most",
                "30",
                "candidate",
                "entities",
                "are",
                "selected",
                "using",
                "the",
                "CrossWikis",
                "dictionary",
                "(Spitkovsky",
                "and",
                "Chang,",
                "2012).",
                "This",
                "dataset",
                "contains",
                "18.5k",
                "training,",
                "4.8k",
                "dev,",
                "and",
                "4.5k",
                "test",
                "examples",
                "from",
                "newswire",
                "text,",
                "so",
                "the",
                "variety",
                "of",
                "entities",
                "and",
                "the",
                "writing",
                "styles",
                "are",
                "limited.",
                "For",
                "this",
                "reason,",
                "we",
                "create",
                "another",
                "NED",
                "dataset",
                "from",
                "WikilinksNED",
                "#TARGET_REF",
                ",",
                "which",
                "includes",
                "a",
                "wide",
                "range",
                "of",
                "entities",
                "and",
                "diverse",
                "writing",
                "styles",
                "from",
                "scraped",
                "English",
                "web",
                "text",
                "linking",
                "to",
                "Wikipedia.",
                "We",
                "limit",
                "the",
                "number",
                "of",
                "candidate",
                "entities",
                "to",
                "3",
                "for",
                "each",
                "instance,",
                "which",
                "still",
                "makes",
                "a",
                "challenging",
                "benchmark.",
                "We",
                "create",
                "5k",
                "training,",
                "1k",
                "dev,",
                "and",
                "1k",
                "test",
                "examples",
                "and",
                "call",
                "this",
                "dataset",
                "WLNED.",
                "In",
                "both",
                "CoNLL-YAGO",
                "and",
                "WLNED,",
                "we",
                "form",
                "descriptions",
                "of",
                "candidate",
                "entities",
                "using",
                "the",
                "Wiki-Context",
                "data,",
                "but",
                "do",
                "not",
                "use",
                "any",
                "structural",
                "information",
                "from",
                "Wikipedia",
                "(hyperlinks,",
                "etc.).",
                "Our",
                "method",
                "simply",
                "computes",
                "cosine",
                "similarity",
                "and",
                "uses",
                "it",
                "as",
                "a",
                "score",
                "for",
                "each",
                "task,",
                "not",
                "introducing",
                "any",
                "new",
                "parameters.",
                "Our",
                "baselines",
                "use",
                "a",
                "trainable",
                "logistic",
                "regression",
                "layer",
                "over",
                "pre-trained",
                "embeddings",
                "to",
                "make",
                "classification",
                "decisions."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Named Entity Disambiguation (NED) We use the standard English CoNLL-YAGO benchmark #REF preprocessed by #REF . For each entity mention, at most 30 candidate entities are selected using the CrossWikis dictionary (Spitkovsky and Chang, 2012). This dataset contains 18.5k training, 4.8k dev, and 4.5k test examples from newswire text, so the variety of entities and the writing styles are limited. For this reason, we create another NED dataset from WikilinksNED #TARGET_REF , which includes a wide range of entities and diverse writing styles from scraped English web text linking to Wikipedia. We limit the number of candidate entities to 3 for each instance, which still makes a challenging benchmark. We create 5k training, 1k dev, and 1k test examples and call this dataset WLNED. In both CoNLL-YAGO and WLNED, we form descriptions of candidate entities using the Wiki-Context data, but do not use any structural information from Wikipedia (hyperlinks, etc.). Our method simply computes cosine similarity and uses it as a score for each task, not introducing any new parameters. Our baselines use a trainable logistic regression layer over pre-trained embeddings to make classification decisions.",
        "output": "{\"INFORMATION\": [\"WikilinksNED #TARGET_REF , which includes a wide range of entities and diverse writing styles from scraped English web text linking to Wikipedia.\"], \"PERCEPTION\": [\"we create another NED dataset from\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Style",
                "transfer",
                "aims",
                "to",
                "change",
                "the",
                "style",
                "attributes",
                "while",
                "preserving",
                "the",
                "content.",
                "Our",
                "work",
                "is",
                "related",
                "to",
                "unsupervised",
                "style",
                "transfer",
                "by",
                "regarding",
                "the",
                "text",
                "complexity",
                "as",
                "one",
                "of",
                "the",
                "style",
                "attributes",
                "#REF",
                ".",
                "#TARGET_REF",
                "demonstrated",
                "that",
                "the",
                "neural",
                "networks",
                "can",
                "capture",
                "the",
                "artistic",
                "style",
                "of",
                "a",
                "diversity",
                "of",
                "paintings.",
                "The",
                "authors",
                "discovered",
                "that",
                "adjusting",
                "parameters",
                "in",
                "the",
                "layer",
                "normalization",
                "mechanism",
                "leads",
                "to",
                "different",
                "artistic",
                "styles.",
                "This",
                "method",
                "permits",
                "users",
                "to",
                "transform",
                "images",
                "to",
                "arbitrary",
                "styles",
                "learned",
                "from",
                "individual",
                "paintings.",
                "#REF",
                "successfully",
                "applied",
                "this",
                "method",
                "to",
                "the",
                "task",
                "of",
                "headline",
                "generation,",
                "allowing",
                "the",
                "model",
                "to",
                "generate",
                "headlines",
                "of",
                "a",
                "specific",
                "style,",
                "such",
                "as",
                "humorous,",
                "romantic",
                "or",
                "click-baity,",
                "in",
                "an",
                "unsupervised",
                "manner."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Style transfer aims to change the style attributes while preserving the content. Our work is related to unsupervised style transfer by regarding the text complexity as one of the style attributes #REF . #TARGET_REF demonstrated that the neural networks can capture the artistic style of a diversity of paintings. The authors discovered that adjusting parameters in the layer normalization mechanism leads to different artistic styles. This method permits users to transform images to arbitrary styles learned from individual paintings. #REF successfully applied this method to the task of headline generation, allowing the model to generate headlines of a specific style, such as humorous, romantic or click-baity, in an unsupervised manner.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF demonstrated that the neural networks can capture the artistic style of a diversity of paintings.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The authors discovered that adjusting parameters in the layer normalization mechanism leads to different artistic styles.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "rest",
                "of",
                "the",
                "article",
                "is",
                "organized",
                "according",
                "to",
                "#TARGET_REF",
                "as",
                "follows:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The rest of the article is organized according to #TARGET_REF as follows:",
        "output": "{\"INFORMATION\": [\"according to #TARGET_REF as follows:\"], \"PERCEPTION\": [\"The rest of the article is organized\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Expert",
                "parameterization.",
                "Independently",
                "parameterizing",
                "each",
                "expert",
                "may",
                "exacerbate",
                "overfitting",
                "since",
                "the",
                "number",
                "of",
                "parameters",
                "increases",
                "linearly",
                "with",
                "the",
                "number",
                "of",
                "experts",
                "#REF",
                ".",
                "We",
                "follow",
                "the",
                "parameter",
                "sharing",
                "schema",
                "in",
                "#TARGET_REF",
                ",",
                "#REF",
                "to",
                "avoid",
                "this",
                "issue.",
                "This",
                "only",
                "requires",
                "a",
                "negligible",
                "increase",
                "in",
                "parameters",
                "over",
                "the",
                "baseline",
                "model",
                "that",
                "does",
                "not",
                "uses",
                "MoE.",
                "In",
                "our",
                "experiments,",
                "we",
                "compared",
                "adding",
                "a",
                "unique",
                "expert",
                "embedding",
                "to",
                "each",
                "input",
                "token",
                "with",
                "adding",
                "an",
                "expert",
                "prefix",
                "token",
                "before",
                "the",
                "input",
                "text",
                "sequence,",
                "where",
                "they",
                "achieved",
                "very",
                "similar",
                "performance."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Expert parameterization. Independently parameterizing each expert may exacerbate overfitting since the number of parameters increases linearly with the number of experts #REF . We follow the parameter sharing schema in #TARGET_REF , #REF to avoid this issue. This only requires a negligible increase in parameters over the baseline model that does not uses MoE. In our experiments, we compared adding a unique expert embedding to each input token with adding an expert prefix token before the input text sequence, where they achieved very similar performance.",
        "output": "{\"INFORMATION\": [\"the parameter sharing schema in #TARGET_REF\", \"This only requires a negligible increase in parameters over the baseline model that does not uses MoE.\"], \"PERCEPTION\": [\"We follow\", \"to avoid this issue.\"], \"BACKGROUND\": [\"Independently parameterizing each expert may exacerbate overfitting\"]}"
    },
    {
        "gold": {
            "text": [
                "Similarly",
                "to",
                "the",
                "previous",
                "editions",
                "of",
                "the",
                "shared",
                "task",
                "#TARGET_REF",
                "The",
                "percentage",
                "of",
                "overlap",
                "is",
                "computed",
                "by",
                "dividing",
                "the",
                "number",
                "of",
                "shared",
                "terms",
                "between",
                "question-answer",
                "pair",
                "and",
                "a",
                "fact",
                "by",
                "the",
                "total",
                "number",
                "of",
                "unique",
                "terms.",
                "To",
                "evaluate",
                "the",
                "systems",
                "in",
                "the",
                "most",
                "challenging",
                "setting,",
                "we",
                "gradually",
                "decrease",
                "the",
                "value",
                "of",
                "T",
                "down",
                "to",
                "0."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Similarly to the previous editions of the shared task #TARGET_REF The percentage of overlap is computed by dividing the number of shared terms between question-answer pair and a fact by the total number of unique terms. To evaluate the systems in the most challenging setting, we gradually decrease the value of T down to 0.",
        "output": "{\"INFORMATION\": [\"the shared task #TARGET_REF\"], \"PERCEPTION\": [\"Similarly to the previous editions of\"], \"BACKGROUND\": [\"The percentage of overlap is computed by dividing the number of shared terms between question-answer pair and a fact by the total number of unique terms.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "related",
                "thrust",
                "of",
                "the",
                "literature",
                "has",
                "looked",
                "at",
                "understanding",
                "entities",
                "using",
                "interpretable",
                "embeddings",
                "based",
                "around",
                "feature",
                "norms",
                "#TARGET_REF",
                ",",
                "this",
                "has",
                "advantages",
                "for",
                "learning",
                "in",
                "few-shot",
                "setups",
                "#REF",
                ".",
                "However,",
                "most",
                "of",
                "this",
                "past",
                "work",
                "has",
                "used",
                "embeddings",
                "that",
                "are",
                "much",
                "lowerdimensional",
                "than",
                "ours,",
                "and",
                "don't",
                "necessarily",
                "to",
                "scale",
                "to",
                "broad-domain",
                "text",
                "or",
                "all",
                "of",
                "Wikipedia."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A related thrust of the literature has looked at understanding entities using interpretable embeddings based around feature norms #TARGET_REF , this has advantages for learning in few-shot setups #REF . However, most of this past work has used embeddings that are much lowerdimensional than ours, and don't necessarily to scale to broad-domain text or all of Wikipedia.",
        "output": "{\"INFORMATION\": [\"feature norms #TARGET_REF ,\"], \"PERCEPTION\": [\"A related thrust of the literature has looked at understanding entities using interpretable embeddings based around\", \"this has advantages for learning in few-shot setups #REF .\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Task-oriented",
                "dialogue",
                "systems",
                "complete",
                "tasks",
                "for",
                "users,",
                "such",
                "as",
                "making",
                "a",
                "hotel",
                "reservation",
                "or",
                "finding",
                "train",
                "routes,",
                "in",
                "a",
                "multi-turn",
                "conversation",
                "#TARGET_REF",
                ".",
                "The",
                "generated",
                "system",
                "utterances",
                "should",
                "not",
                "only",
                "be",
                "naturally",
                "sound,",
                "but",
                "more",
                "importantly",
                "be",
                "informative,",
                "i.e.,",
                "to",
                "proceed",
                "the",
                "dialogue",
                "towards",
                "task",
                "completion.",
                "To",
                "fulfill",
                "this",
                "requirement,",
                "conditioned",
                "response",
                "generation",
                "is",
                "widely",
                "adopted",
                "based",
                "on",
                "system",
                "actions",
                "*",
                "Rui",
                "Zhang",
                "is",
                "the",
                "corresponding",
                "author.",
                "#REF",
                ".",
                "The",
                "response",
                "generation",
                "process",
                "is",
                "decoupled",
                "into",
                "two",
                "consecutive",
                "steps,",
                "where",
                "an",
                "action",
                "is",
                "first",
                "selected",
                "and",
                "then",
                "an",
                "utterance",
                "is",
                "generated",
                "conditioned",
                "on",
                "this",
                "action.",
                "One",
                "can",
                "optimize",
                "each",
                "step",
                "towards",
                "its",
                "goal,",
                "i.e.,",
                "informative",
                "and",
                "naturally",
                "sound,",
                "without",
                "impinging",
                "the",
                "other",
                "#REF",
                ".",
                "However,",
                "such",
                "approaches",
                "rely",
                "on",
                "action",
                "annotations",
                "(as",
                "in",
                "Table",
                "1),",
                "which",
                "require",
                "domain",
                "knowledge",
                "and",
                "extensive",
                "efforts",
                "to",
                "obtain."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Task-oriented dialogue systems complete tasks for users, such as making a hotel reservation or finding train routes, in a multi-turn conversation #TARGET_REF . The generated system utterances should not only be naturally sound, but more importantly be informative, i.e., to proceed the dialogue towards task completion. To fulfill this requirement, conditioned response generation is widely adopted based on system actions * Rui Zhang is the corresponding author. #REF . The response generation process is decoupled into two consecutive steps, where an action is first selected and then an utterance is generated conditioned on this action. One can optimize each step towards its goal, i.e., informative and naturally sound, without impinging the other #REF . However, such approaches rely on action annotations (as in Table 1), which require domain knowledge and extensive efforts to obtain.",
        "output": "{\"INFORMATION\": [\"multi-turn conversation #TARGET_REF .\"], \"PERCEPTION\": [\"Task-oriented dialogue systems complete tasks for users,\", \"in a\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "idea",
                "to",
                "develop",
                "this",
                "sort",
                "of",
                "interaction",
                "in",
                "the",
                "direction",
                "of",
                "a",
                "more",
                "sophisticated",
                "clarification",
                "dialogue",
                "is",
                "now",
                "gaining",
                "currency",
                "with",
                "the",
                "emergence",
                "of",
                "DBMT",
                "#REF",
                "and",
                "the",
                "notion",
                "of",
                "'MT",
                "without",
                "a",
                "source",
                "text'",
                "#TARGET_REF",
                ",",
                "where",
                "the",
                "dialogue",
                "aims",
                "not",
                "merely",
                "at",
                "disambiguating",
                "a",
                "given",
                "text,",
                "but",
                "in",
                "helping",
                "the",
                "user",
                "to",
                "compose",
                "it",
                "in",
                "the",
                "first",
                "place."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with the emergence of DBMT #REF and the notion of 'MT without a source text' #TARGET_REF , where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place.",
        "output": "{\"INFORMATION\": [\"the notion of 'MT without a source text' #TARGET_REF , where the dialogue aims not merely at disambiguating a given text, but in helping the user to compose it in the first place.\"], \"PERCEPTION\": [\"The idea to develop this sort of interaction in the direction of a more sophisticated clarification dialogue is now gaining currency with\"], \"BACKGROUND\": [\"the emergence of DBMT #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "current",
                "state-of-the-art",
                "on",
                "the",
                "explanation",
                "regeneration",
                "task",
                "is",
                "represented",
                "by",
                "a",
                "model",
                "that",
                "employs",
                "a",
                "combination",
                "of",
                "language",
                "models",
                "and",
                "Graph",
                "Neural",
                "Networks",
                "(GNN)",
                "#REF",
                ",",
                "with",
                "the",
                "bulk",
                "of",
                "performance",
                "contributed",
                "from",
                "the",
                "language",
                "model.",
                "Strong",
                "performance",
                "is",
                "also",
                "achieved",
                "by",
                "transformer",
                "models",
                "adapted",
                "to",
                "rank",
                "inference",
                "chains",
                "#REF",
                "or",
                "operating",
                "in",
                "an",
                "iterative",
                "and",
                "recursive",
                "fashion",
                "#REF",
                ".",
                "In",
                "contrast",
                "with",
                "neural-based",
                "models,",
                "recent",
                "works",
                "#TARGET_REF",
                "have",
                "shown",
                "that",
                "the",
                "explanatory",
                "patterns",
                "emerging",
                "in",
                "the",
                "WorldTree",
                "corpus",
                "can",
                "be",
                "leveraged",
                "to",
                "improve",
                "sparse",
                "retrieval",
                "models",
                "and",
                "provide",
                "a",
                "viable",
                "way",
                "to",
                "alleviate",
                "semantic",
                "drift."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The current state-of-the-art on the explanation regeneration task is represented by a model that employs a combination of language models and Graph Neural Networks (GNN) #REF , with the bulk of performance contributed from the language model. Strong performance is also achieved by transformer models adapted to rank inference chains #REF or operating in an iterative and recursive fashion #REF . In contrast with neural-based models, recent works #TARGET_REF have shown that the explanatory patterns emerging in the WorldTree corpus can be leveraged to improve sparse retrieval models and provide a viable way to alleviate semantic drift.",
        "output": "{\"INFORMATION\": [\"recent works #TARGET_REF have shown that the explanatory patterns emerging in the WorldTree corpus can be leveraged to improve sparse retrieval models and provide a viable way to alleviate semantic drift.\"], \"PERCEPTION\": [\"In contrast with neural-based models,\"], \"BACKGROUND\": [\"The current state-of-the-art on the explanation regeneration task is represented by a model that employs a combination of language models and Graph Neural Networks (GNN) #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "BERT",
                "has",
                "12",
                "layers,",
                "each",
                "of",
                "which",
                "has",
                "a",
                "768-dimensional",
                "output",
                "embedding",
                "per",
                "wordpiece.",
                "There",
                "is",
                "some",
                "mixed",
                "information",
                "in",
                "the",
                "literature",
                "as",
                "to",
                "which",
                "layer's",
                "output",
                "is",
                "most",
                "suitable",
                "for",
                "seman-",
                "Evaluation",
                "We",
                "evaluate",
                "the",
                "performance",
                "of",
                "our",
                "parser",
                "using",
                "Counter",
                "#TARGET_REF",
                ",",
                "an",
                "extension",
                "of",
                "the",
                "Smatch",
                "evaluation",
                "metric",
                "#REF",
                ".",
                "Counter",
                "approximates",
                "an",
                "optimal",
                "mapping",
                "between",
                "the",
                "referents",
                "in",
                "the",
                "gold",
                "DRS",
                "and",
                "the",
                "predicted",
                "DRS",
                "using",
                "hill-climbing,",
                "then",
                "outputs",
                "recall,",
                "precision,",
                "and",
                "f-score",
                "for",
                "the",
                "predicted",
                "clauses",
                "compared",
                "to",
                "the",
                "gold",
                "clauses."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "BERT has 12 layers, each of which has a 768-dimensional output embedding per wordpiece. There is some mixed information in the literature as to which layer's output is most suitable for seman- Evaluation We evaluate the performance of our parser using Counter #TARGET_REF , an extension of the Smatch evaluation metric #REF . Counter approximates an optimal mapping between the referents in the gold DRS and the predicted DRS using hill-climbing, then outputs recall, precision, and f-score for the predicted clauses compared to the gold clauses.",
        "output": "{\"INFORMATION\": [\"Counter #TARGET_REF , an extension of the Smatch evaluation metric #REF .\"], \"PERCEPTION\": [\"We evaluate the performance of our parser using\", \"Counter approximates an optimal mapping between the referents in the gold DRS and the predicted DRS using hill-climbing, then outputs recall, precision, and f-score for the predicted clauses compared to the gold clauses.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "strategy",
                "of",
                "weighting",
                "links",
                "between",
                "a",
                "token",
                "and",
                "a",
                "sentence",
                "node",
                "is",
                "straightforward.",
                "The",
                "weight",
                "is",
                "the",
                "average",
                "3",
                "of",
                "embedding",
                "vectors",
                "of",
                "the",
                "token",
                "node.",
                "To",
                "get",
                "embedding",
                "values",
                "for",
                "each",
                "token,",
                "we",
                "used",
                "100-dimensional",
                "GloVe",
                "embeddings",
                "4",
                "for",
                "the",
                "Portuguese",
                "language",
                "#TARGET_REF",
                ".",
                "Figure",
                "3",
                "shows",
                "the",
                "scheme",
                "of",
                "the",
                "network",
                "designed",
                "for",
                "this",
                "task.",
                "One",
                "can",
                "see",
                "that",
                "the",
                "edges",
                "are",
                "undirected",
                "and",
                "weighted,",
                "and",
                "a",
                "sentence",
                "node",
                "may",
                "share",
                "several",
                "token",
                "nodes",
                "whenever",
                "the",
                "token",
                "is",
                "in",
                "the",
                "sentence,",
                "i.e.,",
                "the",
                "edges",
                "between",
                "token",
                "nodes",
                "and",
                "sentence",
                "nodes",
                "are",
                "based",
                "on",
                "word",
                "occurrence",
                "in",
                "sentence."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The strategy of weighting links between a token and a sentence node is straightforward. The weight is the average 3 of embedding vectors of the token node. To get embedding values for each token, we used 100-dimensional GloVe embeddings 4 for the Portuguese language #TARGET_REF . Figure 3 shows the scheme of the network designed for this task. One can see that the edges are undirected and weighted, and a sentence node may share several token nodes whenever the token is in the sentence, i.e., the edges between token nodes and sentence nodes are based on word occurrence in sentence.",
        "output": "{\"INFORMATION\": [\"for the Portuguese language #TARGET_REF\"], \"PERCEPTION\": [\"we used 100-dimensional GloVe embeddings 4\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "score",
                "translation",
                "candidates",
                "we",
                "will",
                "compute",
                "global",
                "and",
                "local",
                "frequencies",
                "of",
                "occurrence",
                "of",
                "substrings",
                "using",
                "the",
                "method",
                "described",
                "by",
                "#TARGET_REF",
                "which",
                "is",
                "based",
                "on",
                "suffix",
                "arrays",
                "and",
                "longest",
                "common",
                "prefix",
                "arrays."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To score translation candidates we will compute global and local frequencies of occurrence of substrings using the method described by #TARGET_REF which is based on suffix arrays and longest common prefix arrays.",
        "output": "{\"INFORMATION\": [\"the method described by #TARGET_REF which is based on suffix arrays and longest common prefix arrays.\"], \"PERCEPTION\": [\"To score translation candidates we will compute global and local frequencies of occurrence of substrings using\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "authors",
                "also",
                "built",
                "their",
                "own",
                "linguistic",
                "resources,",
                "ANERcorp",
                "(an",
                "annotated",
                "corpus)",
                "and",
                "ANERgazet",
                "(a",
                "gazetteer),",
                "which",
                "have",
                "become",
                "benchmarks",
                "for",
                "evaluation.",
                "At",
                "this",
                "time,",
                "work",
                "was",
                "also",
                "done",
                "on",
                "incorporating",
                "POS",
                "information",
                "to",
                "improve",
                "NER.",
                "For",
                "example,",
                "#TARGET_REF",
                "proposed",
                "ANERsys",
                "2.0,",
                "where",
                "they",
                "used",
                "a",
                "POS",
                "tagger",
                "and",
                "a",
                "two",
                "step",
                "approach",
                "to",
                "enhance",
                "the",
                "performance",
                "of",
                "ANERsys",
                "1.0."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The authors also built their own linguistic resources, ANERcorp (an annotated corpus) and ANERgazet (a gazetteer), which have become benchmarks for evaluation. At this time, work was also done on incorporating POS information to improve NER. For example, #TARGET_REF proposed ANERsys 2.0, where they used a POS tagger and a two step approach to enhance the performance of ANERsys 1.0.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF proposed ANERsys 2.0, where they used a POS tagger and a two step approach to enhance the performance of ANERsys 1.0.\"], \"PERCEPTION\": [\"For example,\"], \"BACKGROUND\": [\"work was also done on incorporating POS information to improve NER.\"]}"
    },
    {
        "gold": {
            "text": [
                "1",
                "https://parl.ai/projects/light",
                "Quests",
                "in",
                "LIGHT",
                "#TARGET_REF",
                "take",
                "the",
                "form",
                "of",
                "a",
                "short",
                "motivation",
                "and",
                "goal",
                "action",
                "that",
                "is",
                "required",
                "reach",
                "the",
                "world",
                "state",
                "required",
                "to",
                "finish",
                "the",
                "game.",
                "For",
                "example,",
                "if",
                "the",
                "short",
                "motivation",
                "is",
                "\"Your",
                "motivation",
                "is",
                "to",
                "acquire",
                "a",
                "sword\",",
                "then",
                "the",
                "corresponding",
                "goal",
                "state",
                "would",
                "be",
                "for",
                "the",
                "character",
                "to",
                "have",
                "a",
                "sword",
                "in",
                "their",
                "inventory",
                "and",
                "goal",
                "action",
                "would",
                "be",
                "get",
                "sword.",
                "This",
                "environment",
                "also",
                "contains",
                "a",
                "set",
                "of",
                "human",
                "expert",
                "demonstration",
                "of",
                "people",
                "speaking",
                "and",
                "acting",
                "in",
                "character",
                "while",
                "playing",
                "the",
                "quests",
                "mentioned",
                "above.",
                "Further",
                "details",
                "are",
                "found",
                "in",
                "Appendix",
                "A.1."
            ],
            "context": [
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "1 https://parl.ai/projects/light Quests in LIGHT #TARGET_REF take the form of a short motivation and goal action that is required reach the world state required to finish the game. For example, if the short motivation is \"Your motivation is to acquire a sword\", then the corresponding goal state would be for the character to have a sword in their inventory and goal action would be get sword. This environment also contains a set of human expert demonstration of people speaking and acting in character while playing the quests mentioned above. Further details are found in Appendix A.1.",
        "output": "{\"INFORMATION\": [\"Quests in LIGHT #TARGET_REF take the form of a short motivation and goal action that is required reach the world state required to finish the game.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Further details are found in Appendix A.1.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "Note",
                "on",
                "Decontextualization",
                "Recently,",
                "#TARGET_REF",
                "introduced",
                "the",
                "text-decontextualization",
                "task,",
                "in",
                "which",
                "the",
                "input",
                "is",
                "a",
                "text",
                "and",
                "an",
                "enclosing",
                "textual",
                "context,",
                "and",
                "the",
                "goal",
                "is",
                "to",
                "produce",
                "a",
                "standalone",
                "text",
                "that",
                "can",
                "be",
                "fully",
                "interpreted",
                "outside",
                "of",
                "the",
                "enclosing",
                "context.",
                "The",
                "decontextualization",
                "task",
                "involves",
                "handling",
                "multiple",
                "linguistic",
                "phenomena,",
                "and,",
                "in",
                "order",
                "to",
                "perform",
                "it",
                "well,",
                "one",
                "must",
                "essentially",
                "perform",
                "a",
                "version",
                "of",
                "the",
                "NP",
                "Enrichment",
                "task.",
                "For",
                "example,",
                "decontextualizing",
                "''Prices",
                "are",
                "expected",
                "to",
                "rise''",
                "based",
                "on",
                "''Temporary",
                "copper",
                "shortage.",
                "Prices",
                "are",
                "expected",
                "to",
                "rise'',",
                "involves",
                "establishing",
                "the",
                "relation",
                "''Prices",
                "[of",
                "copper]",
                "are",
                "expected",
                "to",
                "rise'')."
            ],
            "context": [
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "A Note on Decontextualization Recently, #TARGET_REF introduced the text-decontextualization task, in which the input is a text and an enclosing textual context, and the goal is to produce a standalone text that can be fully interpreted outside of the enclosing context. The decontextualization task involves handling multiple linguistic phenomena, and, in order to perform it well, one must essentially perform a version of the NP Enrichment task. For example, decontextualizing ''Prices are expected to rise'' based on ''Temporary copper shortage. Prices are expected to rise'', involves establishing the relation ''Prices [of copper] are expected to rise'').",
        "output": "{\"INFORMATION\": [\"Recently, #TARGET_REF introduced the text-decontextualization task, in which the input is a text and an enclosing textual context, and the goal is to produce a standalone text that can be fully interpreted outside of the enclosing context. The decontextualization task involves handling multiple linguistic phenomena,\"], \"PERCEPTION\": [\"and, in order to perform it well, one must essentially perform a version of the NP Enrichment task.\"], \"BACKGROUND\": [\"For example, decontextualizing ''Prices are expected to rise'' based on ''Temporary copper shortage. Prices are expected to rise'', involves establishing the relation ''Prices [of copper] are expected to rise'').\"]}"
    },
    {
        "gold": {
            "text": [
                "inclusive",
                "hiring",
                "#REF",
                ",",
                "others",
                "suggest",
                "model",
                "biases",
                "towards",
                "occupational",
                "associations",
                "pose",
                "a",
                "risk",
                "of",
                "their",
                "use.",
                "Specifically,",
                "research",
                "has",
                "uncovered",
                "gender",
                "bias",
                "in",
                "large-scale",
                "language",
                "models",
                "by",
                "examining",
                "the",
                "strength",
                "of",
                "statistical",
                "association",
                "between",
                "a",
                "given",
                "gender",
                "and",
                "a",
                "set",
                "of",
                "jobs",
                "using",
                "prompts",
                "such",
                "as",
                "\"the",
                "woman",
                "works",
                "as",
                "a",
                "[token]\"",
                "#REF",
                ".",
                "These",
                "associations",
                "lead",
                "to",
                "representational",
                "harms",
                "#TARGET_REF",
                ",",
                "by",
                "perpetuating",
                "the",
                "notion",
                "of",
                "gendered",
                "roles",
                "in",
                "the",
                "labour",
                "force",
                "and",
                "entrenching",
                "stereotypes",
                "such",
                "as",
                "women",
                "possessing",
                "more",
                "caregiving",
                "qualities.",
                "However,",
                "it",
                "is",
                "unclear",
                "how",
                "these",
                "model",
                "biases",
                "translate",
                "directly",
                "to",
                "language",
                "generation",
                "in",
                "applied",
                "downstream",
                "tasks,",
                "that",
                "is,",
                "how",
                "they",
                "may",
                "give",
                "rise",
                "to",
                "allocational",
                "harms.",
                "One",
                "example",
                "of",
                "such",
                "a",
                "task",
                "is",
                "the",
                "generation",
                "of",
                "job",
                "advertisements",
                "(ads)",
                "which",
                "exemplifies",
                "the",
                "risk",
                "of",
                "allocational",
                "harms",
                "because",
                "candidates",
                "from",
                "a",
                "given",
                "group",
                "may",
                "be",
                "discouraged",
                "to",
                "apply",
                "as",
                "a",
                "result",
                "of",
                "biased",
                "language.",
                "Prior",
                "research",
                "has",
                "demonstrated",
                "gendered",
                "wording",
                "in",
                "job",
                "ads",
                "can",
                "act",
                "as",
                "an",
                "institutional-level",
                "mechanism",
                "to",
                "entrench",
                "traditional",
                "gender",
                "divisions",
                "#REF",
                ".",
                "1",
                "Gender",
                "bias",
                "in",
                "natural",
                "language",
                "processing",
                "(NLP)",
                "has",
                "been",
                "more",
                "widely-discussed",
                "#REF",
                ",",
                "with",
                "some",
                "specific",
                "work",
                "documenting",
                "bias",
                "of",
                "generative",
                "language",
                "models",
                "#REF",
                ".",
                "Early",
                "debiasing",
                "attempts",
                "in",
                "NLP",
                "focused",
                "on",
                "word",
                "embeddings",
                "#REF",
                ",",
                "though",
                "the",
                "efficacy",
                "of",
                "these",
                "methods",
                "has",
                "been",
                "challenged",
                "#REF",
                ".",
                "Some",
                "recent",
                "research",
                "seeks",
                "to",
                "align",
                "generative",
                "language",
                "models",
                "with",
                "societally-desirable",
                "values",
                "#REF",
                ",",
                "reduce",
                "various",
                "dimensions",
                "of",
                "groupdirected",
                "bias",
                "#REF",
                "and",
                "decrease",
                "risk",
                "of",
                "toxicity",
                "#REF",
                ".",
                "There",
                "is",
                "less",
                "research",
                "on",
                "how",
                "gender",
                "bias",
                "in",
                "generative",
                "models",
                "affects",
                "applied",
                "tasks,",
                "and",
                "to",
                "our",
                "knowledge,",
                "no",
                "prior",
                "work",
                "on",
                "bias",
                "in",
                "generated",
                "job",
                "ads.",
                "Furthermore,",
                "there",
                "is",
                "a",
                "lack",
                "of",
                "research",
                "advising",
                "on",
                "how",
                "industry",
                "practitioners",
                "can",
                "effectively",
                "and",
                "cheaply",
                "debias",
                "outputs",
                "whilst",
                "retaining",
                "quality,",
                "accuracy",
                "and",
                "realism."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "inclusive hiring #REF , others suggest model biases towards occupational associations pose a risk of their use. Specifically, research has uncovered gender bias in large-scale language models by examining the strength of statistical association between a given gender and a set of jobs using prompts such as \"the woman works as a [token]\" #REF . These associations lead to representational harms #TARGET_REF , by perpetuating the notion of gendered roles in the labour force and entrenching stereotypes such as women possessing more caregiving qualities. However, it is unclear how these model biases translate directly to language generation in applied downstream tasks, that is, how they may give rise to allocational harms. One example of such a task is the generation of job advertisements (ads) which exemplifies the risk of allocational harms because candidates from a given group may be discouraged to apply as a result of biased language. Prior research has demonstrated gendered wording in job ads can act as an institutional-level mechanism to entrench traditional gender divisions #REF . 1 Gender bias in natural language processing (NLP) has been more widely-discussed #REF , with some specific work documenting bias of generative language models #REF . Early debiasing attempts in NLP focused on word embeddings #REF , though the efficacy of these methods has been challenged #REF . Some recent research seeks to align generative language models with societally-desirable values #REF , reduce various dimensions of groupdirected bias #REF and decrease risk of toxicity #REF . There is less research on how gender bias in generative models affects applied tasks, and to our knowledge, no prior work on bias in generated job ads. Furthermore, there is a lack of research advising on how industry practitioners can effectively and cheaply debias outputs whilst retaining quality, accuracy and realism.",
        "output": "{\"INFORMATION\": [\"representational harms #TARGET_REF\"], \"PERCEPTION\": [\"These associations lead to\", \"by perpetuating the notion of gendered roles in the labour force and entrenching stereotypes\"], \"BACKGROUND\": [\"research has uncovered gender bias in large-scale language models by examining the strength of statistical association between a given gender and a set of jobs using prompts such as \\\"the woman works as a [token]\\\" #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Calibration",
                "requires",
                "that",
                "a",
                "model's",
                "confidence",
                "on",
                "its",
                "predictions",
                "is",
                "equal",
                "to",
                "the",
                "accuracy",
                "of",
                "these",
                "predictions",
                "#TARGET_REF",
                ".",
                "Previous",
                "work",
                "#REF",
                "has",
                "found",
                "that",
                "a",
                "more",
                "calibrated",
                "text",
                "generation",
                "model",
                "tends",
                "to",
                "have",
                "better",
                "performance,",
                "and",
                "techniques",
                "like",
                "label",
                "smoothing",
                "can",
                "improve",
                "both",
                "the",
                "token-level",
                "calibration",
                "and",
                "sequence-level",
                "accuracy",
                "(i.e.",
                "the",
                "ability",
                "of",
                "generating",
                "better",
                "results).",
                "One",
                "intuitive",
                "explanation",
                "of",
                "this",
                "phenomenon",
                "is",
                "to",
                "interpret",
                "the",
                "model's",
                "estimated",
                "probability",
                "of",
                "a",
                "generated",
                "summary",
                "as",
                "the",
                "product",
                "of",
                "the",
                "model's",
                "confidences",
                "on",
                "a",
                "series",
                "of",
                "tokenlevel",
                "predictions.",
                "Then,",
                "since",
                "a",
                "more",
                "calibrated",
                "model's",
                "confidence",
                "estimates",
                "better",
                "the",
                "accuracy",
                "of",
                "its",
                "predictions,",
                "the",
                "model's",
                "estimated",
                "probability",
                "of",
                "one",
                "sequence",
                "should",
                "be",
                "more",
                "indicative",
                "of",
                "the",
                "quality",
                "of",
                "this",
                "sequence,",
                "which",
                "is",
                "essential",
                "for",
                "the",
                "beam",
                "search",
                "during",
                "inference.",
                "However,",
                "the",
                "relation",
                "of",
                "token-level",
                "calibration",
                "and",
                "sequencelevel",
                "performance",
                "remains",
                "inconclusive",
                "#REF",
                ".",
                "10",
                "For",
                "example,",
                "a",
                "generator",
                "that",
                "always",
                "predicts",
                "a",
                "uniform",
                "distribution",
                "over",
                "all",
                "tokens",
                "would",
                "be",
                "perfectly",
                "calibrated,",
                "however,",
                "such",
                "a",
                "model",
                "would",
                "not",
                "generate",
                "high-quality",
                "outputs."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Calibration requires that a model's confidence on its predictions is equal to the accuracy of these predictions #TARGET_REF . Previous work #REF has found that a more calibrated text generation model tends to have better performance, and techniques like label smoothing can improve both the token-level calibration and sequence-level accuracy (i.e. the ability of generating better results). One intuitive explanation of this phenomenon is to interpret the model's estimated probability of a generated summary as the product of the model's confidences on a series of tokenlevel predictions. Then, since a more calibrated model's confidence estimates better the accuracy of its predictions, the model's estimated probability of one sequence should be more indicative of the quality of this sequence, which is essential for the beam search during inference. However, the relation of token-level calibration and sequencelevel performance remains inconclusive #REF . 10 For example, a generator that always predicts a uniform distribution over all tokens would be perfectly calibrated, however, such a model would not generate high-quality outputs.",
        "output": "{\"INFORMATION\": [\"Calibration requires that a model's confidence on its predictions is equal to the accuracy of these predictions #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Previous work #REF has found that a more calibrated text generation model tends to have better performance, and techniques like label smoothing can improve both the token-level calibration and sequence-level accuracy\", \"since a more calibrated model's confidence estimates better the accuracy of its predictions, the model's estimated probability of one sequence should be more indicative of the quality of this sequence, which is essential for the beam search during inference.\"]}"
    },
    {
        "gold": {
            "text": [
                "3.",
                "Simple",
                "errors",
                "in",
                "phone",
                "recognition:",
                "As",
                "noted",
                "in",
                "#TARGET_REF",
                ",",
                "even",
                "the",
                "best-trained",
                "Allosaurus",
                "models,",
                "fine-tuned",
                "on",
                "languagespecific",
                "data,",
                "have",
                "a",
                "non-trivial",
                "Phone",
                "Error",
                "Rate",
                "(PER)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "3. Simple errors in phone recognition: As noted in #TARGET_REF , even the best-trained Allosaurus models, fine-tuned on languagespecific data, have a non-trivial Phone Error Rate (PER).",
        "output": "{\"INFORMATION\": [\"As noted in #TARGET_REF , even the best-trained Allosaurus models, fine-tuned on languagespecific data, have a non-trivial Phone Error Rate (PER).\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "line",
                "of",
                "past",
                "work",
                "tests",
                "if",
                "type",
                "information",
                "or",
                "other",
                "knowledge",
                "is",
                "captured",
                "by",
                "pre-trained",
                "LMs.",
                "#TARGET_REF",
                "report",
                "that",
                "ELMo",
                "performs",
                "well",
                "on",
                "word",
                "sense",
                "disambiguation",
                "and",
                "POS",
                "tagging.",
                "Some",
                "other",
                "work",
                "also",
                "investigates",
                "models'",
                "ability",
                "to",
                "induce",
                "syntactic",
                "information",
                "by",
                "measuring",
                "accuracy",
                "of",
                "a",
                "probe",
                "#REF",
                ".",
                "However,",
                "there",
                "is",
                "significant",
                "uncertainty",
                "about",
                "how",
                "to",
                "calibrate",
                "such",
                "probing",
                "results",
                "#REF",
                ",",
                "our",
                "model's",
                "representations",
                "are",
                "more",
                "directly",
                "interpretable",
                "and",
                "don't",
                "require",
                "posthoc",
                "probing."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Another line of past work tests if type information or other knowledge is captured by pre-trained LMs. #TARGET_REF report that ELMo performs well on word sense disambiguation and POS tagging. Some other work also investigates models' ability to induce syntactic information by measuring accuracy of a probe #REF . However, there is significant uncertainty about how to calibrate such probing results #REF , our model's representations are more directly interpretable and don't require posthoc probing.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF report that ELMo performs well on word sense disambiguation and POS tagging.\"], \"PERCEPTION\": [\"Another line of past work tests if type information or other knowledge is captured by pre-trained LMs.\", \"there is significant uncertainty about how to calibrate such probing results #REF , our model's representations are more directly interpretable and don't require posthoc probing.\"], \"BACKGROUND\": [\"Some other work also investigates models' ability to induce syntactic information by measuring accuracy of a probe #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "After",
                "the",
                "annotations",
                "were",
                "extracted",
                "from",
                "the",
                "database,",
                "the",
                "data",
                "needed",
                "to",
                "be",
                "cleaned",
                "up.",
                "The",
                "different",
                "evaluations",
                "required",
                "different",
                "pre-processing",
                "steps.",
                "Most",
                "commonly,",
                "this",
                "included",
                "the",
                "removal",
                "of",
                "superfluous",
                "characters",
                "containing",
                "no",
                "information.",
                "We",
                "tried",
                "to",
                "keep",
                "as",
                "much",
                "of",
                "the",
                "original",
                "information",
                "as",
                "possible,",
                "including",
                "keeping",
                "offensive,",
                "racist,",
                "and",
                "sexist",
                "language",
                "as",
                "is.",
                "If",
                "such",
                "information",
                "is",
                "removed,",
                "the",
                "usefulness",
                "of",
                "the",
                "data",
                "is",
                "at",
                "risk",
                "of",
                "being",
                "reduced,",
                "particularly",
                "when",
                "used",
                "for",
                "e.g.",
                "offensive",
                "language",
                "detection",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "After the annotations were extracted from the database, the data needed to be cleaned up. The different evaluations required different pre-processing steps. Most commonly, this included the removal of superfluous characters containing no information. We tried to keep as much of the original information as possible, including keeping offensive, racist, and sexist language as is. If such information is removed, the usefulness of the data is at risk of being reduced, particularly when used for e.g. offensive language detection #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"offensive language detection #TARGET_REF\"], \"PERCEPTION\": [\"We tried to keep as much of the original information as possible, including keeping offensive, racist, and sexist language as is.\"], \"BACKGROUND\": [\"After the annotations were extracted from the database, the data needed to be cleaned up.\", \"Most commonly, this included the removal of superfluous characters containing no information.\", \"If such information is removed, the usefulness of the data is at risk of being reduced, particularly when used for e.g.\"]}"
    },
    {
        "gold": {
            "text": [
                "They",
                "are,",
                "as",
                "it",
                "were,",
                "wholly",
                "pragmatic",
                "statisticians:",
                "less",
                "pure",
                "than,",
                "say,",
                "the",
                "Gale",
                "group",
                "(e.g.",
                "#TARGET_REF",
                ")",
                "at",
                "AT&amp,T:",
                "this",
                "is",
                "easily",
                "seen",
                "by",
                "the",
                "IBM",
                "introduction",
                "of",
                "notions",
                "like",
                "the",
                "one",
                "they",
                "call",
                "\"informants\"",
                "where",
                "a",
                "noun",
                "phrase",
                "of",
                "some",
                "sort",
                "is",
                "sought",
                "before",
                "a",
                "particular",
                "text",
                "item",
                "of",
                "interest.",
                "This",
                "is",
                "an",
                "interpolation",
                "of",
                "a",
                "highly",
                "theoretically-loaded",
                "notion",
                "into",
                "a",
                "routine",
                "that,",
                "until",
                "then,",
                "had",
                "treated",
                "all",
                "text",
                "items",
                "as",
                "mere",
                "uninterpreted",
                "symbols."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "They are, as it were, wholly pragmatic statisticians: less pure than, say, the Gale group (e.g. #TARGET_REF ) at AT&amp,T: this is easily seen by the IBM introduction of notions like the one they call \"informants\" where a noun phrase of some sort is sought before a particular text item of interest. This is an interpolation of a highly theoretically-loaded notion into a routine that, until then, had treated all text items as mere uninterpreted symbols.",
        "output": "{\"INFORMATION\": [\"the Gale group (e.g. #TARGET_REF )\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "ATOMIC-LIGHT.",
                "ATOMIC-LIGHT",
                "is",
                "a",
                "(domain-adapted)",
                "fantasy",
                "commonsense",
                "knowledge",
                "graph,",
                "and",
                "as",
                "such",
                "provides",
                "priors",
                "for",
                "an",
                "agent",
                "on",
                "how",
                "to",
                "act",
                "consistently",
                "in",
                "the",
                "world.",
                "For",
                "example,",
                "given",
                "a",
                "clause",
                "such",
                "as",
                "\"The",
                "knight",
                "wishes",
                "to",
                "slay",
                "the",
                "dragon,",
                "as",
                "a",
                "result",
                "the",
                "knight",
                "needs",
                "to",
                "acquire",
                "a",
                "sword,\"",
                "the",
                "task",
                "would",
                "be",
                "to",
                "predict",
                "the",
                "underlined",
                "text-a",
                "form",
                "of",
                "knowledge",
                "graph",
                "completion",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "ATOMIC-LIGHT. ATOMIC-LIGHT is a (domain-adapted) fantasy commonsense knowledge graph, and as such provides priors for an agent on how to act consistently in the world. For example, given a clause such as \"The knight wishes to slay the dragon, as a result the knight needs to acquire a sword,\" the task would be to predict the underlined text-a form of knowledge graph completion #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"knowledge graph completion #TARGET_REF .\"], \"PERCEPTION\": [\"the task would be to predict the underlined text-a form of\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "recent",
                "years,",
                "we",
                "have",
                "witnessed",
                "a",
                "considerable",
                "increase",
                "in",
                "the",
                "use",
                "of",
                "assistive",
                "technologies",
                "that",
                "can",
                "engage",
                "in",
                "communication",
                "and",
                "perform",
                "tasks.",
                "These",
                "can",
                "come",
                "in",
                "different",
                "forms",
                "like",
                "smart",
                "speakers",
                "and",
                "mobile",
                "devices",
                "that",
                "you",
                "can",
                "command",
                "with",
                "audio,",
                "or",
                "more",
                "specialized",
                "task-oriented",
                "robots",
                "that",
                "can",
                "actually",
                "realize",
                "users'",
                "command",
                "in",
                "3D",
                "environments.",
                "The",
                "steady",
                "increase",
                "in",
                "the",
                "use",
                "of",
                "collaborative",
                "robots",
                "#TARGET_REF",
                "in",
                "daily",
                "life",
                "brings",
                "along",
                "another",
                "important",
                "Human-Computer",
                "Interaction",
                "theme:",
                "the",
                "capability",
                "of",
                "engaging",
                "in",
                "a",
                "natural",
                "and",
                "smooth",
                "spoken",
                "dialog",
                "with",
                "humans,",
                "which",
                "is",
                "a",
                "major",
                "scientific",
                "and",
                "technological",
                "challenge.",
                "Particularly,",
                "being",
                "able",
                "to",
                "follow",
                "a",
                "communication",
                "that",
                "conveys",
                "thoughts",
                "and",
                "intentions",
                "expressed",
                "in",
                "a",
                "flexible",
                "manner",
                "without",
                "the",
                "restrictions",
                "of",
                "a",
                "close-set",
                "of",
                "commands",
                "is",
                "a",
                "crucial",
                "component",
                "of",
                "assistive",
                "robots",
                "for",
                "the",
                "handicapped",
                "and",
                "elderly",
                "people",
                "and",
                "for",
                "the",
                "education",
                "/",
                "entertainment",
                "purposes."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In recent years, we have witnessed a considerable increase in the use of assistive technologies that can engage in communication and perform tasks. These can come in different forms like smart speakers and mobile devices that you can command with audio, or more specialized task-oriented robots that can actually realize users' command in 3D environments. The steady increase in the use of collaborative robots #TARGET_REF in daily life brings along another important Human-Computer Interaction theme: the capability of engaging in a natural and smooth spoken dialog with humans, which is a major scientific and technological challenge. Particularly, being able to follow a communication that conveys thoughts and intentions expressed in a flexible manner without the restrictions of a close-set of commands is a crucial component of assistive robots for the handicapped and elderly people and for the education / entertainment purposes.",
        "output": "{\"INFORMATION\": [\"The steady increase in the use of collaborative robots #TARGET_REF in daily life brings along another important Human-Computer Interaction theme: the capability of engaging in a natural and smooth spoken dialog with humans, which is a major scientific and technological challenge.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"In recent years, we have witnessed a considerable increase in the use of assistive technologies that can engage in communication and perform tasks.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "each",
                "segment,",
                "the",
                "human",
                "rater",
                "was",
                "presented",
                "with",
                "a",
                "vertically-arranged",
                "list",
                "showing",
                "all",
                "variants",
                "of",
                "that",
                "segment.",
                "The",
                "first",
                "entry",
                "in",
                "each",
                "list",
                "was",
                "the",
                "segment",
                "in",
                "the",
                "source",
                "language",
                "(Russian).",
                "The",
                "source",
                "segment",
                "was",
                "followed",
                "by",
                "the",
                "reference",
                "translation",
                "in",
                "English.",
                "The",
                "subsequent",
                "eight",
                "entries",
                "were",
                "English",
                "translations",
                "of",
                "the",
                "source",
                "segment,",
                "presented",
                "in",
                "a",
                "randomized",
                "order.",
                "The",
                "English",
                "translations",
                "included",
                "the",
                "unedited",
                "machine",
                "translation",
                "output,",
                "as",
                "produced",
                "by",
                "Moses,",
                "a",
                "post-edited",
                "translation",
                "produced",
                "by",
                "a",
                "monolingual",
                "post-editor",
                "from",
                "#TARGET_REF",
                ",",
                "and",
                "the",
                "six",
                "post-edited",
                "translations",
                "produced",
                "by",
                "the",
                "Russian-English",
                "bilingual",
                "posteditors",
                "in",
                "this",
                "study."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For each segment, the human rater was presented with a vertically-arranged list showing all variants of that segment. The first entry in each list was the segment in the source language (Russian). The source segment was followed by the reference translation in English. The subsequent eight entries were English translations of the source segment, presented in a randomized order. The English translations included the unedited machine translation output, as produced by Moses, a post-edited translation produced by a monolingual post-editor from #TARGET_REF , and the six post-edited translations produced by the Russian-English bilingual posteditors in this study.",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [\"The English translations included the unedited machine translation output, as produced by Moses, a post-edited translation produced by a monolingual post-editor from #TARGET_REF , and the six post-edited translations produced by the Russian-English bilingual posteditors in this study.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Until",
                "recently,",
                "the",
                "interactive",
                "approach",
                "to",
                "MT",
                "almost",
                "inevitably",
                "came",
                "in",
                "the",
                "form",
                "of",
                "the",
                "widely",
                "promoted",
                "Translator's",
                "Workbench'",
                "idea",
                "#TARGET_REF",
                ",",
                "the",
                "main",
                "aims",
                "of",
                "which",
                "are",
                "to",
                "help",
                "translators",
                "to",
                "translate",
                "texts.",
                "Now",
                "it",
                "has",
                "been",
                "acknowledged",
                "that",
                "there",
                "is",
                "a",
                "drawback",
                "in",
                "this",
                "approach,",
                "which",
                "is",
                "that",
                "it",
                "is",
                "sometimes",
                "difficult",
                "to",
                "see",
                "where",
                "the",
                "most",
                "appropriate",
                "division",
                "of",
                "labour",
                "between",
                "the",
                "computer",
                "and",
                "the",
                "human",
                "should",
                "occur,",
                "and",
                "there",
                "is",
                "sometimes",
                "even",
                "a",
                "conflict",
                "between",
                "what",
                "the",
                "system",
                "offers",
                "the",
                "translator-user,",
                "and",
                "what",
                "the",
                "user",
                "already",
                "knows,",
                "or",
                "between",
                "the",
                "extent",
                "to",
                "which",
                "the",
                "system",
                "or",
                "the",
                "user",
                "should",
                "take",
                "the",
                "initiative,",
                "which",
                "might",
                "differ",
                "from",
                "occasion",
                "to",
                "occasion."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Until recently, the interactive approach to MT almost inevitably came in the form of the widely promoted Translator's Workbench' idea #TARGET_REF , the main aims of which are to help translators to translate texts. Now it has been acknowledged that there is a drawback in this approach, which is that it is sometimes difficult to see where the most appropriate division of labour between the computer and the human should occur, and there is sometimes even a conflict between what the system offers the translator-user, and what the user already knows, or between the extent to which the system or the user should take the initiative, which might differ from occasion to occasion.",
        "output": "{\"INFORMATION\": [\"Translator's Workbench' idea #TARGET_REF\", \"to help translators to translate texts.\"], \"PERCEPTION\": [\"Until recently, the interactive approach to MT almost inevitably came in the form of the widely promoted\", \"the main aims of which are\", \"Now it has been acknowledged that there is a drawback in this approach, which is that it is sometimes difficult to see where the most appropriate division of labour between the computer and the human should occur,\"], \"BACKGROUND\": [\"and there is sometimes even a conflict between what the system offers the translator-user, and what the user already knows, or between the extent to which the system or the user should take the initiative,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "our",
                "system,",
                "we",
                "train",
                "a",
                "Transformer",
                "#TARGET_REF",
                "with",
                "a",
                "deep",
                "encoder",
                "#REF",
                "as",
                "baseline",
                "for",
                "abtaining",
                "rich",
                "source",
                "representations,",
                "besides",
                "we",
                "initialize",
                "the",
                "model",
                "with",
                "the",
                "method",
                "mentioned",
                "in",
                "DeepNet",
                "#REF",
                "in",
                "order",
                "to",
                "stabilize",
                "the",
                "training",
                "of",
                "the",
                "deeper",
                "model.",
                "At",
                "the",
                "pre-training",
                "stage,",
                "we",
                "firstly",
                "pretrain",
                "our",
                "model",
                "on",
                "a",
                "large",
                "general",
                "corpus,",
                "then",
                "we",
                "utilize",
                "data",
                "synthesis",
                "methods",
                "such",
                "as",
                "self-training",
                "and",
                "back-translation",
                "to",
                "improve",
                "model",
                "quality."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In our system, we train a Transformer #TARGET_REF with a deep encoder #REF as baseline for abtaining rich source representations, besides we initialize the model with the method mentioned in DeepNet #REF in order to stabilize the training of the deeper model. At the pre-training stage, we firstly pretrain our model on a large general corpus, then we utilize data synthesis methods such as self-training and back-translation to improve model quality.",
        "output": "{\"INFORMATION\": [\"a Transformer #TARGET_REF\"], \"PERCEPTION\": [\"In our system, we train\", \"with a deep encoder #REF as baseline for abtaining rich source representations,\", \"we initialize the model with the method mentioned in DeepNet #REF in order to stabilize the training of the deeper model.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Neural",
                "Machine",
                "Translation",
                "(NMT)",
                "has",
                "opened",
                "several",
                "research",
                "directions",
                "to",
                "exploit",
                "as",
                "many",
                "and",
                "diverse",
                "data",
                "as",
                "possible.",
                "Massive",
                "multilingual",
                "NMT",
                "models,",
                "for",
                "instance,",
                "take",
                "advantage",
                "of",
                "several",
                "language-pair",
                "datasets",
                "in",
                "a",
                "single",
                "system",
                "#TARGET_REF",
                ".",
                "This",
                "offers",
                "several",
                "advantages,",
                "such",
                "as",
                "a",
                "simple",
                "training",
                "process",
                "and",
                "enhanced",
                "performance",
                "of",
                "the",
                "language-pairs",
                "with",
                "little",
                "data",
                "(although",
                "sometimes",
                "detrimental",
                "to",
                "the",
                "high-resource",
                "language-pairs).",
                "However,",
                "massive",
                "models",
                "of",
                "dozens",
                "of",
                "languages",
                "are",
                "not",
                "necessarily",
                "the",
                "best",
                "outcome,",
                "as",
                "it",
                "is",
                "demonstrated",
                "that",
                "smaller",
                "clusters",
                "still",
                "offer",
                "the",
                "same",
                "benefits",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Neural Machine Translation (NMT) has opened several research directions to exploit as many and diverse data as possible. Massive multilingual NMT models, for instance, take advantage of several language-pair datasets in a single system #TARGET_REF . This offers several advantages, such as a simple training process and enhanced performance of the language-pairs with little data (although sometimes detrimental to the high-resource language-pairs). However, massive models of dozens of languages are not necessarily the best outcome, as it is demonstrated that smaller clusters still offer the same benefits #REF .",
        "output": "{\"INFORMATION\": [\"Massive multilingual NMT models, for instance, take advantage of several language-pair datasets in a single system #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Neural Machine Translation (NMT) has opened several research directions to exploit as many and diverse data as possible.\"]}"
    },
    {
        "gold": {
            "text": [
                "Passage",
                "re-ranking",
                "for",
                "open-domain",
                "QA",
                "Based",
                "on",
                "the",
                "retrieved",
                "passages",
                "from",
                "a",
                "first-stage",
                "retriever,",
                "BERT-based",
                "rerankers",
                "have",
                "recently",
                "been",
                "applied",
                "to",
                "retrieval-based",
                "question",
                "answering",
                "and",
                "search-related",
                "tasks",
                "#REF",
                ",",
                "and",
                "yield",
                "substantial",
                "improvements",
                "over",
                "the",
                "traditional",
                "methods.",
                "Although",
                "effective",
                "to",
                "some",
                "extent,",
                "these",
                "rankers",
                "employ",
                "the",
                "cross-encoder",
                "architecture",
                "(as",
                "shown",
                "in",
                "Figure",
                "1b)",
                "that",
                "is",
                "impractical",
                "to",
                "be",
                "applied",
                "to",
                "all",
                "passages",
                "in",
                "a",
                "corpus",
                "with",
                "respect",
                "to",
                "a",
                "question.",
                "The",
                "re-rankers",
                "#TARGET_REF",
                "with",
                "light",
                "weight",
                "interaction",
                "based",
                "on",
                "the",
                "representations",
                "of",
                "dense",
                "retrievers",
                "have",
                "been",
                "studied.",
                "However,",
                "these",
                "techniques",
                "still",
                "rely",
                "on",
                "a",
                "separate",
                "retriever",
                "which",
                "provides",
                "candidates",
                "and",
                "representations.",
                "As",
                "a",
                "comparison,",
                "we",
                "focus",
                "on",
                "developing",
                "dual-encoder",
                "based",
                "retrievers."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Passage re-ranking for open-domain QA Based on the retrieved passages from a first-stage retriever, BERT-based rerankers have recently been applied to retrieval-based question answering and search-related tasks #REF , and yield substantial improvements over the traditional methods. Although effective to some extent, these rankers employ the cross-encoder architecture (as shown in Figure 1b) that is impractical to be applied to all passages in a corpus with respect to a question. The re-rankers #TARGET_REF with light weight interaction based on the representations of dense retrievers have been studied. However, these techniques still rely on a separate retriever which provides candidates and representations. As a comparison, we focus on developing dual-encoder based retrievers.",
        "output": "{\"INFORMATION\": [\"The re-rankers #TARGET_REF with light weight interaction based on the representations of dense retrievers have been studied.\"], \"PERCEPTION\": [\"However, these techniques still rely on a separate retriever which provides candidates and representations. As a comparison, we focus on developing dual-encoder based retrievers.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "evolution",
                "of",
                "the",
                "Information",
                "Age,",
                "where",
                "colossal",
                "amounts",
                "of",
                "research",
                "papers",
                "and",
                "scientific",
                "literature",
                "are",
                "now",
                "available,",
                "the",
                "need",
                "for",
                "a",
                "method",
                "which",
                "measures",
                "the",
                "scientific",
                "impact",
                "of",
                "a",
                "paper",
                "has",
                "become",
                "paramount.",
                "One",
                "such",
                "method",
                "is",
                "citation",
                "analysis.",
                "Citations",
                "are",
                "defined",
                "as",
                "a",
                "reference",
                "to",
                "the",
                "source",
                "of",
                "information",
                "used",
                "in",
                "one's",
                "research.",
                "The",
                "conventional",
                "approach",
                "to",
                "citation",
                "analysis",
                "involves",
                "utilising",
                "the",
                "frequency",
                "of",
                "citations",
                "#TARGET_REF",
                "while",
                "treating",
                "all",
                "citations",
                "equally.",
                "This",
                "methodology",
                "provides",
                "a",
                "vague",
                "or",
                "even",
                "inaccurate",
                "overview",
                "of",
                "scientific",
                "development."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the evolution of the Information Age, where colossal amounts of research papers and scientific literature are now available, the need for a method which measures the scientific impact of a paper has become paramount. One such method is citation analysis. Citations are defined as a reference to the source of information used in one's research. The conventional approach to citation analysis involves utilising the frequency of citations #TARGET_REF while treating all citations equally. This methodology provides a vague or even inaccurate overview of scientific development.",
        "output": "{\"INFORMATION\": [\"the frequency of citations #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The conventional approach to citation analysis involves utilising\", \"while treating all citations equally.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "wait-k",
                "policy",
                "#TARGET_REF",
                "refers",
                "to",
                "write",
                "target",
                "word",
                "y",
                "t",
                "after",
                "reading",
                "source-side",
                "pre-fix",
                "(x",
                "1",
                "..x",
                "t+k−1",
                ").",
                "Let",
                "g(t)",
                "be",
                "a",
                "monotonic",
                "nondecreasing",
                "function",
                "of",
                "t",
                "that",
                "indicates",
                "the",
                "number",
                "of",
                "source",
                "words",
                "read",
                "by",
                "the",
                "encoder",
                "when",
                "writing",
                "the",
                "target",
                "word",
                "y",
                "t",
                ".",
                "Unlike",
                "full-sentence",
                "translation,",
                "the",
                "wait-k",
                "policy",
                "uses",
                "the",
                "source",
                "prefix",
                "(x",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "x",
                "g(t)",
                ")",
                "rather",
                "than",
                "the",
                "whole",
                "sentence",
                "x",
                "to",
                "generate",
                "y",
                "t",
                ":",
                "p(y",
                "t",
                "|x",
                "≤g(t)",
                ",",
                "y",
                "&lt,t",
                ").",
                "Thus,",
                "the",
                "decoding",
                "probability",
                "is",
                "shown",
                "in",
                "Eq.",
                "7,",
                "and",
                "given",
                "training",
                "data",
                "D,",
                "the",
                "training",
                "objective",
                "is",
                "shown",
                "in",
                "Eq.",
                "8."
            ],
            "context": [
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The wait-k policy #TARGET_REF refers to write target word y t after reading source-side pre-fix (x 1 ..x t+k−1 ). Let g(t) be a monotonic nondecreasing function of t that indicates the number of source words read by the encoder when writing the target word y t . Unlike full-sentence translation, the wait-k policy uses the source prefix (x 1 , . . . , x g(t) ) rather than the whole sentence x to generate y t : p(y t |x ≤g(t) , y &lt,t ). Thus, the decoding probability is shown in Eq. 7, and given training data D, the training objective is shown in Eq. 8.",
        "output": "{\"INFORMATION\": [\"The wait-k policy #TARGET_REF\"], \"PERCEPTION\": [\"refers to write target word y t after reading source-side pre-fix (x 1 ..x t+k\\u22121 ).\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Class",
                "Weights:",
                "The",
                "class",
                "unbalance",
                "problem",
                "from",
                "subtask",
                "1a",
                "is",
                "addressed",
                "using",
                "the",
                "weighted",
                "version",
                "of",
                "the",
                "cross-entropy",
                "loss.",
                "The",
                "weights",
                "of",
                "the",
                "two",
                "classes",
                "were",
                "computed",
                "using",
                "the",
                "balanced",
                "heuristic",
                "#TARGET_REF",
                "from",
                "the",
                "scikitlearn",
                "library",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Class Weights: The class unbalance problem from subtask 1a is addressed using the weighted version of the cross-entropy loss. The weights of the two classes were computed using the balanced heuristic #TARGET_REF from the scikitlearn library #REF .",
        "output": "{\"INFORMATION\": [\"the balanced heuristic #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Class Weights: The class unbalance problem from subtask 1a is addressed using the weighted version of the cross-entropy loss. The weights of the two classes were computed using\", \"from the scikitlearn library #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Factored",
                "neural",
                "machine",
                "translation",
                "is",
                "an",
                "extension",
                "of",
                "the",
                "standard",
                "NMT",
                "architecture",
                "which",
                "allows",
                "us",
                "generating",
                "several",
                "output",
                "symbols",
                "simultaneously",
                "as",
                "presented",
                "in",
                "For",
                "simplicity",
                "reasons,",
                "only",
                "two",
                "symbols",
                "are",
                "generated:",
                "the",
                "lemma",
                "and",
                "the",
                "concatenation",
                "of",
                "the",
                "different",
                "factors",
                "that",
                "we",
                "consider.",
                "For",
                "example,",
                "from",
                "the",
                "French",
                "word",
                "devient,",
                "we",
                "obtain",
                "the",
                "lemma",
                "devenir",
                "and",
                "the",
                "factors",
                "VP3#S,",
                "meaning",
                "that",
                "it",
                "is",
                "a",
                "Verb,",
                "in",
                "Present,",
                "3rd",
                "person,",
                "irrelevant",
                "gender",
                "(#)",
                "and",
                "Singular.",
                "The",
                "morphological",
                "and",
                "grammatical",
                "analysis",
                "is",
                "performed",
                "with",
                "the",
                "MACAON",
                "toolkit",
                "#TARGET_REF",
                ".",
                "MACAON",
                "POS-tagger",
                "outputs",
                "the",
                "lemma",
                "and",
                "factors",
                "for",
                "each",
                "word",
                "taking",
                "into",
                "account",
                "its",
                "context.",
                "For",
                "the",
                "very",
                "few",
                "cases",
                "when",
                "MACAON",
                "proposes",
                "multiple",
                "factors,",
                "the",
                "first",
                "proposition",
                "is",
                "taken.",
                "The",
                "decoder",
                "of",
                "the",
                "FNMT",
                "architecture",
                "presented",
                "in",
                "Figure",
                "3",
                "may",
                "lead",
                "to",
                "sequences",
                "with",
                "different",
                "length",
                "since",
                "lemmas",
                "and",
                "factors",
                "are",
                "generated",
                "in",
                "a",
                "synchronous",
                "stream,",
                "but",
                "in",
                "separate",
                "outputs.",
                "Indeed,",
                "each",
                "sequence",
                "of",
                "symbols",
                "ends",
                "when",
                "the",
                "end-of-sequence",
                "(&lt,eos&gt,",
                ")",
                "symbol",
                "is",
                "generated",
                "with",
                "this",
                "architecture,",
                "and",
                "nothing",
                "prevents",
                "the",
                "lemma",
                "generator",
                "to",
                "output",
                "the",
                "&lt,eos&gt,",
                "symbol",
                "before",
                "or",
                "after",
                "the",
                "factors",
                "generator.",
                "To",
                "avoid",
                "this",
                "scenario,",
                "the",
                "length",
                "of",
                "the",
                "factors",
                "sequence",
                "is",
                "constricted",
                "to",
                "be",
                "equal",
                "to",
                "the",
                "length",
                "of",
                "the",
                "lemma",
                "sequence.",
                "This",
                "implies",
                "that",
                "to",
                "ignore",
                "the",
                "&lt,eos&gt,",
                "symbol",
                "for",
                "factors",
                "(to",
                "avoid",
                "shorter",
                "factors",
                "sequence)",
                "and",
                "stop",
                "the",
                "generation",
                "of",
                "factors",
                "when",
                "the",
                "lemma",
                "sequence",
                "has",
                "ended",
                "(to",
                "avoid",
                "longer",
                "factors",
                "sequence).",
                "This",
                "is",
                "motivated",
                "by",
                "the",
                "fact",
                "that",
                "the",
                "lemmas",
                "are",
                "closer",
                "to",
                "the",
                "final",
                "objective",
                "(a",
                "sequence",
                "of",
                "words)",
                "and",
                "that",
                "they",
                "are",
                "the",
                "symbols",
                "carrying",
                "most",
                "of",
                "the",
                "meaning."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The Factored neural machine translation is an extension of the standard NMT architecture which allows us generating several output symbols simultaneously as presented in For simplicity reasons, only two symbols are generated: the lemma and the concatenation of the different factors that we consider. For example, from the French word devient, we obtain the lemma devenir and the factors VP3#S, meaning that it is a Verb, in Present, 3rd person, irrelevant gender (#) and Singular. The morphological and grammatical analysis is performed with the MACAON toolkit #TARGET_REF . MACAON POS-tagger outputs the lemma and factors for each word taking into account its context. For the very few cases when MACAON proposes multiple factors, the first proposition is taken. The decoder of the FNMT architecture presented in Figure 3 may lead to sequences with different length since lemmas and factors are generated in a synchronous stream, but in separate outputs. Indeed, each sequence of symbols ends when the end-of-sequence (&lt,eos&gt, ) symbol is generated with this architecture, and nothing prevents the lemma generator to output the &lt,eos&gt, symbol before or after the factors generator. To avoid this scenario, the length of the factors sequence is constricted to be equal to the length of the lemma sequence. This implies that to ignore the &lt,eos&gt, symbol for factors (to avoid shorter factors sequence) and stop the generation of factors when the lemma sequence has ended (to avoid longer factors sequence). This is motivated by the fact that the lemmas are closer to the final objective (a sequence of words) and that they are the symbols carrying most of the meaning.",
        "output": "{\"INFORMATION\": [\"the MACAON toolkit #TARGET_REF .\"], \"PERCEPTION\": [\"The morphological and grammatical analysis is performed with\"], \"BACKGROUND\": [\"MACAON POS-tagger outputs the lemma and factors for each word taking into account its context. For the very few cases when MACAON proposes multiple factors, the first proposition is taken.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Trace",
                "Embedding:",
                "Each",
                "trace",
                "input",
                "item",
                "t",
                "i",
                "is",
                "projected",
                "into",
                "ti",
                "∈",
                "R",
                "d",
                ".",
                "We",
                "also",
                "generate",
                "Sinusoidal",
                "Positional",
                "Embeddings",
                "#TARGET_REF",
                "o",
                "i",
                "to",
                "capture",
                "the",
                "temporal",
                "order",
                "of",
                "the",
                "traces.",
                "The",
                "final",
                "trace",
                "embedding",
                "T",
                "=",
                "{",
                "t1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "tM",
                "},",
                "where",
                "ti",
                "=",
                "ti",
                "+",
                "o",
                "i",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Trace Embedding: Each trace input item t i is projected into ti ∈ R d . We also generate Sinusoidal Positional Embeddings #TARGET_REF o i to capture the temporal order of the traces. The final trace embedding T = { t1 , . . . , tM }, where ti = ti + o i .",
        "output": "{\"INFORMATION\": [\"Sinusoidal Positional Embeddings #TARGET_REF\"], \"PERCEPTION\": [\"We also generate\", \"o i to capture the temporal order of the traces.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "approach",
                "is",
                "inspired",
                "by",
                "the",
                "fact",
                "that",
                "many",
                "languages",
                "are",
                "primarily",
                "oral,",
                "with",
                "writing",
                "systems",
                "that",
                "represent",
                "spoken",
                "sounds.",
                "We",
                "convert",
                "both",
                "text",
                "and",
                "audio",
                "into",
                "single",
                "common",
                "representation",
                "of",
                "sounds,",
                "or",
                "\"phones,\"",
                "represented",
                "using",
                "the",
                "International",
                "Phonetic",
                "Alphabet,",
                "or",
                "IPA.",
                "Then,",
                "we",
                "perform",
                "both",
                "language",
                "model",
                "pre-training",
                "and",
                "the",
                "training",
                "of",
                "models",
                "for",
                "downstream",
                "tasks",
                "in",
                "this",
                "phonetic",
                "representation.",
                "Well-tested",
                "architectures,",
                "such",
                "as",
                "BERT-style",
                "transformer",
                "models",
                "#TARGET_REF",
                ",",
                "are",
                "thus",
                "flexibly",
                "extended",
                "to",
                "either",
                "speech",
                "or",
                "audio",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Our approach is inspired by the fact that many languages are primarily oral, with writing systems that represent spoken sounds. We convert both text and audio into single common representation of sounds, or \"phones,\" represented using the International Phonetic Alphabet, or IPA. Then, we perform both language model pre-training and the training of models for downstream tasks in this phonetic representation. Well-tested architectures, such as BERT-style transformer models #TARGET_REF , are thus flexibly extended to either speech or audio data.",
        "output": "{\"INFORMATION\": [\"BERT-style transformer models #TARGET_REF ,\"], \"PERCEPTION\": [\"Well-tested architectures, such as\", \"are thus flexibly extended to either speech or audio data.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "goal",
                "of",
                "statistical",
                "machine",
                "translation",
                "is",
                "to",
                "produce",
                "a",
                "target",
                "sentence",
                "e",
                "from",
                "a",
                "source",
                "sentence",
                "f",
                ".",
                "It",
                "is",
                "today",
                "common",
                "practice",
                "to",
                "use",
                "phrases",
                "as",
                "translation",
                "units",
                "#TARGET_REF",
                "and",
                "a",
                "log",
                "linear",
                "framework",
                "in",
                "order",
                "to",
                "introduce",
                "several",
                "models",
                "explaining",
                "the",
                "translation",
                "process:"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The goal of statistical machine translation is to produce a target sentence e from a source sentence f . It is today common practice to use phrases as translation units #TARGET_REF and a log linear framework in order to introduce several models explaining the translation process:",
        "output": "{\"INFORMATION\": [\"use phrases as translation units #TARGET_REF\"], \"PERCEPTION\": [\"It is today common practice to\", \"in order to introduce several models explaining the translation process:\"], \"BACKGROUND\": [\"The goal of statistical machine translation is to produce a target sentence e from a source sentence f .\", \"and a log linear framework\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "other",
                "major",
                "direction,",
                "these",
                "large",
                "Transformer-based",
                "models",
                "have",
                "been",
                "down-sized",
                "to",
                "be",
                "more",
                "time",
                "and",
                "space",
                "efficient.",
                "Different",
                "methods",
                "for",
                "down-sizing",
                "have",
                "been",
                "studied",
                "such",
                "as",
                "pruning",
                "#REF",
                ",",
                "distillation",
                "#REF",
                ",",
                "weight",
                "quantization",
                "#TARGET_REF",
                ",",
                "and",
                "weight",
                "factorization",
                "and",
                "parameter",
                "sharing",
                "#REF",
                ".",
                "Pruning",
                "techniques",
                "have",
                "been",
                "particularly",
                "successful",
                "in",
                "reinforcing",
                "the",
                "folk-lore",
                "that",
                "these",
                "models",
                "are",
                "highly",
                "over-parameterized.",
                "These",
                "pruning",
                "methods",
                "prune",
                "parameters",
                "based",
                "on",
                "magnitude",
                "#REF",
                ",",
                "importance",
                "#REF",
                "or",
                "layer-wise",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the other major direction, these large Transformer-based models have been down-sized to be more time and space efficient. Different methods for down-sizing have been studied such as pruning #REF , distillation #REF , weight quantization #TARGET_REF , and weight factorization and parameter sharing #REF . Pruning techniques have been particularly successful in reinforcing the folk-lore that these models are highly over-parameterized. These pruning methods prune parameters based on magnitude #REF , importance #REF or layer-wise #REF .",
        "output": "{\"INFORMATION\": [\"weight quantization #TARGET_REF\"], \"PERCEPTION\": [\"Different methods for down-sizing have been studied\"], \"BACKGROUND\": [\"In the other major direction, these large Transformer-based models have been down-sized to be more time and space efficient.\", \"such as pruning #REF , distillation #REF ,\", \", and weight factorization and parameter sharing #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "mean",
                "adequacy",
                "score",
                "when",
                "bilingual",
                "participants",
                "were",
                "presented",
                "with",
                "alignments",
                "was",
                "8.35.",
                "When",
                "alignments",
                "were",
                "omitted",
                "from",
                "the",
                "post-editing",
                "tool,",
                "the",
                "mean",
                "adequacy",
                "score",
                "was",
                "7.85.",
                "A",
                "Wilcoxon",
                "signed-rank",
                "test",
                "#TARGET_REF",
                "showed",
                "that",
                "when",
                "participants",
                "were",
                "presented",
                "with",
                "alignments",
                "the",
                "ratings",
                "of",
                "their",
                "translations",
                "were",
                "significantly",
                "higher",
                "than",
                "when",
                "participants",
                "post-edited",
                "without",
                "access",
                "to",
                "alignments",
                "(N",
                "=",
                "6,",
                "Z",
                "=",
                "-2.207,",
                "p",
                "=",
                "0.027)."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The mean adequacy score when bilingual participants were presented with alignments was 8.35. When alignments were omitted from the post-editing tool, the mean adequacy score was 7.85. A Wilcoxon signed-rank test #TARGET_REF showed that when participants were presented with alignments the ratings of their translations were significantly higher than when participants post-edited without access to alignments (N = 6, Z = -2.207, p = 0.027).",
        "output": "{\"INFORMATION\": [\"A Wilcoxon signed-rank test #TARGET_REF showed that when participants were presented with alignments the ratings of their translations were significantly higher than when participants post-edited without access to alignments (N = 6, Z = -2.207, p = 0.027).\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The mean adequacy score when bilingual participants were presented with alignments was 8.35. When alignments were omitted from the post-editing tool, the mean adequacy score was 7.85.\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "a",
                "few",
                "studies",
                "on",
                "the",
                "joint",
                "understanding",
                "of",
                "coreference",
                "relations",
                "and",
                "reading",
                "comprehension.",
                "#TARGET_REF",
                "propose",
                "to",
                "formulate",
                "coreference",
                "resolution",
                "as",
                "a",
                "span-prediction",
                "task",
                "by",
                "generating",
                "a",
                "query",
                "for",
                "each",
                "mention",
                "using",
                "the",
                "surrounding",
                "context,",
                "thus",
                "converting",
                "coreference",
                "resolution",
                "to",
                "a",
                "reading",
                "comprehension",
                "problem.",
                "They",
                "leverage",
                "the",
                "plethora",
                "of",
                "existing",
                "MRC",
                "datasets",
                "for",
                "data",
                "augmentation",
                "and",
                "improve",
                "the",
                "generalization",
                "of",
                "the",
                "coreference",
                "model.",
                "In",
                "parallel",
                "to",
                "#REF",
                ",",
                "#REF",
                "also",
                "cast",
                "ellipsis",
                "and",
                "coreference",
                "resolution",
                "as",
                "reading",
                "comprehension",
                "tasks.",
                "They",
                "leverage",
                "the",
                "existing",
                "neural",
                "archi-tectures",
                "designed",
                "for",
                "MRC",
                "for",
                "ellipsis",
                "resolution",
                "and",
                "outperform",
                "the",
                "previous",
                "best",
                "results.",
                "In",
                "a",
                "similar",
                "direction,",
                "#REF",
                "propose",
                "to",
                "cast",
                "bridging",
                "anaphora",
                "resolution",
                "as",
                "question",
                "answering",
                "and",
                "present",
                "a",
                "question",
                "answering",
                "framework",
                "for",
                "this",
                "task.",
                "However,",
                "none",
                "of",
                "the",
                "above",
                "works",
                "investigate",
                "the",
                "impact",
                "of",
                "using",
                "coreference",
                "data",
                "on",
                "QA.",
                "#REF",
                "use",
                "Amazon",
                "Mechanical",
                "Turkers",
                "to",
                "annotate",
                "the",
                "corresponding",
                "coreference",
                "chains",
                "of",
                "the",
                "answers",
                "in",
                "the",
                "passages",
                "of",
                "Quoref",
                "for",
                "2,000",
                "QA",
                "pairs.",
                "They",
                "then",
                "use",
                "this",
                "additional",
                "coreference",
                "annotation",
                "for",
                "training",
                "a",
                "model",
                "on",
                "Quoref.",
                "They",
                "show",
                "that",
                "including",
                "these",
                "additional",
                "coreference",
                "annotations",
                "improves",
                "the",
                "overall",
                "performance",
                "on",
                "Quoref.",
                "The",
                "proposed",
                "method",
                "by",
                "#REF",
                "requires",
                "annotating",
                "additional",
                "coreference",
                "relations",
                "on",
                "every",
                "new",
                "coreference-aware",
                "QA",
                "dataset.",
                "Contrary",
                "to",
                "this,",
                "our",
                "approach",
                "uses",
                "existing",
                "coreference",
                "resolution",
                "datasets,",
                "and",
                "therefore,",
                "applies",
                "to",
                "any",
                "new",
                "QA",
                "dataset",
                "without",
                "introducing",
                "any",
                "additional",
                "cost."
            ],
            "context": [
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There are a few studies on the joint understanding of coreference relations and reading comprehension. #TARGET_REF propose to formulate coreference resolution as a span-prediction task by generating a query for each mention using the surrounding context, thus converting coreference resolution to a reading comprehension problem. They leverage the plethora of existing MRC datasets for data augmentation and improve the generalization of the coreference model. In parallel to #REF , #REF also cast ellipsis and coreference resolution as reading comprehension tasks. They leverage the existing neural archi-tectures designed for MRC for ellipsis resolution and outperform the previous best results. In a similar direction, #REF propose to cast bridging anaphora resolution as question answering and present a question answering framework for this task. However, none of the above works investigate the impact of using coreference data on QA. #REF use Amazon Mechanical Turkers to annotate the corresponding coreference chains of the answers in the passages of Quoref for 2,000 QA pairs. They then use this additional coreference annotation for training a model on Quoref. They show that including these additional coreference annotations improves the overall performance on Quoref. The proposed method by #REF requires annotating additional coreference relations on every new coreference-aware QA dataset. Contrary to this, our approach uses existing coreference resolution datasets, and therefore, applies to any new QA dataset without introducing any additional cost.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF propose to formulate coreference resolution as a span-prediction task by generating a query for each mention using the surrounding context,\", \"They leverage the plethora of existing MRC datasets for data augmentation and improve the generalization of the coreference model.\"], \"PERCEPTION\": [\"thus converting coreference resolution to a reading comprehension problem.\"], \"BACKGROUND\": [\"studies on the joint understanding of coreference relations and reading comprehension.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Use",
                "of",
                "Prepositions",
                "as",
                "Semantic",
                "Labels",
                "While",
                "the",
                "relations",
                "we",
                "identify",
                "between",
                "NPs",
                "can",
                "be",
                "expressed",
                "using",
                "prepositions,",
                "one",
                "could",
                "argue",
                "that",
                "using",
                "prepositions",
                "as",
                "semantic",
                "labels",
                "is",
                "not",
                "ideal,",
                "due",
                "to",
                "their",
                "inherent",
                "ambiguity",
                "#TARGET_REF",
                ":",
                "indeed",
                "a",
                "preposition",
                "such",
                "as",
                "for",
                "has",
                "multiple",
                "senses,",
                "and",
                "can",
                "indicate",
                "a",
                "large",
                "set",
                "of",
                "semantic",
                "relations",
                "ranging",
                "from",
                "BENEFICIARY",
                "to",
                "DURATION."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The Use of Prepositions as Semantic Labels While the relations we identify between NPs can be expressed using prepositions, one could argue that using prepositions as semantic labels is not ideal, due to their inherent ambiguity #TARGET_REF : indeed a preposition such as for has multiple senses, and can indicate a large set of semantic relations ranging from BENEFICIARY to DURATION.",
        "output": "{\"INFORMATION\": [\"The Use of Prepositions as Semantic Labels While the relations we identify between NPs can be expressed using prepositions, one could argue that using prepositions as semantic labels is not ideal, due to their inherent ambiguity #TARGET_REF :\"], \"PERCEPTION\": [\"indeed a preposition such as for has multiple senses, and can indicate a large set of semantic relations ranging from BENEFICIARY to DURATION.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "Integrated",
                "Gradients",
                "#REF",
                "from",
                "the",
                "Captum",
                "#TARGET_REF",
                "library",
                "for",
                "qualitative",
                "analysis",
                "of",
                "predictions",
                "for",
                "the",
                "SpanBERT-SP,",
                "and",
                "the",
                "RoBERTa-TC",
                "models.",
                "We",
                "calculate",
                "Integrated",
                "Gradients",
                "of",
                "the",
                "targets",
                "with",
                "respect",
                "to",
                "the",
                "embedding",
                "layer",
                "outputs.",
                "The",
                "Riemann",
                "Right",
                "numerical",
                "approximation",
                "method",
                "is",
                "used,",
                "with",
                "n",
                "steps=50.",
                "Following",
                "#REF",
                ",",
                "we",
                "calculate",
                "token-wise",
                "importance",
                "distributions",
                "and",
                "word-wise",
                "distributions",
                "for",
                "a",
                "few",
                "examples.",
                "We",
                "refer",
                "the",
                "paper",
                "to",
                "the",
                "reader",
                "for",
                "more",
                "details."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use Integrated Gradients #REF from the Captum #TARGET_REF library for qualitative analysis of predictions for the SpanBERT-SP, and the RoBERTa-TC models. We calculate Integrated Gradients of the targets with respect to the embedding layer outputs. The Riemann Right numerical approximation method is used, with n steps=50. Following #REF , we calculate token-wise importance distributions and word-wise distributions for a few examples. We refer the paper to the reader for more details.",
        "output": "{\"INFORMATION\": [\"the Captum #TARGET_REF\"], \"PERCEPTION\": [\"We use Integrated Gradients #REF from\", \"library for qualitative analysis of predictions for the SpanBERT-SP, and the RoBERTa-TC models. We calculate Integrated Gradients of the targets with respect to the embedding layer outputs.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "last",
                "years,",
                "there",
                "is",
                "increasing",
                "interest",
                "in",
                "the",
                "interaction",
                "between",
                "rule-based",
                "and",
                "statistical",
                "machine",
                "translation.",
                "A",
                "popular",
                "and",
                "successful",
                "idea",
                "is",
                "statistical",
                "post",
                "editing",
                "#TARGET_REF",
                ".",
                "The",
                "principle",
                "idea",
                "is",
                "to",
                "train",
                "an",
                "SMT",
                "system",
                "to",
                "correct",
                "the",
                "outputs",
                "of",
                "a",
                "rule-based",
                "translation",
                "system."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In the last years, there is increasing interest in the interaction between rule-based and statistical machine translation. A popular and successful idea is statistical post editing #TARGET_REF . The principle idea is to train an SMT system to correct the outputs of a rule-based translation system.",
        "output": "{\"INFORMATION\": [\"statistical post editing #TARGET_REF\", \"The principle idea is to train an SMT system to correct the outputs of a rule-based translation system.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"In the last years, there is increasing interest in the interaction between rule-based and statistical machine translation. A popular and successful idea is\"]}"
    },
    {
        "gold": {
            "text": [
                "4.",
                "For",
                "French,",
                "we",
                "did",
                "not",
                "find",
                "systems",
                "that",
                "did",
                "event",
                "extraction",
                "from",
                "the",
                "French",
                "TimeBank",
                "corpus.",
                "The",
                "existing",
                "literature",
                "either",
                "creates",
                "and",
                "evaluates",
                "on",
                "a",
                "modified",
                "corpus",
                "#TARGET_REF",
                "or",
                "provides",
                "annotations",
                "trained",
                "on",
                "the",
                "TimeML",
                "annotated",
                "data",
                "and",
                "tested",
                "on",
                "Fr-TempEval2)",
                "#REF",
                ".",
                "Therefore,",
                "we",
                "compare",
                "our",
                "performance",
                "to",
                "those,",
                "while",
                "also",
                "understanding",
                "that",
                "the",
                "comparison",
                "is",
                "not",
                "a",
                "strict",
                "metric.",
                "We",
                "hope",
                "to",
                "establish",
                "the",
                "scores",
                "here",
                "as",
                "baseline",
                "for",
                "further",
                "improvement",
                "over",
                "models",
                "in",
                "event",
                "detection",
                "in",
                "French."
            ],
            "context": [
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "4. For French, we did not find systems that did event extraction from the French TimeBank corpus. The existing literature either creates and evaluates on a modified corpus #TARGET_REF or provides annotations trained on the TimeML annotated data and tested on Fr-TempEval2) #REF . Therefore, we compare our performance to those, while also understanding that the comparison is not a strict metric. We hope to establish the scores here as baseline for further improvement over models in event detection in French.",
        "output": "{\"INFORMATION\": [\"on a modified corpus #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"we did not find systems that did event extraction from the French TimeBank corpus. The existing literature either creates and evaluates\", \"or provides annotations trained on the TimeML annotated data and tested on Fr-TempEval2) #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "evaluate",
                "on",
                "7",
                "sequence",
                "labelling",
                "benchmarks:",
                "4",
                "of",
                "which",
                "are",
                "NER",
                "datasets",
                "and",
                "3",
                "of",
                "which",
                "are",
                "POStagging",
                "datasets",
                "1",
                ".",
                "In",
                "brief,",
                "each",
                "dataset",
                "consists",
                "of",
                "a",
                "sequence",
                "of",
                "sentences,",
                "where",
                "each",
                "sentence",
                "has",
                "a",
                "sequence",
                "of",
                "(word:tag)",
                "pairs.",
                "For",
                "NER",
                "we",
                "use",
                "the",
                "BinAjeeba",
                "#TARGET_REF",
                ",",
                "the",
                "ANERCorp",
                "developed",
                "by",
                "#REF",
                ",",
                "and",
                "the",
                "Wikipedia",
                "and",
                "Newswire",
                "datasets",
                "which",
                "are",
                "mapped",
                "2",
                "versions",
                "of",
                "the",
                "fine-grained",
                "WikiFANE",
                "and",
                "NewsFANE",
                "datasets",
                "#REF",
                "respectively.",
                "For",
                "POStagging",
                "we",
                "are",
                "evaluating",
                "on",
                "3",
                "standard",
                "datasets:",
                "WikiNews",
                "#REF",
                ",",
                "Al-Mushaf",
                "#REF",
                ",",
                "Prague",
                "Arabic",
                "Dependency",
                "Tree",
                "Bank",
                "(PADT)",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "We evaluate on 7 sequence labelling benchmarks: 4 of which are NER datasets and 3 of which are POStagging datasets 1 . In brief, each dataset consists of a sequence of sentences, where each sentence has a sequence of (word:tag) pairs. For NER we use the BinAjeeba #TARGET_REF , the ANERCorp developed by #REF , and the Wikipedia and Newswire datasets which are mapped 2 versions of the fine-grained WikiFANE and NewsFANE datasets #REF respectively. For POStagging we are evaluating on 3 standard datasets: WikiNews #REF , Al-Mushaf #REF , Prague Arabic Dependency Tree Bank (PADT) #REF .",
        "output": "{\"INFORMATION\": [\"For NER we use the BinAjeeba #TARGET_REF ,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"We evaluate on 7 sequence labelling benchmarks: 4 of which are NER datasets and 3 of which are POStagging datasets 1 .\", \"For POStagging we are evaluating on 3 standard datasets: WikiNews #REF , Al-Mushaf #REF , Prague Arabic Dependency Tree Bank (PADT) #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Word2VecVN",
                "#TARGET_REF",
                "x",
                "Trained",
                "on",
                "7GB",
                "texts",
                "of",
                "Vietnamese",
                "news",
                "FastText",
                "(Vietnamese",
                "version)",
                "#REF",
                "x"
            ],
            "context": [
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Word2VecVN #TARGET_REF x Trained on 7GB texts of Vietnamese news FastText (Vietnamese version) #REF x",
        "output": "{\"INFORMATION\": [\"Word2VecVN #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"x Trained on 7GB texts of Vietnamese news FastText (Vietnamese version) #REF x\"]}"
    },
    {
        "gold": {
            "text": [
                "Despite",
                "the",
                "inclusion",
                "of",
                "translations",
                "and",
                "contrastive",
                "loss,",
                "we",
                "observed",
                "that",
                "there",
                "is",
                "only",
                "a",
                "marginal",
                "improvement",
                "in",
                "the",
                "QA",
                "performance.",
                "This",
                "can",
                "be",
                "attributed",
                "to",
                "the",
                "smaller",
                "size",
                "of",
                "the",
                "ChAII",
                "dataset",
                "with",
                "1114",
                "instances",
                "#REF",
                ",",
                "which",
                "is",
                "clearly",
                "insufficient",
                "to",
                "fine-tune",
                "a",
                "177M",
                "parameter",
                "model.",
                "Hence,",
                "the",
                "proposed",
                "techniques",
                "have",
                "to",
                "be",
                "evaluated",
                "on",
                "other",
                "larger",
                "datasets",
                "as",
                "well",
                "as",
                "using",
                "other",
                "multilingual",
                "models",
                "like",
                "XLM-RoBERTa",
                "#REF",
                ",",
                "Distill-mBERT",
                "#REF",
                ",",
                "MURIL",
                "#REF",
                "and",
                "Indic-BERT",
                "#TARGET_REF",
                ".",
                "We",
                "hope",
                "that",
                "the",
                "proposed",
                "techniques",
                "will",
                "motivate",
                "further",
                "research",
                "in",
                "this",
                "field,",
                "including",
                "exploration",
                "of",
                "the",
                "same",
                "phenomenon",
                "of",
                "cross-lingual",
                "transfer",
                "in",
                "other",
                "language",
                "families",
                "and",
                "multilingual",
                "tasks."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Despite the inclusion of translations and contrastive loss, we observed that there is only a marginal improvement in the QA performance. This can be attributed to the smaller size of the ChAII dataset with 1114 instances #REF , which is clearly insufficient to fine-tune a 177M parameter model. Hence, the proposed techniques have to be evaluated on other larger datasets as well as using other multilingual models like XLM-RoBERTa #REF , Distill-mBERT #REF , MURIL #REF and Indic-BERT #TARGET_REF . We hope that the proposed techniques will motivate further research in this field, including exploration of the same phenomenon of cross-lingual transfer in other language families and multilingual tasks.",
        "output": "{\"INFORMATION\": [\"Indic-BERT\"], \"PERCEPTION\": [\"the proposed techniques have to be evaluated on other larger datasets as well as using other multilingual models like\", \"We hope that the proposed techniques will motivate further research in this field, including exploration of the same phenomenon of cross-lingual transfer in other language families and multilingual tasks.\"], \"BACKGROUND\": [\"Despite the inclusion of translations and contrastive loss, we observed that there is only a marginal improvement in the QA performance.\", \"XLM-RoBERTa #REF , Distill-mBERT #REF , MURIL #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "(3)",
                "Piano",
                "is",
                "a",
                "kind",
                "of",
                "art",
                "form",
                ".",
                "generation",
                "#TARGET_REF",
                ".",
                "In",
                "these",
                "tasks,",
                "output",
                "spaces",
                "are",
                "constrained",
                "by",
                "input",
                "context,",
                "i.e.,",
                "the",
                "contents",
                "of",
                "multiple",
                "outputs",
                "should",
                "be",
                "similar,",
                "and",
                "globally,",
                "under",
                "the",
                "same",
                "topic.",
                "However,",
                "many",
                "NLG",
                "tasks,",
                "e.g.,",
                "generative",
                "commonsense",
                "reasoning,",
                "pose",
                "unique",
                "challenges",
                "for",
                "generating",
                "multiple",
                "reasonable",
                "outputs",
                "that",
                "are",
                "semantically",
                "different."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "(3) Piano is a kind of art form . generation #TARGET_REF . In these tasks, output spaces are constrained by input context, i.e., the contents of multiple outputs should be similar, and globally, under the same topic. However, many NLG tasks, e.g., generative commonsense reasoning, pose unique challenges for generating multiple reasonable outputs that are semantically different.",
        "output": "{\"INFORMATION\": [\"generation #TARGET_REF\"], \"PERCEPTION\": [\"Piano is a kind of art form\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "log-bilinear",
                "model",
                "for",
                "conditional",
                "word",
                "probabilities",
                "was",
                "introduced",
                "in",
                "a",
                "language",
                "modeling",
                "context",
                "by",
                "#REF",
                ".",
                "#TARGET_REF",
                "influentially",
                "proposed",
                "to",
                "use",
                "the",
                "vector",
                "representations",
                "output",
                "by",
                "the",
                "word",
                "encoder",
                "in",
                "such",
                "a",
                "model",
                "as",
                "general",
                "word",
                "embeddings.",
                "The",
                "current",
                "work",
                "aims",
                "to",
                "return",
                "log-bilinear",
                "models",
                "to",
                "their",
                "language",
                "modeling",
                "roots,",
                "evaluating",
                "the",
                "capabilities",
                "of",
                "these",
                "models",
                "to",
                "estimate",
                "co-occurrence",
                "probabilities",
                "using",
                "pretrained",
                "embeddings",
                "as",
                "input,",
                "with",
                "a",
                "focus",
                "on",
                "word",
                "distributions",
                "where",
                "training",
                "data",
                "is",
                "limited.",
                "Here",
                "the",
                "target",
                "word",
                "vocabulary",
                "is",
                "typically",
                "small",
                "enough",
                "that",
                "the",
                "partition",
                "function",
                "(Eq.",
                "2)",
                "can",
                "be",
                "computed",
                "directly",
                "on",
                "modern",
                "hardware,",
                "so",
                "that",
                "approximations",
                "such",
                "as",
                "noisecontrastive",
                "estimation",
                "#REF",
                "are",
                "not",
                "necessary."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The log-bilinear model for conditional word probabilities was introduced in a language modeling context by #REF . #TARGET_REF influentially proposed to use the vector representations output by the word encoder in such a model as general word embeddings. The current work aims to return log-bilinear models to their language modeling roots, evaluating the capabilities of these models to estimate co-occurrence probabilities using pretrained embeddings as input, with a focus on word distributions where training data is limited. Here the target word vocabulary is typically small enough that the partition function (Eq. 2) can be computed directly on modern hardware, so that approximations such as noisecontrastive estimation #REF are not necessary.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF influentially proposed to use the vector representations output by the word encoder in such a model as general word embeddings.\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "addition,",
                "we",
                "also",
                "examine",
                "the",
                "docTTTTTquery",
                "document",
                "expansion",
                "technique",
                "#TARGET_REF",
                "based",
                "on",
                "predicting",
                "queries",
                "for",
                "which",
                "a",
                "text",
                "would",
                "be",
                "relevant",
                "(henceforth,",
                "just",
                "d2q",
                "for",
                "short).",
                "The",
                "predicted",
                "queries",
                "are",
                "concatenated",
                "to",
                "the",
                "end",
                "of",
                "the",
                "original",
                "text,",
                "this",
                "greatly",
                "improves",
                "BoW",
                "retrieval.",
                "We",
                "call",
                "this",
                "variant",
                "BoW",
                "d2q",
                "and",
                "denote",
                "the",
                "corresponding",
                "pipeline",
                "BoW",
                "d2q",
                "(1000)",
                "+",
                "BERT."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In addition, we also examine the docTTTTTquery document expansion technique #TARGET_REF based on predicting queries for which a text would be relevant (henceforth, just d2q for short). The predicted queries are concatenated to the end of the original text, this greatly improves BoW retrieval. We call this variant BoW d2q and denote the corresponding pipeline BoW d2q (1000) + BERT.",
        "output": "{\"INFORMATION\": [\"the docTTTTTquery document expansion technique #TARGET_REF\"], \"PERCEPTION\": [\"we also examine\", \"based on predicting queries for which a text would be relevant (henceforth, just d2q for short).\"], \"BACKGROUND\": [\"The predicted queries are concatenated to the end of the original text, this greatly improves BoW retrieval.\"]}"
    },
    {
        "gold": {
            "text": [
                "Twitter",
                "has",
                "been",
                "the",
                "most",
                "common",
                "online",
                "platform",
                "from",
                "which",
                "researchers",
                "have",
                "sourced",
                "datasets",
                "with",
                "user",
                "and",
                "community",
                "information.",
                "Galán-García",
                "et",
                "al.",
                "(",
                "2016)",
                "constructed",
                "a",
                "dataset",
                "of",
                "1,",
                "900",
                "tweets",
                "from",
                "19",
                "different",
                "twitter",
                "accounts",
                "with",
                "time",
                "of",
                "publication,",
                "language,",
                "and",
                "geo-position",
                "for",
                "each",
                "tweet",
                "taken",
                "from",
                "the",
                "profile",
                "of",
                "the",
                "user",
                "who",
                "created",
                "it.",
                "#REF",
                "released",
                "a",
                "list",
                "of",
                "16,",
                "907",
                "tweet",
                "IDs",
                "along",
                "with",
                "their",
                "corresponding",
                "annotations,",
                "labeling",
                "each",
                "tweet",
                "as",
                "racist,",
                "sexist",
                "or",
                "neither.",
                "For",
                "each",
                "tweet,",
                "the",
                "dataset",
                "contains",
                "the",
                "gender",
                "of",
                "the",
                "user",
                "who",
                "created",
                "it",
                "along",
                "with",
                "their",
                "geo-location.",
                "Since",
                "Twitter",
                "APIs",
                "allow",
                "researchers",
                "to",
                "access",
                "information",
                "about",
                "a",
                "user",
                "given",
                "a",
                "tweet",
                "ID,",
                "the",
                "dataset",
                "of",
                "#REF",
                "was",
                "expanded",
                "by",
                "#TARGET_REF",
                "to",
                "include",
                "the",
                "follower-following",
                "information",
                "amongst",
                "users",
                "who",
                "created",
                "the",
                "tweets",
                "contained",
                "in",
                "the",
                "dataset.",
                "#REF",
                "2016)",
                "which",
                "respective",
                "contain",
                "5,",
                "668",
                "Portuguese",
                "tweets",
                "and",
                "13,",
                "766",
                "German",
                "tweets",
                "by",
                "using",
                "Twitter",
                "APIs",
                "to",
                "get",
                "user",
                "information",
                "such",
                "as",
                "gender,",
                "number",
                "of",
                "followers,",
                "number",
                "of",
                "status",
                "updates,",
                "etc.",
                "Deviating",
                "from",
                "Twitter,",
                "#REF",
                "released",
                "a",
                "dataset",
                "of",
                "1.45M",
                "abusive",
                "and",
                "benign",
                "comments",
                "in",
                "Greek",
                "sourced",
                "from",
                "the",
                "news",
                "portal",
                "Gazzetta.",
                "For",
                "each",
                "comment,",
                "the",
                "dataset",
                "also",
                "contains",
                "the",
                "ID",
                "of",
                "the",
                "user",
                "who",
                "created",
                "the",
                "comment."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Twitter has been the most common online platform from which researchers have sourced datasets with user and community information. Galán-García et al. ( 2016) constructed a dataset of 1, 900 tweets from 19 different twitter accounts with time of publication, language, and geo-position for each tweet taken from the profile of the user who created it. #REF released a list of 16, 907 tweet IDs along with their corresponding annotations, labeling each tweet as racist, sexist or neither. For each tweet, the dataset contains the gender of the user who created it along with their geo-location. Since Twitter APIs allow researchers to access information about a user given a tweet ID, the dataset of #REF was expanded by #TARGET_REF to include the follower-following information amongst users who created the tweets contained in the dataset. #REF 2016) which respective contain 5, 668 Portuguese tweets and 13, 766 German tweets by using Twitter APIs to get user information such as gender, number of followers, number of status updates, etc. Deviating from Twitter, #REF released a dataset of 1.45M abusive and benign comments in Greek sourced from the news portal Gazzetta. For each comment, the dataset also contains the ID of the user who created the comment.",
        "output": "{\"INFORMATION\": [\"the dataset of #REF was expanded by #TARGET_REF to include the follower-following information amongst users who created the tweets contained in the dataset.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Since Twitter APIs allow researchers to access information about a user given a tweet ID,\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "trace",
                "feature,",
                "we",
                "use",
                "τ",
                "=",
                "0.4s",
                "to",
                "extract",
                "trace",
                "segment",
                "for",
                "feature",
                "extraction.",
                "The",
                "embedding",
                "size",
                "d,",
                "number",
                "of",
                "transformer",
                "layers,",
                "hidden",
                "size",
                "of",
                "the",
                "transformer",
                "feed-forward",
                "layer",
                "are",
                "768,",
                "2,",
                "and",
                "768,",
                "respectively.",
                "The",
                "number",
                "of",
                "attention",
                "heads",
                "is",
                "8,",
                "and",
                "the",
                "dropout",
                "rate",
                "is",
                "0.1.",
                "We",
                "adopt",
                "the",
                "Adam-W",
                "optimizer",
                "#TARGET_REF",
                "with",
                "learning",
                "rate",
                "of",
                "7e-4(which",
                "is",
                "the",
                "best",
                "performance",
                "setting",
                "of",
                "baseline,",
                "and",
                "adopted",
                "widely",
                "for",
                "other",
                "trials),",
                "and",
                "set",
                "two",
                "momentum",
                "parameters",
                "β",
                "1",
                "=",
                "0.9",
                "and",
                "β",
                "2",
                "=",
                "0.99.",
                "We",
                "set",
                "the",
                "batch",
                "size",
                "to",
                "256.",
                "All",
                "models",
                "are",
                "trained",
                "on",
                "4",
                "Tesla",
                "V100",
                "GPUs",
                "with",
                "32GB",
                "memory",
                "for",
                "10",
                "to",
                "12",
                "hours."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "For trace feature, we use τ = 0.4s to extract trace segment for feature extraction. The embedding size d, number of transformer layers, hidden size of the transformer feed-forward layer are 768, 2, and 768, respectively. The number of attention heads is 8, and the dropout rate is 0.1. We adopt the Adam-W optimizer #TARGET_REF with learning rate of 7e-4(which is the best performance setting of baseline, and adopted widely for other trials), and set two momentum parameters β 1 = 0.9 and β 2 = 0.99. We set the batch size to 256. All models are trained on 4 Tesla V100 GPUs with 32GB memory for 10 to 12 hours.",
        "output": "{\"INFORMATION\": [\"the Adam-W optimizer #TARGET_REF with learning rate of 7e-4(which is the best performance setting of baseline,\"], \"PERCEPTION\": [\"We adopt\", \"and adopted widely for other trials),\"], \"BACKGROUND\": [\"and set two momentum parameters \\u03b2 1 = 0.9 and \\u03b2 2 = 0.99. We set the batch size to 256. All models are trained on 4 Tesla V100 GPUs with 32GB memory for 10 to 12 hours.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "perform",
                "pretraining",
                "on",
                "two",
                "widely-used",
                "indomain",
                "datasets:",
                "MSCOCO",
                "Caption",
                "#TARGET_REF",
                "and",
                "Visual",
                "Genome",
                "#REF",
                ",",
                "and",
                "validate",
                "the",
                "learned",
                "multi-modal",
                "representations",
                "on",
                "five",
                "well-known",
                "visual-language",
                "tasks:",
                "Visual",
                "Question",
                "Answering",
                "(VQA),",
                "Imagetext",
                "retrieval,",
                "Nature",
                "Language",
                "Visual",
                "Reasoning",
                "(NLVR",
                "2",
                "),",
                "Visual",
                "Entailment",
                "(VE)",
                "and",
                "Visual",
                "Commonsense",
                "Reasoning",
                "(VCR).",
                "Empirical",
                "results",
                "show",
                "that",
                "our",
                "method",
                "outperforms",
                "the",
                "state-of-theart",
                "end-to-end",
                "approaches",
                "by",
                "a",
                "sizeable",
                "margin.",
                "To",
                "better",
                "understand",
                "our",
                "method,",
                "we",
                "also",
                "provide",
                "a",
                "detailed",
                "ablation",
                "study",
                "and",
                "visualization."
            ],
            "context": [
                3,
                3,
                3,
                2,
                2,
                2,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We perform pretraining on two widely-used indomain datasets: MSCOCO Caption #TARGET_REF and Visual Genome #REF , and validate the learned multi-modal representations on five well-known visual-language tasks: Visual Question Answering (VQA), Imagetext retrieval, Nature Language Visual Reasoning (NLVR 2 ), Visual Entailment (VE) and Visual Commonsense Reasoning (VCR). Empirical results show that our method outperforms the state-of-theart end-to-end approaches by a sizeable margin. To better understand our method, we also provide a detailed ablation study and visualization.",
        "output": "{\"INFORMATION\": [\"MSCOCO Caption #TARGET_REF\"], \"PERCEPTION\": [\"on two widely-used\"], \"BACKGROUND\": [\"We perform pretraining\", \"indomain datasets:\", \"and Visual Genome #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Open-domain",
                "question",
                "answering",
                "(QA)",
                "aims",
                "to",
                "find",
                "the",
                "answers",
                "to",
                "natural",
                "language",
                "questions",
                "from",
                "a",
                "large",
                "collection",
                "of",
                "documents.",
                "Early",
                "QA",
                "systems",
                "#REF",
                "constructed",
                "complicated",
                "pipelines",
                "consisting",
                "of",
                "multiple",
                "components,",
                "including",
                "question",
                "understanding,",
                "document",
                "retrieval,",
                "passage",
                "ranking",
                "and",
                "answer",
                "extraction.",
                "Recently,",
                "inspired",
                "by",
                "the",
                "advancements",
                "of",
                "machine",
                "reading",
                "comprehension",
                "(MRC),",
                "#TARGET_REF",
                "proposed",
                "a",
                "simplified",
                "two-stage",
                "approach,",
                "where",
                "a",
                "traditional",
                "IR",
                "*",
                "Corresponding",
                "authors."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Open-domain question answering (QA) aims to find the answers to natural language questions from a large collection of documents. Early QA systems #REF constructed complicated pipelines consisting of multiple components, including question understanding, document retrieval, passage ranking and answer extraction. Recently, inspired by the advancements of machine reading comprehension (MRC), #TARGET_REF proposed a simplified two-stage approach, where a traditional IR * Corresponding authors.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF proposed a simplified two-stage approach, where a traditional IR * Corresponding authors.\"], \"PERCEPTION\": [\"inspired by the advancements of machine reading comprehension (MRC),\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Bilingual",
                "parallel",
                "corpus",
                "#TARGET_REF",
                "was",
                "used",
                "in",
                "automatic",
                "(BLEU)",
                "evaluation",
                "of",
                "translations.",
                "This",
                "corpus",
                "consists",
                "of",
                "8600",
                "sentences",
                "that",
                "were",
                "not",
                "used",
                "in",
                "translation",
                "system",
                "construction."
            ],
            "context": [
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Bilingual parallel corpus #TARGET_REF was used in automatic (BLEU) evaluation of translations. This corpus consists of 8600 sentences that were not used in translation system construction.",
        "output": "{\"INFORMATION\": [\"Bilingual parallel corpus #TARGET_REF\", \"This corpus consists of 8600 sentences\"], \"PERCEPTION\": [\"was used in automatic (BLEU) evaluation of translations.\", \"that were not used in translation system construction.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "recent",
                "years,",
                "most",
                "work",
                "on",
                "annotating",
                "naturallanguage",
                "text",
                "with",
                "comprehensive,",
                "broad-coverage",
                "meaning",
                "representations",
                "has",
                "been",
                "performed",
                "in",
                "three",
                "frameworks:",
                "Abstract",
                "Meaning",
                "Representations",
                "#REF",
                ",",
                "Universal",
                "Cognitive",
                "Conceptual",
                "Annotation",
                "#REF",
                ",",
                "and",
                "Discourse",
                "Representation",
                "Structures",
                "#REF",
                ".",
                "Accurate",
                "parsers",
                "exist",
                "for",
                "all",
                "three",
                "(e.g.,",
                "#TARGET_REF",
                ".",
                "Each",
                "formalism",
                "has",
                "its",
                "specific",
                "strength:",
                "AMRs",
                "go",
                "very",
                "far",
                "in",
                "abstracting",
                "away",
                "from",
                "surface",
                "variation",
                "in",
                "how",
                "a",
                "certain",
                "meaning",
                "is",
                "expressed,",
                "UCCA",
                "has",
                "a",
                "clear",
                "mapping",
                "between",
                "form",
                "and",
                "meaning",
                "and",
                "a",
                "modular",
                "architecture,",
                "and",
                "DRSs",
                "ground",
                "natural",
                "language",
                "meaning",
                "in",
                "first-order",
                "logic,",
                "by",
                "explicitly",
                "representing",
                "the",
                "scopes",
                "of",
                "negation,",
                "quantification,",
                "disjunction,",
                "etc.",
                "In",
                "this",
                "paper,",
                "we",
                "focus",
                "on",
                "parsing",
                "to",
                "DRSs."
            ],
            "context": [
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In recent years, most work on annotating naturallanguage text with comprehensive, broad-coverage meaning representations has been performed in three frameworks: Abstract Meaning Representations #REF , Universal Cognitive Conceptual Annotation #REF , and Discourse Representation Structures #REF . Accurate parsers exist for all three (e.g., #TARGET_REF . Each formalism has its specific strength: AMRs go very far in abstracting away from surface variation in how a certain meaning is expressed, UCCA has a clear mapping between form and meaning and a modular architecture, and DRSs ground natural language meaning in first-order logic, by explicitly representing the scopes of negation, quantification, disjunction, etc. In this paper, we focus on parsing to DRSs.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"most work on annotating naturallanguage text with comprehensive, broad-coverage meaning representations has been performed in three frameworks: Abstract Meaning Representations #REF , Universal Cognitive Conceptual Annotation #REF , and Discourse Representation Structures #REF . Accurate parsers exist for all three (e.g.,\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "grammar",
                "was",
                "developed",
                "and",
                "refined",
                "in",
                "a",
                "corpus-based",
                "fashion",
                "(e.g.",
                "see",
                "#TARGET_REF",
                ")",
                "by",
                "testing",
                "against",
                "sentences",
                "from",
                "the",
                "Susanne",
                "corpus",
                "#REF",
                ",",
                "a",
                "138K",
                "word",
                "treebanked",
                "and",
                "balanced",
                "subset",
                "of",
                "the",
                "Brown",
                "corpus",
                "1",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "This grammar was developed and refined in a corpus-based fashion (e.g. see #TARGET_REF ) by testing against sentences from the Susanne corpus #REF , a 138K word treebanked and balanced subset of the Brown corpus 1 .",
        "output": "{\"INFORMATION\": [\"#TARGET_REF ) by testing against sentences from the Susanne corpus #REF , a 138K word treebanked and balanced subset of the Brown corpus 1 .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"This grammar was developed and refined in a corpus-based fashion (e.g. see\"]}"
    },
    {
        "gold": {
            "text": [
                "While",
                "there",
                "is",
                "some",
                "divergence",
                "around",
                "the",
                "definition",
                "of",
                "usability,",
                "the",
                "majority",
                "of",
                "terms",
                "in",
                "the",
                "literature",
                "closely",
                "adhere",
                "to",
                "the",
                "ISO",
                "definition.",
                "Following",
                "the",
                "ISO/TR",
                "16982",
                "definition,",
                "usability",
                "is",
                "understood",
                "here",
                "as",
                "\"the",
                "extent",
                "to",
                "which",
                "a",
                "product",
                "can",
                "be",
                "used",
                "by",
                "specified",
                "users",
                "to",
                "achieve",
                "specified",
                "goals",
                "with",
                "effectiveness,",
                "efficiency,",
                "and",
                "satisfaction",
                "in",
                "a",
                "specified",
                "context",
                "of",
                "use\"",
                "#TARGET_REF",
                ".",
                "The",
                "objective",
                "of",
                "this",
                "study",
                "was",
                "to",
                "establish",
                "how",
                "usable",
                "raw",
                "machine",
                "translated",
                "instructions",
                "were",
                "for",
                "end",
                "users",
                "in",
                "comparison",
                "with",
                "the",
                "original",
                "source",
                "text,",
                "which",
                "was",
                "in",
                "English."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "While there is some divergence around the definition of usability, the majority of terms in the literature closely adhere to the ISO definition. Following the ISO/TR 16982 definition, usability is understood here as \"the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use\" #TARGET_REF . The objective of this study was to establish how usable raw machine translated instructions were for end users in comparison with the original source text, which was in English.",
        "output": "{\"INFORMATION\": [\"the ISO/TR 16982 definition,\", \"\\\"the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction in a specified context of use\\\"\"], \"PERCEPTION\": [\"Following\", \"usability is understood here as\"], \"BACKGROUND\": [\"The objective of this study was to establish how usable raw machine translated instructions were for end users in comparison with the original source text, which was in English.\"]}"
    },
    {
        "gold": {
            "text": [
                "Agreement",
                "analysis",
                "over",
                "annotations.",
                "Since",
                "this",
                "annotation",
                "task",
                "is",
                "non-trivial",
                "and",
                "sometimes",
                "subjective,",
                "we",
                "further",
                "compute",
                "the",
                "intraclass",
                "correlation",
                "score",
                "#TARGET_REF",
                "for",
                "the",
                "Amazon",
                "Mechanical",
                "Turk",
                "annotations.",
                "Our",
                "collected",
                "annotations",
                "reaches",
                "an",
                "intraclass",
                "correlation",
                "score",
                "of",
                "0.72,",
                "showing",
                "a",
                "good",
                "agreement",
                "among",
                "annotators.",
                "Another",
                "agreement",
                "we",
                "analyze",
                "is",
                "showing",
                "annotators",
                "5",
                "sample",
                "sentences",
                "compared",
                "to",
                "showing",
                "them",
                "all",
                "sentences,",
                "to",
                "avoid",
                "sample",
                "bias.",
                "We",
                "ask",
                "annotators",
                "to",
                "annotate",
                "a",
                "batch",
                "of",
                "25",
                "tokens",
                "with",
                "all",
                "sentences",
                "containing",
                "the",
                "corresponding",
                "token",
                "shown",
                "to",
                "them.",
                "The",
                "agreement",
                "reaches",
                "84.0%,",
                "indicating",
                "that",
                "showing",
                "5",
                "sample",
                "sentences",
                "does",
                "not",
                "significantly",
                "affect",
                "annotator's",
                "decision",
                "on",
                "the",
                "target",
                "token.",
                "More",
                "details",
                "of",
                "Amazon",
                "Mechanical",
                "Turk",
                "interface",
                "can",
                "be",
                "found",
                "in",
                "the",
                "Appendix."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Agreement analysis over annotations. Since this annotation task is non-trivial and sometimes subjective, we further compute the intraclass correlation score #TARGET_REF for the Amazon Mechanical Turk annotations. Our collected annotations reaches an intraclass correlation score of 0.72, showing a good agreement among annotators. Another agreement we analyze is showing annotators 5 sample sentences compared to showing them all sentences, to avoid sample bias. We ask annotators to annotate a batch of 25 tokens with all sentences containing the corresponding token shown to them. The agreement reaches 84.0%, indicating that showing 5 sample sentences does not significantly affect annotator's decision on the target token. More details of Amazon Mechanical Turk interface can be found in the Appendix.",
        "output": "{\"INFORMATION\": [\"the intraclass correlation score #TARGET_REF\"], \"PERCEPTION\": [\"we further compute\", \"for the Amazon Mechanical Turk annotations.\"], \"BACKGROUND\": [\"Agreement analysis over annotations. Since this annotation task is non-trivial and sometimes subjective,\", \"Our collected annotations reaches an intraclass correlation score of 0.72, showing a good agreement among annotators.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Transformer",
                "architecture",
                "#TARGET_REF",
                "is",
                "based",
                "on",
                "a",
                "stack",
                "of",
                "encoder-decoder",
                "blocks,",
                "composed",
                "at",
                "a",
                "high",
                "level",
                "of",
                "forward",
                "propagation",
                "networks",
                "and",
                "multi-headed",
                "self-attention",
                "operations."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The Transformer architecture #TARGET_REF is based on a stack of encoder-decoder blocks, composed at a high level of forward propagation networks and multi-headed self-attention operations.",
        "output": "{\"INFORMATION\": [\"The Transformer architecture #TARGET_REF is based on a stack of encoder-decoder blocks, composed at a high level of forward propagation networks and multi-headed self-attention operations.\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Training",
                "Configuration.",
                "We",
                "adopt",
                "the",
                "VAE",
                "architecture",
                "from",
                "#TARGET_REF",
                ",",
                "using",
                "a",
                "LSTM",
                "encoder-decoder.",
                "Unless",
                "stated",
                "otherwise,",
                "(word",
                "embedding,",
                "LSTM,",
                "representation",
                "embedding)",
                "dimensionalities",
                "for",
                "YNOC",
                "and",
                "POS",
                "datasets",
                "are",
                "(4D,",
                "32D,",
                "4D)",
                "and",
                "(4D,",
                "64D,",
                "8D),",
                "respectively,",
                "and",
                "we",
                "use",
                "the",
                "latent",
                "code",
                "to",
                "initialize",
                "the",
                "hidden",
                "state",
                "of",
                "the",
                "LSTM",
                "decoder.",
                "We",
                "use",
                "greedy",
                "decoding.",
                "All",
                "models",
                "are",
                "trained",
                "from",
                "multiple",
                "random",
                "starts",
                "using",
                "Adam",
                "(Kingma",
                "and",
                "Ba,",
                "2015)",
                "with",
                "learning",
                "rate",
                "0.001",
                "for",
                "10",
                "epochs.",
                "We",
                "set",
                "batch",
                "size",
                "to",
                "256",
                "and",
                "512",
                "for",
                "YNOC",
                "and",
                "POS,",
                "respectively."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Training Configuration. We adopt the VAE architecture from #TARGET_REF , using a LSTM encoder-decoder. Unless stated otherwise, (word embedding, LSTM, representation embedding) dimensionalities for YNOC and POS datasets are (4D, 32D, 4D) and (4D, 64D, 8D), respectively, and we use the latent code to initialize the hidden state of the LSTM decoder. We use greedy decoding. All models are trained from multiple random starts using Adam (Kingma and Ba, 2015) with learning rate 0.001 for 10 epochs. We set batch size to 256 and 512 for YNOC and POS, respectively.",
        "output": "{\"INFORMATION\": [\"from #TARGET_REF , using a LSTM encoder-decoder.\"], \"PERCEPTION\": [\"We adopt the VAE architecture\"], \"BACKGROUND\": [\"we use the latent code to initialize the hidden state of the LSTM decoder. We use greedy decoding. All models are trained from multiple random starts using Adam (Kingma and Ba, 2015) with learning rate 0.001 for 10 epochs. We set batch size to 256 and 512 for YNOC and POS, respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "Lee",
                "and",
                "Na",
                "(2022)",
                "(JBNU-CCLab)",
                "achieved",
                "their",
                "state-of-the-art",
                "performance",
                "using",
                "SciBERT",
                "#REF",
                ".",
                "Their",
                "entity",
                "model",
                "consists",
                "of",
                "an",
                "MRC-based",
                "model",
                "#TARGET_REF",
                ",",
                "simplifying",
                "the",
                "tasks",
                "as",
                "binary",
                "classification",
                "problems",
                "whether",
                "span",
                "is",
                "valid",
                "using",
                "entity",
                "type",
                "information",
                "as",
                "input",
                "features.",
                "They",
                "proposed",
                "a",
                "simple",
                "rule-based",
                "Symbol",
                "Tokenizer",
                "to",
                "predict",
                "accurately",
                "the",
                "complex",
                "symbols",
                "appearing",
                "in",
                "scientific",
                "documents.",
                "The",
                "relation",
                "model",
                "exploits",
                "entity",
                "span",
                "information",
                "and",
                "entity",
                "type",
                "information",
                "as",
                "input",
                "features",
                "using",
                "typed",
                "entity",
                "marker.",
                "Additionally,",
                "the",
                "paper",
                "ex-ploited",
                "many",
                "regularization",
                "techniques",
                "to",
                "improve",
                "the",
                "model",
                "performance",
                "such",
                "as",
                "regularized",
                "dropout",
                "#REF",
                "and",
                "representational",
                "collapse",
                "prevention",
                "#REF",
                "and",
                "traditional",
                "ensemble",
                "techniques."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Lee and Na (2022) (JBNU-CCLab) achieved their state-of-the-art performance using SciBERT #REF . Their entity model consists of an MRC-based model #TARGET_REF , simplifying the tasks as binary classification problems whether span is valid using entity type information as input features. They proposed a simple rule-based Symbol Tokenizer to predict accurately the complex symbols appearing in scientific documents. The relation model exploits entity span information and entity type information as input features using typed entity marker. Additionally, the paper ex-ploited many regularization techniques to improve the model performance such as regularized dropout #REF and representational collapse prevention #REF and traditional ensemble techniques.",
        "output": "{\"INFORMATION\": [\"an MRC-based model #TARGET_REF ,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Their entity model consists of\", \"simplifying the tasks as binary classification problems whether span is valid using entity type information as input features.\"]}"
    },
    {
        "gold": {
            "text": [
                "Next,",
                "we",
                "experiment",
                "with",
                "three",
                "neural",
                "models",
                "based",
                "on",
                "a",
                "pre-trained",
                "masked",
                "language",
                "model",
                "(MLM),",
                "specifically,",
                "SpanBERT",
                "#TARGET_REF",
                ".",
                "We",
                "also",
                "experiment",
                "with",
                "an",
                "additional",
                "baseline",
                "with",
                "uncontextualized",
                "word",
                "embeddings."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Next, we experiment with three neural models based on a pre-trained masked language model (MLM), specifically, SpanBERT #TARGET_REF . We also experiment with an additional baseline with uncontextualized word embeddings.",
        "output": "{\"INFORMATION\": [\"SpanBERT #TARGET_REF\"], \"PERCEPTION\": [\"Next, we experiment with three neural models based on a pre-trained masked language model (MLM), specifically,\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "first",
                "assumption",
                "we",
                "made",
                "is",
                "highly",
                "dependent",
                "on",
                "the",
                "design",
                "of",
                "the",
                "considered",
                "factors,",
                "i.e.",
                "the",
                "lemmas",
                "are",
                "the",
                "most",
                "informative",
                "factors",
                "among",
                "all.",
                "Then,",
                "we",
                "tried",
                "using",
                "only",
                "the",
                "lemma",
                "embedding",
                "as",
                "feedback",
                "(see",
                "equation",
                "5).",
                "fb(y",
                "t−1",
                ")",
                "=",
                "y",
                "L",
                "t−1",
                "#TARGET_REF",
                "where",
                "y",
                "L",
                "t−1",
                "is",
                "the",
                "embedding",
                "of",
                "the",
                "lemma",
                "generated",
                "at",
                "previous",
                "timestep."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The first assumption we made is highly dependent on the design of the considered factors, i.e. the lemmas are the most informative factors among all. Then, we tried using only the lemma embedding as feedback (see equation 5). fb(y t−1 ) = y L t−1 #TARGET_REF where y L t−1 is the embedding of the lemma generated at previous timestep.",
        "output": "{\"INFORMATION\": [\"fb(y t\\u22121 ) = y L t\\u22121 #TARGET_REF where y L t\\u22121 is the embedding of the lemma generated at previous timestep.\"], \"PERCEPTION\": [\"we tried using only the lemma embedding as feedback\"], \"BACKGROUND\": [\"(see equation 5).\"]}"
    },
    {
        "gold": {
            "text": [
                "Recently",
                "researchers",
                "in",
                "statistical",
                "machine",
                "translation",
                "have",
                "developed",
                "methods",
                "to",
                "move",
                "beyond",
                "single",
                "word",
                "alignments",
                "and",
                "create",
                "richer",
                "translation",
                "models",
                "that",
                "contain",
                "phrasal",
                "alignments",
                "#REF",
                ".",
                "The",
                "general",
                "method",
                "is",
                "to",
                "induce",
                "single",
                "word",
                "alignments",
                "using",
                "maximum",
                "likelihood",
                "estimates",
                "obtained",
                "from",
                "parallel",
                "data",
                "such",
                "as",
                "by",
                "IBM",
                "Model",
                "1",
                "#TARGET_REF",
                "and",
                "to",
                "use",
                "these",
                "alignments",
                "to",
                "suggest",
                "adjacent",
                "words",
                "that",
                "may",
                "compose",
                "a",
                "meaningful",
                "phrase.",
                "By",
                "examining",
                "bidirectional",
                "alignments",
                "for",
                "the",
                "same",
                "parallel",
                "data",
                "a",
                "'symmetrized",
                "alignment",
                "matrix'",
                "can",
                "be",
                "obtained,",
                "and",
                "from",
                "this",
                "information",
                "potential",
                "translations",
                "of",
                "word",
                "sequences",
                "can",
                "be",
                "obtained.",
                "As",
                "long",
                "as",
                "contiguous",
                "sequences",
                "are",
                "examined",
                "it",
                "does",
                "not",
                "matter",
                "if",
                "the",
                "two",
                "languages",
                "have",
                "different",
                "word",
                "order.",
                "The",
                "approach",
                "can",
                "be",
                "further",
                "generalized",
                "by",
                "working",
                "with",
                "word",
                "classes",
                "so",
                "that",
                "hypotheses",
                "for",
                "unseen",
                "phrases",
                "can",
                "be",
                "generated."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Recently researchers in statistical machine translation have developed methods to move beyond single word alignments and create richer translation models that contain phrasal alignments #REF . The general method is to induce single word alignments using maximum likelihood estimates obtained from parallel data such as by IBM Model 1 #TARGET_REF and to use these alignments to suggest adjacent words that may compose a meaningful phrase. By examining bidirectional alignments for the same parallel data a 'symmetrized alignment matrix' can be obtained, and from this information potential translations of word sequences can be obtained. As long as contiguous sequences are examined it does not matter if the two languages have different word order. The approach can be further generalized by working with word classes so that hypotheses for unseen phrases can be generated.",
        "output": "{\"INFORMATION\": [\"IBM Model 1 #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"researchers in statistical machine translation have developed methods to move beyond single word alignments and create richer translation models that contain phrasal alignments #REF . The general method is to induce single word alignments using maximum likelihood estimates obtained from parallel data such as by\", \"and to use these alignments to suggest adjacent words that may compose a meaningful phrase.\"]}"
    },
    {
        "gold": {
            "text": [
                "Definition",
                "extraction",
                "from",
                "scientific",
                "document",
                "is",
                "close",
                "to",
                "the",
                "task",
                "presented",
                "in",
                "SemEval",
                "Task",
                "12.",
                "The",
                "Scientific",
                "Document",
                "Understanding",
                "workshop",
                "has",
                "hosted",
                "the",
                "Acronym",
                "Extraction",
                "and",
                "Acronym",
                "Disambiguation",
                "Shared",
                "Tasks,",
                "namely",
                "Acronym",
                "Extraction",
                "and",
                "Acronym",
                "Disambiguation",
                "Shared",
                "Tasks",
                "#REF",
                ".",
                "The",
                "prior",
                "studies",
                "in",
                "this",
                "research",
                "direction",
                "considers",
                "extracting",
                "definitions",
                "from",
                "the",
                "text",
                "#REF",
                ",",
                "or",
                "together",
                "with",
                "acronyms,",
                "and",
                "acronyms",
                "sense",
                "disambiguation",
                "(Pouran",
                "Ben",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "Definition extraction from scientific document is close to the task presented in SemEval Task 12. The Scientific Document Understanding workshop has hosted the Acronym Extraction and Acronym Disambiguation Shared Tasks, namely Acronym Extraction and Acronym Disambiguation Shared Tasks #REF . The prior studies in this research direction considers extracting definitions from the text #REF , or together with acronyms, and acronyms sense disambiguation (Pouran Ben #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"extracting definitions from the text #REF , or together with acronyms, and acronyms sense disambiguation (Pouran Ben #TARGET_REF\"], \"PERCEPTION\": [\"The prior studies in this research direction considers\"], \"BACKGROUND\": [\"The Scientific Document Understanding workshop has hosted the Acronym Extraction and Acronym Disambiguation Shared Tasks, namely Acronym Extraction and Acronym Disambiguation Shared Tasks #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "English",
                "data",
                "we",
                "used",
                "Stanford",
                "NER",
                "(named",
                "entity",
                "recognition)",
                "#TARGET_REF",
                "to",
                "replace",
                "names",
                "and",
                "locations",
                "with",
                "the",
                "tags:",
                "[PERSON]",
                "and",
                "[LOCATION]",
                "respectively.",
                "We",
                "kept",
                "organization",
                "names",
                "as",
                "is",
                "because",
                "we",
                "felt",
                "that",
                "the",
                "emotions",
                "and",
                "sentiments",
                "towards",
                "some",
                "large",
                "well-known",
                "organizations",
                "differ",
                "too",
                "much",
                "(cf.",
                "IRS,",
                "FBI,",
                "WHO,",
                "EU,",
                "and",
                "MIT).",
                "For",
                "the",
                "Finnish",
                "data,",
                "we",
                "replaced",
                "names",
                "and",
                "locations",
                "using",
                "the",
                "Turku",
                "NER",
                "corpus",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For the English data we used Stanford NER (named entity recognition) #TARGET_REF to replace names and locations with the tags: [PERSON] and [LOCATION] respectively. We kept organization names as is because we felt that the emotions and sentiments towards some large well-known organizations differ too much (cf. IRS, FBI, WHO, EU, and MIT). For the Finnish data, we replaced names and locations using the Turku NER corpus #REF .",
        "output": "{\"INFORMATION\": [\"Stanford NER (named entity recognition) #TARGET_REF\"], \"PERCEPTION\": [\"For the English data we used\", \"to replace names and locations with the tags:\"], \"BACKGROUND\": [\"[PERSON] and [LOCATION] respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "It",
                "is",
                "because",
                "solely",
                "relying",
                "on",
                "network",
                "homophily",
                "as",
                "the",
                "inductive",
                "bias",
                "for",
                "generating",
                "profiles",
                "caused",
                "the",
                "method",
                "of",
                "#REF",
                "to",
                "make",
                "some",
                "faulty",
                "generalizations.",
                "Such",
                "observations",
                "have",
                "also",
                "been",
                "made",
                "by",
                "other",
                "works,",
                "a",
                "prominent",
                "one",
                "of",
                "which",
                "is",
                "the",
                "work",
                "of",
                "#TARGET_REF",
                "who",
                "explored",
                "the",
                "relationships",
                "amongst",
                "gender,",
                "language,",
                "and",
                "social",
                "network",
                "connections.",
                "The",
                "researchers",
                "noted",
                "that",
                "even",
                "though",
                "there",
                "may",
                "exist",
                "many",
                "linguistic",
                "clusters",
                "that",
                "exhibit",
                "strong",
                "orientations",
                "to",
                "one",
                "gender,",
                "yet",
                "the",
                "characteristics",
                "of",
                "any",
                "particular",
                "cluster",
                "do",
                "not",
                "necessarily",
                "align",
                "with",
                "populationlevel",
                "statistics",
                "for",
                "that",
                "gender.",
                "Furthermore,",
                "they",
                "observed",
                "that",
                "there",
                "are",
                "individuals",
                "whose",
                "linguistic",
                "practices",
                "differ",
                "from",
                "population-level",
                "trends",
                "for",
                "their",
                "gender",
                "and",
                "that",
                "gender",
                "homophily",
                "does",
                "not",
                "capture",
                "their",
                "linguistic",
                "practices."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "It is because solely relying on network homophily as the inductive bias for generating profiles caused the method of #REF to make some faulty generalizations. Such observations have also been made by other works, a prominent one of which is the work of #TARGET_REF who explored the relationships amongst gender, language, and social network connections. The researchers noted that even though there may exist many linguistic clusters that exhibit strong orientations to one gender, yet the characteristics of any particular cluster do not necessarily align with populationlevel statistics for that gender. Furthermore, they observed that there are individuals whose linguistic practices differ from population-level trends for their gender and that gender homophily does not capture their linguistic practices.",
        "output": "{\"INFORMATION\": [\"a prominent one of which is the work of #TARGET_REF who explored the relationships amongst gender, language, and social network connections. The researchers noted that even though there may exist many linguistic clusters that exhibit strong orientations to one gender, yet the characteristics of any particular cluster do not necessarily align with populationlevel statistics for that gender. Furthermore, they observed that there are individuals whose linguistic practices differ from population-level trends for their gender and that gender homophily does not capture their linguistic practices.\"], \"PERCEPTION\": [\"Such observations have also been made by other works,\"], \"BACKGROUND\": [\"It is because solely relying on network homophily as the inductive bias for generating profiles caused the method of #REF to make some faulty generalizations.\"]}"
    },
    {
        "gold": {
            "text": [
                "Feed-forward",
                "layer",
                "While",
                "considerable",
                "effort",
                "has",
                "been",
                "dedicated",
                "to",
                "devising",
                "efficient",
                "models",
                "for",
                "long",
                "contexts,",
                "a",
                "large",
                "feed-forward",
                "dimension",
                "is",
                "useful",
                "for",
                "knowledge-intensive",
                "tasks",
                "such",
                "as",
                "opendomain",
                "QA",
                "#REF",
                ",",
                "and",
                "efforts",
                "have",
                "been",
                "made",
                "to",
                "reduce",
                "its",
                "complexity",
                "#TARGET_REF",
                ".",
                "We",
                "benchmark",
                "the",
                "resource",
                "usage",
                "of",
                "top-k",
                "attention",
                "at",
                "a",
                "single",
                "feed-forward",
                "layer",
                "for",
                "different",
                "feed-forward",
                "dimensions",
                "using",
                "batch",
                "size",
                "512",
                "and",
                "input",
                "length",
                "512,",
                "which",
                "results",
                "in",
                "2",
                "18",
                "queries",
                "per",
                "batch."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Feed-forward layer While considerable effort has been dedicated to devising efficient models for long contexts, a large feed-forward dimension is useful for knowledge-intensive tasks such as opendomain QA #REF , and efforts have been made to reduce its complexity #TARGET_REF . We benchmark the resource usage of top-k attention at a single feed-forward layer for different feed-forward dimensions using batch size 512 and input length 512, which results in 2 18 queries per batch.",
        "output": "{\"INFORMATION\": [\"a large feed-forward dimension\", \"efforts have been made to reduce its complexity #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"While considerable effort has been dedicated to devising efficient models for long contexts,\", \"is useful for knowledge-intensive tasks\", \", and\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "trend",
                "of",
                "recent",
                "years",
                "consists",
                "in",
                "training",
                "large",
                "pre-trained",
                "language",
                "models",
                "on",
                "ever",
                "larger",
                "corpora,",
                "with",
                "an",
                "ever-increasing",
                "amount",
                "of",
                "parameters,",
                "which",
                "requires",
                "considerable",
                "computational",
                "resources",
                "that",
                "only",
                "a",
                "few",
                "companies",
                "and",
                "institutions",
                "can",
                "afford.",
                "For",
                "example,",
                "the",
                "base",
                "model",
                "of",
                "BERT",
                "with",
                "110",
                "million",
                "parameters",
                "was",
                "pre-trained",
                "on",
                "16",
                "gigabytes",
                "(GB)",
                "of",
                "text,",
                "while",
                "the",
                "GPT-3",
                "model",
                "#TARGET_REF",
                "was",
                "pre-trained",
                "on",
                "45",
                "terabytes",
                "(TB)",
                "of",
                "text",
                "and",
                "has",
                "175",
                "billion",
                "parameters."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The trend of recent years consists in training large pre-trained language models on ever larger corpora, with an ever-increasing amount of parameters, which requires considerable computational resources that only a few companies and institutions can afford. For example, the base model of BERT with 110 million parameters was pre-trained on 16 gigabytes (GB) of text, while the GPT-3 model #TARGET_REF was pre-trained on 45 terabytes (TB) of text and has 175 billion parameters.",
        "output": "{\"INFORMATION\": [\"GPT-3 model #TARGET_REF was pre-trained on 45 terabytes (TB) of text and has 175 billion parameters.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The trend of recent years consists in training large pre-trained language models on ever larger corpora, with an ever-increasing amount of parameters, which requires considerable computational resources that only a few companies and institutions can afford. For example, the base model of BERT with 110 million parameters was pre-trained on 16 gigabytes (GB) of text, while the\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "definition",
                "generation",
                "task",
                "is",
                "first",
                "introduced",
                "by",
                "#REF",
                ".",
                "Although",
                "this",
                "task",
                "is",
                "proposed",
                "as",
                "a",
                "potentially",
                "useful",
                "tool",
                "for",
                "explainable",
                "AI,",
                "many",
                "subsequent",
                "works",
                "believe",
                "that",
                "it",
                "can",
                "assist",
                "language",
                "learning",
                "by",
                "giving",
                "definitions",
                "for",
                "words",
                "in",
                "the",
                "text",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The definition generation task is first introduced by #REF . Although this task is proposed as a potentially useful tool for explainable AI, many subsequent works believe that it can assist language learning by giving definitions for words in the text #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"many subsequent works believe that it can assist language learning by giving definitions for words in the text #TARGET_REF .\"], \"PERCEPTION\": [\"Although this task is proposed as a potentially useful tool for explainable AI,\"], \"BACKGROUND\": [\"The definition generation task is first introduced by #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "the",
                "secondary",
                "label",
                "sequence",
                "(e.g.,",
                "connectionist",
                "temporal",
                "classification",
                "(CTC)",
                "based",
                "systems).",
                "In",
                "contrast",
                "to",
                "the",
                "previous",
                "two",
                "approaches,",
                "the",
                "O2O",
                "model",
                "does",
                "not",
                "require",
                "postprocessing",
                "to",
                "align",
                "the",
                "label",
                "sequences",
                "during",
                "inference",
                "since",
                "the",
                "output",
                "sequence",
                "preserves",
                "the",
                "alignment",
                "between",
                "the",
                "word",
                "and",
                "corresponding",
                "annotation",
                "labels,",
                "alignment",
                "is",
                "only",
                "needed",
                "for",
                "the",
                "data",
                "preparation",
                "stage",
                "during",
                "training",
                "to",
                "produce",
                "the",
                "appropriate",
                "target",
                "sequences.",
                "For",
                "this",
                "reason,",
                "we",
                "used",
                "the",
                "O2O",
                "model",
                "in",
                "this",
                "study.",
                "This",
                "paper",
                "proposes",
                "to",
                "use",
                "a",
                "state-of-the-art",
                "Transformer-based",
                "E2E",
                "ASR",
                "system",
                "#REF",
                "for",
                "the",
                "O2O",
                "model",
                "with",
                "a",
                "single",
                "sequence,",
                "instead",
                "of",
                "CTC-based",
                "approaches",
                "which",
                "are",
                "frequently",
                "supported",
                "#TARGET_REF",
                ".",
                "Compared",
                "with",
                "the",
                "CTC-based",
                "systems,",
                "this",
                "approach",
                "can",
                "explicitly",
                "model",
                "the",
                "relationship",
                "between",
                "the",
                "output",
                "labels",
                "thanks",
                "to",
                "the",
                "autoregressive",
                "decoder",
                "network,",
                "similar",
                "to",
                "the",
                "conditional",
                "chain",
                "rule",
                "model",
                "in",
                "Fig.",
                "1(b).",
                "We",
                "also",
                "demonstrate",
                "improved",
                "performance",
                "compared",
                "to",
                "the",
                "CTC-based",
                "systems.",
                "Another",
                "contribution",
                "is",
                "that",
                "we",
                "conducted",
                "an",
                "extensive",
                "empirical",
                "evaluation",
                "to",
                "analyze",
                "and",
                "demonstrate",
                "the",
                "utility",
                "of",
                "our",
                "approach.",
                "For",
                "example,",
                "we",
                "applied",
                "the",
                "method",
                "to",
                "English",
                "and",
                "Japanese",
                "ASR",
                "tasks",
                "in",
                "which",
                "phonemic",
                "transcripts",
                "and",
                "POS",
                "tags",
                "are",
                "simultaneously",
                "produced.",
                "Our",
                "approach",
                "predicts",
                "linguistic",
                "annotations",
                "correctly",
                "even",
                "though",
                "corresponding",
                "graphemes",
                "are",
                "wrong,",
                "while",
                "the",
                "pipeline",
                "approach,",
                "in",
                "which",
                "NLP-based",
                "methods",
                "are",
                "applied",
                "to",
                "a",
                "hypothesized",
                "ASR",
                "transcript,",
                "fails.",
                "This",
                "feature",
                "is",
                "helpful",
                "for",
                "the",
                "downstream",
                "NLP",
                "system",
                "like",
                "slot",
                "filling",
                "or",
                "intent",
                "detection.",
                "Besides,",
                "our",
                "approach",
                "is",
                "suitable",
                "for",
                "on-device",
                "applications",
                "because",
                "the",
                "E2E",
                "model",
                "archives",
                "small-footprint",
                "prediction",
                "#REF",
                ".",
                "Note",
                "that",
                "our",
                "primary",
                "goal",
                "is",
                "to",
                "provide",
                "aligned",
                "transcripts",
                "and",
                "linguistic",
                "annotations",
                "with",
                "minimal",
                "degradation",
                "in",
                "ASR",
                "performance.",
                "We",
                "are",
                "not",
                "aiming",
                "to",
                "improve",
                "ASR",
                "performance.",
                "The",
                "features",
                "of",
                "the",
                "proposed",
                "method",
                "are",
                "summarized",
                "as",
                "follows:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "the secondary label sequence (e.g., connectionist temporal classification (CTC) based systems). In contrast to the previous two approaches, the O2O model does not require postprocessing to align the label sequences during inference since the output sequence preserves the alignment between the word and corresponding annotation labels, alignment is only needed for the data preparation stage during training to produce the appropriate target sequences. For this reason, we used the O2O model in this study. This paper proposes to use a state-of-the-art Transformer-based E2E ASR system #REF for the O2O model with a single sequence, instead of CTC-based approaches which are frequently supported #TARGET_REF . Compared with the CTC-based systems, this approach can explicitly model the relationship between the output labels thanks to the autoregressive decoder network, similar to the conditional chain rule model in Fig. 1(b). We also demonstrate improved performance compared to the CTC-based systems. Another contribution is that we conducted an extensive empirical evaluation to analyze and demonstrate the utility of our approach. For example, we applied the method to English and Japanese ASR tasks in which phonemic transcripts and POS tags are simultaneously produced. Our approach predicts linguistic annotations correctly even though corresponding graphemes are wrong, while the pipeline approach, in which NLP-based methods are applied to a hypothesized ASR transcript, fails. This feature is helpful for the downstream NLP system like slot filling or intent detection. Besides, our approach is suitable for on-device applications because the E2E model archives small-footprint prediction #REF . Note that our primary goal is to provide aligned transcripts and linguistic annotations with minimal degradation in ASR performance. We are not aiming to improve ASR performance. The features of the proposed method are summarized as follows:",
        "output": "{\"INFORMATION\": [\"CTC-based approaches which are frequently supported #TARGET_REF .\", \"the CTC-based systems,\", \"the CTC-based systems.\"], \"PERCEPTION\": [\"This paper proposes to use a state-of-the-art Transformer-based E2E ASR system #REF for the O2O model with a single sequence, instead of\", \"Compared with\", \"this approach can explicitly model the relationship between the output labels thanks to the autoregressive decoder network, similar to the conditional chain rule model in\", \"We also demonstrate improved performance compared to\"], \"BACKGROUND\": [\"Fig. 1(b).\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "coherent",
                "development",
                "of",
                "semantic",
                "lexical",
                "resources",
                "must",
                "be",
                "guided",
                "by",
                "an",
                "underlying",
                "theoretical",
                "framework",
                "for",
                "structuring",
                "word",
                "meaning",
                "and",
                "generating",
                "concepts",
                "which",
                "satisfies",
                "both",
                "ontological",
                "considerations",
                "as",
                "well",
                "as",
                "the",
                "need",
                "to",
                "capture",
                "linguistic",
                "generalisations.",
                "The",
                "SIMPLE",
                "model",
                "is",
                "a",
                "concrete",
                "major",
                "step",
                "towards",
                "this",
                "objective.",
                "It",
                "is",
                "based",
                "on",
                "EAGLES",
                "Lexicon/Semantics",
                "Working",
                "Group",
                "recommendations",
                "#REF",
                "and",
                "on",
                "extensions",
                "of",
                "Generative",
                "Lexicon",
                "(GL)",
                "theory",
                "#REF",
                ").",
                "An",
                "essential",
                "characteristicswhich",
                "makes",
                "it",
                "basically",
                "different",
                "from",
                "EuroWordNet",
                "(where",
                "the",
                "main",
                "structuring",
                "semantic",
                "relations",
                "are",
                "synon-ymy",
                "and",
                "hyponymy)",
                "-is",
                "its",
                "ability",
                "to",
                "capture",
                "the",
                "various",
                "dimensions",
                "of",
                "word",
                "meaning",
                "which",
                "are",
                "equally",
                "important",
                "in",
                "language",
                "and",
                "therefore",
                "in",
                "the",
                "development",
                "of",
                "a",
                "computational",
                "lexicon.",
                "The",
                "basic",
                "vocabulary",
                "relies",
                "on",
                "an",
                "extension",
                "of",
                "\"qualia",
                "structure\"",
                "for",
                "structuring",
                "the",
                "semantic/conceptual",
                "types,",
                "which",
                "is",
                "understood",
                "as",
                "a",
                "representational",
                "tool",
                "for",
                "expressing",
                "the",
                "componential",
                "multidimensional",
                "aspect",
                "of",
                "word",
                "meaning",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "A coherent development of semantic lexical resources must be guided by an underlying theoretical framework for structuring word meaning and generating concepts which satisfies both ontological considerations as well as the need to capture linguistic generalisations. The SIMPLE model is a concrete major step towards this objective. It is based on EAGLES Lexicon/Semantics Working Group recommendations #REF and on extensions of Generative Lexicon (GL) theory #REF ). An essential characteristicswhich makes it basically different from EuroWordNet (where the main structuring semantic relations are synon-ymy and hyponymy) -is its ability to capture the various dimensions of word meaning which are equally important in language and therefore in the development of a computational lexicon. The basic vocabulary relies on an extension of \"qualia structure\" for structuring the semantic/conceptual types, which is understood as a representational tool for expressing the componential multidimensional aspect of word meaning #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"The basic vocabulary relies on an extension of \\\"qualia structure\\\" for structuring the semantic/conceptual types, which is understood as a representational tool for expressing the componential multidimensional aspect of word meaning #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "space",
                "complexity",
                "of",
                "the",
                "algorithm",
                "with",
                "respect",
                "to",
                "the",
                "length",
                "n",
                "of",
                "the",
                "input",
                "string",
                "is",
                "O(n",
                "5",
                "),",
                "due",
                "to",
                "the",
                "five",
                "positions",
                "of",
                "the",
                "input",
                "string",
                "stored",
                "in",
                "each",
                "item.",
                "The",
                "time",
                "complexity",
                "is",
                "O(n",
                "7",
                ")",
                "due",
                "to",
                "deduction",
                "steps",
                "in",
                "the",
                "set",
                "v�::?:}",
                ",",
                "0",
                "H",
                "00",
                "-Yl",
                ".",
                "To",
                "reduce",
                "the",
                "time",
                "complexity",
                "we",
                "will",
                "use",
                "a",
                "technique",
                "similar",
                "to",
                "that",
                "used",
                "in",
                "#REF",
                "to",
                "reduce",
                "the",
                "complexity",
                "of",
                "the",
                "tabular",
                "interpretations",
                "of",
                "automata",
                "for",
                "tree",
                "adjoining",
                "languages.",
                "In",
                "this",
                "case",
                ",",
                "we",
                "split",
                "each",
                "deduction",
                "step",
                "in",
                "v�::?:}",
                ",",
                "0",
                "H",
                "00",
                "-Yl",
                "into",
                "two",
                "different",
                "steps",
                "such",
                "that",
                "their",
                "final",
                "complexity",
                "is",
                "at",
                "most",
                "O(n",
                "6",
                ")",
                ".",
                "The",
                "resulting",
                "parsing",
                "schema",
                "is",
                "defined",
                "by",
                "the",
                "following",
                "parsing",
                "system.",
                "6",
                ")",
                "for",
                "a",
                "linear",
                "indexed",
                "grammar",
                "g",
                "and",
                "a",
                "input",
                "string",
                "a",
                "1",
                "...",
                "an",
                "is",
                "defined",
                "as",
                "fo",
                "llows:",
                ",",
                "-,",
                "-],",
                "The",
                "LIG",
                "so",
                "generated",
                "does",
                "not",
                "satisfy",
                "our",
                "definition",
                "of",
                "shared",
                "forest",
                "because",
                "single",
                "parse",
                "trees",
                "can",
                "not",
                "be",
                "extracted",
                "in",
                "linear",
                "time.",
                "Vijay-Shanker",
                "and",
                "Weir",
                "#REF",
                "try",
                "to",
                "solve",
                "this",
                "problem",
                "by",
                "defining",
                "a",
                "non-deterministic",
                "finite",
                "state",
                "automaton",
                "that",
                "determines",
                "if",
                "a",
                "given",
                "LIGed",
                "forest",
                "symbol",
                "(A,",
                "i,",
                "j)[a:]",
                "derives",
                "a",
                "string",
                "of",
                "terminals.",
                "A",
                "similar",
                "finite-state",
                "automata",
                "is",
                "also",
                "defined",
                "by",
                "Nederhof",
                "in",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The space complexity of the algorithm with respect to the length n of the input string is O(n 5 ), due to the five positions of the input string stored in each item. The time complexity is O(n 7 ) due to deduction steps in the set v�::?:} , 0 H 00 -Yl . To reduce the time complexity we will use a technique similar to that used in #REF to reduce the complexity of the tabular interpretations of automata for tree adjoining languages. In this case , we split each deduction step in v�::?:} , 0 H 00 -Yl into two different steps such that their final complexity is at most O(n 6 ) . The resulting parsing schema is defined by the following parsing system. 6 ) for a linear indexed grammar g and a input string a 1 ... an is defined as fo llows: , -, -], The LIG so generated does not satisfy our definition of shared forest because single parse trees can not be extracted in linear time. Vijay-Shanker and Weir #REF try to solve this problem by defining a non-deterministic finite state automaton that determines if a given LIGed forest symbol (A, i, j)[a:] derives a string of terminals. A similar finite-state automata is also defined by Nederhof in #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"A\", \"finite-state automata is also defined by Nederhof in #TARGET_REF .\"], \"PERCEPTION\": [\"similar\"], \"BACKGROUND\": [\"non-deterministic finite state automaton that determines if a given LIGed forest symbol (A, i, j)[a:] derives a string of terminals.\"]}"
    },
    {
        "gold": {
            "text": [
                "Automatic",
                "extraction",
                "of",
                "events",
                "has",
                "gained",
                "sizable",
                "attention",
                "in",
                "subfields",
                "of",
                "NLP",
                "and",
                "information",
                "retrieval",
                "such",
                "as",
                "automatic",
                "summarization,",
                "question",
                "answering",
                "and",
                "knowledge",
                "graph",
                "embeddings",
                "#TARGET_REF",
                ",",
                "as",
                "events",
                "are",
                "a",
                "representation",
                "of",
                "temporal",
                "information",
                "and",
                "sequences",
                "in",
                "text.",
                "Various",
                "developments",
                "in",
                "guidelines",
                "and",
                "datasets",
                "for",
                "event",
                "detection",
                "have",
                "been",
                "met",
                "with",
                "equally",
                "fast",
                "paced",
                "evolution",
                "of",
                "automatic",
                "event",
                "annotation",
                "and",
                "detection",
                "methodologies",
                "in",
                "the",
                "last",
                "few",
                "years",
                "#REF",
                ".",
                "On",
                "a",
                "larger",
                "scale,",
                "event",
                "extraction",
                "has",
                "extended",
                "to",
                "many",
                "languages",
                "beyond",
                "English,",
                "including",
                "French",
                "#REF",
                ",",
                "Spanish",
                "#REF",
                ",",
                "Italian",
                "#REF",
                "and",
                "very",
                "recently,",
                "Hindi",
                "#REF",
                ".",
                "Event",
                "detection",
                "architectures",
                "have",
                "their",
                "origins",
                "in",
                "statistical",
                "models",
                "such",
                "as",
                "K-means",
                "and",
                "hierarchical",
                "clustering",
                "methods",
                "#REF",
                ",",
                "which",
                "have",
                "more",
                "recently",
                "given",
                "way",
                "to",
                "neural",
                "models.",
                "Deep",
                "neural",
                "architectures",
                "on",
                "event",
                "annotation",
                "vary",
                "based",
                "on",
                "the",
                "approach",
                "taken",
                "to",
                "identifying",
                "and",
                "handling",
                "the",
                "data."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Automatic extraction of events has gained sizable attention in subfields of NLP and information retrieval such as automatic summarization, question answering and knowledge graph embeddings #TARGET_REF , as events are a representation of temporal information and sequences in text. Various developments in guidelines and datasets for event detection have been met with equally fast paced evolution of automatic event annotation and detection methodologies in the last few years #REF . On a larger scale, event extraction has extended to many languages beyond English, including French #REF , Spanish #REF , Italian #REF and very recently, Hindi #REF . Event detection architectures have their origins in statistical models such as K-means and hierarchical clustering methods #REF , which have more recently given way to neural models. Deep neural architectures on event annotation vary based on the approach taken to identifying and handling the data.",
        "output": "{\"INFORMATION\": [\"knowledge graph embeddings #TARGET_REF ,\"], \"PERCEPTION\": [\"Automatic extraction of events has gained sizable attention in subfields of NLP and information retrieval such as\", \"as events are a representation of temporal information and sequences in text.\"], \"BACKGROUND\": [\"automatic summarization, question answering and\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "relationship",
                "between",
                "productivity",
                "and",
                "regularity",
                "is",
                "discussed",
                "by",
                "#TARGET_REF",
                ".",
                "In",
                "a",
                "computational",
                "context,",
                "the",
                "regularity",
                "of",
                "a",
                "word",
                "formation",
                "rule",
                "is",
                "what",
                "makes",
                "it",
                "possible",
                "to",
                "describe",
                "it",
                "in",
                "the",
                "form",
                "of",
                "a",
                "procedure",
                "which",
                "can",
                "be",
                "used",
                "to",
                "recognize",
                "new",
                "words."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The relationship between productivity and regularity is discussed by #TARGET_REF . In a computational context, the regularity of a word formation rule is what makes it possible to describe it in the form of a procedure which can be used to recognize new words.",
        "output": "{\"INFORMATION\": [\"The relationship between productivity and regularity is discussed by #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "alleviate",
                "this,",
                "past",
                "work",
                "proposed",
                "approximation",
                "methods",
                "for",
                "the",
                "computation",
                "of",
                "softmax(QK",
                ").",
                "One",
                "major",
                "line",
                "of",
                "research",
                "focused",
                "on",
                "sparse",
                "attention",
                "variants,",
                "where",
                "only",
                "a",
                "few",
                "similarity",
                "scores",
                "are",
                "computed",
                "per",
                "query,",
                "and",
                "the",
                "rest",
                "are",
                "ignored.",
                "Methods",
                "differ",
                "by",
                "which",
                "query-key",
                "pairs",
                "are",
                "selected",
                "#REF",
                ".",
                "A",
                "second",
                "line",
                "of",
                "research",
                "explored",
                "dense",
                "variants",
                "#REF",
                ")",
                "(cf.",
                "#TARGET_REF",
                "for",
                "a",
                "survey).",
                "For",
                "example,",
                "instead",
                "of",
                "computing",
                "the",
                "attention",
                "scores",
                "exactly",
                "for",
                "only",
                "a",
                "small",
                "number",
                "of",
                "querykey",
                "pairs,",
                "#REF",
                "compute",
                "an",
                "approximation",
                "of",
                "scores",
                "for",
                "all",
                "pairs."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "To alleviate this, past work proposed approximation methods for the computation of softmax(QK ). One major line of research focused on sparse attention variants, where only a few similarity scores are computed per query, and the rest are ignored. Methods differ by which query-key pairs are selected #REF . A second line of research explored dense variants #REF ) (cf. #TARGET_REF for a survey). For example, instead of computing the attention scores exactly for only a small number of querykey pairs, #REF compute an approximation of scores for all pairs.",
        "output": "{\"INFORMATION\": [\"research explored dense variants\", \"#TARGET_REF for a survey).\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"To alleviate this, past work proposed approximation methods for the computation of softmax(QK ).\", \"For example, instead of computing the attention scores exactly for only a small number of querykey pairs, #REF compute an approximation of scores for all pairs.\"]}"
    },
    {
        "gold": {
            "text": [
                "Research",
                "shows",
                "that",
                "affect",
                "categories",
                "are",
                "quite",
                "universal",
                "#REF",
                ".",
                "Therefore,",
                "theoretically",
                "they",
                "should",
                "also",
                "to",
                "a",
                "large",
                "degree",
                "retain",
                "emotion",
                "categories",
                "when",
                "translated.",
                "Annotation",
                "projection",
                "has",
                "been",
                "shown",
                "to",
                "offer",
                "reliable",
                "results",
                "in",
                "different",
                "NLP",
                "and",
                "NLU",
                "tasks",
                "#TARGET_REF",
                ".",
                "Projection",
                "is",
                "sometimes",
                "the",
                "only",
                "feasible",
                "way",
                "to",
                "produce",
                "resources",
                "for",
                "under-resourced",
                "languages.",
                "By",
                "taking",
                "datasets",
                "created",
                "for",
                "high-resource",
                "languages",
                "and",
                "projecting",
                "these",
                "results",
                "on",
                "the",
                "corresponding",
                "items",
                "in",
                "the",
                "underresourced",
                "language",
                "using",
                "parallel",
                "corpora,",
                "we",
                "can",
                "create",
                "datasets",
                "in",
                "as",
                "many",
                "languages",
                "as",
                "exist",
                "in",
                "the",
                "parallel",
                "corpus.",
                "A",
                "parallel",
                "corpus",
                "for",
                "multiple",
                "languages",
                "enables",
                "the",
                "simultaneous",
                "creation",
                "of",
                "resources",
                "for",
                "multiple",
                "languages",
                "at",
                "a",
                "low",
                "cost."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Research shows that affect categories are quite universal #REF . Therefore, theoretically they should also to a large degree retain emotion categories when translated. Annotation projection has been shown to offer reliable results in different NLP and NLU tasks #TARGET_REF . Projection is sometimes the only feasible way to produce resources for under-resourced languages. By taking datasets created for high-resource languages and projecting these results on the corresponding items in the underresourced language using parallel corpora, we can create datasets in as many languages as exist in the parallel corpus. A parallel corpus for multiple languages enables the simultaneous creation of resources for multiple languages at a low cost.",
        "output": "{\"INFORMATION\": [\"Annotation projection has been shown to offer reliable results in different NLP and NLU tasks #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "investigate",
                "the",
                "relationship",
                "of",
                "the",
                "above",
                "defined",
                "relatedness",
                "measures,",
                "we",
                "compute",
                "correlations",
                "between",
                "the",
                "score",
                "they",
                "assign",
                "to",
                "100.000",
                "random",
                "word",
                "pairs.",
                "As",
                "Table",
                "1",
                "shows,",
                "none",
                "of",
                "the",
                "measures",
                "are",
                "near",
                "equivalent,",
                "but",
                "they",
                "have",
                "nonzero",
                "correlations.",
                "They",
                "also",
                "show",
                "high",
                "positive",
                "correlations",
                "with",
                "MEN",
                "#TARGET_REF",
                "and",
                "WS-353",
                "relatedness",
                "#REF",
                ",",
                "as",
                "can",
                "be",
                "seen",
                "in",
                "Table",
                "2,",
                "which",
                "is",
                "hopeful",
                "for",
                "their",
                "usability",
                "as",
                "relatedness",
                "in",
                "Codenames",
                "agents."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "To investigate the relationship of the above defined relatedness measures, we compute correlations between the score they assign to 100.000 random word pairs. As Table 1 shows, none of the measures are near equivalent, but they have nonzero correlations. They also show high positive correlations with MEN #TARGET_REF and WS-353 relatedness #REF , as can be seen in Table 2, which is hopeful for their usability as relatedness in Codenames agents.",
        "output": "{\"INFORMATION\": [\"with MEN #TARGET_REF\"], \"PERCEPTION\": [\"They also show high positive correlations\", \"which is hopeful for their usability as relatedness in Codenames agents.\"], \"BACKGROUND\": [\"and WS-353 relatedness #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Once",
                "the",
                "best",
                "performing",
                "adapted",
                "language",
                "models",
                "were",
                "identified,",
                "we",
                "tried",
                "to",
                "further",
                "boost",
                "the",
                "performance",
                "by",
                "providing",
                "the",
                "HPB",
                "SMT",
                "system",
                "with",
                "target-side",
                "syntactic",
                "information",
                "extracted",
                "using",
                "CCG",
                "resources",
                "#TARGET_REF",
                ".",
                "We",
                "used",
                "CCG",
                "categories",
                "to",
                "label",
                "non-terminals",
                "in",
                "hierarchical",
                "rules.",
                "Different",
                "CCG-based",
                "labeling",
                "approaches",
                "were",
                "explored,",
                "each",
                "focussing",
                "on",
                "a",
                "different",
                "aspect",
                "of",
                "information",
                "reflected",
                "in",
                "CCG",
                "categories.",
                "The",
                "best",
                "performing",
                "system",
                "was",
                "a",
                "CCGaugmented",
                "HPB",
                "system",
                "for",
                "both",
                "language",
                "pairs",
                "providing",
                "a",
                "statistically",
                "significant",
                "improvement",
                "of",
                "0.93",
                "absolute",
                "BLEU",
                "points",
                "(3.25%",
                "relative)",
                "and",
                "0.44",
                "absolute",
                "BLEU",
                "points",
                "(3.7%",
                "relative)",
                "over",
                "the",
                "Ar-En",
                "and",
                "Zh-En",
                "mixture-adapted",
                "PB-SMT",
                "baselines,",
                "respectively."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0
            ]
        },
        "input": "Once the best performing adapted language models were identified, we tried to further boost the performance by providing the HPB SMT system with target-side syntactic information extracted using CCG resources #TARGET_REF . We used CCG categories to label non-terminals in hierarchical rules. Different CCG-based labeling approaches were explored, each focussing on a different aspect of information reflected in CCG categories. The best performing system was a CCGaugmented HPB system for both language pairs providing a statistically significant improvement of 0.93 absolute BLEU points (3.25% relative) and 0.44 absolute BLEU points (3.7% relative) over the Ar-En and Zh-En mixture-adapted PB-SMT baselines, respectively.",
        "output": "{\"INFORMATION\": [\"CCG resources #TARGET_REF .\"], \"PERCEPTION\": [\"Once the best performing adapted language models were identified, we tried to further boost the performance by providing the HPB SMT system with target-side syntactic information extracted using\", \"We used CCG categories to label non-terminals in hierarchical rules. Different CCG-based labeling approaches were explored, each focussing on a different aspect of information reflected in CCG categories. The best performing system was a CCGaugmented HPB system for both language pairs providing a statistically significant improvement of 0.93 absolute BLEU points (3.25% relative) and 0.44 absolute BLEU points (3.7% relative) over the Ar-En and Zh-En mixture-adapted PB-SMT baselines,\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "quality",
                "is",
                "measured",
                "by",
                "standard",
                "N-gram",
                "based",
                "metrics,",
                "including",
                "the",
                "BLEU",
                "score",
                "#REF",
                "and",
                "the",
                "ROUGE",
                "score",
                "#TARGET_REF",
                ".",
                "This",
                "measures",
                "the",
                "highest",
                "accuracy",
                "comparing",
                "the",
                "best",
                "hypothesis",
                "among",
                "the",
                "top-K",
                "with",
                "the",
                "target",
                "#REF",
                ".",
                "Concretely,",
                "we",
                "generate",
                "hypotheses",
                "{",
                "Ŷ",
                "(1)",
                ",",
                "•",
                "•",
                "•",
                "Ŷ",
                "(K)",
                "}",
                "from",
                "each",
                "source",
                "X",
                "and",
                "keep",
                "the",
                "hypothesis",
                "Ŷ",
                "best",
                "that",
                "achieves",
                "the",
                "best",
                "sentencelevel",
                "metric",
                "with",
                "the",
                "target",
                "Y",
                ".",
                "Then",
                "we",
                "calculate",
                "a",
                "corpus-level",
                "metric",
                "with",
                "the",
                "greedily-selected",
                "hypotheses",
                "{Y",
                "(i),best",
                "}",
                "N",
                "i=1",
                "and",
                "references",
                "{Y",
                "(i)",
                "}",
                "N",
                "i=1",
                ".",
                "The",
                "diversity",
                "of",
                "evaluated",
                "by",
                "three",
                "aspects:",
                "concept,",
                "pairwise",
                "and",
                "corpus",
                "diversity."
            ],
            "context": [
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The quality is measured by standard N-gram based metrics, including the BLEU score #REF and the ROUGE score #TARGET_REF . This measures the highest accuracy comparing the best hypothesis among the top-K with the target #REF . Concretely, we generate hypotheses { Ŷ (1) , • • • Ŷ (K) } from each source X and keep the hypothesis Ŷ best that achieves the best sentencelevel metric with the target Y . Then we calculate a corpus-level metric with the greedily-selected hypotheses {Y (i),best } N i=1 and references {Y (i) } N i=1 . The diversity of evaluated by three aspects: concept, pairwise and corpus diversity.",
        "output": "{\"INFORMATION\": [\"by standard N-gram based metrics,\", \"and the ROUGE score #TARGET_REF .\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"including the BLEU score #REF\", \"This measures the highest accuracy comparing the best hypothesis among the top-K with the target #REF . Concretely, we generate hypotheses { \\u0176 (1) , \\u2022 \\u2022 \\u2022 \\u0176 (K) } from each source X and keep the hypothesis \\u0176 best that achieves the best sentencelevel metric with the target Y . Then we calculate a corpus-level metric with the greedily-selected hypotheses {Y (i),best } N i=1 and references {Y (i) } N i=1 . The diversity of evaluated by three aspects: concept, pairwise and corpus diversity.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "most",
                "studies,",
                "model",
                "robustness",
                "is",
                "evaluated",
                "based",
                "on",
                "a",
                "given",
                "test",
                "dataset",
                "or",
                "synthetic",
                "sentences",
                "constructed",
                "from",
                "templates",
                "#TARGET_REF",
                ".",
                "Specifically,",
                "the",
                "robustness",
                "of",
                "a",
                "model",
                "is",
                "often",
                "evaluated",
                "by",
                "the",
                "ratio",
                "of",
                "test",
                "examples",
                "where",
                "the",
                "model",
                "prediction",
                "cannot",
                "be",
                "altered",
                "by",
                "semantic-invariant",
                "perturbation.",
                "We",
                "refer",
                "to",
                "this",
                "type",
                "of",
                "evaluations",
                "as",
                "the",
                "first-order",
                "robustness",
                "evaluation.",
                "However,",
                "even",
                "if",
                "a",
                "model",
                "is",
                "first-order",
                "robust",
                "on",
                "an",
                "input",
                "sentence",
                "x",
                "0",
                ",",
                "it",
                "is",
                "possible",
                "that",
                "the",
                "model",
                "is",
                "not",
                "robust",
                "on",
                "a",
                "natural",
                "sentence",
                "x0",
                "that",
                "is",
                "slightly",
                "modified",
                "from",
                "x",
                "0",
                ".",
                "In",
                "that",
                "case,",
                "adversarial",
                "examples",
                "still",
                "exist",
                "even",
                "if",
                "first-order",
                "attacks",
                "cannot",
                "find",
                "any",
                "of",
                "them",
                "from",
                "the",
                "given",
                "test",
                "dataset.",
                "Throughout",
                "this",
                "paper,",
                "we",
                "call",
                "x0",
                "a",
                "vulnerable",
                "example.",
                "The",
                "existence",
                "of",
                "such",
                "examples",
                "exposes",
                "weaknesses",
                "in",
                "models'",
                "understanding",
                "and",
                "presents",
                "challenges",
                "for",
                "model",
                "deployment.",
                "Fig.",
                "1",
                "illustrates",
                "an",
                "example."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In most studies, model robustness is evaluated based on a given test dataset or synthetic sentences constructed from templates #TARGET_REF . Specifically, the robustness of a model is often evaluated by the ratio of test examples where the model prediction cannot be altered by semantic-invariant perturbation. We refer to this type of evaluations as the first-order robustness evaluation. However, even if a model is first-order robust on an input sentence x 0 , it is possible that the model is not robust on a natural sentence x0 that is slightly modified from x 0 . In that case, adversarial examples still exist even if first-order attacks cannot find any of them from the given test dataset. Throughout this paper, we call x0 a vulnerable example. The existence of such examples exposes weaknesses in models' understanding and presents challenges for model deployment. Fig. 1 illustrates an example.",
        "output": "{\"INFORMATION\": [\"based on a given test dataset or synthetic sentences constructed from templates #TARGET_REF .\"], \"PERCEPTION\": [\"model robustness is evaluated\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "While",
                "reading",
                "comprehension",
                "(RC)",
                "and",
                "question",
                "answering",
                "(QA)",
                "are",
                "often",
                "used",
                "interchangeably",
                "in",
                "the",
                "literature,",
                "measuring",
                "the",
                "reading",
                "comprehension",
                "capacity",
                "of",
                "models",
                "via",
                "question",
                "answering,",
                "as",
                "implemented",
                "in",
                "benchmarks",
                "such",
                "as",
                "SQuAD",
                "#REF",
                ",",
                "BoolQ",
                "#REF",
                "and",
                "others,",
                "has",
                "several",
                "well-documented",
                "problems",
                "#TARGET_REF",
                ".",
                "We",
                "argue",
                "that",
                "the",
                "TNE",
                "task",
                "we",
                "propose",
                "herein",
                "has",
                "properties",
                "that",
                "make",
                "it",
                "appealing",
                "for",
                "assessing",
                "RC,",
                "more",
                "than",
                "QA",
                "is.",
                "First,",
                "benchmarks",
                "for",
                "extractive",
                "(span-marking)",
                "QA",
                "are",
                "sensitive",
                "to",
                "the",
                "span-boundary",
                "selection,",
                "on",
                "the",
                "other",
                "hand,",
                "benchmarks",
                "for",
                "yes/no,",
                "multiple",
                "choice,",
                "or",
                "generative",
                "questions",
                "can",
                "in",
                "principle",
                "be",
                "answered",
                "in",
                "a",
                "way",
                "that",
                "is",
                "completely",
                "divorced",
                "from",
                "the",
                "text.",
                "On",
                "a",
                "more",
                "fundamental",
                "level,",
                "all",
                "QA",
                "benchmarks",
                "are",
                "very",
                "sensitive",
                "to",
                "lexical",
                "choices",
                "in",
                "the",
                "question",
                "and",
                "its",
                "similarity",
                "to",
                "the",
                "text.",
                "Furthermore,",
                "QA",
                "benchmarks",
                "rely",
                "on",
                "human",
                "authored",
                "questions",
                "that",
                "are",
                "easy",
                "to",
                "solve",
                "based",
                "on",
                "surface",
                "artifacts.",
                "Finally,",
                "in",
                "many",
                "cases,",
                "the",
                "existence",
                "of",
                "the",
                "question",
                "itself",
                "provides",
                "a",
                "huge",
                "hint",
                "towards",
                "the",
                "answer",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "While reading comprehension (RC) and question answering (QA) are often used interchangeably in the literature, measuring the reading comprehension capacity of models via question answering, as implemented in benchmarks such as SQuAD #REF , BoolQ #REF and others, has several well-documented problems #TARGET_REF . We argue that the TNE task we propose herein has properties that make it appealing for assessing RC, more than QA is. First, benchmarks for extractive (span-marking) QA are sensitive to the span-boundary selection, on the other hand, benchmarks for yes/no, multiple choice, or generative questions can in principle be answered in a way that is completely divorced from the text. On a more fundamental level, all QA benchmarks are very sensitive to lexical choices in the question and its similarity to the text. Furthermore, QA benchmarks rely on human authored questions that are easy to solve based on surface artifacts. Finally, in many cases, the existence of the question itself provides a huge hint towards the answer #REF .",
        "output": "{\"INFORMATION\": [\"measuring the reading comprehension capacity of models via question answering,\", \"has several well-documented problems #TARGET_REF .\"], \"PERCEPTION\": [\"While reading comprehension (RC) and question answering (QA) are often used interchangeably in the literature,\"], \"BACKGROUND\": [\"as implemented in benchmarks such as SQuAD #REF , BoolQ #REF and others,\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "connection",
                "according",
                "to",
                "the",
                "knowledge",
                "graph",
                "ConceptNet5",
                "#TARGET_REF",
                ","
            ],
            "context": [
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• connection according to the knowledge graph ConceptNet5 #TARGET_REF ,",
        "output": "{\"INFORMATION\": [\"the knowledge graph ConceptNet5 #TARGET_REF ,\"], \"PERCEPTION\": [\"connection according to\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Many",
                "works",
                "address",
                "the",
                "issue",
                "of",
                "model",
                "compression",
                "with",
                "quantization,",
                "pruning,",
                "knowledge",
                "distillation",
                "or",
                "a",
                "combination",
                "of",
                "these",
                "approaches.",
                "The",
                "idea",
                "of",
                "quantization",
                "#TARGET_REF",
                "is",
                "to",
                "take",
                "advantage",
                "of",
                "the",
                "use",
                "of",
                "lower",
                "precision",
                "bit-width",
                "floats",
                "to",
                "reduce",
                "memory",
                "usage",
                "and",
                "increase",
                "computational",
                "density.",
                "Following",
                "the",
                "same",
                "objective,",
                "pruning",
                "#REF",
                "consists",
                "in",
                "removing",
                "parts",
                "of",
                "a",
                "model",
                "(weight",
                "bindings,",
                "attentional",
                "heads)",
                "with",
                "minimal",
                "precision",
                "losses.",
                "Finally,",
                "knowledge",
                "distillation",
                "#REF",
                "enables",
                "the",
                "generation",
                "of",
                "models",
                "that",
                "mimic",
                "the",
                "performance",
                "of",
                "a",
                "large",
                "model",
                "(or",
                "set",
                "of",
                "models)",
                "while",
                "having",
                "fewer",
                "parameters."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Many works address the issue of model compression with quantization, pruning, knowledge distillation or a combination of these approaches. The idea of quantization #TARGET_REF is to take advantage of the use of lower precision bit-width floats to reduce memory usage and increase computational density. Following the same objective, pruning #REF consists in removing parts of a model (weight bindings, attentional heads) with minimal precision losses. Finally, knowledge distillation #REF enables the generation of models that mimic the performance of a large model (or set of models) while having fewer parameters.",
        "output": "{\"INFORMATION\": [\"The idea of quantization #TARGET_REF is to take advantage of the use of lower precision bit-width floats to reduce memory usage and increase computational density.\"], \"PERCEPTION\": [\"Many works address the issue of model compression with quantization,\", \"of these approaches.\"], \"BACKGROUND\": [\"pruning, knowledge distillation or a combination\"]}"
    },
    {
        "gold": {
            "text": [
                "Data",
                "set.",
                "The",
                "stimulus",
                "set",
                "includes",
                "4,479",
                "sentences",
                "(74,953",
                "tokens)",
                "selected",
                "from",
                "the",
                "English",
                "Web",
                "Treebank",
                "#REF",
                ",",
                "covering",
                "the",
                "genres",
                "weblogs,",
                "newsgroups,",
                "reviews",
                "and",
                "Yahoo",
                "Answers.",
                "The",
                "mean",
                "sentence",
                "length",
                "is",
                "16.7",
                "words",
                "(standard",
                "deviation:",
                "12.23).",
                "75",
                "sessions",
                "of",
                "EEG",
                "data",
                "are",
                "included",
                "over",
                "20",
                "days,",
                "each",
                "lasting",
                "20-25",
                "minutes,",
                "from",
                "a",
                "single",
                "subject",
                "who",
                "read",
                "approximately",
                "five",
                "and",
                "a",
                "half",
                "iterations",
                "of",
                "the",
                "stimulus",
                "set",
                "(i.e.",
                "24,323",
                "sentences",
                "and",
                "404,205",
                "tokens",
                "in",
                "total,",
                "thereby",
                "substantially",
                "exceeding",
                "current",
                "freely",
                "accessible",
                "data",
                "sets,",
                "e.g.",
                "#TARGET_REF",
                ".",
                "Three",
                "sessions",
                "were",
                "excluded",
                "because",
                "of",
                "data",
                "corruption."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Data set. The stimulus set includes 4,479 sentences (74,953 tokens) selected from the English Web Treebank #REF , covering the genres weblogs, newsgroups, reviews and Yahoo Answers. The mean sentence length is 16.7 words (standard deviation: 12.23). 75 sessions of EEG data are included over 20 days, each lasting 20-25 minutes, from a single subject who read approximately five and a half iterations of the stimulus set (i.e. 24,323 sentences and 404,205 tokens in total, thereby substantially exceeding current freely accessible data sets, e.g. #TARGET_REF . Three sessions were excluded because of data corruption.",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [\"24,323 sentences and 404,205 tokens in total, thereby substantially exceeding current freely accessible data sets,\"], \"BACKGROUND\": [\"#TARGET_REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Figure",
                "1:",
                "Pipeline",
                "of",
                "NMT",
                "system",
                "with",
                "Factored",
                "output",
                "Multiple",
                "output",
                "neural",
                "networks",
                "were",
                "previously",
                "pro-posed",
                "#TARGET_REF",
                "using",
                "scheduled",
                "decoders",
                "with",
                "multiple",
                "source",
                "and",
                "target",
                "languages.",
                "In",
                "contrast",
                "to",
                "this,",
                "the",
                "FNMT",
                "system",
                "simultaneously",
                "produces",
                "several",
                "outputs.",
                "Given",
                "both",
                "outputs",
                "(lemma",
                "and",
                "factors)",
                "and",
                "linguistic",
                "resources,",
                "the",
                "final",
                "surface",
                "form",
                "is",
                "easily",
                "generated."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Figure 1: Pipeline of NMT system with Factored output Multiple output neural networks were previously pro-posed #TARGET_REF using scheduled decoders with multiple source and target languages. In contrast to this, the FNMT system simultaneously produces several outputs. Given both outputs (lemma and factors) and linguistic resources, the final surface form is easily generated.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF using scheduled decoders with multiple source and target languages.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Pipeline of NMT system with Factored output Multiple output neural networks were previously pro-posed\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "O2M",
                "models",
                "shown",
                "in",
                "Fig.",
                "1(a),",
                "a",
                "multitask",
                "objective",
                "is",
                "used",
                "in",
                "which",
                "an",
                "extra",
                "branch",
                "is",
                "tasked",
                "with",
                "estimating",
                "the",
                "secondary",
                "label",
                "sequence.",
                "For",
                "example,",
                "in",
                "#REF",
                ",",
                "the",
                "phonemic",
                "transcript",
                "is",
                "produced",
                "in",
                "addition",
                "to",
                "the",
                "graphemic",
                "transcript.",
                "The",
                "O2M",
                "model",
                "can",
                "estimate",
                "each",
                "sequence",
                "more",
                "accurately",
                "than",
                "separate",
                "models",
                "responsible",
                "for",
                "producing",
                "phonemic",
                "and",
                "graphemic",
                "transcripts",
                "independently.",
                "We",
                "can",
                "implement",
                "this",
                "approach",
                "with",
                "less",
                "effort",
                "by",
                "attaching",
                "multiple",
                "loss",
                "functions",
                "to",
                "the",
                "base",
                "architecture.",
                "However,",
                "this",
                "O2M",
                "model",
                "does",
                "not",
                "explicitly",
                "consider",
                "dependencies",
                "between",
                "phonemic",
                "and",
                "graphemic",
                "transcripts.",
                "Furthermore,",
                "aligning",
                "phoneme",
                "and",
                "grapheme",
                "sub-sequences",
                "requires",
                "additional",
                "post-processing",
                "based",
                "on",
                "time",
                "alignment",
                "or",
                "alignment",
                "across",
                "the",
                "multiple",
                "sequences",
                "during",
                "inference.",
                "Performance",
                "of",
                "downstream",
                "NLP",
                "tasks",
                "built",
                "on",
                "top",
                "of",
                "ASR",
                "outputs",
                "will",
                "suffer",
                "if",
                "this",
                "post-processing",
                "fails",
                "to",
                "generate",
                "alignment.",
                "#REF",
                "shows",
                "an",
                "O2O",
                "model",
                "with",
                "a",
                "conditional",
                "chain",
                "mapping.",
                "This",
                "method",
                "for",
                "multiple",
                "sequence",
                "modeling",
                "has",
                "been",
                "applied",
                "to",
                "dialog",
                "modeling",
                "#REF",
                ",",
                "speaker",
                "diarization",
                "#TARGET_REF",
                ",",
                "and",
                "multi-speaker",
                "ASR",
                "#REF",
                ".",
                "Unlike",
                "the",
                "O2M",
                "model,",
                "this",
                "model",
                "can",
                "predict",
                "a",
                "variable",
                "number",
                "of",
                "output",
                "sequences",
                "while",
                "explicitly",
                "considering",
                "dependencies",
                "between",
                "the",
                "multiple",
                "sequences",
                "based",
                "on",
                "the",
                "probabilistic",
                "chain",
                "rule.",
                "However,",
                "modeling",
                "these",
                "inter-sequence",
                "dependencies",
                "requires",
                "more",
                "complicated",
                "neural",
                "architectures,",
                "and",
                "alignment",
                "of",
                "the",
                "sequences",
                "still",
                "requires",
                "post-processing",
                "during",
                "inference."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In O2M models shown in Fig. 1(a), a multitask objective is used in which an extra branch is tasked with estimating the secondary label sequence. For example, in #REF , the phonemic transcript is produced in addition to the graphemic transcript. The O2M model can estimate each sequence more accurately than separate models responsible for producing phonemic and graphemic transcripts independently. We can implement this approach with less effort by attaching multiple loss functions to the base architecture. However, this O2M model does not explicitly consider dependencies between phonemic and graphemic transcripts. Furthermore, aligning phoneme and grapheme sub-sequences requires additional post-processing based on time alignment or alignment across the multiple sequences during inference. Performance of downstream NLP tasks built on top of ASR outputs will suffer if this post-processing fails to generate alignment. #REF shows an O2O model with a conditional chain mapping. This method for multiple sequence modeling has been applied to dialog modeling #REF , speaker diarization #TARGET_REF , and multi-speaker ASR #REF . Unlike the O2M model, this model can predict a variable number of output sequences while explicitly considering dependencies between the multiple sequences based on the probabilistic chain rule. However, modeling these inter-sequence dependencies requires more complicated neural architectures, and alignment of the sequences still requires post-processing during inference.",
        "output": "{\"INFORMATION\": [\"speaker diarization #TARGET_REF\"], \"PERCEPTION\": [\"This method for multiple sequence modeling has been applied to\"], \"BACKGROUND\": [\"#REF shows an O2O model with a conditional chain mapping.\", \"dialog modeling #REF ,\", \", and multi-speaker ASR #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "order",
                "to",
                "accomplish",
                "the",
                "high-performance",
                "natural",
                "language",
                "processing,",
                "we",
                "have",
                "designed",
                "a",
                "highly",
                "parallel",
                "machine",
                "called",
                "Semantic",
                "Network",
                "Array",
                "Processor",
                "(SNAP)",
                "[Moldovan",
                "and",
                "#REF",
                "[",
                "#TARGET_REF",
                ",",
                "and",
                "implemented",
                "an",
                "experimental",
                "machine",
                "translation",
                "system",
                "*This",
                "research",
                "is",
                "funded",
                "by",
                "the",
                "National",
                "Science",
                "Foundation",
                "Grant",
                "No.",
                ".",
                "A",
                "version",
                "of",
                "this",
                "paper",
                "will",
                "appear",
                "in",
                "the",
                "International",
                "Joint",
                "Conference",
                "on",
                "Artificial",
                "Intelligence",
                "(IJCAI-91)."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In order to accomplish the high-performance natural language processing, we have designed a highly parallel machine called Semantic Network Array Processor (SNAP) [Moldovan and #REF [ #TARGET_REF , and implemented an experimental machine translation system *This research is funded by the National Science Foundation Grant No. . A version of this paper will appear in the International Joint Conference on Artificial Intelligence (IJCAI-91).",
        "output": "{\"INFORMATION\": [\"Semantic Network Array Processor (SNAP) [Moldovan and #REF [ #TARGET_REF ,\"], \"PERCEPTION\": [\"In order to accomplish the high-performance natural language processing, we have designed a highly parallel machine called\", \"and implemented an experimental machine translation system\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "FrALBERT",
                "Crawl",
                "projects",
                "such",
                "as",
                "OSCAR",
                "#REF",
                "or",
                "CCNet",
                "#TARGET_REF",
                "corpora,",
                "and",
                "because",
                "we",
                "focus",
                "on",
                "factual",
                "QA,",
                "we",
                "decide",
                "to",
                "use",
                "only",
                "Wikipedia",
                "as",
                "our",
                "primary",
                "source",
                "of",
                "knowledge.",
                "We",
                "used",
                "the",
                "same",
                "learning",
                "configuration",
                "as",
                "the",
                "original",
                "model",
                "with",
                "a",
                "batch",
                "size",
                "of",
                "128",
                "and",
                "a",
                "initial",
                "learning",
                "rate",
                "set",
                "to",
                "3.125",
                "×",
                "10",
                "-4",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "FrALBERT Crawl projects such as OSCAR #REF or CCNet #TARGET_REF corpora, and because we focus on factual QA, we decide to use only Wikipedia as our primary source of knowledge. We used the same learning configuration as the original model with a batch size of 128 and a initial learning rate set to 3.125 × 10 -4 .",
        "output": "{\"INFORMATION\": [\"FrALBERT Crawl projects such as\", \"or CCNet #TARGET_REF corpora,\"], \"PERCEPTION\": [\"and because we focus on factual QA, we decide to use only Wikipedia as our primary source of knowledge.\"], \"BACKGROUND\": [\"OSCAR #REF\", \"We used the same learning configuration as the original model with a batch size of 128 and a initial learning rate set to 3.125 \\u00d7 10 -4 .\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "parse",
                "this",
                "type",
                "of",
                "grammars,",
                "tabulation",
                "techniques",
                "with",
                "polynomial",
                "complexity",
                "can",
                "be",
                "designed",
                "based",
                "on",
                "a",
                "property",
                "defined",
                "in",
                "#TARGET_REF",
                ",",
                "that",
                "we",
                "call",
                "context-freeness",
                "property",
                "of",
                "LIG,",
                "establishing",
                "that",
                "ifA[,]",
                "⇒",
                "uB[",
                "]w",
                "where",
                "u,",
                "w",
                "E",
                "v,",
                ",",
                "A,",
                "B",
                "E",
                "VN",
                ",",
                ",",
                "E",
                "Vi",
                "U",
                "{€}",
                "and",
                "B[]",
                "is",
                "a",
                "dependent",
                "descendant",
                "of",
                "A[,],",
                "then",
                "for",
                "each",
                "Yi,",
                "Y2",
                "E_",
                "(VN[Vt]",
                "U",
                "VT",
                ")*and",
                "/3",
                "E",
                "V/",
                "we",
                "have",
                "Y1",
                "A[/3,]Y2",
                "⇒",
                "Y1uB[,B]wY2.",
                "Also,",
                "if",
                "B[,]",
                "is",
                "a",
                "dependent",
                "descendant",
                "of",
                "A[",
                "]",
                "and",
                "A[",
                "]",
                "⇒",
                "uB[,]w",
                "then",
                "Y",
                "1",
                "A[/3]Y",
                "2",
                "⇒",
                "Y",
                "1",
                "uB",
                "[/3,]wY",
                "2."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To parse this type of grammars, tabulation techniques with polynomial complexity can be designed based on a property defined in #TARGET_REF , that we call context-freeness property of LIG, establishing that ifA[,] ⇒ uB[ ]w where u, w E v, , A, B E VN , , E Vi U {€} and B[] is a dependent descendant of A[,], then for each Yi, Y2 E_ (VN[Vt] U VT )*and /3 E V/ we have Y1 A[/3,]Y2 ⇒ Y1uB[,B]wY2. Also, if B[,] is a dependent descendant of A[ ] and A[ ] ⇒ uB[,]w then Y 1 A[/3]Y 2 ⇒ Y 1 uB [/3,]wY 2.",
        "output": "{\"INFORMATION\": [\"a property defined in #TARGET_REF ,\"], \"PERCEPTION\": [\"To parse this type of grammars, tabulation techniques with polynomial complexity can be designed based on\", \"that we call context-freeness property of LIG,\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Gender-Coded",
                "Word",
                "Prevalence",
                "This",
                "method",
                "#TARGET_REF",
                ")",
                "is",
                "operationalised",
                "through",
                "a",
                "set",
                "of",
                "masculine-and",
                "feminine-themed",
                "words",
                "in",
                "the",
                "context",
                "of",
                "job",
                "ads.",
                "\"Adventurous\"",
                "and",
                "\"stubborn\"",
                "are",
                "coded",
                "as",
                "masculine",
                "words",
                "while",
                "\"affectionate\"",
                "and",
                "\"kind\"",
                "are",
                "coded",
                "as",
                "feminine",
                "words.",
                "This",
                "research",
                "provides",
                "us",
                "with",
                "42",
                "masculine",
                "and",
                "40",
                "feminine",
                "words,",
                "with",
                "a",
                "wider",
                "set",
                "of",
                "potential",
                "words",
                "permeating",
                "from",
                "these",
                "(i.e.",
                "\"Compet*\"",
                "which",
                "may",
                "manifest",
                "itself",
                "as",
                "competitive,",
                "competition",
                "and",
                "so",
                "on).",
                "Our",
                "measure",
                "counts",
                "the",
                "prevalence",
                "of",
                "these",
                "words",
                "in",
                "a",
                "given",
                "text.",
                "The",
                "calculation",
                "is:"
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3
            ]
        },
        "input": "Gender-Coded Word Prevalence This method #TARGET_REF ) is operationalised through a set of masculine-and feminine-themed words in the context of job ads. \"Adventurous\" and \"stubborn\" are coded as masculine words while \"affectionate\" and \"kind\" are coded as feminine words. This research provides us with 42 masculine and 40 feminine words, with a wider set of potential words permeating from these (i.e. \"Compet*\" which may manifest itself as competitive, competition and so on). Our measure counts the prevalence of these words in a given text. The calculation is:",
        "output": "{\"INFORMATION\": [\"Gender-Coded Word Prevalence This method #TARGET_REF ) is operationalised through a set of masculine-and feminine-themed words in the context of job ads.\", \"This research provides us with 42 masculine and 40 feminine words, with a wider set of potential words permeating from these\"], \"PERCEPTION\": [\"Our measure counts the prevalence of these words in a given text.\"], \"BACKGROUND\": [\"\\\"Adventurous\\\" and \\\"stubborn\\\" are coded as masculine words while \\\"affectionate\\\" and \\\"kind\\\" are coded as feminine words.\", \"\\\"Compet*\\\" which may manifest itself as competitive, competition and so on).\", \"The calculation is:\"]}"
    },
    {
        "gold": {
            "text": [
                "By",
                "conducting",
                "a",
                "joint",
                "model",
                "for",
                "the",
                "two",
                "tasks,",
                "a",
                "synergistic",
                "effect",
                "can",
                "be",
                "achieved",
                "#REF",
                "2019b).",
                "To",
                "build",
                "multi-turn",
                "dialogue",
                "datasets,",
                "most",
                "studies",
                "have",
                "recruited",
                "workers",
                "via",
                "crowd-sourcing",
                "to",
                "collect",
                "task-oriented",
                "dialogues",
                "across",
                "different",
                "domains",
                "(e.g.",
                "in-car",
                "assistant",
                "#REF",
                ",",
                "navigation",
                "and",
                "events",
                "#REF",
                ",",
                "multidomains",
                "#TARGET_REF",
                ",",
                "personal",
                "notifications",
                "#REF",
                ").",
                "Recently,",
                "deep",
                "learning",
                "models",
                "have",
                "also",
                "been",
                "extensively",
                "studied",
                "in",
                "order",
                "to",
                "capture",
                "the",
                "contextual",
                "signals",
                "from",
                "multiple",
                "sequential",
                "inputs.",
                "(e.g.",
                "BiLSTM",
                "with",
                "attention",
                "#REF",
                ",",
                "GRU",
                "with",
                "self-attention",
                "and",
                "context-fusion",
                "#REF",
                ".",
                "The",
                "models",
                "listed",
                "all",
                "show",
                "an",
                "increase",
                "in",
                "semantic",
                "detection",
                "performance",
                "when",
                "the",
                "context",
                "is",
                "included",
                "in",
                "the",
                "analysis."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "By conducting a joint model for the two tasks, a synergistic effect can be achieved #REF 2019b). To build multi-turn dialogue datasets, most studies have recruited workers via crowd-sourcing to collect task-oriented dialogues across different domains (e.g. in-car assistant #REF , navigation and events #REF , multidomains #TARGET_REF , personal notifications #REF ). Recently, deep learning models have also been extensively studied in order to capture the contextual signals from multiple sequential inputs. (e.g. BiLSTM with attention #REF , GRU with self-attention and context-fusion #REF . The models listed all show an increase in semantic detection performance when the context is included in the analysis.",
        "output": "{\"INFORMATION\": [\"multidomains #TARGET_REF ,\"], \"PERCEPTION\": [\"To build multi-turn dialogue datasets, most studies have recruited workers via crowd-sourcing to collect task-oriented dialogues across different domains\"], \"BACKGROUND\": [\"in-car assistant #REF , navigation and events #REF ,\", \"personal notifications #REF ).\"]}"
    },
    {
        "gold": {
            "text": [
                "Hierarchical",
                "rules",
                "are",
                "extracted",
                "from",
                "the",
                "training",
                "corpus",
                "by",
                "subtracting",
                "continuous",
                "phrase-pairs",
                "attested",
                "in",
                "the",
                "translation",
                "table",
                "recursively",
                "from",
                "longer",
                "phrases",
                "and",
                "replacing",
                "them",
                "with",
                "the",
                "non-terminal",
                "symbol",
                "X.",
                "Non-terminals",
                "in",
                "hierarchical",
                "rules",
                "act",
                "as",
                "placeholders",
                "that",
                "are",
                "replaced",
                "with",
                "other",
                "phrases",
                "during",
                "translation",
                "in",
                "a",
                "bottom-up",
                "fashion.",
                "Hierarchical",
                "rules",
                "are",
                "extracted",
                "from",
                "the",
                "training",
                "corpus",
                "without",
                "using",
                "any",
                "syntactic",
                "information.",
                "As",
                "the",
                "resulting",
                "system",
                "is",
                "syntactically",
                "unaware,",
                "the",
                "HPB",
                "SMT",
                "system",
                "can",
                "produce",
                "ungrammatical",
                "translations.",
                "Therefore,",
                "several",
                "approaches",
                "have",
                "tried",
                "to",
                "provide",
                "the",
                "HPB",
                "SMT",
                "system",
                "with",
                "syntactic",
                "information.",
                "Syntax",
                "augmented",
                "Machine",
                "Translation",
                "(SAMT)",
                "#TARGET_REF",
                "uses",
                "target-side",
                "phrase-structure",
                "grammar",
                "syntactic",
                "trees",
                "to",
                "label",
                "non-terminals",
                "in",
                "hierarchical",
                "rules.",
                "These",
                "non-terminal",
                "labels",
                "represent",
                "syntactic",
                "constraints",
                "imposed",
                "on",
                "target",
                "phrase",
                "replacements",
                "during",
                "translation",
                "aiming",
                "to",
                "produce",
                "more",
                "grammatical",
                "translations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Hierarchical rules are extracted from the training corpus by subtracting continuous phrase-pairs attested in the translation table recursively from longer phrases and replacing them with the non-terminal symbol X. Non-terminals in hierarchical rules act as placeholders that are replaced with other phrases during translation in a bottom-up fashion. Hierarchical rules are extracted from the training corpus without using any syntactic information. As the resulting system is syntactically unaware, the HPB SMT system can produce ungrammatical translations. Therefore, several approaches have tried to provide the HPB SMT system with syntactic information. Syntax augmented Machine Translation (SAMT) #TARGET_REF uses target-side phrase-structure grammar syntactic trees to label non-terminals in hierarchical rules. These non-terminal labels represent syntactic constraints imposed on target phrase replacements during translation aiming to produce more grammatical translations.",
        "output": "{\"INFORMATION\": [\"Syntax augmented Machine Translation (SAMT)\"], \"PERCEPTION\": [\"uses target-side phrase-structure grammar syntactic trees to label non-terminals in hierarchical rules.\"], \"BACKGROUND\": [\"several approaches have tried to provide the HPB SMT system with syntactic information.\"]}"
    },
    {
        "gold": {
            "text": [
                "Moreover,",
                "we",
                "also",
                "compared",
                "the",
                "FNMT",
                "system",
                "to",
                "the",
                "multiway,",
                "multilingual",
                "NMT",
                "system",
                "#TARGET_REF",
                ".",
                "This",
                "method",
                "can",
                "train",
                "several",
                "encoder",
                "and",
                "decoders",
                "sharing",
                "only",
                "the",
                "attention",
                "mechanism",
                "between",
                "them.",
                "In",
                "order",
                "to",
                "reproduce",
                "our",
                "experiments",
                "using",
                "the",
                "multilingual",
                "architecture,",
                "we",
                "used",
                "one",
                "input",
                "encoder",
                "(at",
                "word-level)",
                "for",
                "English",
                "and",
                "two",
                "separate",
                "decoders",
                ":",
                "French",
                "lemmas",
                "and",
                "French",
                "factors.",
                "The",
                "final",
                "word",
                "is",
                "obtained",
                "by",
                "the",
                "factors-to-word",
                "process",
                "as",
                "used",
                "with",
                "our",
                "FNMT",
                "system.",
                "As",
                "presented",
                "in",
                "Table",
                "1,",
                "Multilingual",
                "approach",
                "performs",
                "better",
                "than",
                "all",
                "other",
                "systems",
                "at",
                "lemma",
                "and",
                "factors",
                "level.",
                "However,",
                "the",
                "performance",
                "at",
                "word",
                "level",
                "is",
                "the",
                "lowest",
                "due",
                "to",
                "the",
                "desyncronization",
                "of",
                "the",
                "two",
                "outputs",
                "which",
                "are",
                "trained",
                "independently."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Moreover, we also compared the FNMT system to the multiway, multilingual NMT system #TARGET_REF . This method can train several encoder and decoders sharing only the attention mechanism between them. In order to reproduce our experiments using the multilingual architecture, we used one input encoder (at word-level) for English and two separate decoders : French lemmas and French factors. The final word is obtained by the factors-to-word process as used with our FNMT system. As presented in Table 1, Multilingual approach performs better than all other systems at lemma and factors level. However, the performance at word level is the lowest due to the desyncronization of the two outputs which are trained independently.",
        "output": "{\"INFORMATION\": [\"the multiway, multilingual NMT system #TARGET_REF .\"], \"PERCEPTION\": [\"we also compared the FNMT system to\", \"This method can train several encoder and decoders sharing only the attention mechanism between them.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Each",
                "language",
                "part",
                "of",
                "the",
                "bilingual",
                "word",
                "list",
                "was",
                "treated",
                "independently",
                "using",
                "the",
                "same",
                "method,",
                "but",
                "obviously",
                "different",
                "corpus.",
                "Each",
                "word",
                "from",
                "bilingual",
                "word",
                "list",
                "was",
                "stemmed",
                "using",
                "a",
                "modified",
                "version",
                "of",
                "#TARGET_REF",
                "algorithm",
                "that",
                "takes",
                "into",
                "consideration",
                "only",
                "extensions",
                "that",
                "were",
                "present",
                "in",
                "paradigms.",
                "This",
                "means",
                "that",
                "each",
                "word",
                "is",
                "shortened",
                "of",
                "the",
                "longest",
                "possible",
                "extension",
                "producing",
                "word's",
                "stem.",
                "All",
                "extensions",
                "are",
                "attached",
                "to",
                "the",
                "stem",
                "producing",
                "a",
                "multiset",
                "of",
                "words.",
                "This",
                "multiset",
                "is",
                "searched",
                "in",
                "monolingual",
                "referential",
                "corpus,",
                "in",
                "our",
                "case",
                "#REF",
                ",",
                "all",
                "words",
                "that",
                "are",
                "found",
                "in",
                "corpus",
                "present",
                "a",
                "list",
                "of",
                "possible",
                "extensions,",
                "thus",
                "reducing",
                "the",
                "number",
                "of",
                "all",
                "extensions",
                "to",
                "a",
                "moderate",
                "number."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Each language part of the bilingual word list was treated independently using the same method, but obviously different corpus. Each word from bilingual word list was stemmed using a modified version of #TARGET_REF algorithm that takes into consideration only extensions that were present in paradigms. This means that each word is shortened of the longest possible extension producing word's stem. All extensions are attached to the stem producing a multiset of words. This multiset is searched in monolingual referential corpus, in our case #REF , all words that are found in corpus present a list of possible extensions, thus reducing the number of all extensions to a moderate number.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF algorithm that takes into consideration only extensions that were present in paradigms.\"], \"PERCEPTION\": [\"Each word from bilingual word list was stemmed using a modified version of\", \"This means that each word is shortened of the longest possible extension producing word's stem. All extensions are attached to the stem producing a multiset of words.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "argumentation",
                "theory,",
                "Walton's",
                "argumentation",
                "schemes",
                "specify",
                "common",
                "reasoning",
                "patterns",
                "used",
                "in",
                "arguments",
                "#TARGET_REF",
                ".",
                "We",
                "focus",
                "on",
                "two",
                "schemes",
                "related",
                "to",
                "normative",
                "arguments,",
                "whose",
                "claims",
                "suggest",
                "that",
                "an",
                "action",
                "or",
                "situation",
                "be",
                "brought",
                "about.",
                "Normative",
                "claims",
                "are",
                "one",
                "of",
                "the",
                "most",
                "common",
                "proposition",
                "types",
                "in",
                "argumentation",
                "#REF",
                "and",
                "have",
                "received",
                "much",
                "attention",
                "in",
                "the",
                "literature",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0
            ]
        },
        "input": "In argumentation theory, Walton's argumentation schemes specify common reasoning patterns used in arguments #TARGET_REF . We focus on two schemes related to normative arguments, whose claims suggest that an action or situation be brought about. Normative claims are one of the most common proposition types in argumentation #REF and have received much attention in the literature #REF .",
        "output": "{\"INFORMATION\": [\"used in arguments #TARGET_REF .\"], \"PERCEPTION\": [\"Walton's argumentation schemes specify common reasoning patterns\", \"We focus on two schemes related to normative arguments,\"], \"BACKGROUND\": [\"whose claims suggest that an action or situation be brought about. Normative claims are one of the most common proposition types in argumentation #REF and have received much attention in the literature #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "we",
                "have",
                "a",
                "single",
                "multiclass",
                "head",
                "that",
                "outputs",
                "the",
                "connecting",
                "preposition",
                "or",
                "NONE,",
                "in",
                "case",
                "the",
                "NPs",
                "are",
                "not",
                "connected.",
                "We",
                "also",
                "experiment",
                "with",
                "a",
                "frozen",
                "(or",
                "''probing'')",
                "variant",
                "of",
                "both",
                "models,",
                "in",
                "which",
                "we",
                "keep",
                "the",
                "MLM",
                "frozen,",
                "and",
                "update",
                "only",
                "the",
                "NP",
                "encoding",
                "and",
                "prediction",
                "heads.",
                "The",
                "frozen",
                "architecture",
                "is",
                "intended",
                "to",
                "quantify",
                "the",
                "degree",
                "to",
                "which",
                "the",
                "pretrained",
                "MLM",
                "encodes",
                "the",
                "relevant",
                "information,",
                "and",
                "it",
                "is",
                "very",
                "similar",
                "to",
                "the",
                "edge-probing",
                "architecture",
                "of",
                "#TARGET_REF",
                ".",
                "Finally,",
                "the",
                "static",
                "variant",
                "aims",
                "to",
                "measure",
                "how",
                "well",
                "a",
                "model",
                "can",
                "perform",
                "with",
                "NPs",
                "alone,",
                "without",
                "considering",
                "their",
                "context.",
                "This",
                "model",
                "sums",
                "all",
                "the",
                "static",
                "embeddings",
                "of",
                "each",
                "span",
                "and",
                "uses",
                "the",
                "same",
                "modeling",
                "as",
                "the",
                "coupled",
                "prediction.",
                "This",
                "baseline",
                "uses",
                "the",
                "300-dim",
                "word2vec",
                "non-contextualized",
                "embeddings",
                "#REF",
                ".",
                "We",
                "experiment",
                "with",
                "two",
                "versions:",
                "decoupled",
                "and",
                "coupled."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "we have a single multiclass head that outputs the connecting preposition or NONE, in case the NPs are not connected. We also experiment with a frozen (or ''probing'') variant of both models, in which we keep the MLM frozen, and update only the NP encoding and prediction heads. The frozen architecture is intended to quantify the degree to which the pretrained MLM encodes the relevant information, and it is very similar to the edge-probing architecture of #TARGET_REF . Finally, the static variant aims to measure how well a model can perform with NPs alone, without considering their context. This model sums all the static embeddings of each span and uses the same modeling as the coupled prediction. This baseline uses the 300-dim word2vec non-contextualized embeddings #REF . We experiment with two versions: decoupled and coupled.",
        "output": "{\"INFORMATION\": [\"the edge-probing architecture of #TARGET_REF .\"], \"PERCEPTION\": [\"We also experiment with a frozen (or ''probing'') variant of both models, in which we keep the MLM frozen, and update only the NP encoding and prediction heads.\"], \"BACKGROUND\": [\"The frozen architecture is intended to quantify the degree to which the pretrained MLM encodes the relevant information, and it is very similar to\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "candidate",
                "quality",
                "measure",
                "M",
                "can",
                "be",
                "defined",
                "in",
                "many",
                "ways.",
                "In",
                "this",
                "work",
                "we",
                "define",
                "it",
                "as",
                "the",
                "ROUGE",
                "#TARGET_REF",
                ")",
                "score",
                "of",
                "a",
                "candidate",
                "summary",
                "S",
                "i",
                "given",
                "the",
                "reference",
                "summary",
                "S",
                "*",
                ".",
                "To",
                "coordinate",
                "a",
                "pre-trained",
                "abstractive",
                "model,",
                "we",
                "1)",
                "use",
                "it",
                "to",
                "generate",
                "different",
                "candidate",
                "summaries",
                "with",
                "various",
                "levels",
                "of",
                "quality,",
                "2",
                "then",
                "2)",
                "encourage",
                "the",
                "model",
                "to",
                "assign",
                "higher",
                "estimated",
                "probabilities",
                "to",
                "better",
                "candidates",
                "by",
                "fine-tuning",
                "the",
                "model",
                "with",
                "a",
                "contrastive",
                "loss,",
                "following",
                "the",
                "previous",
                "work",
                "#REF",
                ":"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The candidate quality measure M can be defined in many ways. In this work we define it as the ROUGE #TARGET_REF ) score of a candidate summary S i given the reference summary S * . To coordinate a pre-trained abstractive model, we 1) use it to generate different candidate summaries with various levels of quality, 2 then 2) encourage the model to assign higher estimated probabilities to better candidates by fine-tuning the model with a contrastive loss, following the previous work #REF :",
        "output": "{\"INFORMATION\": [\"the ROUGE #TARGET_REF ) score\"], \"PERCEPTION\": [\"The candidate quality measure M can be defined in many ways. In this work we define it as\", \"of a candidate summary S i given the reference summary S * .\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Incorporating",
                "external",
                "knowledge",
                "is",
                "essential",
                "for",
                "many",
                "NLG",
                "tasks",
                "to",
                "augment",
                "the",
                "limited",
                "textual",
                "information",
                "#REF",
                ".",
                "Some",
                "recent",
                "work",
                "explored",
                "using",
                "graph",
                "neural",
                "networks",
                "(GNN)",
                "to",
                "reason",
                "over",
                "multihop",
                "relational",
                "knowledge",
                "graph",
                "(KG)",
                "paths",
                "#REF",
                ".",
                "For",
                "example,",
                "#REF",
                "enriched",
                "the",
                "context",
                "representations",
                "of",
                "the",
                "input",
                "sequence",
                "with",
                "neighbouring",
                "concepts",
                "on",
                "ConceptNet",
                "using",
                "graph",
                "attention.",
                "#REF",
                "performed",
                "dynamic",
                "multi-hop",
                "reasoning",
                "on",
                "multi-relational",
                "paths",
                "extracted",
                "from",
                "the",
                "external",
                "commonsense",
                "KG.",
                "Recently,",
                "some",
                "work",
                "attempted",
                "to",
                "integrate",
                "external",
                "commonsense",
                "knowledge",
                "into",
                "generative",
                "pretrained",
                "language",
                "models",
                "#TARGET_REF",
                ".",
                "For",
                "example,",
                "#REF",
                "conducted",
                "post-training",
                "on",
                "sythetic",
                "data",
                "constructed",
                "from",
                "commonsense",
                "KG",
                "by",
                "translating",
                "triplets",
                "into",
                "natural",
                "language",
                "texts",
                "using",
                "templates.",
                "#REF",
                "wrote",
                "a",
                "comprehensive",
                "survey",
                "for",
                "more",
                "detailed",
                "comparisons",
                "of",
                "different",
                "knowledge",
                "graph",
                "enhanced",
                "NLG",
                "methods."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Incorporating external knowledge is essential for many NLG tasks to augment the limited textual information #REF . Some recent work explored using graph neural networks (GNN) to reason over multihop relational knowledge graph (KG) paths #REF . For example, #REF enriched the context representations of the input sequence with neighbouring concepts on ConceptNet using graph attention. #REF performed dynamic multi-hop reasoning on multi-relational paths extracted from the external commonsense KG. Recently, some work attempted to integrate external commonsense knowledge into generative pretrained language models #TARGET_REF . For example, #REF conducted post-training on sythetic data constructed from commonsense KG by translating triplets into natural language texts using templates. #REF wrote a comprehensive survey for more detailed comparisons of different knowledge graph enhanced NLG methods.",
        "output": "{\"INFORMATION\": [\"Recently,\", \"integrate external commonsense knowledge into generative pretrained language models #TARGET_REF .\"], \"PERCEPTION\": [\"some work attempted to\"], \"BACKGROUND\": [\"Incorporating external knowledge is essential for many NLG tasks\", \"For example, #REF conducted post-training on sythetic data constructed from commonsense KG by translating triplets into natural language texts using templates.\"]}"
    },
    {
        "gold": {
            "text": [
                "WM",
                "is",
                "a",
                "long-term,",
                "open-ended",
                "project",
                "which",
                "originated",
                "with",
                "#TARGET_REF",
                ".",
                "Subsequently",
                "it",
                "was",
                "developed",
                "at",
                "Universities",
                "in",
                "Basel,",
                "Amsterdam",
                "(Vrije",
                "Universiteit),",
                "and",
                "Lugano",
                "(SUPSI",
                "and",
                "USI),",
                "funded",
                "in",
                "part",
                "by",
                "the",
                "Swiss",
                "federal",
                "government",
                "and",
                "by",
                "private",
                "companies."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "WM is a long-term, open-ended project which originated with #TARGET_REF . Subsequently it was developed at Universities in Basel, Amsterdam (Vrije Universiteit), and Lugano (SUPSI and USI), funded in part by the Swiss federal government and by private companies.",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [\"WM is a long-term, open-ended project which originated with #TARGET_REF .\"], \"BACKGROUND\": [\"Subsequently it was developed at Universities in Basel, Amsterdam\", \"and Lugano\", \"funded in part by the Swiss federal government and by private companies.\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "parser",
                "also",
                "consistently",
                "fails",
                "to",
                "recognize",
                "generic",
                "you",
                "as",
                "opposed",
                "to",
                "deictic",
                "you",
                "(cf.",
                "Appendix,",
                "Figure",
                "8),",
                "which",
                "points",
                "to",
                "the",
                "importance",
                "of",
                "discourse",
                "context",
                "for",
                "understanding",
                "the",
                "(speaker)",
                "meaning",
                "of",
                "even",
                "a",
                "single",
                "word,",
                "and",
                "perhaps",
                "to",
                "something",
                "that",
                "all",
                "current",
                "DRS",
                "parsers",
                "lack:",
                "an",
                "explicit",
                "distinction",
                "between",
                "sentence",
                "meaning",
                "and",
                "speaker",
                "meaning",
                "(cf.",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0
            ]
        },
        "input": "Our parser also consistently fails to recognize generic you as opposed to deictic you (cf. Appendix, Figure 8), which points to the importance of discourse context for understanding the (speaker) meaning of even a single word, and perhaps to something that all current DRS parsers lack: an explicit distinction between sentence meaning and speaker meaning (cf. #TARGET_REF .",
        "output": "{\"INFORMATION\": [], \"PERCEPTION\": [\"Our parser also consistently fails to recognize generic you as opposed to deictic you\", \"which points to\", \"to something that all current DRS parsers lack: an explicit distinction between sentence meaning and speaker meaning (cf. #TARGET_REF\"], \"BACKGROUND\": [\"(cf. Appendix, Figure 8),\", \"the importance of discourse context for understanding the (speaker) meaning of even a single word, and\"]}"
    },
    {
        "gold": {
            "text": [
                "MMB",
                "was",
                "much",
                "associated",
                "with",
                "the",
                "use",
                "of",
                "interlinguas",
                "for",
                "MT",
                "(machine",
                "translation)",
                "and",
                "for",
                "meaning",
                "representation",
                "#REF",
                ",",
                "and",
                "her",
                "reply",
                "to",
                "Bar-Hillel's",
                "criticism",
                "of",
                "their",
                "use",
                "has",
                "been",
                "much",
                "quoted.",
                "The",
                "notion",
                "of",
                "a",
                "uniform",
                "and",
                "universal",
                "meaning",
                "representation",
                "for",
                "translating",
                "between",
                "languages",
                "has",
                "continued",
                "to",
                "be",
                "a",
                "strategy",
                "within",
                "the",
                "field:",
                "it",
                "had",
                "a",
                "significant",
                "role",
                "in",
                "AI",
                "(artificial",
                "intelligence)",
                "systems",
                "such",
                "as",
                "conceptual",
                "dependency",
                "#TARGET_REF",
                "and",
                "preference",
                "semantics",
                "#REF",
                ",",
                "and",
                "is",
                "now",
                "to",
                "be",
                "found",
                "in",
                "recent",
                "attempts",
                "to",
                "use",
                "Esperanto",
                "as",
                "an",
                "interlingua",
                "for",
                "MT."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "MMB was much associated with the use of interlinguas for MT (machine translation) and for meaning representation #REF , and her reply to Bar-Hillel's criticism of their use has been much quoted. The notion of a uniform and universal meaning representation for translating between languages has continued to be a strategy within the field: it had a significant role in AI (artificial intelligence) systems such as conceptual dependency #TARGET_REF and preference semantics #REF , and is now to be found in recent attempts to use Esperanto as an interlingua for MT.",
        "output": "{\"INFORMATION\": [\"conceptual dependency #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"The notion of a uniform and universal meaning representation for translating between languages has continued to be a strategy within the field: it had a significant role in AI (artificial intelligence) systems such as\", \"and preference semantics #REF , and is now to be found in recent attempts to use Esperanto as an interlingua for MT.\"]}"
    },
    {
        "gold": {
            "text": [
                "Quoref",
                "#TARGET_REF",
                "is",
                "a",
                "dataset",
                "that",
                "is",
                "particularly",
                "designed",
                "for",
                "evaluating",
                "coreference",
                "understanding",
                "of",
                "MRC",
                "models.",
                "Figure",
                "1",
                "shows",
                "a",
                "QA",
                "sample",
                "from",
                "Quoref",
                "in",
                "which",
                "the",
                "model",
                "needs",
                "to",
                "resolve",
                "the",
                "coreference",
                "relation",
                "between",
                "\"his\"",
                "and",
                "\"John",
                "Motteux\"",
                "to",
                "answer",
                "the",
                "question.",
                "Recent",
                "large",
                "pre-trained",
                "language",
                "models",
                "reached",
                "high",
                "performance",
                "on",
                "Quoref.",
                "However,",
                "our",
                "results",
                "and",
                "analyses",
                "suggest",
                "that",
                "this",
                "dataset",
                "contains",
                "artifacts",
                "and",
                "does",
                "not",
                "reflect",
                "the",
                "natural",
                "distribution",
                "and,",
                "therefore,",
                "the",
                "challenges",
                "of",
                "coreference",
                "reasoning.",
                "As",
                "a",
                "result,",
                "high",
                "performances",
                "on",
                "Quoref",
                "do",
                "not",
                "necessarily",
                "reflect",
                "the",
                "coreference",
                "reasoning",
                "capabilities",
                "of",
                "the",
                "examined",
                "models",
                "and",
                "answering",
                "questions",
                "that",
                "require",
                "coreference",
                "reasoning",
                "might",
                "be",
                "a",
                "greater",
                "challenge",
                "than",
                "current",
                "scores",
                "suggest."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Quoref #TARGET_REF is a dataset that is particularly designed for evaluating coreference understanding of MRC models. Figure 1 shows a QA sample from Quoref in which the model needs to resolve the coreference relation between \"his\" and \"John Motteux\" to answer the question. Recent large pre-trained language models reached high performance on Quoref. However, our results and analyses suggest that this dataset contains artifacts and does not reflect the natural distribution and, therefore, the challenges of coreference reasoning. As a result, high performances on Quoref do not necessarily reflect the coreference reasoning capabilities of the examined models and answering questions that require coreference reasoning might be a greater challenge than current scores suggest.",
        "output": "{\"INFORMATION\": [\"Quoref #TARGET_REF is a dataset that is particularly designed for evaluating coreference understanding of MRC models.\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Figure 1 shows a QA sample from Quoref\"]}"
    },
    {
        "gold": {
            "text": [
                "By",
                "contrast,",
                "engineering",
                "applications",
                "mainly",
                "aim",
                "to",
                "maximise",
                "performance",
                "accuracy,",
                "utilising",
                "all",
                "available",
                "information",
                "and",
                "more",
                "powerful",
                "nonlinear",
                "classifiers.",
                "Intriguingly,",
                "recent",
                "studies",
                "have",
                "shown",
                "that",
                "adding",
                "human",
                "eye",
                "tracking",
                "data",
                "#TARGET_REF",
                "or",
                "morphosyntactic",
                "information",
                "extracted",
                "from",
                "human",
                "functional",
                "magnetic",
                "resonance",
                "imaging",
                "(fMRI)",
                "signals",
                "during",
                "sentence",
                "reading,",
                "can",
                "substantially",
                "improve",
                "PoS",
                "induction",
                "#REF",
                ").",
                "Yet,",
                "morphosynactic",
                "information",
                "obtained",
                "from",
                "fMRI",
                "is",
                "limited,",
                "because",
                "fMRI",
                "measures",
                "only",
                "the",
                "slow",
                "changes",
                "in",
                "blood",
                "oxygenation,",
                "peaking",
                "5-6",
                "s",
                "after",
                "stimulus",
                "onset,",
                "rather",
                "than",
                "the",
                "rapid",
                "neural",
                "activity",
                "during",
                "language",
                "processing."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "By contrast, engineering applications mainly aim to maximise performance accuracy, utilising all available information and more powerful nonlinear classifiers. Intriguingly, recent studies have shown that adding human eye tracking data #TARGET_REF or morphosyntactic information extracted from human functional magnetic resonance imaging (fMRI) signals during sentence reading, can substantially improve PoS induction #REF ). Yet, morphosynactic information obtained from fMRI is limited, because fMRI measures only the slow changes in blood oxygenation, peaking 5-6 s after stimulus onset, rather than the rapid neural activity during language processing.",
        "output": "{\"INFORMATION\": [\"recent studies have shown that adding human eye tracking data #TARGET_REF\", \"during sentence reading, can substantially improve PoS induction #REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"or morphosyntactic information extracted from human functional magnetic resonance imaging (fMRI) signals\"]}"
    },
    {
        "gold": {
            "text": [
                "Toxic",
                "comments,",
                "posts,",
                "and",
                "other",
                "types",
                "of",
                "content",
                "became",
                "more",
                "common",
                "in",
                "social",
                "media",
                "nowadays.",
                "They",
                "contain",
                "forms",
                "of",
                "non-acceptable",
                "language",
                "(profanity),",
                "which",
                "may",
                "be",
                "concealed",
                "or",
                "explicit,",
                "including",
                "insults",
                "and",
                "threats",
                "directed",
                "to",
                "a",
                "group",
                "or",
                "individual",
                "#TARGET_REF",
                ".",
                "These",
                "comments",
                "spread",
                "rapidly",
                "on",
                "the",
                "internet,",
                "especially",
                "on",
                "social",
                "networks",
                "where",
                "they",
                "find",
                "acceptance,",
                "and",
                "may",
                "culminate",
                "in",
                "several",
                "threats",
                "to",
                "individuals,",
                "becoming",
                "a",
                "serious",
                "concern",
                "for",
                "government",
                "organizations,",
                "online",
                "communities,",
                "and",
                "social",
                "media",
                "platforms."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Toxic comments, posts, and other types of content became more common in social media nowadays. They contain forms of non-acceptable language (profanity), which may be concealed or explicit, including insults and threats directed to a group or individual #TARGET_REF . These comments spread rapidly on the internet, especially on social networks where they find acceptance, and may culminate in several threats to individuals, becoming a serious concern for government organizations, online communities, and social media platforms.",
        "output": "{\"INFORMATION\": [\"insults and threats directed to a group or individual #TARGET_REF .\"], \"PERCEPTION\": [\"These comments spread rapidly on the internet, especially on social networks where they find acceptance, and may culminate in several threats to individuals, becoming a serious concern for government organizations, online communities, and social media platforms.\"], \"BACKGROUND\": [\"Toxic comments, posts, and other types of content became more common in social media nowadays. They contain forms of non-acceptable language (profanity), which may be concealed or explicit, including\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "related",
                "area",
                "of",
                "LCP",
                "is",
                "CWI.",
                "Early",
                "studies",
                "on",
                "CWI",
                "either",
                "attempt",
                "to",
                "simplify",
                "all",
                "words",
                "#TARGET_REF",
                "or",
                "set",
                "a",
                "frequency-based",
                "threshold",
                "#REF",
                ".",
                "#REF",
                "indicates",
                "that",
                "a",
                "classification-based",
                "method",
                "to",
                "CWI",
                "is",
                "the",
                "most",
                "promising",
                "one.",
                "Most",
                "of",
                "the",
                "teams",
                "participating",
                "in",
                "two",
                "CWI",
                "shared",
                "tasks",
                "also",
                "use",
                "classification",
                "approaches",
                "with",
                "extensive",
                "feature",
                "engineering."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A related area of LCP is CWI. Early studies on CWI either attempt to simplify all words #TARGET_REF or set a frequency-based threshold #REF . #REF indicates that a classification-based method to CWI is the most promising one. Most of the teams participating in two CWI shared tasks also use classification approaches with extensive feature engineering.",
        "output": "{\"INFORMATION\": [\"attempt to simplify all words #TARGET_REF\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"Early studies on CWI either\", \"or set a frequency-based threshold #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "the",
                "standard",
                "ROUGE",
                "#TARGET_REF",
                ")",
                "Perl",
                "package",
                "15",
                "for",
                "evaluation.",
                "The",
                "command",
                "line",
                "parameters",
                "are",
                "'-c",
                "95",
                "-r",
                "1000",
                "-n",
                "2",
                "-m'.",
                "Before",
                "the",
                "Datasets",
                "λ",
                "(Eq.",
                "8)",
                "α",
                "(Eq.",
                "9)",
                "γ",
                "(Eq.",
                "10)",
                "CNNDM",
                "0.001",
                "2.0",
                "100",
                "XSum",
                "0.1",
                "0.6",
                "100",
                "NYT",
                "0.001",
                "2.0",
                "100"
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use the standard ROUGE #TARGET_REF ) Perl package 15 for evaluation. The command line parameters are '-c 95 -r 1000 -n 2 -m'. Before the Datasets λ (Eq. 8) α (Eq. 9) γ (Eq. 10) CNNDM 0.001 2.0 100 XSum 0.1 0.6 100 NYT 0.001 2.0 100",
        "output": "{\"INFORMATION\": [\"ROUGE #TARGET_REF ) Perl package 15\"], \"PERCEPTION\": [\"We use the standard\", \"for evaluation.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "R-1/2/L",
                "are",
                "the",
                "ROUGE-1/2/L",
                "F1",
                "scores.",
                "Coefficients",
                "of",
                "the",
                "Multi-Task",
                "Loss",
                "The",
                "multitask",
                "loss",
                "(Eq.",
                "10)",
                "used",
                "to",
                "train",
                "our",
                "model",
                "contains",
                "two",
                "parts:",
                "the",
                "cross-entropy",
                "loss",
                "and",
                "the",
                "contastive",
                "loss.",
                "As",
                "shown",
                "in",
                "Tab.",
                "3,",
                "as",
                "the",
                "weight",
                "of",
                "the",
                "contrastive",
                "loss",
                "(γ)",
                "increases,",
                "the",
                "model's",
                "performance",
                "improves.",
                "However,",
                "the",
                "cross-entropy",
                "loss",
                "is",
                "still",
                "necessary",
                "to",
                "preserve",
                "the",
                "model's",
                "ability",
                "as",
                "a",
                "generation",
                "model.",
                "We",
                "argue",
                "that",
                "this",
                "is",
                "because",
                "the",
                "token",
                "level",
                "accuracy",
                "is",
                "still",
                "important",
                "during",
                "the",
                "autoregressive",
                "generation",
                "process,",
                "where",
                "the",
                "individual",
                "tokens",
                "are",
                "predicted",
                "sequentially.",
                "In",
                "addition,",
                "we",
                "also",
                "found",
                "that",
                "the",
                "model",
                "tends",
                "to",
                "achieve",
                "the",
                "best",
                "performance",
                "(w.r.t",
                "the",
                "ROUGE",
                "scores",
                "on",
                "the",
                "development",
                "set)",
                "faster",
                "with",
                "a",
                "higher",
                "γ.",
                "Specifically,",
                "it",
                "requires",
                "less",
                "than",
                "one",
                "entire",
                "epoch",
                "to",
                "achieve",
                "the",
                "best",
                "performance",
                "on",
                "CNNDM,",
                "making",
                "our",
                "approach",
                "an",
                "efficient",
                "fine-tuning",
                "method.Coefficient",
                "(γ)",
                "R-1",
                "R-2",
                "R-L",
                "0",
                "(Generation-Finetuning",
                "as",
                "a",
                "Loop",
                "Since",
                "the",
                "fine-tuned",
                "model",
                "(BRIO-Mul)",
                "is",
                "still",
                "able",
                "to",
                "gen-",
                "erate,",
                "we",
                "can",
                "use",
                "it",
                "to",
                "generate",
                "a",
                "new",
                "set",
                "of",
                "candidates",
                "in",
                "the",
                "same",
                "way",
                "as",
                "we",
                "used",
                "the",
                "pre-trained",
                "BART",
                "model,",
                "and",
                "continue",
                "fine-tuning",
                "it",
                "on",
                "this",
                "newly",
                "created",
                "set",
                "of",
                "candidates",
                "#TARGET_REF",
                ".",
                "Fig.",
                "2",
                "illustrates",
                "this",
                "iterative",
                "process.",
                "The",
                "results",
                "shown",
                "in",
                "Tab.",
                "4",
                "illustrate",
                "that",
                "this",
                "new",
                "model",
                "(BRIO-Loop)",
                "outperforms",
                "BRIO-Mul.",
                "Besides,",
                "the",
                "model",
                "reached",
                "the",
                "best",
                "performance",
                "very",
                "quickly,",
                "showing",
                "the",
                "potential",
                "of",
                "adopting",
                "our",
                "method",
                "in",
                "an",
                "online",
                "framework",
                "where",
                "the",
                "new",
                "candidates",
                "are",
                "dynamically",
                "generated",
                "from",
                "the",
                "current",
                "model.",
                "We",
                "leave",
                "this",
                "direction",
                "for",
                "future",
                "work."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "R-1/2/L are the ROUGE-1/2/L F1 scores. Coefficients of the Multi-Task Loss The multitask loss (Eq. 10) used to train our model contains two parts: the cross-entropy loss and the contastive loss. As shown in Tab. 3, as the weight of the contrastive loss (γ) increases, the model's performance improves. However, the cross-entropy loss is still necessary to preserve the model's ability as a generation model. We argue that this is because the token level accuracy is still important during the autoregressive generation process, where the individual tokens are predicted sequentially. In addition, we also found that the model tends to achieve the best performance (w.r.t the ROUGE scores on the development set) faster with a higher γ. Specifically, it requires less than one entire epoch to achieve the best performance on CNNDM, making our approach an efficient fine-tuning method.Coefficient (γ) R-1 R-2 R-L 0 (Generation-Finetuning as a Loop Since the fine-tuned model (BRIO-Mul) is still able to gen- erate, we can use it to generate a new set of candidates in the same way as we used the pre-trained BART model, and continue fine-tuning it on this newly created set of candidates #TARGET_REF . Fig. 2 illustrates this iterative process. The results shown in Tab. 4 illustrate that this new model (BRIO-Loop) outperforms BRIO-Mul. Besides, the model reached the best performance very quickly, showing the potential of adopting our method in an online framework where the new candidates are dynamically generated from the current model. We leave this direction for future work.",
        "output": "{\"INFORMATION\": [\"Since the fine-tuned model\", \"is still able to gen- erate, we can\", \"generate a new set of candidates\", \"and continue fine-tuning it on this newly created set of candidates #TARGET_REF .\"], \"PERCEPTION\": [\"use it to\", \"in the same way as we used the pre-trained BART model,\"], \"BACKGROUND\": [\"(BRIO-Mul)\", \"Fig. 2 illustrates this iterative process.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "following",
                "are",
                "examples",
                "of",
                "the",
                "hierarchical",
                "CFG",
                "rules",
                "extracted",
                "from",
                "the",
                "Chinese-English",
                "sentence",
                "pair",
                "(Aozhou",
                "shi",
                "yu",
                "Beihan",
                "you",
                "bangjiao",
                "de",
                "shaoshu",
                "guojia",
                "zhiyi,",
                "Australia",
                "is",
                "one",
                "of",
                "the",
                "few",
                "countries",
                "that",
                "have",
                "diplomatic",
                "relations",
                "with",
                "North",
                "Korea)",
                "#TARGET_REF",
                ":"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                0
            ]
        },
        "input": "The following are examples of the hierarchical CFG rules extracted from the Chinese-English sentence pair (Aozhou shi yu Beihan you bangjiao de shaoshu guojia zhiyi, Australia is one of the few countries that have diplomatic relations with North Korea) #TARGET_REF :",
        "output": "{\"INFORMATION\": [\"the Chinese-English sentence pair\", \"#TARGET_REF\"], \"PERCEPTION\": [\"The following are examples of the hierarchical CFG rules extracted from\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "With",
                "the",
                "advent",
                "of",
                "deep",
                "learning,",
                "new",
                "automatic",
                "metrics",
                "have",
                "arisen,",
                "both",
                "in",
                "response",
                "to",
                "and",
                "making",
                "use",
                "of",
                "the",
                "technical",
                "advances",
                "brought",
                "by",
                "deep",
                "learning.",
                "In",
                "particular,",
                "metrics",
                "like",
                "COMET",
                "#TARGET_REF",
                "and",
                "BERTScore",
                "use",
                "large",
                "pre-trained",
                "language",
                "models",
                "(LLMs)",
                "to",
                "generate",
                "scores",
                "for",
                "candidate",
                "sentences.",
                "The",
                "use",
                "of",
                "these",
                "LLMs",
                "allows",
                "for",
                "metrics",
                "that",
                "take",
                "advantage",
                "of",
                "the",
                "linguistic",
                "capabilities",
                "of",
                "these",
                "LLMs,",
                "and",
                "no",
                "longer",
                "rely",
                "solely",
                "on",
                "surface-level",
                "features",
                "such",
                "as",
                "n-grams."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "With the advent of deep learning, new automatic metrics have arisen, both in response to and making use of the technical advances brought by deep learning. In particular, metrics like COMET #TARGET_REF and BERTScore use large pre-trained language models (LLMs) to generate scores for candidate sentences. The use of these LLMs allows for metrics that take advantage of the linguistic capabilities of these LLMs, and no longer rely solely on surface-level features such as n-grams.",
        "output": "{\"INFORMATION\": [\"COMET #TARGET_REF\"], \"PERCEPTION\": [\"metrics like\", \"and BERTScore use large pre-trained language models (LLMs) to generate scores for candidate sentences. The use of these LLMs allows for metrics that take advantage of the linguistic capabilities of these LLMs, and no longer rely solely on surface-level features such as n-grams.\"], \"BACKGROUND\": [\"With the advent of deep learning, new automatic metrics have arisen, both in response to and making use of the technical advances brought by deep learning.\"]}"
    },
    {
        "gold": {
            "text": [
                "Task",
                "2:",
                "Occupation",
                "classification.",
                "Following",
                "#TARGET_REF",
                ",",
                "we",
                "use",
                "the",
                "biographies",
                "#REF",
                "to",
                "predict",
                "whether",
                "the",
                "occupation",
                "is",
                "a",
                "surgeon",
                "or",
                "physician",
                "(non-surgeon).",
                "The",
                "training",
                "data",
                "consists",
                "of",
                "17,",
                "629",
                "biographies",
                "and",
                "the",
                "dev",
                "set",
                "contains",
                "2,",
                "519",
                "samples."
            ],
            "context": [
                0,
                0,
                3,
                3,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Task 2: Occupation classification. Following #TARGET_REF , we use the biographies #REF to predict whether the occupation is a surgeon or physician (non-surgeon). The training data consists of 17, 629 biographies and the dev set contains 2, 519 samples.",
        "output": "{\"INFORMATION\": [\"use the biographies #REF to predict whether the occupation is a surgeon or physician (non-surgeon).\"], \"PERCEPTION\": [\"Following #TARGET_REF , we\"], \"BACKGROUND\": [\"Occupation classification.\", \"The training data consists of 17, 629 biographies and the dev set contains 2, 519 samples.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "feature",
                "functions",
                "h",
                "i",
                "are",
                "the",
                "system",
                "models",
                "and",
                "the",
                "λ",
                "i",
                "weights",
                "are",
                "typically",
                "optimized",
                "to",
                "maximize",
                "a",
                "scoring",
                "function",
                "on",
                "a",
                "development",
                "set",
                "#TARGET_REF",
                ".",
                "In",
                "our",
                "system",
                "fourteen",
                "features",
                "functions",
                "were",
                "used,",
                "namely",
                "phrase",
                "and",
                "lexical",
                "translation",
                "probabilities",
                "in",
                "both",
                "directions,",
                "seven",
                "features",
                "for",
                "the",
                "lexicalized",
                "distortion",
                "model,",
                "a",
                "word",
                "and",
                "a",
                "phrase",
                "penalty",
                "and",
                "a",
                "target",
                "language",
                "model",
                "(LM)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The feature functions h i are the system models and the λ i weights are typically optimized to maximize a scoring function on a development set #TARGET_REF . In our system fourteen features functions were used, namely phrase and lexical translation probabilities in both directions, seven features for the lexicalized distortion model, a word and a phrase penalty and a target language model (LM).",
        "output": "{\"INFORMATION\": [\"on a development set\"], \"PERCEPTION\": [\"the \\u03bb i weights are typically optimized to maximize a scoring function\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "In-game",
                "chat",
                "has",
                "similar",
                "characteristics",
                "to",
                "multi-turn",
                "dialogue",
                "in",
                "NLU.",
                "The",
                "approaches",
                "used",
                "in",
                "multi-turn",
                "dialogue",
                "analysis",
                "have",
                "not",
                "yet",
                "been",
                "observed",
                "in",
                "toxicity",
                "datasets.",
                "In",
                "NLU,",
                "generally,",
                "intent",
                "classification",
                "(IC)",
                "is",
                "treated",
                "as",
                "a",
                "semantic",
                "utterance",
                "classification",
                "task",
                "and",
                "slot",
                "filling",
                "(SF)",
                "is",
                "treated",
                "as",
                "a",
                "sequential",
                "token",
                "labelling",
                "task",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In-game chat has similar characteristics to multi-turn dialogue in NLU. The approaches used in multi-turn dialogue analysis have not yet been observed in toxicity datasets. In NLU, generally, intent classification (IC) is treated as a semantic utterance classification task and slot filling (SF) is treated as a sequential token labelling task #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"slot filling (SF) is treated as a sequential token labelling task #TARGET_REF .\"], \"PERCEPTION\": [\"In NLU, generally,\"], \"BACKGROUND\": [\"intent classification (IC) is treated as a semantic utterance classification task and\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "first",
                "goal",
                "of",
                "this",
                "experiment",
                "is",
                "to",
                "see",
                "if",
                "the",
                "logical",
                "mechanisms",
                "improve",
                "the",
                "predictive",
                "power",
                "of",
                "a",
                "model",
                "trained",
                "without",
                "concerning",
                "them.",
                "Thus,",
                "our",
                "first",
                "baseline",
                "is",
                "BERT",
                "fine-tuned",
                "on",
                "the",
                "main",
                "task",
                "only.",
                "This",
                "method",
                "recently",
                "yielded",
                "the",
                "(near)",
                "best",
                "accuracy",
                "in",
                "argumentative",
                "relation",
                "classification",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The first goal of this experiment is to see if the logical mechanisms improve the predictive power of a model trained without concerning them. Thus, our first baseline is BERT fine-tuned on the main task only. This method recently yielded the (near) best accuracy in argumentative relation classification #TARGET_REF .",
        "output": "{\"INFORMATION\": [\"argumentative relation classification #TARGET_REF .\"], \"PERCEPTION\": [\"our first baseline is BERT fine-tuned on the main task only.\"], \"BACKGROUND\": [\"This method recently yielded the (near) best accuracy in\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "also",
                "introduced",
                "innovations",
                "in",
                "terms",
                "of",
                "scoring",
                "functions,",
                "firstly",
                "by",
                "refining",
                "the",
                "scoring",
                "function",
                "of",
                "#TARGET_REF",
                ",",
                "and",
                "secondly",
                "by",
                "using",
                "the",
                "harmonic",
                "mean",
                "of",
                "the",
                "relatedness",
                "to",
                "the",
                "clue",
                "word.",
                "This",
                "improved",
                "the",
                "performance",
                "of",
                "the",
                "best",
                "agents",
                "substantially."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We also introduced innovations in terms of scoring functions, firstly by refining the scoring function of #TARGET_REF , and secondly by using the harmonic mean of the relatedness to the clue word. This improved the performance of the best agents substantially.",
        "output": "{\"INFORMATION\": [\"scoring function of #TARGET_REF ,\"], \"PERCEPTION\": [\"We also introduced innovations in terms of scoring functions, firstly by refining the\", \"This improved the performance of the best agents substantially.\"], \"BACKGROUND\": [\"and secondly by using the harmonic mean of the relatedness to the clue word.\"]}"
    },
    {
        "gold": {
            "text": [
                "Gridach",
                "(2016)",
                "proposed",
                "a",
                "character",
                "aware",
                "neural",
                "network",
                "model",
                "using",
                "a",
                "CRF",
                "on",
                "top",
                "of",
                "a",
                "Bi-LSTM.",
                "The",
                "aim",
                "of",
                "that",
                "model",
                "was",
                "to",
                "predict",
                "the",
                "NER",
                "tags",
                "by",
                "exploiting",
                "word",
                "and",
                "character",
                "embeddings.",
                "In",
                "our",
                "approach,",
                "we",
                "follow",
                "the",
                "same",
                "architecture.",
                "First,",
                "as",
                "shown",
                "in",
                "Figure",
                "(2)",
                "we",
                "use",
                "the",
                "character",
                "model",
                "directly",
                "to",
                "individually",
                "train",
                "character",
                "embeddings.",
                "The",
                "inputs",
                "to",
                "this",
                "model",
                "are",
                "word",
                "and",
                "character",
                "input",
                "layers",
                "as",
                "indicated",
                "by",
                "arrow",
                "(A).",
                "The",
                "word",
                "embedding",
                "layer",
                "takes",
                "as",
                "input",
                "pre-trained",
                "embedding",
                "matrix",
                "developed",
                "by",
                "#TARGET_REF",
                ",",
                "transforming",
                "the",
                "word",
                "input",
                "layer",
                "into",
                "word",
                "embeddings.",
                "The",
                "character",
                "embedding",
                "layer",
                "is",
                "randomly",
                "initialized",
                "and",
                "trained",
                "by",
                "the",
                "C-Bi-LSTM.",
                "The",
                "forward",
                "and",
                "the",
                "backward",
                "output",
                "from",
                "this",
                "C-Bi-LSTM",
                "is",
                "concatenated",
                "with",
                "the",
                "output",
                "from",
                "the",
                "word",
                "embedding",
                "layer",
                "and",
                "passed",
                "to",
                "the",
                "main",
                "Bi-LSTM.",
                "The",
                "output",
                "from",
                "this",
                "is",
                "passed",
                "to",
                "a",
                "Dense",
                "layer",
                "which",
                "maps",
                "the",
                "output",
                "of",
                "the",
                "main",
                "Bi-LSTM",
                "to",
                "the",
                "CRF",
                "layer,",
                "following",
                "#REF",
                ".",
                "After",
                "training",
                "the",
                "character",
                "model,",
                "we",
                "extract",
                "the",
                "forward",
                "and",
                "the",
                "backward",
                "output",
                "of",
                "the",
                "C-Bi-LSTM",
                "and",
                "use",
                "them",
                "to",
                "initialize",
                "the",
                "character",
                "embedding",
                "layer",
                "in",
                "the",
                "combination",
                "model."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Gridach (2016) proposed a character aware neural network model using a CRF on top of a Bi-LSTM. The aim of that model was to predict the NER tags by exploiting word and character embeddings. In our approach, we follow the same architecture. First, as shown in Figure (2) we use the character model directly to individually train character embeddings. The inputs to this model are word and character input layers as indicated by arrow (A). The word embedding layer takes as input pre-trained embedding matrix developed by #TARGET_REF , transforming the word input layer into word embeddings. The character embedding layer is randomly initialized and trained by the C-Bi-LSTM. The forward and the backward output from this C-Bi-LSTM is concatenated with the output from the word embedding layer and passed to the main Bi-LSTM. The output from this is passed to a Dense layer which maps the output of the main Bi-LSTM to the CRF layer, following #REF . After training the character model, we extract the forward and the backward output of the C-Bi-LSTM and use them to initialize the character embedding layer in the combination model.",
        "output": "{\"INFORMATION\": [\"pre-trained embedding matrix developed by #TARGET_REF\"], \"PERCEPTION\": [\"The word embedding layer takes as input\", \", transforming the word input layer into word embeddings.\"], \"BACKGROUND\": [\"The inputs to this model are word and character input layers as indicated by arrow (A).\"]}"
    },
    {
        "gold": {
            "text": [
                "Evaluation",
                "As",
                "evaluation",
                "measures,",
                "we",
                "have",
                "adopted",
                "corpus",
                "BLEU",
                "#TARGET_REF",
                "to",
                "assess",
                "syntactic",
                "quality",
                "and",
                "the",
                "Kullback-Leibler",
                "(KL)",
                "divergence",
                "#REF",
                "between",
                "the",
                "topic",
                "used",
                "for",
                "conditioning",
                "and",
                "the",
                "topic",
                "extracted",
                "from",
                "the",
                "generated",
                "sentence",
                "to",
                "assess",
                "semantic",
                "coherence.",
                "A",
                "low",
                "KL",
                "value",
                "means",
                "that",
                "the",
                "distribution",
                "inferred",
                "from",
                "the",
                "output",
                "of",
                "the",
                "model",
                "is",
                "similar",
                "to",
                "the",
                "one",
                "extracted",
                "from",
                "the",
                "conditioning",
                "input",
                "sentence",
                "and",
                "used",
                "as",
                "conditioning",
                "vector",
                "c.",
                "This",
                "implies",
                "that",
                "the",
                "semantic",
                "conditioning",
                "has",
                "been",
                "carried",
                "out",
                "successfully."
            ],
            "context": [
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Evaluation As evaluation measures, we have adopted corpus BLEU #TARGET_REF to assess syntactic quality and the Kullback-Leibler (KL) divergence #REF between the topic used for conditioning and the topic extracted from the generated sentence to assess semantic coherence. A low KL value means that the distribution inferred from the output of the model is similar to the one extracted from the conditioning input sentence and used as conditioning vector c. This implies that the semantic conditioning has been carried out successfully.",
        "output": "{\"INFORMATION\": [\"corpus BLEU #TARGET_REF\"], \"PERCEPTION\": [\"we have adopted\", \"to assess syntactic quality and the Kullback-Leibler (KL) divergence\", \"between the topic used for conditioning and the topic extracted from the generated sentence to assess semantic coherence.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Recently,",
                "many",
                "reports",
                "have",
                "described",
                "studies",
                "using",
                "deep",
                "learning",
                "for",
                "dialogue",
                "systems",
                "that",
                "have",
                "achieved",
                "good",
                "performance.",
                "They",
                "can",
                "generate",
                "fluent",
                "sentences",
                "based",
                "on",
                "a",
                "user's",
                "utterances",
                "#REF",
                ".",
                "Nevertheless,",
                "such",
                "neural",
                "dialogue",
                "systems",
                "tend",
                "to",
                "generate",
                "phrases",
                "such",
                "as",
                "\"Yes\"",
                "and",
                "\"I",
                "do",
                "not",
                "know\"",
                "frequently",
                "in",
                "non-task-oriented",
                "dialog",
                "systems,",
                "referred",
                "to",
                "as",
                "the",
                "low",
                "diversity",
                "issue",
                "and",
                "the",
                "generic",
                "response",
                "issue.",
                "After",
                "training",
                "by",
                "a",
                "loss",
                "function",
                "of",
                "similarity",
                "with",
                "gold",
                "standard",
                "reference",
                "sentences,",
                "frequent",
                "phrases",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "assigned",
                "a",
                "large",
                "occurrence",
                "probability",
                "than",
                "rare",
                "phrases",
                "are.",
                "#TARGET_REF",
                "proposed",
                "an",
                "Inverse",
                "Token",
                "Frequency",
                "(ITF)",
                "loss,",
                "which",
                "multiplies",
                "the",
                "Softmax",
                "Cross-Entropy",
                "(SCE)",
                "loss",
                "by",
                "weights",
                "based",
                "on",
                "the",
                "inverse",
                "of",
                "the",
                "frequency",
                "of",
                "tokens.",
                "This",
                "ITF",
                "loss",
                "incorporates",
                "the",
                "frequency",
                "distribution",
                "of",
                "token",
                "classes",
                "so",
                "that",
                "rare",
                "tokens",
                "become",
                "more",
                "likely",
                "to",
                "appear."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Recently, many reports have described studies using deep learning for dialogue systems that have achieved good performance. They can generate fluent sentences based on a user's utterances #REF . Nevertheless, such neural dialogue systems tend to generate phrases such as \"Yes\" and \"I do not know\" frequently in non-task-oriented dialog systems, referred to as the low diversity issue and the generic response issue. After training by a loss function of similarity with gold standard reference sentences, frequent phrases are more likely to be assigned a large occurrence probability than rare phrases are. #TARGET_REF proposed an Inverse Token Frequency (ITF) loss, which multiplies the Softmax Cross-Entropy (SCE) loss by weights based on the inverse of the frequency of tokens. This ITF loss incorporates the frequency distribution of token classes so that rare tokens become more likely to appear.",
        "output": "{\"INFORMATION\": [\"#TARGET_REF proposed an Inverse Token Frequency (ITF) loss, which multiplies the Softmax Cross-Entropy (SCE) loss by weights based on the inverse of the frequency of tokens.\"], \"PERCEPTION\": [\"This ITF loss incorporates the frequency distribution of token classes so that rare tokens become more likely to appear.\"], \"BACKGROUND\": [\"After training by a loss function of similarity with gold standard reference sentences, frequent phrases are more likely to be assigned a large occurrence probability than rare phrases are.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "and",
                "the",
                "BabelNet",
                "knowledge",
                "graph",
                "#TARGET_REF",
                ",",
                "with",
                "a",
                "framework",
                "that",
                "associates",
                "words",
                "according",
                "to",
                "special",
                "rules,",
                "developed",
                "specifically",
                "for",
                "this",
                "purpose."
            ],
            "context": [
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "• and the BabelNet knowledge graph #TARGET_REF , with a framework that associates words according to special rules, developed specifically for this purpose.",
        "output": "{\"INFORMATION\": [\"the BabelNet knowledge graph #TARGET_REF ,\"], \"PERCEPTION\": [], \"BACKGROUND\": [\"with a framework that associates words according to special rules, developed specifically for this purpose.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "fine-tuning",
                "the",
                "downstream",
                "NER",
                "task,",
                "we",
                "use",
                "the",
                "MasakhaNER",
                "data",
                "set",
                "#TARGET_REF",
                ".",
                "As",
                "with",
                "other",
                "text-based",
                "data",
                "sets,",
                "we",
                "transform",
                "the",
                "NER",
                "sample",
                "with",
                "Epitran",
                "to",
                "map",
                "the",
                "samples",
                "into",
                "the",
                "phonetic",
                "representation."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For fine-tuning the downstream NER task, we use the MasakhaNER data set #TARGET_REF . As with other text-based data sets, we transform the NER sample with Epitran to map the samples into the phonetic representation.",
        "output": "{\"INFORMATION\": [\"the MasakhaNER data set #TARGET_REF .\"], \"PERCEPTION\": [\"For fine-tuning the downstream NER task, we use\", \"As with other text-based data sets, we transform the NER sample with Epitran to map the samples into the phonetic representation.\"], \"BACKGROUND\": []}"
    },
    {
        "gold": {
            "text": [
                "Recently,",
                "some",
                "works",
                "have",
                "used",
                "subword",
                "units",
                "level",
                "instead",
                "of",
                "word-level",
                "for",
                "translation.",
                "In",
                "#REF",
                ",",
                "the",
                "rare",
                "and",
                "unknown",
                "words",
                "are",
                "encoded",
                "as",
                "subword",
                "units",
                "with",
                "the",
                "Byte",
                "Pair",
                "Encoding",
                "(BPE)",
                "algorithm.",
                "The",
                "authors",
                "show",
                "that",
                "this",
                "method",
                "can",
                "generate",
                "words",
                "which",
                "are",
                "unseen",
                "at",
                "training",
                "time.",
                "Another",
                "lower",
                "level",
                "for",
                "translation",
                "is",
                "the",
                "character-level",
                "NMT,",
                "which",
                "has",
                "been",
                "presented",
                "in",
                "several",
                "works",
                "#TARGET_REF",
                "and",
                "showed",
                "promising",
                "results."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Recently, some works have used subword units level instead of word-level for translation. In #REF , the rare and unknown words are encoded as subword units with the Byte Pair Encoding (BPE) algorithm. The authors show that this method can generate words which are unseen at training time. Another lower level for translation is the character-level NMT, which has been presented in several works #TARGET_REF and showed promising results.",
        "output": "{\"INFORMATION\": [\"Another lower level for translation is the character-level NMT, which has been presented in several works #TARGET_REF\"], \"PERCEPTION\": [\"and showed promising results.\"], \"BACKGROUND\": []}"
    }
]