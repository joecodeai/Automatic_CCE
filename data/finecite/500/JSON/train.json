[
    {
        "gold": {
            "text": [
                "As",
                "training",
                "loss,",
                "we",
                "have",
                "used",
                "a",
                "non-saturating",
                "GAN",
                "loss",
                "function",
                "#TARGET_REF",
                ",",
                "that,",
                "considering",
                "the",
                "doublediscriminator",
                "model,",
                "is",
                "extended",
                "as:lD",
                "=",
                "1",
                "m",
                "m",
                "X",
                "i=1",
                "✓",
                "log(D",
                "S",
                "(xr))",
                "+",
                "log(1",
                "D",
                "S",
                "(G(xz)))",
                "◆",
                "+",
                "✓",
                "log(D",
                "T",
                "(xr))",
                "+",
                "log(1",
                "D",
                "T",
                "(G(xz)))◆",
                "1",
                "All",
                "the",
                "training",
                "information",
                "and",
                "hyperparameters",
                "are",
                "described",
                "in",
                "Appendix",
                "D.",
                "We",
                "will",
                "release",
                "all",
                "our",
                "code",
                "publicly",
                "after",
                "the",
                "anonymity",
                "period.",
                "1:",
                "CTERM-GAN",
                "architecture",
                "lG",
                "=",
                "1",
                "m",
                "m",
                "X",
                "i=1",
                "",
                "log(D",
                "S",
                "(G(xz)))",
                "log(D",
                "T",
                "(G(xz)))where",
                "is",
                "a",
                "hyperparameter",
                "that",
                "assigns",
                "a",
                "relative",
                "weight",
                "to",
                "the",
                "topic",
                "discriminator",
                "with",
                "respect",
                "to",
                "the",
                "syntax",
                "one.",
                "plays",
                "an",
                "important",
                "role",
                "during",
                "training",
                "since,",
                "if",
                "it",
                "is",
                "too",
                "low,",
                "the",
                "model",
                "ignores",
                "the",
                "conditioning",
                "due",
                "to",
                "the",
                "limited",
                "penalty.",
                "Conversely,",
                "a",
                "too",
                "high",
                "a",
                "value",
                "would",
                "give",
                "too",
                "much",
                "importance",
                "to",
                "the",
                "conditioning,",
                "affecting",
                "the",
                "quality",
                "of",
                "the",
                "generated",
                "sentence."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "As training loss, we have used a non-saturating GAN loss function #TARGET_REF , that, considering the doublediscriminator model, is extended as:lD = 1 m m X i=1 ✓ log(D S (xr)) + log(1 D S (G(xz))) ◆ + ✓ log(D T (xr)) + log(1 D T (G(xz)))◆ 1 All the training information and hyperparameters are described in Appendix D. We will release all our code publicly after the anonymity period. 1: CTERM-GAN architecture lG = 1 m m X i=1  log(D S (G(xz))) log(D T (G(xz)))where is a hyperparameter that assigns a relative weight to the topic discriminator with respect to the syntax one. plays an important role during training since, if it is too low, the model ignores the conditioning due to the limited penalty. Conversely, a too high a value would give too much importance to the conditioning, affecting the quality of the generated sentence.",
        "output": "{\"INFO\": [\"a non-saturating GAN loss function #TARGET_REF\", \"1 m m X i=1 \\uf8ff\\u2713 log(D S (xr)) + log(1 D S (G(xz))) \\u25c6 + \\u2713 log(D T (xr)) + log(1 D T (G(xz)))\\u25c6 1\"], \"PERCEPT\": [\"we have used\", \"that, considering the doublediscriminator model, is extended as:lD\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Apart",
                "from",
                "designing",
                "classification",
                "tasks",
                "for",
                "disentanglement",
                "evaluation,",
                "another",
                "method",
                "is",
                "based",
                "on",
                "estimating",
                "the",
                "mutual",
                "information",
                "(MI)",
                "between",
                "a",
                "single",
                "dimension",
                "of",
                "the",
                "latent",
                "variable",
                "and",
                "a",
                "single",
                "generative",
                "factor.",
                "#REF",
                "propose",
                "to",
                "use",
                "the",
                "average",
                "of",
                "the",
                "gap",
                "(difference)",
                "between",
                "the",
                "largest",
                "normalised",
                "MI",
                "(by",
                "the",
                "information",
                "entropy",
                "of",
                "the",
                "generative",
                "factor)",
                "and",
                "the",
                "second",
                "largest",
                "normalised",
                "MI",
                "over",
                "all",
                "generative",
                "factors",
                "as",
                "the",
                "disentanglement",
                "score,",
                "whereas",
                "the",
                "modularity",
                "metric",
                "of",
                "#TARGET_REF",
                "measures",
                "whether",
                "a",
                "single",
                "latent",
                "variable",
                "has",
                "the",
                "highest",
                "MI",
                "with",
                "only",
                "one",
                "generative",
                "factor",
                "and",
                "none",
                "with",
                "others."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Apart from designing classification tasks for disentanglement evaluation, another method is based on estimating the mutual information (MI) between a single dimension of the latent variable and a single generative factor. #REF propose to use the average of the gap (difference) between the largest normalised MI (by the information entropy of the generative factor) and the second largest normalised MI over all generative factors as the disentanglement score, whereas the modularity metric of #TARGET_REF measures whether a single latent variable has the highest MI with only one generative factor and none with others.",
        "output": "{\"INFO\": [\"the modularity metric of #TARGET_REF measures whether a single latent variable has the highest MI with only one generative factor and none with others.\"], \"PERCEPT\": [\"#REF propose to use the average of the gap (difference) between the largest normalised MI\", \"and the second largest normalised MI over all generative factors as the disentanglement score,\"], \"BACK\": [\"(by the information entropy of the generative factor)\"]}"
    },
    {
        "gold": {
            "text": [
                "Genuine",
                "tokens",
                "are",
                "tokens",
                "that",
                "causally",
                "affect",
                "a",
                "task's",
                "label",
                "#REF",
                ",",
                "and",
                "thus",
                "the",
                "correlations",
                "between",
                "those",
                "tokens",
                "and",
                "the",
                "labels",
                "are",
                "what",
                "we",
                "expect",
                "the",
                "model",
                "to",
                "capture",
                "and",
                "to",
                "more",
                "heavily",
                "rely",
                "on.",
                "On",
                "the",
                "other",
                "hand,",
                "spurious",
                "tokens,",
                "or",
                "shortcuts",
                "as",
                "commonly",
                "denoted",
                "in",
                "prior",
                "work",
                "#REF",
                ",",
                "are",
                "features",
                "that",
                "correlate",
                "with",
                "task",
                "labels",
                "but",
                "are",
                "not",
                "genuine,",
                "and",
                "thus",
                "might",
                "fail",
                "to",
                "transfer",
                "to",
                "challenging",
                "test",
                "conditions",
                "#REF",
                "or",
                "out-of-distribution",
                "data,",
                "spurious",
                "tokens",
                "do",
                "not",
                "causally",
                "affect",
                "task",
                "labels",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Genuine tokens are tokens that causally affect a task's label #REF , and thus the correlations between those tokens and the labels are what we expect the model to capture and to more heavily rely on. On the other hand, spurious tokens, or shortcuts as commonly denoted in prior work #REF , are features that correlate with task labels but are not genuine, and thus might fail to transfer to challenging test conditions #REF or out-of-distribution data, spurious tokens do not causally affect task labels #TARGET_REF .",
        "output": "{\"INFO\": [\"task labels #TARGET_REF .\"], \"PERCEPT\": [\"thus might fail to transfer to challenging test conditions #REF or out-of-distribution data,\"], \"BACK\": [\"Genuine tokens are tokens that causally affect a task's label #REF , and thus the correlations between those tokens and the labels are what we expect the model to capture and to more heavily rely on.\", \"spurious tokens do not causally affect\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "utilised",
                "the",
                "ANLT",
                "metagrammatical",
                "formalism",
                "to",
                "develop",
                "a",
                "feature-based,",
                "declara",
                "tive",
                "description",
                "of",
                "PoS",
                "label",
                "sequences",
                "for",
                "English.",
                "This",
                "grammar",
                "compiles",
                "into",
                "a",
                "DCG-like",
                "grammar",
                "of",
                "approximately",
                "400",
                "rules.",
                "It",
                "has",
                "been",
                "designed",
                "to",
                "enumerate",
                "possible",
                "valencies",
                "for",
                "predicates",
                "(verbs,",
                "adj",
                "ectives",
                "and",
                "nouns)",
                "by",
                "including",
                "separate",
                "rules",
                "for",
                "each",
                "pattern",
                "of",
                "possible",
                "complementation",
                "in",
                "English.",
                "The",
                "distinction",
                "between",
                "arguments",
                "and",
                "adj",
                "uncts",
                "is",
                "expressed,",
                "following",
                "X-bar",
                "theory",
                "(e.g.",
                "#TARGET_REF",
                ",",
                "by",
                "Chomsky-adjunction",
                "of",
                "adjuncts",
                "to",
                "maximal",
                "projections",
                "{XP",
                "�",
                "XP",
                "Adjunct)",
                "as",
                "opposed",
                "to",
                "government",
                "of",
                "arguments",
                "(i.e.",
                "arguments",
                "are",
                "sisters",
                "within",
                "Xl",
                "projections,",
                "XI",
                "�",
                "XO",
                "Argl.",
                "..",
                "ArgN)",
                ".",
                "Although",
                "the",
                "grammar",
                "enumerates",
                "complementation",
                "possibilities",
                "and",
                "checks",
                "for",
                "global",
                "sentential",
                "well-formedness,",
                "it",
                "is",
                "best",
                "de",
                "scribed",
                "as",
                "'intermediate'",
                "as",
                "it",
                "does",
                "not",
                "attempt",
                "to",
                "associate",
                "'displaced'",
                "constituents",
                "with",
                "their",
                "canonical",
                "position",
                "/",
                "grammatical",
                "role."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We utilised the ANLT metagrammatical formalism to develop a feature-based, declara tive description of PoS label sequences for English. This grammar compiles into a DCG-like grammar of approximately 400 rules. It has been designed to enumerate possible valencies for predicates (verbs, adj ectives and nouns) by including separate rules for each pattern of possible complementation in English. The distinction between arguments and adj uncts is expressed, following X-bar theory (e.g. #TARGET_REF , by Chomsky-adjunction of adjuncts to maximal projections {XP � XP Adjunct) as opposed to government of arguments (i.e. arguments are sisters within Xl projections, XI � XO Argl. .. ArgN) . Although the grammar enumerates complementation possibilities and checks for global sentential well-formedness, it is best de scribed as 'intermediate' as it does not attempt to associate 'displaced' constituents with their canonical position / grammatical role.",
        "output": "{\"INFO\": [\"#TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"The distinction between arguments and adj uncts is expressed, following X-bar theory (e.g.\", \"by Chomsky-adjunction of adjuncts to maximal projections {XP \\ufffd XP Adjunct) as opposed to government of arguments (i.e. arguments are sisters within Xl projections, XI \\ufffd XO Argl. .. ArgN) .\"]}"
    },
    {
        "gold": {
            "text": [
                "Most",
                "previous",
                "attempts",
                "aim",
                "to",
                "describe",
                "the",
                "image",
                "indicating",
                "the",
                "salient",
                "objects",
                "and",
                "relations",
                "without",
                "considering",
                "user",
                "intention.",
                "To",
                "generate",
                "controllable",
                "and",
                "explainable",
                "captions,",
                "recent",
                "works",
                "dedicated",
                "to",
                "establishing",
                "a",
                "new",
                "controllable",
                "image",
                "captioning",
                "task",
                "to",
                "generate",
                "the",
                "caption",
                "at",
                "will.",
                "The",
                "captioning",
                "process",
                "can",
                "be",
                "controlled",
                "by",
                "POS",
                "tagging",
                "#REF",
                ",",
                "sentiment",
                "#TARGET_REF",
                ",",
                "length",
                "#REF",
                ",",
                "bounding",
                "boxes",
                "#REF",
                ",",
                "and",
                "mouse",
                "traces",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Most previous attempts aim to describe the image indicating the salient objects and relations without considering user intention. To generate controllable and explainable captions, recent works dedicated to establishing a new controllable image captioning task to generate the caption at will. The captioning process can be controlled by POS tagging #REF , sentiment #TARGET_REF , length #REF , bounding boxes #REF , and mouse traces #REF .",
        "output": "{\"INFO\": [\"The captioning process can be controlled\", \"sentiment #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"recent works dedicated to establishing a new controllable image captioning task to generate the caption at will.\", \"by POS tagging #REF ,\", \"length #REF , bounding boxes #REF , and mouse traces #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "past",
                "few",
                "years,",
                "Natural",
                "Language",
                "Processing",
                "(NLP)",
                "researchers",
                "have",
                "proposed",
                "several",
                "online",
                "game/community",
                "toxicity",
                "analysis",
                "frameworks",
                "Figure",
                "1:",
                "An",
                "example",
                "intent/slot",
                "annotation",
                "from",
                "the",
                "CONDA",
                "(CONtextual",
                "Dual-Annotated)",
                "dataset.",
                "#TARGET_REF",
                "and",
                "datasets",
                "#REF",
                ".",
                "However,",
                "existing",
                "datasets",
                "(1)",
                "focus",
                "only",
                "on",
                "the",
                "single",
                "utterance",
                "level",
                "without",
                "deeper",
                "understanding",
                "of",
                "context",
                "in",
                "the",
                "whole",
                "conversation/chat,",
                "and",
                "(2)",
                "do",
                "not",
                "explicitly",
                "use",
                "semantic",
                "clues",
                "from",
                "the",
                "words",
                "within",
                "the",
                "utterance."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the past few years, Natural Language Processing (NLP) researchers have proposed several online game/community toxicity analysis frameworks Figure 1: An example intent/slot annotation from the CONDA (CONtextual Dual-Annotated) dataset. #TARGET_REF and datasets #REF . However, existing datasets (1) focus only on the single utterance level without deeper understanding of context in the whole conversation/chat, and (2) do not explicitly use semantic clues from the words within the utterance.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"In the past few years, Natural Language Processing (NLP) researchers have proposed several online game/community toxicity analysis frameworks\", \"and datasets\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "TNE",
                "task",
                "we",
                "define",
                "side-steps",
                "all",
                "the",
                "above",
                "issues.",
                "It",
                "is",
                "based",
                "on",
                "the",
                "text",
                "alone,",
                "without",
                "revealing",
                "additional",
                "information",
                "not",
                "present",
                "in",
                "the",
                "text.",
                "The",
                "exhaustive",
                "nature",
                "of",
                "the",
                "task",
                "entails",
                "looking",
                "both",
                "at",
                "positive",
                "instances",
                "(where",
                "a",
                "relation",
                "exists)",
                "and",
                "negative",
                "ones",
                "(where",
                "it",
                "doesn't),",
                "making",
                "it",
                "harder",
                "for",
                "models",
                "to",
                "pick",
                "up",
                "shallow",
                "heuristics.",
                "We",
                "don't",
                "reveal",
                "information",
                "to",
                "a",
                "model,",
                "beyond",
                "the",
                "information",
                "that",
                "the",
                "two",
                "NPs",
                "appear",
                "in",
                "the",
                "same",
                "text.",
                "Finally,",
                "the",
                "list",
                "of",
                "NPs",
                "to",
                "be",
                "considered",
                "is",
                "pre-specified,",
                "isolating",
                "the",
                "problem",
                "of",
                "understanding",
                "the",
                "relations",
                "between",
                "NPs",
                "in",
                "the",
                "text",
                "from",
                "the",
                "much",
                "easier",
                "yet",
                "intervening",
                "problem",
                "of",
                "identifying",
                "NPs",
                "and",
                "agreeing",
                "on",
                "their",
                "exact",
                "spans.",
                "#TARGET_REF",
                "Table",
                "1:",
                "Prepositions",
                "used",
                "in",
                "TNE.",
                "Thus,",
                "we",
                "consider",
                "TNE",
                "a",
                "less",
                "biased",
                "and",
                "less",
                "gameable",
                "measure",
                "of",
                "RC",
                "than",
                "QA-based",
                "benchmarks.",
                "Of",
                "course,",
                "the",
                "information",
                "captured",
                "by",
                "TNE",
                "is",
                "limited",
                "and",
                "does",
                "not",
                "cover",
                "all",
                "levels",
                "of",
                "text",
                "understanding.",
                "Yet,",
                "performing",
                "the",
                "task",
                "correctly",
                "entails",
                "a",
                "non-trivial",
                "comprehension",
                "of",
                "texts,",
                "which",
                "human",
                "readers",
                "do",
                "as",
                "a",
                "byproduct",
                "of",
                "reading."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The TNE task we define side-steps all the above issues. It is based on the text alone, without revealing additional information not present in the text. The exhaustive nature of the task entails looking both at positive instances (where a relation exists) and negative ones (where it doesn't), making it harder for models to pick up shallow heuristics. We don't reveal information to a model, beyond the information that the two NPs appear in the same text. Finally, the list of NPs to be considered is pre-specified, isolating the problem of understanding the relations between NPs in the text from the much easier yet intervening problem of identifying NPs and agreeing on their exact spans. #TARGET_REF Table 1: Prepositions used in TNE. Thus, we consider TNE a less biased and less gameable measure of RC than QA-based benchmarks. Of course, the information captured by TNE is limited and does not cover all levels of text understanding. Yet, performing the task correctly entails a non-trivial comprehension of texts, which human readers do as a byproduct of reading.",
        "output": "{\"INFO\": [\"identifying NPs and agreeing on their exact spans. #TARGET_REF\"], \"PERCEPT\": [\"the list of NPs to be considered is pre-specified, isolating the problem of understanding the relations between NPs in the text from the much easier yet intervening problem of\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "A",
                "bilingual",
                "parallel",
                "corpus",
                "#REF",
                "was",
                "used",
                "for",
                "automatic",
                "evaluation",
                "using",
                "BLEU",
                "metric",
                "#REF",
                ".",
                "The",
                "results",
                "are",
                "presented",
                "in",
                "Table",
                "2.",
                "The",
                "values",
                "are",
                "quite",
                "low,",
                "partly",
                "due",
                "to",
                "reasons",
                "explained",
                "in",
                "(Callison-Burch",
                "et",
                "al.,",
                "partly",
                "due",
                "to",
                "unknown",
                "words",
                "in",
                "test",
                "corpus.",
                "Figure",
                "6",
                "shows",
                "results",
                "of",
                "evaluation",
                "of",
                "translation",
                "quality",
                "using",
                "subjective",
                "measures",
                "using",
                "methodology",
                "#TARGET_REF",
                ".",
                "The",
                "methodology",
                "is",
                "explained",
                "in",
                "chapter",
                "4.1.",
                "Four",
                "independent",
                "evaluators",
                "(two",
                "native",
                "speakers)",
                "evaluated",
                "sets",
                "of",
                "100",
                "sentences",
                "using",
                "this",
                "methodology."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "A bilingual parallel corpus #REF was used for automatic evaluation using BLEU metric #REF . The results are presented in Table 2. The values are quite low, partly due to reasons explained in (Callison-Burch et al., partly due to unknown words in test corpus. Figure 6 shows results of evaluation of translation quality using subjective measures using methodology #TARGET_REF . The methodology is explained in chapter 4.1. Four independent evaluators (two native speakers) evaluated sets of 100 sentences using this methodology.",
        "output": "{\"INFO\": [\"evaluation of translation quality using subjective measures using methodology #TARGET_REF .\"], \"PERCEPT\": [\"results of\", \"The methodology is explained in chapter 4.1.\"], \"BACK\": [\"A bilingual parallel corpus #REF was used for automatic evaluation using BLEU metric #REF\", \"Figure 6 shows\", \"Four independent evaluators (two native speakers) evaluated sets of 100 sentences using this methodology.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "SPARKLE",
                "project",
                "has",
                "shown",
                "(see",
                "#TARGET_REF",
                "how",
                "far",
                "simple",
                "robust",
                "phrasal",
                "parsing",
                "combined",
                "with",
                "classification",
                "techniques",
                "utilising",
                "limited",
                "and",
                "manageable",
                "linguistic",
                "knowledge",
                "and",
                "statistical",
                "data",
                "from",
                "substantial",
                "corpora",
                "can",
                "ameliorate",
                "this",
                "problem",
                "in",
                "the",
                "area",
                "of",
                "predicate",
                "subcategorisation,",
                "argument",
                "structure",
                "and",
                "semantic",
                "preferences,",
                "an",
                "area",
                "in",
                "which",
                "most",
                "extant",
                "conventional",
                "dictionaries,",
                "lexical",
                "databases",
                "and",
                "realistic",
                "lexicons",
                "are",
                "demonstrably",
                "weak",
                "or",
                "-when",
                "available",
                "-by",
                "necessity",
                "never",
                "complete."
            ],
            "context": [
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The SPARKLE project has shown (see #TARGET_REF how far simple robust phrasal parsing combined with classification techniques utilising limited and manageable linguistic knowledge and statistical data from substantial corpora can ameliorate this problem in the area of predicate subcategorisation, argument structure and semantic preferences, an area in which most extant conventional dictionaries, lexical databases and realistic lexicons are demonstrably weak or -when available -by necessity never complete.",
        "output": "{\"INFO\": [\"#TARGET_REF how far simple robust phrasal parsing combined with classification techniques utilising limited and manageable linguistic knowledge and statistical data from substantial corpora\"], \"PERCEPT\": [\"has shown (see\", \"can ameliorate this problem\"], \"BACK\": [\"The SPARKLE project\", \"in the area of predicate subcategorisation, argument structure and semantic preferences, an area in which most extant conventional dictionaries, lexical databases and realistic lexicons are demonstrably weak or -when available -by necessity never complete.\"]}"
    },
    {
        "gold": {
            "text": [
                "A2C",
                "Training.",
                "Each",
                "parallel",
                "A2C",
                "agent",
                "samples",
                "from",
                "the",
                "the",
                "current",
                "pool",
                "of",
                "available",
                "questsi.e.",
                "the",
                "curriculum-for",
                "a",
                "fixed",
                "number",
                "of",
                "steps",
                "k",
                "before",
                "switching",
                "to",
                "the",
                "quest",
                "pool",
                "corresponding",
                "to",
                "the",
                "next",
                "higher",
                "level",
                "difficulty",
                "curriculum.",
                "The",
                "initial",
                "pool",
                "of",
                "quests",
                "is",
                "the",
                "training",
                "set",
                "of",
                "LIGHT-Quests",
                "as",
                "seen",
                "in",
                "#TARGET_REF",
                "and",
                "all",
                "pools",
                "after",
                "that",
                "correspond",
                "to",
                "decreasing",
                "values",
                "of",
                "n",
                "used",
                "when",
                "generating",
                "the",
                "curriculums",
                "(as",
                "seen",
                "in",
                "Figure",
                "6)."
            ],
            "context": [
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "A2C Training. Each parallel A2C agent samples from the the current pool of available questsi.e. the curriculum-for a fixed number of steps k before switching to the quest pool corresponding to the next higher level difficulty curriculum. The initial pool of quests is the training set of LIGHT-Quests as seen in #TARGET_REF and all pools after that correspond to decreasing values of n used when generating the curriculums (as seen in Figure 6).",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"A2C Training.\", \"The initial pool of quests is the training set of LIGHT-Quests as seen in\", \"and all pools after that correspond to decreasing values of n used when generating the curriculums (as seen in Figure 6).\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "performance",
                "of",
                "QA",
                "models",
                "are",
                "evaluated",
                "using",
                "the",
                "Exact",
                "Match",
                "(EM)",
                "and",
                "F1",
                "scores.",
                "The",
                "EM",
                "score",
                "is",
                "the",
                "percentage",
                "of",
                "system",
                "outputs",
                "that",
                "match",
                "exactly",
                "with",
                "the",
                "ground",
                "truth",
                "answers.",
                "The",
                "F1",
                "score",
                "is",
                "a",
                "combined",
                "measure",
                "of",
                "precision",
                "and",
                "recall",
                "that",
                "is",
                "less",
                "strict",
                "than",
                "EM.",
                "The",
                "evaluation",
                "process",
                "3",
                "involves",
                "post-processing",
                "identical",
                "to",
                "that",
                "presented",
                "by",
                "d'Hoffschmidt",
                "et",
                "al.",
                "(",
                "2020)",
                "and",
                "inspired",
                "by",
                "that",
                "proposed",
                "for",
                "English",
                "by",
                "#TARGET_REF",
                ",",
                "which",
                "consists",
                "of",
                "the",
                "removal",
                "of",
                "punctuation",
                "marks",
                "and",
                "determiners",
                "4",
                "as",
                "well",
                "as",
                "a",
                "down-casing",
                "of",
                "the",
                "answers",
                "(ground",
                "truths",
                "and",
                "predictions)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The performance of QA models are evaluated using the Exact Match (EM) and F1 scores. The EM score is the percentage of system outputs that match exactly with the ground truth answers. The F1 score is a combined measure of precision and recall that is less strict than EM. The evaluation process 3 involves post-processing identical to that presented by d'Hoffschmidt et al. ( 2020) and inspired by that proposed for English by #TARGET_REF , which consists of the removal of punctuation marks and determiners 4 as well as a down-casing of the answers (ground truths and predictions).",
        "output": "{\"INFO\": [\"inspired by that proposed for English by #TARGET_REF\", \"which consists of the removal of punctuation marks and determiners 4 as well as a down-casing of the answers (ground truths and predictions).\"], \"PERCEPT\": [], \"BACK\": [\"The evaluation process 3 involves post-processing identical to that presented by d'Hoffschmidt et al. ( 2020)\"]}"
    },
    {
        "gold": {
            "text": [
                "Commonsense",
                "explanation",
                "generation.",
                "It",
                "aims",
                "to",
                "generate",
                "an",
                "explanation",
                "given",
                "a",
                "counterfactual",
                "statement",
                "for",
                "sense-making",
                "#REF",
                ".",
                "We",
                "use",
                "the",
                "benchmark",
                "dataset",
                "ComVE",
                "from",
                "SemEval-2020",
                "Task",
                "4",
                "#REF",
                ".",
                "The",
                "dataset",
                "contains",
                "10,000",
                "/",
                "997",
                "/",
                "1,000",
                "examples",
                "for",
                "training",
                "/",
                "development",
                "/",
                "test",
                "sets,",
                "respectively.",
                "The",
                "average",
                "input/output",
                "length",
                "is",
                "7.7",
                "/",
                "9.0",
                "words.",
                "All",
                "examples",
                "in",
                "the",
                "dataset",
                "have",
                "3",
                "references.",
                "Abductive",
                "commonsense",
                "reasoning.",
                "It",
                "is",
                "also",
                "referred",
                "as",
                "α-NLG.",
                "It",
                "is",
                "the",
                "task",
                "of",
                "generating",
                "a",
                "valid",
                "hypothesis",
                "about",
                "the",
                "likely",
                "explanations",
                "to",
                "partially",
                "observable",
                "past",
                "and",
                "future.",
                "We",
                "use",
                "the",
                "ART",
                "benchmark",
                "dataset",
                "#TARGET_REF",
                "that",
                "consists",
                "of",
                "50,481",
                "/",
                "1,779",
                "/",
                "3,560",
                "examples",
                "for",
                "training",
                "/",
                "development",
                "/",
                "test",
                "sets.",
                "The",
                "average",
                "input/output",
                "length",
                "is",
                "17.4",
                "/",
                "10.8",
                "words.",
                "Each",
                "example",
                "in",
                "the",
                "ART",
                "dataset",
                "has",
                "1",
                "to",
                "5",
                "references."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Commonsense explanation generation. It aims to generate an explanation given a counterfactual statement for sense-making #REF . We use the benchmark dataset ComVE from SemEval-2020 Task 4 #REF . The dataset contains 10,000 / 997 / 1,000 examples for training / development / test sets, respectively. The average input/output length is 7.7 / 9.0 words. All examples in the dataset have 3 references. Abductive commonsense reasoning. It is also referred as α-NLG. It is the task of generating a valid hypothesis about the likely explanations to partially observable past and future. We use the ART benchmark dataset #TARGET_REF that consists of 50,481 / 1,779 / 3,560 examples for training / development / test sets. The average input/output length is 17.4 / 10.8 words. Each example in the ART dataset has 1 to 5 references.",
        "output": "{\"INFO\": [\"ART benchmark dataset #TARGET_REF that consists of 50,481 / 1,779 / 3,560 examples for training / development / test sets. The average input/output length is 17.4 / 10.8 words.\"], \"PERCEPT\": [\"We use the\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "EEG",
                "signals",
                "were",
                "extracted",
                "from",
                "-100",
                "to",
                "700",
                "ms",
                "relative",
                "to",
                "word",
                "onset.",
                "For",
                "baseline",
                "correction,",
                "we",
                "subtracted",
                "the",
                "channel-wise",
                "mean",
                "from",
                "-100",
                "ms",
                "to",
                "0",
                "ms",
                "from",
                "the",
                "evoked",
                "post-stimulus",
                "EEG",
                "response",
                "([0",
                "700]",
                "ms",
                "separately",
                "for",
                "each",
                "word,",
                "see",
                "Figure",
                "1).",
                "EEG",
                "data",
                "were",
                "spatially",
                "multivariate",
                "noise",
                "normalised",
                "using",
                "the",
                "noise",
                "covariance",
                "matrix",
                "estimated",
                "separately",
                "for",
                "each",
                "target",
                "class",
                "#TARGET_REF",
                ".",
                "Each",
                "EEG",
                "trial",
                "was",
                "annotated",
                "with",
                "the",
                "gold",
                "part",
                "of",
                "speech",
                "tags",
                "of",
                "the",
                "current",
                "and",
                "subsequent",
                "words,",
                "their",
                "word",
                "lengths,",
                "and",
                "Zipf-logarithmic",
                "frequency",
                "scores",
                "from",
                "the",
                "Python",
                "package",
                "WordFreq",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "EEG signals were extracted from -100 to 700 ms relative to word onset. For baseline correction, we subtracted the channel-wise mean from -100 ms to 0 ms from the evoked post-stimulus EEG response ([0 700] ms separately for each word, see Figure 1). EEG data were spatially multivariate noise normalised using the noise covariance matrix estimated separately for each target class #TARGET_REF . Each EEG trial was annotated with the gold part of speech tags of the current and subsequent words, their word lengths, and Zipf-logarithmic frequency scores from the Python package WordFreq #REF .",
        "output": "{\"INFO\": [\"the noise covariance matrix estimated separately for each target class #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"EEG data were spatially multivariate noise normalised using\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "same",
                "direction",
                "but",
                "with",
                "the",
                "other",
                "output",
                "information,",
                "we",
                "used",
                "only",
                "the",
                "factors",
                "embedding",
                "as",
                "feedback",
                "(see",
                "equation",
                "6).",
                "fb(y",
                "t−1",
                ")",
                "=",
                "y",
                "F",
                "t−1",
                "#TARGET_REF",
                "where",
                "y",
                "F",
                "t−1",
                "is",
                "the",
                "embedding",
                "of",
                "the",
                "factors",
                "generated",
                "at",
                "the",
                "previous",
                "timestep."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "In the same direction but with the other output information, we used only the factors embedding as feedback (see equation 6). fb(y t−1 ) = y F t−1 #TARGET_REF where y F t−1 is the embedding of the factors generated at the previous timestep.",
        "output": "{\"INFO\": [\"fb(y t\\u22121 ) = y F t\\u22121 #TARGET_REF\"], \"PERCEPT\": [\"In the same direction but with the other output information, we used only the factors embedding as feedback\"], \"BACK\": [\"(see equation 6).\", \"where y F t\\u22121 is the embedding of the factors generated at the previous timestep.\"]}"
    },
    {
        "gold": {
            "text": [
                "Figure",
                "6,",
                "«",
                "½",
                "and",
                "«",
                "¾",
                "are",
                "initial",
                "trees,",
                "¬",
                "½",
                "is",
                "an",
                "auxiliary",
                "tree.",
                "The",
                "trees",
                "are",
                "combined",
                "together",
                "by",
                "two",
                "operations,",
                "substitution",
                "and",
                "adjunction.",
                "Under",
                "substitution,",
                "a",
                "node",
                "marked",
                "for",
                "substitution",
                "5",
                "in",
                "a",
                "tree",
                "is",
                "replaced",
                "by",
                "an",
                "initial",
                "tree",
                "with",
                "the",
                "same",
                "label",
                "at",
                "the",
                "root,",
                "under",
                "adjunction,",
                "an",
                "internal",
                "node",
                "in",
                "a",
                "tree",
                "is",
                "'split",
                "apart',",
                "replaced",
                "by",
                "an",
                "auxiliary",
                "tree",
                "with",
                "the",
                "same",
                "label",
                "at",
                "the",
                "root",
                "and",
                "foot.",
                "In",
                "the",
                "DERIVED",
                "TREE",
                "for",
                "the",
                "string",
                ",",
                "in",
                "Figure",
                "6,",
                "copies",
                "of",
                "¬",
                "½",
                "have",
                "been",
                "adjoined",
                "either",
                "at",
                "the",
                "root",
                "node",
                "labelled",
                "of",
                "other",
                "nodes",
                "¬",
                "½",
                "or",
                "ultimately",
                "at",
                "the",
                "node",
                "of",
                "«",
                "½",
                ",",
                "an",
                "«",
                "¾",
                "tree",
                "has",
                "been",
                "substituted",
                "into",
                "each",
                "¬",
                "½",
                "tree",
                "at",
                "the",
                "node",
                "labelled",
                ".",
                "The",
                "derivation",
                "history",
                "is",
                "recorded",
                "in",
                "the",
                "DERIVATION",
                "TREE",
                "(Figure",
                "6).",
                "It",
                "can",
                "be",
                "seen",
                "that",
                "the",
                "TAG",
                "property",
                "of",
                "an",
                "'extended",
                "domain",
                "of",
                "locality'",
                "can",
                "allow",
                "the",
                "two",
                "s",
                "in",
                "the",
                "generated",
                "string",
                "to",
                "be",
                "separated",
                "by",
                "an",
                "abitrary",
                "amount",
                "of",
                "intervening",
                "material,",
                "this",
                "characteristic",
                "is",
                "used",
                "for",
                "representation",
                "of,",
                "for",
                "example,",
                "WH-phenomena",
                "when",
                "TAG",
                "derived",
                "trees",
                "are",
                "used",
                "for",
                "a",
                "linguistic",
                "representation.",
                "Of",
                "more",
                "interest",
                "for",
                "us",
                "than",
                "the",
                "derived",
                "string",
                "is",
                "the",
                "nature",
                "of",
                "the",
                "derived",
                "tree:",
                "the",
                "branches",
                "containing",
                "the",
                "nodes",
                "in",
                "the",
                "derived",
                "tree",
                "are",
                "also",
                "separated",
                "by",
                "an",
                "arbitary",
                "distance."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Figure 6, « ½ and « ¾ are initial trees, ¬ ½ is an auxiliary tree. The trees are combined together by two operations, substitution and adjunction. Under substitution, a node marked for substitution 5 in a tree is replaced by an initial tree with the same label at the root, under adjunction, an internal node in a tree is 'split apart', replaced by an auxiliary tree with the same label at the root and foot. In the DERIVED TREE for the string , in Figure 6, copies of ¬ ½ have been adjoined either at the root node labelled of other nodes ¬ ½ or ultimately at the node of « ½ , an « ¾ tree has been substituted into each ¬ ½ tree at the node labelled . The derivation history is recorded in the DERIVATION TREE (Figure 6). It can be seen that the TAG property of an 'extended domain of locality' can allow the two s in the generated string to be separated by an abitrary amount of intervening material, this characteristic is used for representation of, for example, WH-phenomena when TAG derived trees are used for a linguistic representation. Of more interest for us than the derived string is the nature of the derived tree: the branches containing the nodes in the derived tree are also separated by an arbitary distance.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"Figure 6, \\u00ab \\u00bd and \\u00ab \\u00be are initial trees, \\u00ac \\u00bd is an auxiliary tree.\"]}"
    },
    {
        "gold": {
            "text": [
                "Semantic",
                "Similarity",
                "In",
                "addition",
                "to",
                "the",
                "BLEU",
                "score,",
                "we",
                "use",
                "the",
                "sentence-transformers",
                "toolkit",
                "#TARGET_REF",
                "to",
                "convert",
                "the",
                "generated",
                "definitions",
                "and",
                "references",
                "into",
                "sentence",
                "vectors,",
                "and",
                "calculate",
                "cosine",
                "similarity",
                "between",
                "them."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Semantic Similarity In addition to the BLEU score, we use the sentence-transformers toolkit #TARGET_REF to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them.",
        "output": "{\"INFO\": [\"the sentence-transformers toolkit #TARGET_REF\"], \"PERCEPT\": [\"we use\", \"to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Controllability",
                "Analysis",
                "on",
                "Temporal",
                "Frequency",
                "Then,",
                "we",
                "analyze",
                "the",
                "controllability",
                "of",
                "the",
                "temporal",
                "frequency",
                "τ",
                "to",
                "present",
                "whether",
                "the",
                "coarse-grained",
                "or",
                "fine-grained",
                "tracepoints",
                "(sampling",
                "rate,",
                "in",
                "other",
                "words)",
                "affects",
                "the",
                "generation",
                "performance.",
                "As",
                "the",
                "Table",
                "4",
                "shows,",
                "we",
                "change",
                "the",
                "temporal",
                "frequency",
                "τ",
                "from",
                "0.4",
                "to",
                "1.2.",
                "A",
                "performance",
                "drop",
                "is",
                "impressive",
                "with",
                "the",
                "τ",
                "getting",
                "larger.",
                "The",
                "purpose",
                "of",
                "this",
                "experiment",
                "for",
                "various",
                "τ",
                "is",
                "to",
                "simulate",
                "the",
                "trace",
                "drawing",
                "speed",
                "of",
                "users",
                "in",
                "a",
                "real",
                "application",
                "scenario,",
                "and",
                "a",
                "larger",
                "τ",
                "is",
                "equivalent",
                "to",
                "a",
                "faster",
                "drawing",
                "speed.",
                "As",
                "#TARGET_REF",
                "has",
                "demonstrated,",
                "the",
                "length",
                "is",
                "one",
                "of",
                "the",
                "critical",
                "facts",
                "that",
                "impact",
                "quantitative",
                "performance.",
                "This",
                "result",
                "implies",
                "we",
                "can",
                "further",
                "decide",
                "to",
                "generate",
                "either",
                "a",
                "coarse-grained",
                "or",
                "fine-grained",
                "caption",
                "by",
                "controlling",
                "the",
                "time-frequency",
                "τ",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                1,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Controllability Analysis on Temporal Frequency Then, we analyze the controllability of the temporal frequency τ to present whether the coarse-grained or fine-grained tracepoints (sampling rate, in other words) affects the generation performance. As the Table 4 shows, we change the temporal frequency τ from 0.4 to 1.2. A performance drop is impressive with the τ getting larger. The purpose of this experiment for various τ is to simulate the trace drawing speed of users in a real application scenario, and a larger τ is equivalent to a faster drawing speed. As #TARGET_REF has demonstrated, the length is one of the critical facts that impact quantitative performance. This result implies we can further decide to generate either a coarse-grained or fine-grained caption by controlling the time-frequency τ .",
        "output": "{\"INFO\": [\"#TARGET_REF\", \"the length is one of the critical facts that impact quantitative performance.\"], \"PERCEPT\": [\"As\", \"has demonstrated,\", \"This result implies we can further decide to generate either a coarse-grained or fine-grained caption by controlling the time-frequency \\u03c4 .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "collect",
                "the",
                "data",
                "for",
                "two",
                "months",
                "from",
                "August",
                "to",
                "October",
                "2020.",
                "There",
                "are",
                "two",
                "main",
                "sources",
                "of",
                "the",
                "data:",
                "SNSs",
                "and",
                "Vietnamese",
                "newspapers.",
                "As",
                "for",
                "the",
                "former",
                "source,",
                "public",
                "social",
                "media",
                "posts",
                "are",
                "retrieved",
                "from",
                "news",
                "groups",
                "and",
                "key",
                "opinion",
                "leaders",
                "(KOLs).",
                "Many",
                "fake",
                "news,",
                "however,",
                "has",
                "been",
                "flagged",
                "and",
                "removed",
                "from",
                "the",
                "social",
                "networking",
                "sites",
                "since",
                "the",
                "enforcement",
                "of",
                "Vietnamese",
                "cybersecurity",
                "law",
                "in",
                "2019",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "to",
                "include",
                "the",
                "deleted",
                "fake",
                "news,",
                "we",
                "gather",
                "newspaper",
                "articles",
                "reporting",
                "these",
                "posts",
                "and",
                "recreate",
                "their",
                "content."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We collect the data for two months from August to October 2020. There are two main sources of the data: SNSs and Vietnamese newspapers. As for the former source, public social media posts are retrieved from news groups and key opinion leaders (KOLs). Many fake news, however, has been flagged and removed from the social networking sites since the enforcement of Vietnamese cybersecurity law in 2019 #TARGET_REF . Therefore, to include the deleted fake news, we gather newspaper articles reporting these posts and recreate their content.",
        "output": "{\"INFO\": [\"Many fake news,\", \"has been flagged and removed from the social networking sites since the enforcement of Vietnamese cybersecurity law in 2019 #TARGET_REF .\"], \"PERCEPT\": [\"We collect the data for two months from August to October 2020. There are two main sources of the data: SNSs and Vietnamese newspapers. As for the former source, public social media posts are retrieved from news groups and key opinion leaders (KOLs).\", \"to include the deleted fake news, we gather newspaper articles reporting these posts and recreate their content.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Linguistic",
                "Embedding",
                "For",
                "the",
                "language",
                "D,",
                "we",
                "first",
                "tokenize",
                "the",
                "sentence",
                "into",
                "a",
                "sequence",
                "of",
                "word",
                "tokens",
                "using",
                "WordPiece",
                "#TARGET_REF",
                ",",
                "then",
                "encode",
                "them",
                "into",
                "word",
                "embeddings",
                "W",
                "=",
                "{w",
                "j",
                "}",
                "T",
                "j=1",
                "where",
                "w",
                "j",
                "∈",
                "R",
                "dw",
                "is",
                "the",
                "feature",
                "vector.",
                "Similarly,",
                "an",
                "index",
                "position",
                "#REF",
                "embedding",
                "is",
                "supplemented",
                "to",
                "each",
                "word",
                "embedding."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Linguistic Embedding For the language D, we first tokenize the sentence into a sequence of word tokens using WordPiece #TARGET_REF , then encode them into word embeddings W = {w j } T j=1 where w j ∈ R dw is the feature vector. Similarly, an index position #REF embedding is supplemented to each word embedding.",
        "output": "{\"INFO\": [\"WordPiece #TARGET_REF ,\"], \"PERCEPT\": [\"we first tokenize the sentence into a sequence of word tokens using\", \"then encode them into word embeddings W = {w j } T j=1 where w j \\u2208 R dw is the feature vector.\"], \"BACK\": [\"Linguistic Embedding For the language D,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "addition,",
                "in",
                "order",
                "to",
                "have",
                "both",
                "the",
                "high",
                "performance",
                "of",
                "post-norm",
                "and",
                "the",
                "stable",
                "training",
                "of",
                "pre-norm",
                "(Nguyen",
                "and",
                "Salazar,",
                "2019),",
                "we",
                "use",
                "the",
                "methods",
                "mentioned",
                "in",
                "DeepNet",
                "#TARGET_REF",
                "For",
                "training",
                "the",
                "full-sentence",
                "translation",
                "model,",
                "given",
                "the",
                "source",
                "sentence",
                "x,",
                "the",
                "probability",
                "of",
                "predicting",
                "the",
                "target",
                "sentence",
                "y",
                "is",
                "as",
                "shown",
                "in",
                "Eq.",
                "1,",
                "and",
                "the",
                "training",
                "objective",
                "is",
                "to",
                "minimize",
                "the",
                "negative",
                "log-likelihood",
                "as",
                "shown",
                "in",
                "Eq.",
                "2.p(y|x)",
                "=",
                "|y|",
                "t=1",
                "p(y",
                "t",
                "|x,",
                "y",
                "&lt,t",
                ",",
                "θ)(1)loss",
                "f",
                "ull",
                "(θ)",
                "=",
                "−",
                "(x,y)∈D",
                "logp",
                "g",
                "(y|x,",
                "θ)",
                "(2)The",
                "batch",
                "size",
                "for",
                "training",
                "is",
                "4,096",
                "tokens",
                "per",
                "GPU,",
                "and",
                "we",
                "trained",
                "our",
                "model",
                "for",
                "7",
                "epochs",
                "on",
                "4",
                "NVIDIA",
                "V100",
                "GPUs",
                "for",
                "about",
                "10",
                "hours."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In addition, in order to have both the high performance of post-norm and the stable training of pre-norm (Nguyen and Salazar, 2019), we use the methods mentioned in DeepNet #TARGET_REF For training the full-sentence translation model, given the source sentence x, the probability of predicting the target sentence y is as shown in Eq. 1, and the training objective is to minimize the negative log-likelihood as shown in Eq. 2.p(y|x) = |y| t=1 p(y t |x, y &lt,t , θ)(1)loss f ull (θ) = − (x,y)∈D logp g (y|x, θ) (2)The batch size for training is 4,096 tokens per GPU, and we trained our model for 7 epochs on 4 NVIDIA V100 GPUs for about 10 hours.",
        "output": "{\"INFO\": [\"DeepNet #TARGET_REF\"], \"PERCEPT\": [\"we use the methods mentioned in\"], \"BACK\": [\"in order to have both the high performance of post-norm and the stable training of pre-norm (Nguyen and Salazar, 2019),\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "future",
                "work",
                "we",
                "hope",
                "to",
                "study",
                "the",
                "effect",
                "of",
                "corpus",
                "size",
                "and",
                "corpus",
                "diversity",
                "on",
                "translation",
                "effectiveness.",
                "We",
                "also",
                "hope",
                "to",
                "focus",
                "on",
                "evaluation",
                "of",
                "longer",
                "MWEs",
                "(i.e.,",
                "trigrams",
                "and",
                "longer)",
                "as",
                "well",
                "as",
                "consider",
                "the",
                "possibility",
                "that",
                "efficient",
                "suffix-based",
                "wildcard",
                "searches",
                "#TARGET_REF",
                "may",
                "enable",
                "correct",
                "translation",
                "of",
                "non-contiguous",
                "phrases."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "In future work we hope to study the effect of corpus size and corpus diversity on translation effectiveness. We also hope to focus on evaluation of longer MWEs (i.e., trigrams and longer) as well as consider the possibility that efficient suffix-based wildcard searches #TARGET_REF may enable correct translation of non-contiguous phrases.",
        "output": "{\"INFO\": [\"efficient suffix-based wildcard searches #TARGET_REF\"], \"PERCEPT\": [\"In future work we hope to study the effect of corpus size and corpus diversity on translation effectiveness. We also hope to focus on evaluation of longer MWEs (i.e., trigrams and longer) as well as consider the possibility that\", \"may enable correct translation of non-contiguous phrases.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "14th",
                "century",
                "#TARGET_REF",
                ".",
                "Even",
                "state-of-the-art",
                "multilingual",
                "NLP",
                "systems",
                "perform",
                "sub-optimally",
                "on",
                "Dravidian",
                "languages",
                "#REF",
                ".",
                "This",
                "can",
                "be",
                "explained",
                "by",
                "the",
                "fact",
                "that",
                "multilingual",
                "language",
                "models",
                "are",
                "often",
                "jointly",
                "trained",
                "on",
                "100+",
                "languages",
                "and",
                "Indian",
                "languages",
                "constitute",
                "only",
                "a",
                "small",
                "fraction",
                "of",
                "their",
                "vocabulary",
                "and",
                "training",
                "data",
                "(as",
                "shown",
                "in",
                "Figure",
                "2).",
                "Machine",
                "learning",
                "models",
                "and",
                "tools",
                "have",
                "been",
                "proposed",
                "for",
                "many",
                "Natural",
                "Language",
                "Understanding",
                "tasks.",
                "In",
                "this",
                "work,",
                "we",
                "focus",
                "on",
                "Extractive",
                "Question-Answering",
                "(QA),",
                "where",
                "the",
                "goal",
                "is",
                "to",
                "localize",
                "the",
                "answer",
                "to",
                "a",
                "question",
                "within",
                "a",
                "large",
                "context",
                "(see",
                "Figure",
                "1).",
                "Specifically,",
                "we",
                "aim",
                "to",
                "develop",
                "a",
                "common",
                "multilingual",
                "question",
                "answering",
                "model",
                "for",
                "multiple",
                "Indian",
                "languages.",
                "A",
                "multilingual",
                "model",
                "has",
                "several",
                "advantages:",
                "(1)",
                "learning",
                "of",
                "cues",
                "across",
                "different",
                "languages,",
                "(2)",
                "a",
                "single",
                "model",
                "for",
                "many",
                "languages,",
                "and",
                "(3)",
                "avoiding",
                "dependency",
                "on",
                "English",
                "translation",
                "during",
                "inference.",
                "In",
                "this",
                "work,",
                "we",
                "start",
                "with",
                "a",
                "pre-trained",
                "multilingual",
                "Bidi-",
                "rectional",
                "Encoder",
                "Representations",
                "from",
                "Transformers",
                "(mBERT)",
                "model",
                "and",
                "further",
                "pre-train",
                "it",
                "with",
                "SQuAD",
                "#REF",
                ",",
                "a",
                "large-scale",
                "question",
                "answering",
                "dataset",
                "in",
                "English.",
                "The",
                "resulting",
                "English-language",
                "mBERT-QA",
                "model",
                "is",
                "fine-tuned",
                "and",
                "evaluated",
                "for",
                "Indian",
                "languages",
                "Tamil",
                "and",
                "Hindi",
                "using",
                "the",
                "ChAII",
                "dataset",
                "#REF",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "14th century #TARGET_REF . Even state-of-the-art multilingual NLP systems perform sub-optimally on Dravidian languages #REF . This can be explained by the fact that multilingual language models are often jointly trained on 100+ languages and Indian languages constitute only a small fraction of their vocabulary and training data (as shown in Figure 2). Machine learning models and tools have been proposed for many Natural Language Understanding tasks. In this work, we focus on Extractive Question-Answering (QA), where the goal is to localize the answer to a question within a large context (see Figure 1). Specifically, we aim to develop a common multilingual question answering model for multiple Indian languages. A multilingual model has several advantages: (1) learning of cues across different languages, (2) a single model for many languages, and (3) avoiding dependency on English translation during inference. In this work, we start with a pre-trained multilingual Bidi- rectional Encoder Representations from Transformers (mBERT) model and further pre-train it with SQuAD #REF , a large-scale question answering dataset in English. The resulting English-language mBERT-QA model is fine-tuned and evaluated for Indian languages Tamil and Hindi using the ChAII dataset #REF .",
        "output": "{\"INFO\": [\"14th century #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "they",
                "are",
                "both",
                "considered",
                "low-resource",
                "languages.",
                "Kinyarwanda",
                "in",
                "particular,",
                "though",
                "spoken",
                "by",
                "approximately",
                "13-22",
                "million",
                "people",
                "5",
                ",",
                "has",
                "very",
                "little",
                "text",
                "data",
                "available",
                "in",
                "that",
                "language,",
                "with",
                "fewer",
                "than",
                "3,000",
                "articles",
                "on",
                "the",
                "Kinyarwanda-language",
                "Wikipedia,",
                "and",
                "Swahili",
                "comparatively",
                "ahead",
                "but",
                "still",
                "poorly",
                "resourced",
                "at",
                "approximately",
                "68,000",
                "articles,",
                "far",
                "less",
                "than",
                "many",
                "European",
                "languages.",
                "6",
                ",",
                "though",
                "some",
                "datasets",
                "have",
                "been",
                "created",
                "such",
                "as",
                "KINNEWS",
                "#REF",
                ".",
                "On",
                "the",
                "other",
                "hand,",
                "Kinyarwanda",
                "is",
                "uniquely",
                "placed",
                "as",
                "a",
                "language",
                "to",
                "leverage",
                "speech-based",
                "technologies,",
                "due",
                "to",
                "well-organized",
                "efforts",
                "7",
                "to",
                "collect",
                "voice",
                "data",
                "for",
                "that",
                "language.",
                "It",
                "is",
                "in",
                "fact",
                "one",
                "of",
                "the",
                "largest",
                "subsets",
                "available",
                "on",
                "the",
                "Common",
                "Voice",
                "Dataset",
                "#TARGET_REF",
                ",",
                "with",
                "1,183",
                "hours",
                "of",
                "voice",
                "clips",
                "collected",
                "and",
                "validated.",
                "Choosing",
                "these",
                "two",
                "languages",
                "allowed",
                "us",
                "to",
                "test",
                "the",
                "use",
                "of",
                "the",
                "technique",
                "on",
                "legitimately",
                "low-resourced",
                "languages",
                "that",
                "could",
                "benefit",
                "from",
                "improved",
                "NLP",
                "technology,",
                "and",
                "which",
                "as",
                "part",
                "of",
                "the",
                "same",
                "family",
                "of",
                "languages",
                "5",
                "Sources",
                "vary:",
                "Ethnologue",
                "cites",
                "\"Total",
                "users",
                "in",
                "all",
                "countries:",
                "13,133,980\",",
                "but",
                "there",
                "are",
                "22",
                "million",
                "according",
                "to",
                "WorldData.info",
                "(https://www.worlddata.info/languages/kinyarwanda.php)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "they are both considered low-resource languages. Kinyarwanda in particular, though spoken by approximately 13-22 million people 5 , has very little text data available in that language, with fewer than 3,000 articles on the Kinyarwanda-language Wikipedia, and Swahili comparatively ahead but still poorly resourced at approximately 68,000 articles, far less than many European languages. 6 , though some datasets have been created such as KINNEWS #REF . On the other hand, Kinyarwanda is uniquely placed as a language to leverage speech-based technologies, due to well-organized efforts 7 to collect voice data for that language. It is in fact one of the largest subsets available on the Common Voice Dataset #TARGET_REF , with 1,183 hours of voice clips collected and validated. Choosing these two languages allowed us to test the use of the technique on legitimately low-resourced languages that could benefit from improved NLP technology, and which as part of the same family of languages 5 Sources vary: Ethnologue cites \"Total users in all countries: 13,133,980\", but there are 22 million according to WorldData.info (https://www.worlddata.info/languages/kinyarwanda.php).",
        "output": "{\"INFO\": [\"the Common Voice Dataset #TARGET_REF , with 1,183 hours of voice clips collected and validated.\"], \"PERCEPT\": [\"It is\", \"one of the largest subsets available on\"], \"BACK\": [\"Kinyarwanda is uniquely placed as a language to leverage speech-based technologies,\"]}"
    },
    {
        "gold": {
            "text": [
                "Proposed",
                "model",
                "I",
                "propose",
                "a",
                "log-bilinear",
                "model",
                "#TARGET_REF",
                "using",
                "word",
                "embeddings",
                "as",
                "input:",
                "1"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                0
            ]
        },
        "input": "Proposed model I propose a log-bilinear model #TARGET_REF using word embeddings as input: 1",
        "output": "{\"INFO\": [\"log-bilinear model #TARGET_REF\"], \"PERCEPT\": [\"Proposed model I propose a\", \"using word embeddings as input:\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Prior",
                "to",
                "this",
                "shared",
                "task,",
                "some",
                "studies",
                "have",
                "created",
                "datasets",
                "for",
                "similar",
                "tasks",
                "#REF",
                ".",
                "However,",
                "one",
                "of",
                "them",
                "is",
                "created",
                "for",
                "publications",
                "written",
                "in",
                "Japanese",
                "#TARGET_REF",
                ",",
                "making",
                "it",
                "nearly",
                "impossible",
                "to",
                "transfer",
                "to",
                "English",
                "literature.",
                "While",
                "two",
                "other",
                "datasets",
                "#REF",
                "only",
                "annotate",
                "small-scale",
                "golden",
                "datasets",
                "for",
                "evaluation",
                "purposes.",
                "As",
                "the",
                "result,",
                "no",
                "training",
                "data",
                "is",
                "available",
                "for",
                "training",
                "deep",
                "neural",
                "network",
                "models.",
                "In",
                "this",
                "shared",
                "task,",
                "we",
                "provide",
                "a",
                "large-scale",
                "dataset",
                "for",
                "English",
                "literature",
                "that",
                "we",
                "believe",
                "will",
                "provide",
                "enough",
                "supervision",
                "for",
                "the",
                "promising",
                "deep",
                "neural",
                "network-based",
                "models."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Prior to this shared task, some studies have created datasets for similar tasks #REF . However, one of them is created for publications written in Japanese #TARGET_REF , making it nearly impossible to transfer to English literature. While two other datasets #REF only annotate small-scale golden datasets for evaluation purposes. As the result, no training data is available for training deep neural network models. In this shared task, we provide a large-scale dataset for English literature that we believe will provide enough supervision for the promising deep neural network-based models.",
        "output": "{\"INFO\": [\"one\", \"is created for publications written in Japanese #TARGET_REF ,\"], \"PERCEPT\": [\"of them\", \"making it nearly impossible to transfer to English literature.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "#TARGET_REF",
                ",",
                "authors",
                "propose",
                "to",
                "carefully",
                "organise",
                "the",
                "batches",
                "so",
                "that",
                "only",
                "a",
                "subset",
                "K",
                "of",
                "the",
                "target",
                "vocabulary",
                "is",
                "possibly",
                "generated",
                "at",
                "training",
                "time.",
                "This",
                "allows",
                "the",
                "system",
                "to",
                "train",
                "a",
                "model",
                "with",
                "much",
                "larger",
                "target",
                "vocabulary",
                "without",
                "substantially",
                "increasing",
                "the",
                "computational",
                "complexity.",
                "Another",
                "alternative",
                "is",
                "proposed",
                "by",
                "#REF",
                "where",
                "a",
                "structured",
                "output",
                "layer",
                "(SOUL)",
                "is",
                "defined",
                "to",
                "handle",
                "the",
                "words",
                "not",
                "appearing",
                "in",
                "the",
                "shortlist.",
                "This",
                "allows",
                "the",
                "system",
                "to",
                "always",
                "apply",
                "the",
                "softmax",
                "normalization",
                "on",
                "a",
                "layer",
                "with",
                "reduced",
                "size."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In #TARGET_REF , authors propose to carefully organise the batches so that only a subset K of the target vocabulary is possibly generated at training time. This allows the system to train a model with much larger target vocabulary without substantially increasing the computational complexity. Another alternative is proposed by #REF where a structured output layer (SOUL) is defined to handle the words not appearing in the shortlist. This allows the system to always apply the softmax normalization on a layer with reduced size.",
        "output": "{\"INFO\": [\"In #TARGET_REF , authors propose to carefully organise the batches so that only a subset K of the target vocabulary is possibly generated at training time.\"], \"PERCEPT\": [\"This allows the system to train a model with much larger target vocabulary without substantially increasing the computational complexity.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Outside",
                "of",
                "speech",
                "recognition",
                "focused",
                "work,",
                "#REF",
                "(and",
                "other",
                "researchers",
                "cited",
                "therein)",
                "attempt",
                "to",
                "\"fuse\"",
                "audio",
                "and",
                "text",
                "at",
                "the",
                "word",
                "level",
                "for",
                "emotion",
                "recognition.",
                "They",
                "introduce",
                "another",
                "architecture",
                "that",
                "internally",
                "represents",
                "both",
                "audio",
                "and",
                "text.",
                "However,",
                "the",
                "so-called",
                "WISE",
                "framework",
                "relies",
                "on",
                "speech",
                "recognition",
                "to",
                "generate",
                "the",
                "text",
                "corresponding",
                "to",
                "audio",
                "frames",
                "in",
                "real-time.",
                "The",
                "current",
                "work",
                "explicitly",
                "avoids",
                "reliance",
                "on",
                "speech",
                "recognition.",
                "The",
                "2021",
                "Multimodal",
                "Sentiment",
                "Analysis",
                "(MuSe)",
                "challenge",
                "continues",
                "this",
                "vein",
                "of",
                "research",
                "integrating",
                "audio,",
                "video,",
                "text,",
                "and",
                "physiology",
                "data",
                "in",
                "an",
                "emotion",
                "recognition",
                "task",
                "#REF",
                ".",
                "Contributions",
                "to",
                "this",
                "challenge,",
                "such",
                "as",
                "#TARGET_REF",
                ",",
                "introduce",
                "a",
                "variety",
                "of",
                "ways",
                "to",
                "\"fuse\"",
                "audio",
                "and",
                "text",
                "inputs.",
                "However,",
                "these",
                "contributions",
                "are",
                "squarely",
                "focused",
                "on",
                "emotion/sentiment",
                "analysis",
                "and",
                "do",
                "not",
                "propose",
                "methods",
                "for",
                "flexible,",
                "phonetic",
                "language",
                "models.",
                "#REF",
                "introduced",
                "functionality",
                "for",
                "\"textless\"",
                "NLP.",
                "They",
                "explored",
                "the",
                "possibility",
                "of",
                "creating",
                "a",
                "dialogue",
                "system",
                "from",
                "only",
                "audio",
                "inputs",
                "(i.e.,",
                "without",
                "text).",
                "As",
                "part",
                "of",
                "this",
                "system,",
                "language",
                "models",
                "are",
                "directly",
                "trained",
                "on",
                "audio",
                "units",
                "without",
                "any",
                "text.",
                "This",
                "advances",
                "the",
                "state-of-the-art",
                "with",
                "regard",
                "to",
                "self-supervised",
                "speech",
                "methods,",
                "but",
                "it",
                "does",
                "not",
                "provide",
                "the",
                "flexibility",
                "in",
                "audio",
                "and/or",
                "text",
                "language",
                "modeling",
                "introduced",
                "here."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Outside of speech recognition focused work, #REF (and other researchers cited therein) attempt to \"fuse\" audio and text at the word level for emotion recognition. They introduce another architecture that internally represents both audio and text. However, the so-called WISE framework relies on speech recognition to generate the text corresponding to audio frames in real-time. The current work explicitly avoids reliance on speech recognition. The 2021 Multimodal Sentiment Analysis (MuSe) challenge continues this vein of research integrating audio, video, text, and physiology data in an emotion recognition task #REF . Contributions to this challenge, such as #TARGET_REF , introduce a variety of ways to \"fuse\" audio and text inputs. However, these contributions are squarely focused on emotion/sentiment analysis and do not propose methods for flexible, phonetic language models. #REF introduced functionality for \"textless\" NLP. They explored the possibility of creating a dialogue system from only audio inputs (i.e., without text). As part of this system, language models are directly trained on audio units without any text. This advances the state-of-the-art with regard to self-supervised speech methods, but it does not provide the flexibility in audio and/or text language modeling introduced here.",
        "output": "{\"INFO\": [\"#TARGET_REF , introduce a variety of ways to \\\"fuse\\\" audio and text inputs.\"], \"PERCEPT\": [\"such as\"], \"BACK\": [\"Contributions to this challenge,\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "we",
                "discussed",
                "in",
                "Section",
                "4.1.2,",
                "we",
                "computed",
                "the",
                "annotation",
                "structure",
                "accuracy",
                "(ASA),",
                "and",
                "it",
                "turns",
                "out",
                "that",
                "its",
                "range",
                "was",
                "from",
                "98.9",
                "%",
                "to",
                "100.0",
                "%.",
                "This",
                "means",
                "that",
                "the",
                "proposed",
                "joint",
                "model",
                "can",
                "consistently",
                "predict",
                "transcriptions",
                "and",
                "the",
                "linguistic",
                "annotations",
                "in",
                "the",
                "correct",
                "order",
                "almost",
                "perfectly.",
                "We",
                "found",
                "that",
                "almost",
                "all",
                "errors",
                "of",
                "the",
                "transition",
                "occurred",
                "in",
                "the",
                "last",
                "word,",
                "which",
                "might",
                "be",
                "caused",
                "by",
                "beam",
                "search",
                "errors.",
                "Pipeline",
                "is",
                "ASR",
                "predicting",
                "transcriptions",
                "followed",
                "by",
                "the",
                "NLP-based",
                "linguistic",
                "annotation",
                "system",
                "#TARGET_REF",
                ".",
                "Proposed",
                "predicts",
                "graphemes",
                "and",
                "phonemes",
                "followed",
                "by",
                "POS",
                "tags",
                "from",
                "speech.",
                "Note",
                "that",
                "we",
                "used",
                "only",
                "the",
                "sentences",
                "whose",
                "hypothesized",
                "ASR",
                "transcript",
                "is",
                "predicted",
                "correctly",
                "for",
                "evaluation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "As we discussed in Section 4.1.2, we computed the annotation structure accuracy (ASA), and it turns out that its range was from 98.9 % to 100.0 %. This means that the proposed joint model can consistently predict transcriptions and the linguistic annotations in the correct order almost perfectly. We found that almost all errors of the transition occurred in the last word, which might be caused by beam search errors. Pipeline is ASR predicting transcriptions followed by the NLP-based linguistic annotation system #TARGET_REF . Proposed predicts graphemes and phonemes followed by POS tags from speech. Note that we used only the sentences whose hypothesized ASR transcript is predicted correctly for evaluation.",
        "output": "{\"INFO\": [\"the NLP-based linguistic annotation system #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Pipeline is ASR predicting transcriptions followed by\"]}"
    },
    {
        "gold": {
            "text": [
                "Bidirectional",
                "Encoder",
                "Representations",
                "from",
                "Transformers",
                "(BERT)",
                "#TARGET_REF",
                "is",
                "a",
                "deep",
                "learning",
                "model",
                "for",
                "general-purpose",
                "language",
                "representations.",
                "BERT",
                "is",
                "often",
                "used",
                "as",
                "the",
                "backbone",
                "model",
                "for",
                "several",
                "NLP",
                "tasks",
                "like",
                "semantic",
                "analysis,",
                "question",
                "answering,",
                "and",
                "named",
                "entity",
                "recognition.",
                "The",
                "bidirectional",
                "transformer",
                "used",
                "in",
                "BERT",
                "has",
                "a",
                "deeper",
                "sense",
                "of",
                "language",
                "context",
                "and",
                "generates",
                "intricate",
                "semantic",
                "feature",
                "representations.",
                "These",
                "representations",
                "are",
                "learned",
                "through",
                "a",
                "pre-training",
                "step",
                "using",
                "Next",
                "Sentence",
                "Prediction",
                "(NSP)",
                "and",
                "Masked",
                "Language",
                "Modelling",
                "(MLM)",
                "as",
                "pretext",
                "tasks",
                "and",
                "transferred",
                "to",
                "the",
                "downstream",
                "NLP",
                "tasks.",
                "The",
                "goal",
                "of",
                "the",
                "Next",
                "Sentence",
                "Prediction",
                "task",
                "is",
                "to",
                "identify",
                "whether",
                "the",
                "two",
                "input",
                "sentences",
                "are",
                "consecutive",
                "or",
                "not.",
                "In",
                "Masked",
                "Language",
                "Modelling,",
                "BERT",
                "is",
                "trained",
                "to",
                "predict",
                "randomly",
                "masked",
                "words",
                "in",
                "a",
                "sentence.",
                "The",
                "Transformer",
                "network",
                "receives",
                "a",
                "sequence",
                "of",
                "tokens",
                "as",
                "input",
                "and",
                "utilizes",
                "the",
                "attention",
                "mechanism",
                "to",
                "learn",
                "the",
                "contextual",
                "relationships",
                "between",
                "words",
                "in",
                "a",
                "text.",
                "These",
                "relationships",
                "can",
                "then",
                "be",
                "used",
                "to",
                "extract",
                "high-quality"
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Bidirectional Encoder Representations from Transformers (BERT) #TARGET_REF is a deep learning model for general-purpose language representations. BERT is often used as the backbone model for several NLP tasks like semantic analysis, question answering, and named entity recognition. The bidirectional transformer used in BERT has a deeper sense of language context and generates intricate semantic feature representations. These representations are learned through a pre-training step using Next Sentence Prediction (NSP) and Masked Language Modelling (MLM) as pretext tasks and transferred to the downstream NLP tasks. The goal of the Next Sentence Prediction task is to identify whether the two input sentences are consecutive or not. In Masked Language Modelling, BERT is trained to predict randomly masked words in a sentence. The Transformer network receives a sequence of tokens as input and utilizes the attention mechanism to learn the contextual relationships between words in a text. These relationships can then be used to extract high-quality",
        "output": "{\"INFO\": [\"Bidirectional Encoder Representations from Transformers (BERT) #TARGET_REF is a deep learning model for general-purpose language representations.\"], \"PERCEPT\": [], \"BACK\": [\"BERT is often used as the backbone model for several NLP tasks like semantic analysis, question answering, and named entity recognition. The bidirectional transformer used in BERT has a deeper sense of language context and generates intricate semantic feature representations.\", \"BERT is trained to predict randomly masked words in a sentence.\"]}"
    },
    {
        "gold": {
            "text": [
                "Comparing",
                "Eq.",
                "6",
                "with",
                "Eq.",
                "3,",
                "the",
                "major",
                "difference",
                "is",
                "that",
                "during",
                "inference",
                "the",
                "model",
                "makes",
                "new",
                "predictions",
                "based",
                "on",
                "its",
                "own",
                "previous",
                "predictions",
                "S",
                "&lt,t",
                "instead",
                "of",
                "the",
                "reference",
                "S",
                "*",
                "&lt,t",
                ".",
                "As",
                "a",
                "result,",
                "even",
                "if",
                "the",
                "generation",
                "model",
                "g",
                "achieves",
                "very",
                "high",
                "accuracy",
                "w.r.t.",
                "Eq.",
                "3,",
                "once",
                "S",
                "&lt,t",
                "starts",
                "to",
                "deviate",
                "from",
                "S",
                "*",
                ",",
                "there",
                "is",
                "the",
                "risk",
                "that",
                "the",
                "performance",
                "of",
                "g",
                "will",
                "significantly",
                "degrade.",
                "This",
                "problem",
                "has",
                "been",
                "identified",
                "as",
                "the",
                "exposure",
                "bias",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "Comparing Eq. 6 with Eq. 3, the major difference is that during inference the model makes new predictions based on its own previous predictions S &lt,t instead of the reference S * &lt,t . As a result, even if the generation model g achieves very high accuracy w.r.t. Eq. 3, once S &lt,t starts to deviate from S * , there is the risk that the performance of g will significantly degrade. This problem has been identified as the exposure bias #TARGET_REF .",
        "output": "{\"INFO\": [\"This problem has been identified as the exposure bias #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"even if the generation model g achieves very high accuracy w.r.t. Eq. 3, once S &lt,t starts to deviate from S * , there is the risk that the performance of g will significantly degrade.\"]}"
    },
    {
        "gold": {
            "text": [
                "on",
                "as",
                "an",
                "adverbial",
                "or",
                "a",
                "prepositional",
                "phrase,",
                "as",
                "in",
                "Jean",
                "a",
                "traversé",
                "le",
                "lac",
                "à",
                "la",
                "nage,",
                "(Jean",
                "crosses",
                "the",
                "lake",
                "by",
                "swimming).",
                "This",
                "type",
                "of",
                "structural",
                "correspondence",
                "has",
                "been",
                "typically",
                "handled",
                "best",
                "by",
                "interlingua",
                "approaches,",
                "since",
                "traditional",
                "transfer",
                "approaches",
                "required",
                "that",
                "every",
                "possible",
                "combination",
                "of",
                "manner",
                "of",
                "motion",
                "verb",
                "and",
                "path",
                "prepositional",
                "phrase",
                "be",
                "listed",
                "explicitly,",
                "and",
                "paired",
                "with",
                "its",
                "target",
                "language",
                "equivalent.",
                "The",
                "lexico-structural",
                "approach",
                "allows",
                "the",
                "entire",
                "class",
                "of",
                "English",
                "manner",
                "of",
                "motion",
                "verbs",
                "that",
                "have",
                "adjoined",
                "path",
                "prepositional",
                "phrases,",
                "to",
                "be",
                "associated",
                "in",
                "a",
                "single",
                "transfer",
                "lexicon",
                "entry",
                "with",
                "the",
                "class",
                "of",
                "French",
                "directed",
                "motion",
                "verbs",
                "with",
                "adjoined",
                "manners",
                "of",
                "motion.",
                "This",
                "is",
                "effected",
                "by",
                "treating",
                "manner",
                "of",
                "motion,",
                "path",
                "and",
                "directed",
                "motion",
                "as",
                "cross-linguistic",
                "semantic",
                "features",
                "that",
                "occur",
                "in",
                "both",
                "languages,",
                "and",
                "serve",
                "to",
                "anchor",
                "the",
                "correspondences",
                "#TARGET_REF",
                ".",
                "These",
                "are",
                "the",
                "same",
                "basic",
                "components",
                "that",
                "Jackendoff",
                "ascribes",
                "to",
                "change-of-location",
                "verbs",
                "in",
                "his",
                "Lexical",
                "Conceptual",
                "Structures",
                "(LCS),",
                "GO,",
                "PATH",
                "and",
                "MANNER,",
                "#REF",
                ".",
                "A",
                "similar",
                "interlingua",
                "treatment,",
                "also",
                "based",
                "on",
                "LCS,",
                "would",
                "decompose",
                "the",
                "English",
                "phrase",
                "swim",
                "across",
                "the",
                "lake",
                "into",
                "the",
                "same",
                "three",
                "separate",
                "components",
                "which",
                "would",
                "constitute",
                "the",
                "predicates",
                "of",
                "the",
                "predicate-argument",
                "structure.",
                "This",
                "predicate",
                "argument",
                "structure,",
                "the",
                "LCS,",
                "then",
                "also",
                "serves",
                "as",
                "the",
                "representation",
                "for",
                "the",
                "French",
                "translation",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "on as an adverbial or a prepositional phrase, as in Jean a traversé le lac à la nage, (Jean crosses the lake by swimming). This type of structural correspondence has been typically handled best by interlingua approaches, since traditional transfer approaches required that every possible combination of manner of motion verb and path prepositional phrase be listed explicitly, and paired with its target language equivalent. The lexico-structural approach allows the entire class of English manner of motion verbs that have adjoined path prepositional phrases, to be associated in a single transfer lexicon entry with the class of French directed motion verbs with adjoined manners of motion. This is effected by treating manner of motion, path and directed motion as cross-linguistic semantic features that occur in both languages, and serve to anchor the correspondences #TARGET_REF . These are the same basic components that Jackendoff ascribes to change-of-location verbs in his Lexical Conceptual Structures (LCS), GO, PATH and MANNER, #REF . A similar interlingua treatment, also based on LCS, would decompose the English phrase swim across the lake into the same three separate components which would constitute the predicates of the predicate-argument structure. This predicate argument structure, the LCS, then also serves as the representation for the French translation #REF .",
        "output": "{\"INFO\": [\"This is effected by treating manner of motion, path and directed motion as cross-linguistic semantic features that occur in both languages, and serve to anchor the correspondences #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"The lexico-structural approach allows the entire class of English manner of motion verbs that have adjoined path prepositional phrases, to be associated in a single transfer lexicon entry with the class of French directed motion verbs with adjoined manners of motion.\", \"These are the same basic components that Jackendoff ascribes to change-of-location verbs in his Lexical Conceptual Structures (LCS), GO, PATH and MANNER, #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Despite",
                "of",
                "the",
                "advantages",
                "of",
                "using",
                "CCG",
                "categories",
                "to",
                "label",
                "non-terminals",
                "in",
                "the",
                "HPB",
                "system",
                "compared",
                "with",
                "SAMT",
                "labels,",
                "richness",
                "of",
                "CCG",
                "categories",
                "still",
                "leads",
                "to",
                "a",
                "large",
                "number",
                "of",
                "different",
                "non-terminal",
                "labels.",
                "This",
                "causes",
                "fragmentation",
                "of",
                "rule",
                "probabilities",
                "and",
                "consequently",
                "affects",
                "translation",
                "quality",
                "negatively.",
                "A",
                "CCG",
                "category",
                "C",
                "takes",
                "the",
                "form",
                "of",
                "C=(T\\L)/R",
                "where",
                "L",
                "represents",
                "the",
                "left",
                "argument",
                "category,",
                "R",
                "the",
                "right",
                "argument",
                "category,",
                "and",
                "T",
                "the",
                "resulting",
                "category.",
                "Each",
                "of",
                "these",
                "constituent",
                "categories",
                "might",
                "be",
                "atomic",
                "or",
                "complex.",
                "Furthermore,",
                "some",
                "atomic",
                "CCG",
                "categories",
                "have",
                "features",
                "expressed",
                "between",
                "brackets",
                "which",
                "describe",
                "certain",
                "syntactic",
                "information.",
                "For",
                "example,",
                "the",
                "atomic",
                "category",
                "S",
                "might",
                "have",
                "a",
                "feature",
                "attached",
                "to",
                "it",
                "which",
                "distinguishes",
                "types",
                "of",
                "sentences",
                "such",
                "as",
                "declarative",
                "S[dcl]",
                "or",
                "wh-question",
                "S[wq].",
                "All",
                "the",
                "additional",
                "information",
                "represented",
                "in",
                "a",
                "single",
                "CCG",
                "category",
                "increases",
                "the",
                "number",
                "of",
                "different",
                "CCG",
                "categories",
                "and",
                "leads",
                "to",
                "label",
                "sparsity",
                "problem.",
                "In",
                "order",
                "to",
                "address",
                "this",
                "problem,",
                "we",
                "simplify",
                "CCG",
                "non-terminal",
                "labels",
                "by",
                "reducing",
                "the",
                "amount",
                "of",
                "the",
                "information",
                "represented",
                "in",
                "them",
                "using",
                "the",
                "following",
                "approaches",
                "#TARGET_REF",
                ":"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Despite of the advantages of using CCG categories to label non-terminals in the HPB system compared with SAMT labels, richness of CCG categories still leads to a large number of different non-terminal labels. This causes fragmentation of rule probabilities and consequently affects translation quality negatively. A CCG category C takes the form of C=(T\\L)/R where L represents the left argument category, R the right argument category, and T the resulting category. Each of these constituent categories might be atomic or complex. Furthermore, some atomic CCG categories have features expressed between brackets which describe certain syntactic information. For example, the atomic category S might have a feature attached to it which distinguishes types of sentences such as declarative S[dcl] or wh-question S[wq]. All the additional information represented in a single CCG category increases the number of different CCG categories and leads to label sparsity problem. In order to address this problem, we simplify CCG non-terminal labels by reducing the amount of the information represented in them using the following approaches #TARGET_REF :",
        "output": "{\"INFO\": [\"reducing the amount of the information represented in them using the following approaches #TARGET_REF :\"], \"PERCEPT\": [\"In order to address this problem, we simplify CCG non-terminal labels by\"], \"BACK\": [\"All the additional information represented in a single CCG category increases the number of different CCG categories and leads to label sparsity problem.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "fact,",
                "homophily",
                "is",
                "so",
                "prominent,",
                "#REF",
                "noted",
                "in",
                "their",
                "work",
                "that",
                "the",
                "profiles",
                "they",
                "generated",
                "from",
                "the",
                "social",
                "graph",
                "of",
                "users",
                "and",
                "tweets",
                "could",
                "encode",
                "patters",
                "of",
                "similar",
                "linguistic",
                "practices",
                "amongst",
                "connected",
                "users",
                "in",
                "the",
                "Waseem",
                "and",
                "Hovy",
                "(2016)",
                "dataset,",
                "hence",
                "allowing",
                "for",
                "comments",
                "with",
                "implicit",
                "and",
                "generalized",
                "sexism",
                "or",
                "racism",
                "to",
                "be",
                "better",
                "detected.",
                "Moreover,",
                "homophily",
                "has",
                "direct",
                "associations",
                "with",
                "all",
                "the",
                "four",
                "aspects",
                "of",
                "context",
                "that",
                "we",
                "described",
                "in",
                "section",
                "2,",
                "i.e.,",
                "similar",
                "sociolinguistic",
                "norms",
                "and",
                "shared",
                "language",
                "markers",
                "facilitate",
                "homophilic",
                "ties",
                "in",
                "social",
                "networks",
                "#TARGET_REF",
                ",",
                "as",
                "do",
                "shared",
                "beliefs,",
                "stereotypes,",
                "and",
                "demographic",
                "traits",
                "#REF",
                ".",
                "Therefore,",
                "capturing",
                "homophily",
                "allows",
                "for",
                "all",
                "the",
                "four",
                "aspects",
                "to",
                "be",
                "directly",
                "captured",
                "together.",
                "We",
                "note",
                "that",
                "just",
                "exploiting",
                "simplistic",
                "and",
                "limited",
                "inductive",
                "biases",
                "that",
                "are",
                "easy",
                "to",
                "extract,",
                "like",
                "gender",
                "of",
                "the",
                "user,",
                "can",
                "render",
                "methods",
                "prone",
                "to",
                "making",
                "faulty",
                "generalizations",
                "because",
                "of",
                "overfitting",
                "to",
                "patterns",
                "in",
                "the",
                "training",
                "data.",
                "This",
                "is",
                "also",
                "evident",
                "from",
                "the",
                "observations",
                "that",
                "#REF",
                "made",
                "in",
                "their",
                "work.",
                "They",
                "noted",
                "that",
                "the",
                "profiles",
                "they",
                "generated",
                "from",
                "the",
                "social",
                "graph",
                "consisting",
                "of",
                "user",
                "and",
                "tweet",
                "nodes",
                "improved",
                "F",
                "1",
                "scores",
                "over",
                "the",
                "profiles",
                "#REF",
                "generated",
                "from",
                "the",
                "social",
                "graph",
                "just",
                "consisting",
                "of",
                "users,",
                "with",
                "the",
                "gains",
                "mainly",
                "coming",
                "from",
                "increase",
                "in",
                "precision."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In fact, homophily is so prominent, #REF noted in their work that the profiles they generated from the social graph of users and tweets could encode patters of similar linguistic practices amongst connected users in the Waseem and Hovy (2016) dataset, hence allowing for comments with implicit and generalized sexism or racism to be better detected. Moreover, homophily has direct associations with all the four aspects of context that we described in section 2, i.e., similar sociolinguistic norms and shared language markers facilitate homophilic ties in social networks #TARGET_REF , as do shared beliefs, stereotypes, and demographic traits #REF . Therefore, capturing homophily allows for all the four aspects to be directly captured together. We note that just exploiting simplistic and limited inductive biases that are easy to extract, like gender of the user, can render methods prone to making faulty generalizations because of overfitting to patterns in the training data. This is also evident from the observations that #REF made in their work. They noted that the profiles they generated from the social graph consisting of user and tweet nodes improved F 1 scores over the profiles #REF generated from the social graph just consisting of users, with the gains mainly coming from increase in precision.",
        "output": "{\"INFO\": [\"similar sociolinguistic norms and shared language markers facilitate homophilic ties in social networks #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"as do shared beliefs, stereotypes, and demographic traits\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "this",
                "end,",
                "the",
                "alignment",
                "process",
                "involves",
                "training",
                "three",
                "#REF",
                "biencoder",
                "retrieval",
                "models",
                "to",
                "retrieve",
                "the",
                "most",
                "likely",
                "characters,",
                "locations,",
                "and",
                "objects",
                "required",
                "flesh",
                "the",
                "environment",
                "out",
                "and",
                "make",
                "the",
                "quest",
                "achievable.",
                "We",
                "use",
                "the",
                "same",
                "biencoder",
                "architecture",
                "proposed",
                "by",
                "#TARGET_REF",
                "which",
                "encodes",
                "context",
                "using",
                "one",
                "transformer",
                "and",
                "candidates",
                "with",
                "anotherscoring",
                "candidates",
                "via",
                "inner",
                "product",
                "between",
                "the",
                "two",
                "encoded",
                "vectors.",
                "The",
                "character",
                "retrieval",
                "model",
                "is",
                "conditioned",
                "on",
                "the",
                "initial",
                "character,",
                "quest,",
                "and",
                "location-producing",
                "additional",
                "characters",
                "required",
                "to",
                "complete",
                "the",
                "world."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To this end, the alignment process involves training three #REF biencoder retrieval models to retrieve the most likely characters, locations, and objects required flesh the environment out and make the quest achievable. We use the same biencoder architecture proposed by #TARGET_REF which encodes context using one transformer and candidates with anotherscoring candidates via inner product between the two encoded vectors. The character retrieval model is conditioned on the initial character, quest, and location-producing additional characters required to complete the world.",
        "output": "{\"INFO\": [\"#TARGET_REF which encodes context using one transformer and candidates with anotherscoring candidates via inner product between the two encoded vectors.\"], \"PERCEPT\": [\"We use the same biencoder architecture proposed by\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Leveraging",
                "sparsity",
                "of",
                "matrices",
                "We",
                "considered",
                "the",
                "option",
                "of",
                "performing",
                "matrix",
                "products",
                "involving",
                "large",
                "sparse",
                "matrices",
                "(Lines",
                "8,",
                "15,",
                "21,",
                "25",
                "in",
                "our",
                "pseudo-code",
                "(",
                "§2.2))",
                "by",
                "representing",
                "them",
                "in",
                "PyTorch's",
                "torch.sparse_coo_tensor",
                "format",
                "and",
                "using",
                "the",
                "torch.sparse",
                "framework",
                "to",
                "explicitly",
                "leverage",
                "their",
                "sparsity",
                "for",
                "saving",
                "compute.",
                "Unfortunately,",
                "the",
                "results",
                "were",
                "not",
                "encour-",
                "aging",
                "even",
                "for",
                "k",
                "=",
                "1%",
                "of",
                "number",
                "of",
                "keys",
                "(Figure",
                "4).",
                "While",
                "future",
                "devices",
                "might",
                "allow",
                "faster",
                "sparsedense",
                "products,",
                "in",
                "the",
                "immediate",
                "future,",
                "one",
                "can",
                "leverage",
                "block-sparse",
                "kernels",
                "#REF",
                "which",
                "have",
                "been",
                "successfully",
                "used",
                "for",
                "such",
                "products",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Leveraging sparsity of matrices We considered the option of performing matrix products involving large sparse matrices (Lines 8, 15, 21, 25 in our pseudo-code ( §2.2)) by representing them in PyTorch's torch.sparse_coo_tensor format and using the torch.sparse framework to explicitly leverage their sparsity for saving compute. Unfortunately, the results were not encour- aging even for k = 1% of number of keys (Figure 4). While future devices might allow faster sparsedense products, in the immediate future, one can leverage block-sparse kernels #REF which have been successfully used for such products #TARGET_REF .",
        "output": "{\"INFO\": [\"While future devices might allow faster sparsedense products, in the immediate future,\", \"which have been successfully used for such products #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"one can leverage block-sparse kernels #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "=",
                "{µ1,",
                "...,",
                "µn},",
                "and",
                "σ(.)",
                "is",
                "the",
                "standard",
                "deviation.",
                "catello",
                "et",
                "al.",
                "(",
                "2019)",
                "on",
                "image",
                "domain.",
                "In",
                "Table",
                "3",
                "(Top-3",
                "column)",
                "we",
                "report",
                "the",
                "number",
                "of",
                "appearances",
                "of",
                "a",
                "model",
                "among",
                "the",
                "top",
                "3",
                "highest",
                "scoring",
                "models",
                "on",
                "at",
                "least",
                "one",
                "disentanglement",
                "metric.",
                "The",
                "ranking",
                "suggests",
                "that",
                "β-VAE",
                "with",
                "smaller",
                "β",
                "values",
                "reach",
                "better",
                "disentangled",
                "representations,",
                "and",
                "MAT-VAE",
                "performing",
                "superior",
                "on",
                "YNOC",
                "and",
                "poorly",
                "on",
                "POS,",
                "highlighting",
                "its",
                "more",
                "challenging",
                "nature.",
                "For",
                "MAT-VAE",
                "we",
                "also",
                "observe",
                "an",
                "interesting",
                "correlation",
                "between",
                "sparsity",
                "and",
                "disentanglement:",
                "for",
                "instance",
                "on",
                "YNOC,",
                "MAT-VAE",
                "(β",
                "=",
                "0.01,",
                "λ",
                "=",
                "0.1)",
                "achieves",
                "the",
                "highest",
                "Hoyer",
                "(See",
                "Table",
                "4)",
                "and",
                "occurs",
                "7",
                "times",
                "among",
                "Top-3",
                "(see",
                "Table",
                "3).",
                "Interestingly,",
                "the",
                "success",
                "of",
                "MAT-VAE",
                "does",
                "not",
                "translate",
                "to",
                "POS",
                "dataset,",
                "where",
                "it",
                "underperforms",
                "AE.",
                "These",
                "two",
                "observations",
                "suggest",
                "that",
                "sparsity",
                "could",
                "be",
                "a",
                "facilitator",
                "for",
                "disentanglement,",
                "but",
                "achieving",
                "a",
                "stable",
                "level",
                "of",
                "sparsity",
                "remains",
                "as",
                "a",
                "challenge.",
                "The",
                "more",
                "recent",
                "development",
                "in",
                "the",
                "direction",
                "of",
                "sparsity,",
                "HSVAE",
                "#TARGET_REF",
                ",",
                "addresses",
                "the",
                "stability",
                "issue",
                "of",
                "MAT-VAE",
                "but",
                "we",
                "leave",
                "its",
                "exploration",
                "to",
                "future",
                "work."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "= {µ1, ..., µn}, and σ(.) is the standard deviation. catello et al. ( 2019) on image domain. In Table 3 (Top-3 column) we report the number of appearances of a model among the top 3 highest scoring models on at least one disentanglement metric. The ranking suggests that β-VAE with smaller β values reach better disentangled representations, and MAT-VAE performing superior on YNOC and poorly on POS, highlighting its more challenging nature. For MAT-VAE we also observe an interesting correlation between sparsity and disentanglement: for instance on YNOC, MAT-VAE (β = 0.01, λ = 0.1) achieves the highest Hoyer (See Table 4) and occurs 7 times among Top-3 (see Table 3). Interestingly, the success of MAT-VAE does not translate to POS dataset, where it underperforms AE. These two observations suggest that sparsity could be a facilitator for disentanglement, but achieving a stable level of sparsity remains as a challenge. The more recent development in the direction of sparsity, HSVAE #TARGET_REF , addresses the stability issue of MAT-VAE but we leave its exploration to future work.",
        "output": "{\"INFO\": [\"The more recent development in the direction of sparsity, HSVAE #TARGET_REF ,\"], \"PERCEPT\": [\"For MAT-VAE we also observe an interesting correlation between sparsity and disentanglement:\", \"Interestingly, the success of MAT-VAE does not translate to POS dataset, where it underperforms AE. These two observations suggest that sparsity could be a facilitator for disentanglement, but achieving a stable level of sparsity remains as a challenge.\", \"addresses the stability issue of MAT-VAE but we leave its exploration to future work.\"], \"BACK\": [\"for instance on YNOC, MAT-VAE (\\u03b2 = 0.01, \\u03bb = 0.1) achieves the highest Hoyer (See Table 4) and occurs 7 times among Top-3 (see Table 3).\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "other",
                "current",
                "actions",
                "in",
                "the",
                "field",
                "of",
                "LR",
                "(e.g.",
                "EAGLES,",
                "which",
                "is",
                "a",
                "direct",
                "descendant",
                "of",
                "the",
                "\"Pisa",
                "Group\",",
                "set-up",
                "at",
                "the",
                "Grosseto",
                "Workshop",
                "by",
                "the",
                "Istituto",
                "di",
                "Linguistica",
                "Computazionale",
                "(ILC)",
                "of",
                "Pisa",
                "and",
                "sponsored",
                "by",
                "the",
                "Association",
                "for",
                "Computational",
                "Linguistics",
                "#REF",
                "(ACL)",
                "to",
                "explore",
                "the",
                "feasibility",
                "of",
                "\"polytheoretical",
                "lexicons\"",
                "#REF",
                ")),",
                "the",
                "PAROLE",
                "and",
                "SIMPLE",
                "projects,",
                "building",
                "large",
                "corpora",
                "and",
                "lexicons",
                "for",
                "many",
                "European",
                "languages,",
                "are",
                "the",
                "follow-up",
                "of",
                "some",
                "initiatives",
                "promoted",
                "at",
                "the",
                "Grosseto",
                "Workshop.",
                "The",
                "Council",
                "of",
                "Europe,",
                "which",
                "had",
                "co-sponsored",
                "the",
                "workshop,",
                "formed",
                "a",
                "group",
                "of",
                "experts,",
                "representing",
                "European",
                "institutes",
                "with",
                "a",
                "well",
                "established",
                "tradition",
                "in",
                "the",
                "field",
                "of",
                "lexical",
                "and",
                "corpus",
                "studies,",
                "to",
                "explore",
                "the",
                "feasibility",
                "of",
                "harmonising",
                "their",
                "activities,",
                "in",
                "order",
                "to",
                "establish",
                "a",
                "Network",
                "of",
                "European",
                "Reference",
                "Corpora",
                "(NERC,",
                "for",
                "which",
                "see",
                "#TARGET_REF",
                ".",
                "This",
                "group,",
                "gradually",
                "enlarged",
                "to",
                "include",
                "members",
                "of",
                "all",
                "the",
                "European",
                "Union",
                "(EU)",
                "languages,",
                "constituted",
                "the",
                "PAROLE",
                "Consortium",
                "which",
                "has",
                "executed",
                "the",
                "LE",
                "(Language",
                "Engineering)",
                "PAROLE",
                "project",
                "now",
                "followed",
                "by",
                "the",
                "LE",
                "SIMPLE",
                "project",
                "carried",
                "on",
                "by",
                "a",
                "similar",
                "Consortium",
                "1",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "As other current actions in the field of LR (e.g. EAGLES, which is a direct descendant of the \"Pisa Group\", set-up at the Grosseto Workshop by the Istituto di Linguistica Computazionale (ILC) of Pisa and sponsored by the Association for Computational Linguistics #REF (ACL) to explore the feasibility of \"polytheoretical lexicons\" #REF )), the PAROLE and SIMPLE projects, building large corpora and lexicons for many European languages, are the follow-up of some initiatives promoted at the Grosseto Workshop. The Council of Europe, which had co-sponsored the workshop, formed a group of experts, representing European institutes with a well established tradition in the field of lexical and corpus studies, to explore the feasibility of harmonising their activities, in order to establish a Network of European Reference Corpora (NERC, for which see #TARGET_REF . This group, gradually enlarged to include members of all the European Union (EU) languages, constituted the PAROLE Consortium which has executed the LE (Language Engineering) PAROLE project now followed by the LE SIMPLE project carried on by a similar Consortium 1 .",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"This group, gradually enlarged to include members of all the European Union (EU) languages, constituted the PAROLE Consortium which has executed the LE (Language Engineering) PAROLE project now followed by the LE SIMPLE project carried on by a similar Consortium 1 .\"], \"BACK\": [\"The Council of Europe, which had co-sponsored the workshop, formed a group of experts, representing European institutes with a well established tradition in the field of lexical and corpus studies, to explore the feasibility of harmonising their activities, in order to establish a Network of European Reference Corpora (NERC, for which see\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "second",
                "dataset",
                "is",
                "Debatepedia",
                "arguments",
                "#TARGET_REF",
                ".",
                "A",
                "total",
                "of",
                "508",
                "topics",
                "are",
                "paired",
                "with",
                "15K",
                "pro",
                "and",
                "con",
                "responses,",
                "and",
                "we",
                "treat",
                "each",
                "pair",
                "as",
                "an",
                "argument",
                "and",
                "each",
                "topic",
                "and",
                "response",
                "as",
                "claim",
                "and",
                "statement,",
                "respectively."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The second dataset is Debatepedia arguments #TARGET_REF . A total of 508 topics are paired with 15K pro and con responses, and we treat each pair as an argument and each topic and response as claim and statement, respectively.",
        "output": "{\"INFO\": [\"Debatepedia arguments #TARGET_REF . A total of 508 topics are paired with 15K pro and con responses,\"], \"PERCEPT\": [\"The second dataset is\", \"and we treat each pair as an argument and each topic and response as claim and statement, respectively.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Toxicity",
                "Datasets",
                "in",
                "Online",
                "Community",
                "An",
                "extensive",
                "body",
                "of",
                "work",
                "has",
                "focused",
                "on",
                "datasets",
                "to",
                "detect",
                "toxicity",
                "including",
                "hate",
                "speech",
                "#REF",
                "and",
                "abusive",
                "language",
                "#TARGET_REF",
                ".",
                "However,",
                "the",
                "majority",
                "of",
                "toxicity",
                "datasets",
                "do",
                "not",
                "consider",
                "the",
                "context",
                "of",
                "a",
                "conversation,",
                "instead",
                "simply",
                "analysing",
                "a",
                "single",
                "utterance.",
                "Even",
                "if",
                "a",
                "model",
                "uses",
                "contextual",
                "information",
                "#REF",
                ",",
                "it",
                "is",
                "limited",
                "to",
                "metainformation",
                "(e.g.",
                "news",
                "title",
                "or",
                "user",
                "name)",
                "which",
                "is",
                "not",
                "sufficient",
                "to",
                "understand",
                "a",
                "conversation.",
                "In",
                "our",
                "research,",
                "context",
                "is",
                "defined",
                "as",
                "linguistic",
                "contextual",
                "information,",
                "particularly",
                "previous",
                "single",
                "or",
                "multiple",
                "utterances.",
                "Along",
                "similar",
                "lines,",
                "recent",
                "studies",
                "have",
                "focused",
                "on",
                "conversation",
                "aiming",
                "to",
                "discover",
                "warning",
                "signals",
                "#REF",
                ",",
                "to",
                "generate",
                "intervention",
                "responses",
                "#REF",
                ",",
                "or",
                "to",
                "measure",
                "the",
                "importance",
                "of",
                "context",
                "#REF",
                ".",
                "Existing",
                "toxicity",
                "datasets",
                "mainly",
                "focus",
                "on",
                "annotating",
                "at",
                "utterance-level,",
                "whereas",
                "ours",
                "conducts",
                "a",
                "dual-level",
                "annotation",
                "at",
                "utterance",
                "and",
                "token-level,",
                "while",
                "also",
                "providing",
                "a",
                "conversation",
                "history",
                "(see",
                "Table",
                "1).",
                "These",
                "extra",
                "features",
                "are",
                "what",
                "distinguish",
                "CONDA."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Toxicity Datasets in Online Community An extensive body of work has focused on datasets to detect toxicity including hate speech #REF and abusive language #TARGET_REF . However, the majority of toxicity datasets do not consider the context of a conversation, instead simply analysing a single utterance. Even if a model uses contextual information #REF , it is limited to metainformation (e.g. news title or user name) which is not sufficient to understand a conversation. In our research, context is defined as linguistic contextual information, particularly previous single or multiple utterances. Along similar lines, recent studies have focused on conversation aiming to discover warning signals #REF , to generate intervention responses #REF , or to measure the importance of context #REF . Existing toxicity datasets mainly focus on annotating at utterance-level, whereas ours conducts a dual-level annotation at utterance and token-level, while also providing a conversation history (see Table 1). These extra features are what distinguish CONDA.",
        "output": "{\"INFO\": [\"datasets to detect toxicity including\", \"abusive language #TARGET_REF .\"], \"PERCEPT\": [\"An extensive body of work has focused on\", \"However, the majority of toxicity datasets do not consider the context of a conversation, instead simply analysing a single utterance.\", \"Existing toxicity datasets mainly focus on annotating at utterance-level, whereas ours conducts a dual-level annotation at utterance and token-level, while also providing a conversation history\"], \"BACK\": [\"(see Table 1).\"]}"
    },
    {
        "gold": {
            "text": [
                "processing",
                "later",
                "from",
                "200",
                "ms",
                "onwards",
                "with",
                "a",
                "slight",
                "left-hemispheric",
                "predominance",
                "#REF",
                ".",
                "The",
                "word",
                "class",
                "effect",
                "emerged",
                "in",
                "early",
                "and",
                "late",
                "time",
                "windows",
                "with",
                "the",
                "effect",
                "at",
                "about",
                "550",
                "ms",
                "in",
                "line",
                "with",
                "the",
                "wellknown",
                "P600",
                "as",
                "an",
                "ERP",
                "indicator",
                "for",
                "syntactic",
                "processing",
                "#REF",
                ".",
                "Word",
                "length",
                "and",
                "frequency",
                "effects",
                "were",
                "stronger",
                "than",
                "the",
                "word",
                "class",
                "effect,",
                "see",
                "#REF",
                ".",
                "As",
                "expected,",
                "decoding",
                "accuracy",
                "increased",
                "when",
                "EEG",
                "signals",
                "were",
                "averaged",
                "across",
                "trials.",
                "Thus,",
                "carefully",
                "controlling",
                "each",
                "comparison",
                "of",
                "interest",
                "(e.g.",
                "word",
                "class)",
                "for",
                "the",
                "effects",
                "of",
                "no",
                "interest",
                "(e.g.",
                "word",
                "length",
                "and",
                "gressively",
                "generates",
                "dependencies",
                "amongst",
                "training",
                "samples",
                "thereby",
                "limiting",
                "their",
                "additional",
                "benefit",
                "beyond",
                "250k.",
                "We",
                "formally",
                "assessed",
                "whether",
                "the",
                "Transformer",
                "that",
                "scored",
                "best",
                "on",
                "the",
                "dev",
                "set",
                "obtained",
                "better",
                "decoding",
                "accuracy",
                "for",
                "250K",
                "than",
                "for",
                "the",
                "original",
                "20k",
                "training",
                "set",
                "(n.b.",
                "we",
                "performed",
                "this",
                "statistical",
                "test",
                "on",
                "the",
                "test",
                "set,",
                "because",
                "the",
                "3",
                "and",
                "10",
                "trial",
                "averages",
                "within",
                "the",
                "dev",
                "set",
                "were",
                "not",
                "independent",
                "from",
                "one",
                "another",
                "as",
                "a",
                "result",
                "of",
                "boostrapping).",
                "Indeed,",
                "for",
                "both",
                "3",
                "and",
                "10",
                "trial",
                "averages",
                "the",
                "Transformer's",
                "(but",
                "not",
                "the",
                "SVM's)",
                "decoding",
                "accuracy",
                "was",
                "significantly",
                "better",
                "for",
                "250k",
                "than",
                "the",
                "original",
                "20k",
                "training",
                "set",
                "(p",
                "&lt,",
                "0.01,",
                "Wilcoxon",
                "signed-rank",
                "test)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "processing later from 200 ms onwards with a slight left-hemispheric predominance #REF . The word class effect emerged in early and late time windows with the effect at about 550 ms in line with the wellknown P600 as an ERP indicator for syntactic processing #REF . Word length and frequency effects were stronger than the word class effect, see #REF . As expected, decoding accuracy increased when EEG signals were averaged across trials. Thus, carefully controlling each comparison of interest (e.g. word class) for the effects of no interest (e.g. word length and gressively generates dependencies amongst training samples thereby limiting their additional benefit beyond 250k. We formally assessed whether the Transformer that scored best on the dev set obtained better decoding accuracy for 250K than for the original 20k training set (n.b. we performed this statistical test on the test set, because the 3 and 10 trial averages within the dev set were not independent from one another as a result of boostrapping). Indeed, for both 3 and 10 trial averages the Transformer's (but not the SVM's) decoding accuracy was significantly better for 250k than the original 20k training set (p &lt, 0.01, Wilcoxon signed-rank test).",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "have",
                "also",
                "collated",
                "eye",
                "tracking",
                "measurements",
                "such",
                "as",
                "total",
                "fixation",
                "counts,",
                "average",
                "fixation",
                "duration",
                "and",
                "percentage",
                "change",
                "in",
                "pupil",
                "dilation,",
                "all",
                "of",
                "which",
                "are",
                "shown",
                "to",
                "be",
                "indicators",
                "of",
                "cognitive",
                "load",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "We have also collated eye tracking measurements such as total fixation counts, average fixation duration and percentage change in pupil dilation, all of which are shown to be indicators of cognitive load #TARGET_REF .",
        "output": "{\"INFO\": [\"all of which are shown to be indicators of cognitive load #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"We have also collated eye tracking measurements such as total fixation counts, average fixation duration and percentage change in pupil dilation,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "keystroke",
                "logging",
                "data",
                "gathered",
                "for",
                "Spanish-English",
                "post-editors",
                "allowed",
                "the",
                "computation",
                "of",
                "Pause",
                "to",
                "Word",
                "Ratio",
                "(PWR).",
                "For",
                "each",
                "segment,",
                "PWR",
                "is",
                "the",
                "ratio",
                "of",
                "the",
                "number",
                "of",
                "pauses",
                "exceeding",
                "300ms",
                "to",
                "the",
                "number",
                "of",
                "words",
                "in",
                "the",
                "MT",
                "segment,",
                "it",
                "is",
                "a",
                "measure",
                "of",
                "cognitive",
                "effort",
                "in",
                "post-editing",
                "#TARGET_REF",
                ".",
                "Higher",
                "PWR",
                "corresponds",
                "to",
                "higher",
                "cognitive",
                "effort.",
                "Contrary",
                "to",
                "expectation,",
                "the",
                "mean",
                "PWR",
                "for",
                "Spanish-English",
                "post-editors",
                "was",
                "slightly",
                "higher",
                "for",
                "the",
                "segments",
                "with",
                "alignment",
                "(0.70)",
                "than",
                "for",
                "those",
                "without",
                "alignment",
                "(0.63).",
                "However,",
                "the",
                "numerical",
                "difference",
                "was",
                "not",
                "significant."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The keystroke logging data gathered for Spanish-English post-editors allowed the computation of Pause to Word Ratio (PWR). For each segment, PWR is the ratio of the number of pauses exceeding 300ms to the number of words in the MT segment, it is a measure of cognitive effort in post-editing #TARGET_REF . Higher PWR corresponds to higher cognitive effort. Contrary to expectation, the mean PWR for Spanish-English post-editors was slightly higher for the segments with alignment (0.70) than for those without alignment (0.63). However, the numerical difference was not significant.",
        "output": "{\"INFO\": [\"PWR is the ratio of the number of pauses exceeding 300ms to the number of words in the MT segment, it is a measure of cognitive effort in post-editing #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Higher PWR corresponds to higher cognitive effort. Contrary to expectation, the mean PWR for Spanish-English post-editors was slightly higher for the segments with alignment (0.70) than for those without alignment (0.63).\"]}"
    },
    {
        "gold": {
            "text": [
                "Communities.",
                "There",
                "can",
                "be",
                "scenarios",
                "where",
                "whole",
                "communities",
                "of",
                "users",
                "on",
                "a",
                "platform",
                "may",
                "be",
                "indulging",
                "in",
                "abusive",
                "behavior,",
                "e.g.,",
                "by",
                "widely",
                "circulating",
                "an",
                "abusive",
                "view",
                "against",
                "a",
                "demographic",
                "group",
                "based",
                "on",
                "shared",
                "beliefs,",
                "common",
                "stereotypes",
                "or",
                "other",
                "homophilic",
                "ties.",
                "In",
                "such",
                "cases,",
                "just",
                "taking",
                "down",
                "specific",
                "instances",
                "of",
                "abusive",
                "language",
                "and",
                "providing",
                "justifications",
                "individually",
                "to",
                "the",
                "respective",
                "users",
                "may",
                "not",
                "prove",
                "effective.",
                "Users",
                "may",
                "continue",
                "to",
                "promote",
                "the",
                "abusive",
                "view,",
                "defying",
                "the",
                "norms",
                "of",
                "the",
                "platform",
                "in",
                "the",
                "process",
                "and",
                "ignoring",
                "the",
                "justifications",
                "given",
                "to",
                "them.",
                "The",
                "reason",
                "for",
                "this",
                "comes",
                "from",
                "social",
                "influence",
                "theory",
                "which",
                "says",
                "that",
                "a",
                "user's",
                "behavior",
                "is",
                "affected",
                "by",
                "three",
                "broad",
                "varieties",
                "of",
                "social",
                "influence",
                "#REF",
                ",",
                "i.e.,",
                "compliance,",
                "identification,",
                "and",
                "internalization.",
                "Compliance",
                "occurs",
                "when",
                "the",
                "user",
                "behaves",
                "a",
                "certain",
                "way",
                "so",
                "as",
                "to",
                "appear",
                "in",
                "congruence",
                "with",
                "opinions",
                "of",
                "others",
                "who",
                "matter",
                "to",
                "them,",
                "identification",
                "occurs",
                "when",
                "the",
                "user",
                "adopts",
                "behaviors",
                "in",
                "order",
                "to",
                "associate",
                "with",
                "others",
                "they",
                "admire,",
                "and",
                "internalization",
                "is",
                "when",
                "the",
                "user",
                "adopts",
                "the",
                "values",
                "and",
                "beliefs",
                "of",
                "others.",
                "The",
                "influences",
                "occur",
                "because",
                "of",
                "two",
                "needs",
                "of",
                "the",
                "user,",
                "the",
                "need",
                "to",
                "be",
                "liked",
                "(normative)",
                "and",
                "the",
                "need",
                "to",
                "be",
                "right",
                "(informational).",
                "In",
                "order",
                "to",
                "fulfill",
                "the",
                "latter,",
                "people",
                "may",
                "accept",
                "the",
                "three",
                "varieties",
                "of",
                "influence",
                "when",
                "there",
                "is",
                "lack",
                "of",
                "information,",
                "a",
                "concept",
                "known",
                "as",
                "social",
                "proof",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Communities. There can be scenarios where whole communities of users on a platform may be indulging in abusive behavior, e.g., by widely circulating an abusive view against a demographic group based on shared beliefs, common stereotypes or other homophilic ties. In such cases, just taking down specific instances of abusive language and providing justifications individually to the respective users may not prove effective. Users may continue to promote the abusive view, defying the norms of the platform in the process and ignoring the justifications given to them. The reason for this comes from social influence theory which says that a user's behavior is affected by three broad varieties of social influence #REF , i.e., compliance, identification, and internalization. Compliance occurs when the user behaves a certain way so as to appear in congruence with opinions of others who matter to them, identification occurs when the user adopts behaviors in order to associate with others they admire, and internalization is when the user adopts the values and beliefs of others. The influences occur because of two needs of the user, the need to be liked (normative) and the need to be right (informational). In order to fulfill the latter, people may accept the three varieties of influence when there is lack of information, a concept known as social proof #TARGET_REF .",
        "output": "{\"INFO\": [\"a concept known as social proof #TARGET_REF .\"], \"PERCEPT\": [\"The influences occur because of two needs of the user,\", \"the need to be right (informational). In order to fulfill the latter, people may accept the three varieties of influence when there is lack of information,\"], \"BACK\": [\"Compliance occurs when the user behaves a certain way so as to appear in congruence with opinions of others who matter to them, identification occurs when the user adopts behaviors in order to associate with others they admire, and internalization is when the user adopts the values and beliefs of others.\", \"the need to be liked (normative) and\"]}"
    },
    {
        "gold": {
            "text": [
                "Multi-Task",
                "Learning",
                "represents",
                "a",
                "training",
                "strategy",
                "where",
                "a",
                "shared",
                "model",
                "is",
                "simultaneously",
                "learning",
                "multiple",
                "tasks.",
                "#REF",
                "analysed",
                "the",
                "techniques",
                "applied",
                "in",
                "MTL",
                "and",
                "compared",
                "the",
                "hard",
                "parameter",
                "sharing",
                "and",
                "soft",
                "parameter",
                "sharing",
                "paradigms,",
                "concluding",
                "that",
                "the",
                "former",
                "is",
                "still",
                "pervasive",
                "in",
                "nowadays",
                "approaches.",
                "MTL",
                "proved",
                "to",
                "fasten",
                "the",
                "convergence",
                "and",
                "to",
                "improve",
                "the",
                "model",
                "performance",
                "in",
                "a",
                "variety",
                "of",
                "NLP",
                "applications,",
                "including",
                "named",
                "entity",
                "recognition",
                "#REF",
                ",",
                "fake",
                "news",
                "detection",
                "#REF",
                ",",
                "multilingual",
                "offensive",
                "language",
                "identification",
                "#REF",
                ",",
                "sentiment",
                "analysis",
                "#REF",
                ",",
                "humor",
                "classification",
                "#REF",
                ",",
                "recommender",
                "systems",
                "#REF",
                ",",
                "and",
                "even",
                "question",
                "answering",
                "#REF",
                ".",
                "MTL",
                "also",
                "increases",
                "performance",
                "in",
                "conjunction",
                "with",
                "semi-supervised",
                "learning",
                "#REF",
                ",",
                "curriculum",
                "learning",
                "#REF",
                ",",
                "sequence-tosequence",
                "#REF",
                ",",
                "reinforcement",
                "learning",
                "#REF",
                ",",
                "and",
                "adversarial",
                "learning",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0
            ]
        },
        "input": "Multi-Task Learning represents a training strategy where a shared model is simultaneously learning multiple tasks. #REF analysed the techniques applied in MTL and compared the hard parameter sharing and soft parameter sharing paradigms, concluding that the former is still pervasive in nowadays approaches. MTL proved to fasten the convergence and to improve the model performance in a variety of NLP applications, including named entity recognition #REF , fake news detection #REF , multilingual offensive language identification #REF , sentiment analysis #REF , humor classification #REF , recommender systems #REF , and even question answering #REF . MTL also increases performance in conjunction with semi-supervised learning #REF , curriculum learning #REF , sequence-tosequence #REF , reinforcement learning #REF , and adversarial learning #TARGET_REF .",
        "output": "{\"INFO\": [\"adversarial learning\"], \"PERCEPT\": [\"MTL also increases performance in conjunction with\"], \"BACK\": [\"Multi-Task Learning represents a training strategy where a shared model is simultaneously learning multiple tasks.\", \"semi-supervised learning #REF , curriculum learning #REF , sequence-tosequence #REF , reinforcement learning #REF , and\"]}"
    },
    {
        "gold": {
            "text": [
                "Given",
                "that",
                "Task",
                "1",
                "was",
                "present",
                "in",
                "previous",
                "editions",
                "of",
                "the",
                "SMM4h",
                "shared",
                "task",
                "#REF",
                ",",
                "several",
                "approaches",
                "were",
                "employed",
                "to",
                "address",
                "its",
                "challenges.",
                "For",
                "example,",
                "the",
                "winning",
                "team",
                "from",
                "2019",
                "#REF",
                "used",
                "an",
                "ensemble",
                "of",
                "BioBERT-CRF",
                "models",
                "for",
                "the",
                "ADE",
                "extraction",
                "task,",
                "while",
                "addressing",
                "the",
                "resolution",
                "task",
                "as",
                "a",
                "classification.",
                "The",
                "system",
                "proposed",
                "by",
                "#REF",
                "ranked",
                "first",
                "at",
                "the",
                "end-to-end",
                "2020",
                "competition",
                "using",
                "the",
                "pretrained",
                "EnDR-BERT",
                "#REF",
                "and",
                "the",
                "CSIRO",
                "Adverse",
                "Drug",
                "Event",
                "Corpus",
                "(CADEC)",
                "#REF",
                "for",
                "further",
                "training",
                "the",
                "model.",
                "In",
                "addition,",
                "#TARGET_REF",
                "showed",
                "that",
                "bidirectional",
                "Transformers",
                "trained",
                "using",
                "class",
                "weighting,",
                "together",
                "with",
                "ensembles",
                "that",
                "combine",
                "various",
                "configurations,",
                "achieve",
                "an",
                "F1-score",
                "of",
                ".705",
                "on",
                "the",
                "dataset",
                "made",
                "available",
                "for",
                "that",
                "edition",
                "of",
                "the",
                "competition."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Given that Task 1 was present in previous editions of the SMM4h shared task #REF , several approaches were employed to address its challenges. For example, the winning team from 2019 #REF used an ensemble of BioBERT-CRF models for the ADE extraction task, while addressing the resolution task as a classification. The system proposed by #REF ranked first at the end-to-end 2020 competition using the pretrained EnDR-BERT #REF and the CSIRO Adverse Drug Event Corpus (CADEC) #REF for further training the model. In addition, #TARGET_REF showed that bidirectional Transformers trained using class weighting, together with ensembles that combine various configurations, achieve an F1-score of .705 on the dataset made available for that edition of the competition.",
        "output": "{\"INFO\": [\"#TARGET_REF showed that bidirectional Transformers trained using class weighting, together with ensembles that combine various configurations, achieve an F1-score of .705 on the dataset made available for that edition of the competition.\"], \"PERCEPT\": [], \"BACK\": [\"the winning team from 2019 #REF used an ensemble of BioBERT-CRF models for the ADE extraction task, while addressing the resolution task as a classification. The system proposed by #REF ranked first at the end-to-end 2020 competition using the pretrained EnDR-BERT #REF and the CSIRO Adverse Drug Event Corpus (CADEC) #REF for further training the model.\"]}"
    },
    {
        "gold": {
            "text": [
                "All",
                "models",
                "use",
                "the",
                "SHIBA",
                "implementation",
                "of",
                "CA-NINE",
                "#REF",
                ".",
                "SHIBA",
                "was",
                "designed",
                "for",
                "use",
                "on",
                "the",
                "Japanese",
                "[jpn]",
                "language,",
                "which",
                "does",
                "not",
                "include",
                "spaces",
                "between",
                "its",
                "characters",
                "(similar",
                "to",
                "our",
                "phonetic",
                "representations",
                "without",
                "word",
                "boundaries).",
                "We",
                "used",
                "the",
                "default",
                "hyperparameter",
                "settings",
                "for",
                "SHIBA",
                "pre-training",
                "and",
                "finetuning,",
                "because",
                "we",
                "are",
                "primarily",
                "concerned",
                "with",
                "the",
                "relative",
                "impact",
                "of",
                "various",
                "combinations",
                "of",
                "pretraining",
                "data",
                "on",
                "the",
                "downstream",
                "NER",
                "tasks.",
                "We",
                "use",
                "the",
                "Hugging",
                "Face",
                "transformers",
                "library",
                "#TARGET_REF",
                "to",
                "train",
                "all",
                "models."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2
            ]
        },
        "input": "All models use the SHIBA implementation of CA-NINE #REF . SHIBA was designed for use on the Japanese [jpn] language, which does not include spaces between its characters (similar to our phonetic representations without word boundaries). We used the default hyperparameter settings for SHIBA pre-training and finetuning, because we are primarily concerned with the relative impact of various combinations of pretraining data on the downstream NER tasks. We use the Hugging Face transformers library #TARGET_REF to train all models.",
        "output": "{\"INFO\": [\"Hugging Face transformers library #TARGET_REF\"], \"PERCEPT\": [\"We use the\", \"to train all models.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Baselines",
                "We",
                "compare",
                "the",
                "SimpDefiner",
                "with",
                "generation-simplification",
                "pipelines.",
                "We",
                "first",
                "employ",
                "LOG-CaD",
                "#REF",
                "and",
                "MASS",
                "#REF",
                "models",
                "to",
                "generate",
                "definitions,",
                "and",
                "then",
                "employ",
                "ACCESS",
                "#TARGET_REF",
                "and",
                "MUSS",
                "#REF",
                "models",
                "to",
                "simplify",
                "them.",
                "Thus,",
                "we",
                "have",
                "four",
                "different",
                "pipeline",
                "baselines.",
                "Since",
                "these",
                "models",
                "are",
                "not",
                "available",
                "in",
                "Chinese,",
                "we",
                "only",
                "apply",
                "these",
                "pipelines",
                "to",
                "English",
                "datasets.",
                "For",
                "the",
                "Chinese",
                "SDG",
                "task,",
                "we",
                "specially",
                "pretrained",
                "a",
                "MASS-ZH",
                "model",
                "from",
                "scratch",
                "using",
                "the",
                "Chinese",
                "Gigaword",
                "Fifth",
                "Edition",
                "3",
                "corpus.",
                "Note",
                "that",
                "we",
                "set",
                "the",
                "learning",
                "rate",
                "to",
                "3e-4,",
                "warmup",
                "steps",
                "to",
                "500",
                "when",
                "fine-tuning",
                "both",
                "MASS",
                "and",
                "MASS-ZH."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                1,
                1,
                3,
                3,
                3,
                1,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Baselines We compare the SimpDefiner with generation-simplification pipelines. We first employ LOG-CaD #REF and MASS #REF models to generate definitions, and then employ ACCESS #TARGET_REF and MUSS #REF models to simplify them. Thus, we have four different pipeline baselines. Since these models are not available in Chinese, we only apply these pipelines to English datasets. For the Chinese SDG task, we specially pretrained a MASS-ZH model from scratch using the Chinese Gigaword Fifth Edition 3 corpus. Note that we set the learning rate to 3e-4, warmup steps to 500 when fine-tuning both MASS and MASS-ZH.",
        "output": "{\"INFO\": [\"ACCESS #TARGET_REF\", \"models\"], \"PERCEPT\": [\"We\", \"employ\", \"to simplify them.\"], \"BACK\": [\"We compare the SimpDefiner with generation-simplification pipelines.\", \"and MUSS #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "Peru,",
                "before",
                "NMT,",
                "there",
                "were",
                "studies",
                "in",
                "rulebased",
                "MT,",
                "based",
                "on",
                "the",
                "Apertium",
                "platform",
                "#REF",
                ",",
                "for",
                "Quechua",
                "Eastern",
                "Apurimac",
                "(qve)",
                "and",
                "Quechua",
                "Cuzco",
                "(quz)",
                "#REF",
                ".",
                "Furthermore,",
                "#REF",
                "improved",
                "alignments",
                "for",
                "quz",
                "by",
                "using",
                "an",
                "agglutinative",
                "language",
                "as",
                "Finnish",
                "as",
                "a",
                "pivot.",
                "Apart",
                "from",
                "the",
                "Quechua",
                "variants,",
                "only",
                "Aymara",
                "#REF",
                "and",
                "Shipibo-Konibo",
                "#TARGET_REF",
                "have",
                "been",
                "addressed",
                "with",
                "rule-based",
                "and",
                "statistical",
                "MT,",
                "respectively.",
                "#REF",
                "for",
                "Southern",
                "Quechua,",
                "and",
                "Gómez",
                "#REF",
                "for",
                "Shipibo-Konibo,",
                "are",
                "the",
                "only",
                "studies",
                "that",
                "employed",
                "sequence-tosequence",
                "NMT",
                "models.",
                "They",
                "also",
                "performed",
                "transfer",
                "learning",
                "experiments",
                "with",
                "potentially",
                "related",
                "language",
                "pairs",
                "(e.g.",
                "Finnish",
                "or",
                "Turkish,",
                "which",
                "are",
                "agglutinative",
                "languages).",
                "However,",
                "as",
                "far",
                "as",
                "we",
                "know,",
                "this",
                "is",
                "the",
                "first",
                "study",
                "that",
                "trains",
                "a",
                "multilingual",
                "model",
                "for",
                "some",
                "language",
                "spoken",
                "in",
                "Peru.",
                "For",
                "related",
                "work",
                "on",
                "multilingual",
                "NMT,",
                "we",
                "refer",
                "the",
                "readers",
                "to",
                "the",
                "survey",
                "of",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                1,
                1,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In Peru, before NMT, there were studies in rulebased MT, based on the Apertium platform #REF , for Quechua Eastern Apurimac (qve) and Quechua Cuzco (quz) #REF . Furthermore, #REF improved alignments for quz by using an agglutinative language as Finnish as a pivot. Apart from the Quechua variants, only Aymara #REF and Shipibo-Konibo #TARGET_REF have been addressed with rule-based and statistical MT, respectively. #REF for Southern Quechua, and Gómez #REF for Shipibo-Konibo, are the only studies that employed sequence-tosequence NMT models. They also performed transfer learning experiments with potentially related language pairs (e.g. Finnish or Turkish, which are agglutinative languages). However, as far as we know, this is the first study that trains a multilingual model for some language spoken in Peru. For related work on multilingual NMT, we refer the readers to the survey of #REF .",
        "output": "{\"INFO\": [\"Shipibo-Konibo #TARGET_REF have been addressed with\", \"statistical MT,\"], \"PERCEPT\": [\"Apart from the Quechua variants, only\", \"respectively.\"], \"BACK\": [\"Aymara #REF and\", \"rule-based and\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "CSC",
                "captures",
                "ordering",
                "constraints",
                "of",
                "natural",
                "language,",
                "and",
                "it",
                "roughly",
                "corresponds",
                "to",
                "phrase",
                "structure",
                "rules.",
                "CSCs",
                "can",
                "be",
                "used",
                "to",
                "represent",
                "syntax",
                "and",
                "semantics",
                "of",
                "sentences",
                "at",
                "different",
                "levels",
                "of",
                "abstraction",
                "from",
                "instances",
                "of",
                "surface",
                "sequence",
                "to",
                "linguistically",
                "motivated",
                "grammar",
                "such",
                "as",
                "Lexical-Functional",
                "Grammar",
                "(LFG)",
                "#TARGET_REF",
                ".",
                "As",
                "shown",
                "in",
                "figure",
                "2,",
                "a",
                "CSC",
                "consists",
                "of",
                "a",
                "root",
                "node",
                "(CSR),",
                "element",
                "nodes",
                "(CSE),",
                "a",
                "FIRST",
                "link,",
                "a",
                "LAST",
                "link,",
                "NEXT",
                "link(s)",
                "and",
                "ROLE",
                "links.",
                "A",
                "CSR",
                "is",
                "a",
                "representative",
                "node",
                "for",
                "the",
                "meaning",
                "of",
                "the",
                "entire",
                "CSC",
                "structure,",
                "CSRs",
                "are",
                "connected",
                "to",
                "their",
                "designated",
                "interlingual",
                "concepts",
                "by",
                "ENG",
                "or",
                "JPN.",
                "Each",
                "CSC",
                "has",
                "one",
                "or",
                "more",
                "CSEs",
                "linked",
                "to",
                "a",
                "CSR",
                "by",
                "ROLE",
                "links.",
                "The",
                "ordering",
                "constraints",
                "between",
                "two",
                "concept",
                "sequence",
                "element",
                "nodes",
                "are",
                "represented",
                "by",
                "NEXT",
                "link.",
                "FIRST",
                "and",
                "LAST",
                "links",
                "in",
                "each",
                "CSC",
                "points",
                "to",
                "the",
                "first",
                "and",
                "last",
                "elements,",
                "respectively.",
                "Also,",
                "each",
                "CSE",
                "represents",
                "the",
                "relevant",
                "case",
                "role,",
                "and",
                "the",
                "case",
                "role",
                "has",
                "a",
                "selectional",
                "restriction.",
                "Since",
                "we",
                "want",
                "to",
                "avoid",
                "heavy",
                "symbolic",
                "operations",
                "during",
                "parsing,",
                "ROLE",
                "links",
                "and",
                "associated",
                "constraint",
                "links",
                "are",
                "used",
                "instead",
                "of",
                "performing",
                "type",
                "and",
                "value",
                "consistency",
                "check",
                "by",
                "unification.",
                "Therefore",
                "each",
                "CSE",
                "is",
                "used",
                "for",
                "both",
                "enforcing",
                "the",
                "ordering",
                "constraint",
                "and",
                "capturing",
                "semantic",
                "information."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A CSC captures ordering constraints of natural language, and it roughly corresponds to phrase structure rules. CSCs can be used to represent syntax and semantics of sentences at different levels of abstraction from instances of surface sequence to linguistically motivated grammar such as Lexical-Functional Grammar (LFG) #TARGET_REF . As shown in figure 2, a CSC consists of a root node (CSR), element nodes (CSE), a FIRST link, a LAST link, NEXT link(s) and ROLE links. A CSR is a representative node for the meaning of the entire CSC structure, CSRs are connected to their designated interlingual concepts by ENG or JPN. Each CSC has one or more CSEs linked to a CSR by ROLE links. The ordering constraints between two concept sequence element nodes are represented by NEXT link. FIRST and LAST links in each CSC points to the first and last elements, respectively. Also, each CSE represents the relevant case role, and the case role has a selectional restriction. Since we want to avoid heavy symbolic operations during parsing, ROLE links and associated constraint links are used instead of performing type and value consistency check by unification. Therefore each CSE is used for both enforcing the ordering constraint and capturing semantic information.",
        "output": "{\"INFO\": [\"Lexical-Functional Grammar (LFG) #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"CSCs can be used to represent syntax and semantics of sentences at different levels of abstraction from instances of surface sequence to linguistically motivated grammar such as\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "middle",
                "layers",
                "in",
                "BERT",
                "have",
                "been",
                "shown",
                "to",
                "have",
                "specific",
                "characteristics",
                "of",
                "higher",
                "attention",
                "entropy",
                "and",
                "greater",
                "attention",
                "to",
                "specific",
                "tokens",
                "#TARGET_REF",
                ".",
                "We",
                "thus",
                "considered",
                "configurations",
                "where",
                "we",
                "compare",
                "pruning",
                "top",
                "and",
                "bottom",
                "layers",
                "against",
                "pruning",
                "middle",
                "layers",
                "(last",
                "eight",
                "rows",
                "of",
                "Table",
                "5).",
                "The",
                "results",
                "indicate",
                "a",
                "clear",
                "preference:",
                "In",
                "14",
                "out",
                "of",
                "16",
                "cases,",
                "pruning",
                "the",
                "middle",
                "layers",
                "performs",
                "worse",
                "that",
                "pruning",
                "equal",
                "number",
                "of",
                "layers",
                "distributed",
                "among",
                "top/bottom",
                "layers.",
                "Indeed,",
                "we",
                "incur",
                "an",
                "additional",
                "over",
                "2%",
                "average",
                "drop",
                "in",
                "accuracy",
                "for",
                "QNLI",
                "and",
                "SST-2",
                "tasks,",
                "indicating",
                "a",
                "task-specific",
                "sensitivity",
                "to",
                "pruning",
                "middle",
                "layers."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The middle layers in BERT have been shown to have specific characteristics of higher attention entropy and greater attention to specific tokens #TARGET_REF . We thus considered configurations where we compare pruning top and bottom layers against pruning middle layers (last eight rows of Table 5). The results indicate a clear preference: In 14 out of 16 cases, pruning the middle layers performs worse that pruning equal number of layers distributed among top/bottom layers. Indeed, we incur an additional over 2% average drop in accuracy for QNLI and SST-2 tasks, indicating a task-specific sensitivity to pruning middle layers.",
        "output": "{\"INFO\": [\"to specific tokens #TARGET_REF .\"], \"PERCEPT\": [\"The middle layers in BERT have been shown to have specific characteristics of higher attention entropy and greater attention\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "propose",
                "a",
                "three-stage",
                "pipeline",
                "called",
                "Multilingual",
                "Constrative",
                "Training",
                "(MuCoT)",
                "to",
                "effectively",
                "train",
                "the",
                "mBERT",
                "model",
                "for",
                "question-answering",
                "in",
                "low-resource",
                "languages.",
                "An",
                "illustration",
                "of",
                "this",
                "pipeline",
                "for",
                "two",
                "low-resource",
                "languages,",
                "namely",
                "Tamil",
                "and",
                "Hindi,",
                "is",
                "shown",
                "in",
                "Figure",
                "3.",
                "The",
                "first",
                "stage",
                "is",
                "pre-training",
                "the",
                "baseline",
                "multilingual",
                "model",
                "(mBERT).",
                "The",
                "second",
                "stage",
                "involves",
                "pre-training",
                "the",
                "QA",
                "head",
                "using",
                "the",
                "large-scale",
                "dataset(s)",
                "in",
                "high",
                "resource",
                "language(s).",
                "In",
                "Figure",
                "3,",
                "English",
                "is",
                "considered",
                "the",
                "high-resource",
                "language",
                "and",
                "SQuAD",
                "#REF",
                "dataset",
                "is",
                "used",
                "to",
                "pre-train",
                "the",
                "QA",
                "head",
                "and",
                "obtain",
                "the",
                "mBERT-QA",
                "model.",
                "The",
                "final",
                "stage",
                "involves",
                "fine-tuning",
                "the",
                "mBERT-QA",
                "model",
                "using",
                "both",
                "original",
                "and",
                "augmented",
                "samples",
                "from",
                "the",
                "target",
                "low-resource",
                "languages.",
                "In",
                "this",
                "work,",
                "ChAII",
                "#TARGET_REF",
                "dataset",
                "is",
                "used",
                "for",
                "obtaining",
                "training",
                "samples",
                "in",
                "Tamil",
                "and",
                "Hindi."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "We propose a three-stage pipeline called Multilingual Constrative Training (MuCoT) to effectively train the mBERT model for question-answering in low-resource languages. An illustration of this pipeline for two low-resource languages, namely Tamil and Hindi, is shown in Figure 3. The first stage is pre-training the baseline multilingual model (mBERT). The second stage involves pre-training the QA head using the large-scale dataset(s) in high resource language(s). In Figure 3, English is considered the high-resource language and SQuAD #REF dataset is used to pre-train the QA head and obtain the mBERT-QA model. The final stage involves fine-tuning the mBERT-QA model using both original and augmented samples from the target low-resource languages. In this work, ChAII #TARGET_REF dataset is used for obtaining training samples in Tamil and Hindi.",
        "output": "{\"INFO\": [\"ChAII #TARGET_REF dataset is used for obtaining training samples in Tamil and Hindi.\"], \"PERCEPT\": [\"In this work,\"], \"BACK\": [\"The final stage involves fine-tuning the mBERT-QA model using both original and augmented samples from the target low-resource languages.\"]}"
    },
    {
        "gold": {
            "text": [
                "If",
                "recombination",
                "or",
                "rephrasing",
                "is",
                "required",
                "during",
                "the",
                "composition",
                "process,",
                "this",
                "implies",
                "consultation",
                "with",
                "the",
                "user.",
                "Therefore,",
                "the",
                "system",
                "must",
                "be",
                "able",
                "to",
                "interact",
                "in",
                "an",
                "intelligent",
                "manner",
                "with",
                "the",
                "user",
                "and,",
                "consequently,",
                "an",
                "additional",
                "module",
                "in",
                "the",
                "form",
                "of",
                "a",
                "human-machine",
                "interaction",
                "dialogue",
                "model",
                "is",
                "required.",
                "In",
                "order",
                "for",
                "the",
                "system",
                "to",
                "interact",
                "'intelligently',",
                "it",
                "must",
                "understand",
                "the",
                "communicative",
                "intent",
                "of",
                "the",
                "user",
                "and",
                "therefore",
                "must",
                "have",
                "knowledge",
                "of",
                "the",
                "domain.",
                "We",
                "will",
                "not",
                "address",
                "here",
                "this",
                "aspect",
                "of",
                "the",
                "proposed",
                "system,",
                "which",
                "is",
                "essentially",
                "a",
                "typical",
                "problem",
                "of",
                "task-oriented",
                "dialogue",
                "(",
                "#TARGET_REF",
                ")."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "If recombination or rephrasing is required during the composition process, this implies consultation with the user. Therefore, the system must be able to interact in an intelligent manner with the user and, consequently, an additional module in the form of a human-machine interaction dialogue model is required. In order for the system to interact 'intelligently', it must understand the communicative intent of the user and therefore must have knowledge of the domain. We will not address here this aspect of the proposed system, which is essentially a typical problem of task-oriented dialogue ( #TARGET_REF ).",
        "output": "{\"INFO\": [\"this aspect of the proposed system, which is essentially a typical problem of task-oriented dialogue ( #TARGET_REF ).\"], \"PERCEPT\": [\"If recombination or rephrasing is required during the composition process, this implies consultation with the user. Therefore, the system must be able to interact in an intelligent manner with the user and, consequently, an additional module in the form of a human-machine interaction dialogue model is required.\", \"We will not address here\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Syntactic",
                "constraint",
                "network",
                "(SCN)",
                "is",
                "a",
                "new",
                "feature",
                "which",
                "has",
                "not",
                "been",
                "used",
                "in",
                "the",
                "previous",
                "works",
                "in",
                "memory-based",
                "NLP",
                "SCN",
                "is",
                "used",
                "to",
                "handle",
                "syntactic",
                "phenomena",
                "without",
                "undermining",
                "benefits",
                "of",
                "memory-based",
                "approach.",
                "Although,",
                "unification",
                "has",
                "been",
                "the",
                "central",
                "operation",
                "in",
                "the",
                "recent",
                "syntactic",
                "theories",
                "such",
                "as",
                "LFG",
                "#REF",
                "and",
                "HPSG",
                "#REF",
                ",",
                "we",
                "prefer",
                "SCN",
                "over",
                "unificationbased",
                "approach",
                "because",
                "unification",
                "is",
                "computationally",
                "expensive",
                "and",
                "it",
                "is",
                "not",
                "suitable",
                "for",
                "massively",
                "parallel",
                "implementation.",
                "Although",
                "there",
                "is",
                "a",
                "report",
                "on",
                "an",
                "unification",
                "algorithm",
                "on",
                "massively",
                "parallel",
                "machines",
                "#REF",
                ",",
                "still",
                "it",
                "is",
                "computationally",
                "expensive,",
                "and",
                "takes",
                "up",
                "major",
                "part",
                "of",
                "computing",
                "lime",
                "even",
                "on",
                "SNAP.",
                "In",
                "addition.",
                "there",
                "is",
                "a",
                "report",
                "that",
                "unification",
                "is",
                "not",
                "necessary",
                "the",
                "correct",
                "mechanism",
                "of",
                "enforcing",
                "Figure",
                "2:",
                "Concept",
                "Sequence",
                "on",
                "SNAP",
                "agreement",
                "#REF",
                ".",
                "Also,",
                "the",
                "classification-based",
                "approach",
                "#TARGET_REF",
                ",",
                "which",
                "pre-compiles",
                "a",
                "hierarchy",
                "of",
                "feature",
                "structures",
                "in",
                "the",
                "form",
                "of",
                "a",
                "semantic",
                "network,",
                "can",
                "carry",
                "out",
                "similar",
                "task",
                "with",
                "less",
                "computational",
                "cost",
                "#REF",
                ".",
                "Finally,",
                "current",
                "unification",
                "hard-rejects",
                "failure",
                "which",
                "is",
                "not",
                "desirable",
                "from",
                "our",
                "point.",
                "We",
                "want",
                "the",
                "system",
                "to",
                "be",
                "robust",
                "enough",
                "that",
                "while",
                "recognizing",
                "minor",
                "syntactic",
                "violation,",
                "it",
                "keep",
                "processing",
                "to",
                "get",
                "meaning",
                "of",
                "the",
                "sentence."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Syntactic constraint network (SCN) is a new feature which has not been used in the previous works in memory-based NLP SCN is used to handle syntactic phenomena without undermining benefits of memory-based approach. Although, unification has been the central operation in the recent syntactic theories such as LFG #REF and HPSG #REF , we prefer SCN over unificationbased approach because unification is computationally expensive and it is not suitable for massively parallel implementation. Although there is a report on an unification algorithm on massively parallel machines #REF , still it is computationally expensive, and takes up major part of computing lime even on SNAP. In addition. there is a report that unification is not necessary the correct mechanism of enforcing Figure 2: Concept Sequence on SNAP agreement #REF . Also, the classification-based approach #TARGET_REF , which pre-compiles a hierarchy of feature structures in the form of a semantic network, can carry out similar task with less computational cost #REF . Finally, current unification hard-rejects failure which is not desirable from our point. We want the system to be robust enough that while recognizing minor syntactic violation, it keep processing to get meaning of the sentence.",
        "output": "{\"INFO\": [\"the classification-based approach #TARGET_REF , which pre-compiles a hierarchy of feature structures in the form of a semantic network,\"], \"PERCEPT\": [\"can carry out similar task with less computational cost #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Compositionality",
                "and",
                "Its",
                "Benefits",
                "Is",
                "our",
                "semantic",
                "parser",
                "compositional?",
                "#TARGET_REF",
                "provide",
                "a",
                "definition",
                "of",
                "compositionality",
                "in",
                "meaning",
                "systems,",
                "which",
                "we",
                "summarize",
                "as",
                "follows:",
                "(1)",
                "there",
                "is",
                "a",
                "finite",
                "set",
                "of",
                "atomic",
                "word-meaning",
                "pairings,",
                "(2)",
                "there",
                "is",
                "a",
                "finite",
                "number",
                "of",
                "rules",
                "combining",
                "constituent-meaning",
                "pairings",
                "into",
                "larger",
                "constituent-meaning",
                "pairings,",
                "and",
                "any",
                "non-atomic",
                "constituent-meaning",
                "pairing",
                "is",
                "a",
                "function",
                "of",
                "the",
                "constituent-meaning",
                "pairings",
                "from",
                "which",
                "it",
                "is",
                "created",
                "and",
                "of",
                "the",
                "rule",
                "that",
                "creates",
                "it,",
                "(3)",
                "meaning",
                "representations",
                "are",
                "not",
                "changed",
                "destructively.",
                "They",
                "argue",
                "that",
                "compositional",
                "aspects",
                "of",
                "meaning",
                "such",
                "as",
                "predicate-argument",
                "structure",
                "should",
                "be",
                "processed",
                "by",
                "compositional",
                "systems,",
                "whereas",
                "noncompositional",
                "aspects",
                "such",
                "as",
                "anaphora",
                "or",
                "word",
                "senses",
                "should",
                "be",
                "handled",
                "by",
                "different",
                "mechanisms."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Compositionality and Its Benefits Is our semantic parser compositional? #TARGET_REF provide a definition of compositionality in meaning systems, which we summarize as follows: (1) there is a finite set of atomic word-meaning pairings, (2) there is a finite number of rules combining constituent-meaning pairings into larger constituent-meaning pairings, and any non-atomic constituent-meaning pairing is a function of the constituent-meaning pairings from which it is created and of the rule that creates it, (3) meaning representations are not changed destructively. They argue that compositional aspects of meaning such as predicate-argument structure should be processed by compositional systems, whereas noncompositional aspects such as anaphora or word senses should be handled by different mechanisms.",
        "output": "{\"INFO\": [\"provide a definition of compositionality in meaning systems,\"], \"PERCEPT\": [\"we summarize as follows: (1) there is a finite set of atomic word-meaning pairings, (2) there is a finite number of rules combining constituent-meaning pairings into larger constituent-meaning pairings, and any non-atomic constituent-meaning pairing is a function of the constituent-meaning pairings from which it is created and of the rule that creates it, (3) meaning representations are not changed destructively.\"], \"BACK\": [\"They argue that compositional aspects of meaning such as predicate-argument structure should be processed by compositional systems, whereas noncompositional aspects such as anaphora or word senses should be handled by different mechanisms.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper",
                "we",
                "describe",
                "the",
                "machine",
                "translation",
                "systems",
                "built",
                "for",
                "our",
                "participation",
                "in",
                "IWSLT",
                "2011",
                "evaluation",
                "campaign",
                "#TARGET_REF",
                "for",
                "the",
                "Arabic-English",
                "(Ar-En)",
                "and",
                "Chinese-English",
                "(Zh-En)",
                "MT",
                "track",
                "translation",
                "tasks.",
                "We",
                "use",
                "different",
                "SMT",
                "models,",
                "ranging",
                "from",
                "standard",
                "phrase-based",
                "SMT",
                "models",
                "#REF",
                "to",
                "CCG-augmented",
                "hierarchical",
                "phrasebased",
                "models",
                "#REF",
                "to",
                "translate",
                "the",
                "test",
                "data",
                "provided.",
                "The",
                "open-domain",
                "nature",
                "of",
                "the",
                "data",
                "and",
                "the",
                "restricted",
                "size",
                "of",
                "the",
                "in-domain",
                "training",
                "corpora",
                "necessitated",
                "the",
                "use",
                "of",
                "domain",
                "adaptation",
                "techniques",
                "to",
                "improve",
                "translation",
                "quality."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this paper we describe the machine translation systems built for our participation in IWSLT 2011 evaluation campaign #TARGET_REF for the Arabic-English (Ar-En) and Chinese-English (Zh-En) MT track translation tasks. We use different SMT models, ranging from standard phrase-based SMT models #REF to CCG-augmented hierarchical phrasebased models #REF to translate the test data provided. The open-domain nature of the data and the restricted size of the in-domain training corpora necessitated the use of domain adaptation techniques to improve translation quality.",
        "output": "{\"INFO\": [\"IWSLT 2011 evaluation campaign #TARGET_REF\", \"the Arabic-English (Ar-En) and Chinese-English (Zh-En) MT track translation tasks.\"], \"PERCEPT\": [\"In this paper we describe the machine translation systems built for our participation in\", \"for\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "10",
                "An",
                "example",
                "of",
                "this",
                "type",
                "of",
                "work",
                "is",
                "#TARGET_REF",
                ".",
                "In",
                "Arabic",
                "a",
                "root",
                "such",
                "as",
                "ktb",
                "is",
                "combined",
                "with",
                "a",
                "vowel",
                "pattern",
                "to",
                "produce",
                "words",
                "such",
                "as",
                "kitaab",
                "('book')",
                "and",
                "kutub",
                "('books').",
                "It",
                "is",
                "interesting",
                "to",
                "note",
                "that",
                "the",
                "traditional",
                "approach",
                "to",
                "Arabic",
                "roots",
                "results",
                "in",
                "approximately",
                "10,000",
                "different",
                "items.",
                "This",
                "number",
                "corresponds",
                "more",
                "closely",
                "to",
                "the",
                "number",
                "of",
                "simple",
                "lexemes",
                "to",
                "be",
                "expected",
                "in",
                "the",
                "lexicon",
                "of",
                "a",
                "language",
                "than",
                "to",
                "the",
                "number",
                "of",
                "lexemes.",
                "It",
                "is",
                "then",
                "not",
                "surprising",
                "to",
                "find",
                "items",
                "such",
                "as",
                "kaatib",
                "('writer'),",
                "kutib",
                "('be",
                "written')",
                "with",
                "the",
                "same",
                "root.",
                "11",
                "In",
                "principle",
                "we",
                "could",
                "of",
                "course",
                "reverse",
                "the",
                "entire",
                "system.",
                "Thus,",
                "languages",
                "such",
                "as",
                "Navajo,",
                "which",
                "use",
                "only",
                "prefixation,",
                "are",
                "not",
                "a",
                "major",
                "problem.",
                "12",
                "There",
                "is",
                "of",
                "course",
                "a",
                "different",
                "prefixation",
                "process",
                "attaching",
                "un-to",
                "a",
                "verb",
                "as",
                "in",
                "undo,",
                "but",
                "it",
                "would",
                "yield",
                "the",
                "wrong",
                "analysis",
                "for",
                "unacceptable.",
                "The",
                "word",
                "means",
                "'which",
                "cannot",
                "be",
                "accepted',",
                "not",
                "'which",
                "can",
                "be",
                "unaccepted'."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "10 An example of this type of work is #TARGET_REF . In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab ('book') and kutub ('books'). It is interesting to note that the traditional approach to Arabic roots results in approximately 10,000 different items. This number corresponds more closely to the number of simple lexemes to be expected in the lexicon of a language than to the number of lexemes. It is then not surprising to find items such as kaatib ('writer'), kutib ('be written') with the same root. 11 In principle we could of course reverse the entire system. Thus, languages such as Navajo, which use only prefixation, are not a major problem. 12 There is of course a different prefixation process attaching un-to a verb as in undo, but it would yield the wrong analysis for unacceptable. The word means 'which cannot be accepted', not 'which can be unaccepted'.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"An example of this type of work is #TARGET_REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "used",
                "GNU",
                "Parallel",
                "for",
                "much",
                "of",
                "the",
                "dataset",
                "processing",
                "#REF",
                ".",
                "In",
                "combination",
                "with",
                "#TARGET_REF",
                "from",
                "Hugging",
                "Face,",
                "GNU",
                "Parallel",
                "significantly",
                "accelerated",
                "pre-processing",
                "and",
                "phone",
                "transcription."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We used GNU Parallel for much of the dataset processing #REF . In combination with #TARGET_REF from Hugging Face, GNU Parallel significantly accelerated pre-processing and phone transcription.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"In combination with #TARGET_REF from Hugging Face, GNU Parallel significantly accelerated pre-processing and phone transcription.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Word",
                "associations",
                "have",
                "been",
                "a",
                "subject",
                "of",
                "active",
                "research",
                "for",
                "a",
                "long",
                "time",
                "in",
                "cognitive",
                "science",
                "and",
                "psycholinguistics",
                "for",
                "various",
                "reasons.",
                "They",
                "were",
                "used",
                "to",
                "study",
                "mental",
                "functioning,",
                "memory,",
                "and",
                "certain",
                "diseases.",
                "Word",
                "associations",
                "were",
                "also",
                "applied",
                "for",
                "modeling",
                "the",
                "cognitive",
                "lexicon",
                "and",
                "some",
                "linguistic",
                "processes",
                "(summarized",
                "by",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1
            ]
        },
        "input": "Word associations have been a subject of active research for a long time in cognitive science and psycholinguistics for various reasons. They were used to study mental functioning, memory, and certain diseases. Word associations were also applied for modeling the cognitive lexicon and some linguistic processes (summarized by #TARGET_REF .",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"Word associations have been a subject of active research for a long time in cognitive science and psycholinguistics for various reasons.\"], \"BACK\": [\"They were used to study mental functioning, memory, and certain diseases. Word associations were also applied for modeling the cognitive lexicon and some linguistic processes (summarized by\"]}"
    },
    {
        "gold": {
            "text": [
                "we",
                "use",
                "the",
                "annotation",
                "labels",
                "provided",
                "in",
                "the",
                "corpus.",
                "Note",
                "that",
                "some",
                "of",
                "the",
                "POS",
                "tags",
                "are",
                "estimated",
                "using",
                "a",
                "morphological",
                "analysis",
                "model.",
                "For",
                "the",
                "English",
                "data,",
                "we",
                "obtain",
                "these",
                "sequences",
                "from",
                "the",
                "pronunciation",
                "dictionary",
                "provided",
                "in",
                "the",
                "corpus",
                "and",
                "WordNet",
                "#REF",
                ",",
                "respectively.",
                "Some",
                "words",
                "in",
                "the",
                "vocabulary",
                "have",
                "two",
                "or",
                "more",
                "pronunciations",
                "in",
                "the",
                "pronunciation",
                "dictionary.",
                "To",
                "obtain",
                "phoneme",
                "sequences,",
                "we",
                "randomly",
                "selected",
                "a",
                "single",
                "pronunciation",
                "per",
                "word",
                "from",
                "the",
                "candidate",
                "pronunciations.",
                "Since",
                "in",
                "WordNet,",
                "57",
                "%",
                "of",
                "the",
                "words",
                "in",
                "the",
                "corpus",
                "are",
                "not",
                "annotated",
                "with",
                "the",
                "POS",
                "tags,",
                "we",
                "annotated",
                "these",
                "labels",
                "with",
                "the",
                "output",
                "of",
                "the",
                "POS",
                "tagging",
                "system",
                "#TARGET_REF",
                ".",
                "Next,",
                "we",
                "replaced",
                "these",
                "phonemes",
                "and",
                "POS",
                "tags",
                "with",
                "special",
                "symbols",
                "(Fig.",
                "2(c))",
                "to",
                "distinguish",
                "them",
                "from",
                "the",
                "grapheme",
                "symbols.",
                "Third,",
                "we",
                "split",
                "graphemic",
                "and",
                "linguistic",
                "annotation",
                "sequences",
                "at",
                "word",
                "boundaries",
                "and",
                "obtain",
                "sub-sequences",
                "(ȳ",
                "i,k",
                "in",
                "Eq.",
                "(",
                "8))",
                "(Fig.",
                "2(d)).",
                "Then",
                "sub-sequences",
                "are",
                "aggregated",
                "with",
                "the",
                "segments",
                "(s",
                "i",
                "in",
                "Eq.",
                "(",
                "8))",
                "and",
                "collapsed",
                "into",
                "the",
                "target",
                "sequence",
                "in",
                "the",
                "manner",
                "of",
                "Eq.",
                "(8)",
                "(Fig.",
                "2(e)).",
                "For",
                "the",
                "English",
                "data,",
                "we",
                "applied",
                "byte-pair",
                "encoding",
                "(BPE)",
                "#REF",
                "to",
                "the",
                "collapsed",
                "target",
                "sequence",
                "(Fig.",
                "2(f))."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "we use the annotation labels provided in the corpus. Note that some of the POS tags are estimated using a morphological analysis model. For the English data, we obtain these sequences from the pronunciation dictionary provided in the corpus and WordNet #REF , respectively. Some words in the vocabulary have two or more pronunciations in the pronunciation dictionary. To obtain phoneme sequences, we randomly selected a single pronunciation per word from the candidate pronunciations. Since in WordNet, 57 % of the words in the corpus are not annotated with the POS tags, we annotated these labels with the output of the POS tagging system #TARGET_REF . Next, we replaced these phonemes and POS tags with special symbols (Fig. 2(c)) to distinguish them from the grapheme symbols. Third, we split graphemic and linguistic annotation sequences at word boundaries and obtain sub-sequences (ȳ i,k in Eq. ( 8)) (Fig. 2(d)). Then sub-sequences are aggregated with the segments (s i in Eq. ( 8)) and collapsed into the target sequence in the manner of Eq. (8) (Fig. 2(e)). For the English data, we applied byte-pair encoding (BPE) #REF to the collapsed target sequence (Fig. 2(f)).",
        "output": "{\"INFO\": [\"POS tagging system #TARGET_REF .\"], \"PERCEPT\": [\"Since in WordNet, 57 % of the words in the corpus are not annotated with the POS tags, we annotated these labels with the output of the\"], \"BACK\": [\"For the English data, we obtain these sequences from the pronunciation dictionary provided in\", \"WordNet #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Early",
                "work",
                "on",
                "the",
                "detection",
                "and",
                "classification",
                "of",
                "Named",
                "Entities",
                "in",
                "Arabic",
                "NER",
                "used",
                "a",
                "rule-based",
                "or",
                "grammar-based",
                "approach",
                "#REF",
                ".",
                "Subsequently,",
                "the",
                "field",
                "shifted",
                "generally",
                "to",
                "a",
                "machine",
                "learning",
                "approach",
                "-thus",
                "avoiding",
                "the",
                "time-consuming",
                "and",
                "expensive",
                "maintenance",
                "of",
                "rule-sets.",
                "Within",
                "this",
                "general",
                "approach",
                "a",
                "wide",
                "variety",
                "of",
                "techniques",
                "have",
                "all",
                "been",
                "applied",
                "to",
                "the",
                "Arabic",
                "NER",
                "problem",
                "including",
                "Support",
                "Vector",
                "Machines",
                "(SVM)",
                "#TARGET_REF",
                ",",
                "Conditional",
                "Random",
                "Fields",
                "(CRF)",
                "#REF",
                ",",
                "Maximum",
                "Entropy",
                "(ME)",
                "#REF",
                ",",
                "Hidden",
                "Markov",
                "Models",
                "(HMM)",
                "and",
                "Decision",
                "Trees",
                "#REF",
                ".",
                "Notably,",
                "#REF",
                "developed",
                "an",
                "Arabic",
                "NER",
                "system,",
                "ANERsys",
                "1.0,",
                "which",
                "employed",
                "maximum",
                "entropy",
                "and",
                "could",
                "recognize",
                "four",
                "types",
                "of",
                "Named",
                "Entities."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Early work on the detection and classification of Named Entities in Arabic NER used a rule-based or grammar-based approach #REF . Subsequently, the field shifted generally to a machine learning approach -thus avoiding the time-consuming and expensive maintenance of rule-sets. Within this general approach a wide variety of techniques have all been applied to the Arabic NER problem including Support Vector Machines (SVM) #TARGET_REF , Conditional Random Fields (CRF) #REF , Maximum Entropy (ME) #REF , Hidden Markov Models (HMM) and Decision Trees #REF . Notably, #REF developed an Arabic NER system, ANERsys 1.0, which employed maximum entropy and could recognize four types of Named Entities.",
        "output": "{\"INFO\": [\"the Arabic NER problem including Support Vector Machines (SVM) #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"a wide variety of techniques have all been applied to\", \"Conditional Random Fields (CRF) #REF , Maximum Entropy (ME) #REF , Hidden Markov Models (HMM) and Decision Trees #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "One",
                "of",
                "the",
                "known",
                "drawbacks",
                "of",
                "many",
                "NLP",
                "datasets",
                "is",
                "that",
                "they",
                "contain",
                "artifacts.",
                "2",
                "Models",
                "tend",
                "to",
                "ex-ploit",
                "these",
                "easy-to-learn",
                "patterns",
                "in",
                "the",
                "early",
                "stages",
                "of",
                "training",
                "#TARGET_REF",
                ",",
                "and",
                "therefore,",
                "they",
                "may",
                "not",
                "focus",
                "on",
                "learning",
                "harder",
                "patterns",
                "of",
                "the",
                "data",
                "that",
                "are",
                "useful",
                "for",
                "solving",
                "the",
                "underlying",
                "task.",
                "As",
                "a",
                "result,",
                "overfitting",
                "to",
                "dataset-specific",
                "artifacts",
                "limits",
                "the",
                "robustness",
                "and",
                "generalization",
                "of",
                "NLP",
                "models."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "One of the known drawbacks of many NLP datasets is that they contain artifacts. 2 Models tend to ex-ploit these easy-to-learn patterns in the early stages of training #TARGET_REF , and therefore, they may not focus on learning harder patterns of the data that are useful for solving the underlying task. As a result, overfitting to dataset-specific artifacts limits the robustness and generalization of NLP models.",
        "output": "{\"INFO\": [\"in the early stages of training #TARGET_REF\"], \"PERCEPT\": [\"Models tend to ex-ploit these easy-to-learn patterns\"], \"BACK\": [\"they may not focus on learning harder patterns of the data that are useful for solving the underlying task. As a result, overfitting to dataset-specific artifacts limits the robustness and generalization of NLP models.\"]}"
    },
    {
        "gold": {
            "text": [
                "Pruning",
                "Based",
                "on",
                "Component.",
                "Some",
                "studies",
                "show",
                "that",
                "heads",
                "in",
                "the",
                "ED",
                "component",
                "are",
                "most",
                "important",
                "while",
                "those",
                "in",
                "the",
                "ES",
                "module",
                "are",
                "least",
                "important",
                "#TARGET_REF",
                ".",
                "We",
                "choose",
                "4",
                "different",
                "pruning",
                "percentages",
                "and",
                "in",
                "each",
                "case",
                "consider",
                "three",
                "configurations",
                "where",
                "the",
                "number",
                "of",
                "attention",
                "heads",
                "is",
                "least",
                "in",
                "one",
                "chosen",
                "component",
                "(ES,",
                "ED,",
                "DS).",
                "The",
                "configurations",
                "and",
                "corresponding",
                "BLEU",
                "scores",
                "on",
                "the",
                "EN-RU",
                "dataset",
                "are",
                "shown",
                "in",
                "Table",
                "3.",
                "We",
                "identify",
                "no",
                "consistent",
                "preference",
                "in",
                "the",
                "pruning",
                "strategy:",
                "In",
                "the",
                "4",
                "cases",
                "considered,",
                "each",
                "of",
                "the",
                "3",
                "configurations",
                "has",
                "the",
                "highest",
                "BLEU",
                "score",
                "in",
                "at",
                "least",
                "one",
                "case.",
                "Note",
                "that",
                "we",
                "chose",
                "the",
                "number",
                "of",
                "heads",
                "in",
                "each",
                "layer",
                "#REF",
                "to",
                "be",
                "consistent",
                "with",
                "those",
                "used",
                "in",
                "#REF",
                ".",
                "Varying",
                "Pruning",
                "Percentage.",
                "We",
                "vary",
                "the",
                "pruning",
                "percentage",
                "from",
                "10",
                "to",
                "90%",
                "and",
                "report",
                "the",
                "accuracy",
                "on",
                "the",
                "4",
                "GLUE",
                "tasks:",
                "MNLI-M,",
                "QQP,",
                "QNLI,",
                "and",
                "SST-2",
                "(Table",
                "4).",
                "We",
                "observe",
                "that",
                "half",
                "of",
                "the",
                "attention",
                "heads",
                "can",
                "be",
                "pruned",
                "with",
                "an",
                "average",
                "accuracy",
                "drop",
                "of",
                "under",
                "1%.",
                "As",
                "shown",
                "in",
                "Figure",
                "1,",
                "beyond",
                "50%",
                "pruning,",
                "the",
                "accuracy",
                "drop",
                "is",
                "sharper."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Pruning Based on Component. Some studies show that heads in the ED component are most important while those in the ES module are least important #TARGET_REF . We choose 4 different pruning percentages and in each case consider three configurations where the number of attention heads is least in one chosen component (ES, ED, DS). The configurations and corresponding BLEU scores on the EN-RU dataset are shown in Table 3. We identify no consistent preference in the pruning strategy: In the 4 cases considered, each of the 3 configurations has the highest BLEU score in at least one case. Note that we chose the number of heads in each layer #REF to be consistent with those used in #REF . Varying Pruning Percentage. We vary the pruning percentage from 10 to 90% and report the accuracy on the 4 GLUE tasks: MNLI-M, QQP, QNLI, and SST-2 (Table 4). We observe that half of the attention heads can be pruned with an average accuracy drop of under 1%. As shown in Figure 1, beyond 50% pruning, the accuracy drop is sharper.",
        "output": "{\"INFO\": [\"studies show that heads in the ED component are most important while those in the ES module are least important #TARGET_REF .\"], \"PERCEPT\": [\"We choose 4 different pruning percentages and in each case consider three configurations where the number of attention heads is least in one chosen component (ES, ED, DS).\"], \"BACK\": [\"Pruning Based on Component. Some\"]}"
    },
    {
        "gold": {
            "text": [
                "Irrespective",
                "of",
                "how",
                "the",
                "suffix",
                "array",
                "is",
                "created,",
                "#TARGET_REF",
                "demonstrated",
                "how",
                "given",
                "a",
                "suffix",
                "array,",
                "frequencies",
                "of",
                "occurrence",
                "for",
                "all",
                "substrings",
                "can",
                "be",
                "ascertained",
                "in",
                "linear",
                "time.",
                "More",
                "precisely,",
                "by",
                "doing",
                "O(N)",
                "preprocessing,",
                "frequency",
                "information",
                "about",
                "any",
                "substring",
                "can",
                "be",
                "obtained",
                "in",
                "O(log",
                "N)",
                "time.",
                "Enumerating",
                "over",
                "all",
                "substrings",
                "naturally",
                "requires",
                "quadratic",
                "time.",
                "However,",
                "their",
                "technique",
                "works",
                "by",
                "partitioning",
                "substrings",
                "into",
                "at",
                "most",
                "2N",
                "classes",
                "which",
                "have",
                "unique",
                "collection",
                "frequency,",
                "the",
                "number",
                "of",
                "times",
                "the",
                "string",
                "occurs",
                "in",
                "the",
                "text,",
                "and",
                "document",
                "frequency,",
                "the",
                "number",
                "of",
                "separate",
                "documents",
                "the",
                "string",
                "occurs",
                "in.",
                "(The",
                "text",
                "may",
                "contain",
                "special",
                "end-of-document",
                "markers.)"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Irrespective of how the suffix array is created, #TARGET_REF demonstrated how given a suffix array, frequencies of occurrence for all substrings can be ascertained in linear time. More precisely, by doing O(N) preprocessing, frequency information about any substring can be obtained in O(log N) time. Enumerating over all substrings naturally requires quadratic time. However, their technique works by partitioning substrings into at most 2N classes which have unique collection frequency, the number of times the string occurs in the text, and document frequency, the number of separate documents the string occurs in. (The text may contain special end-of-document markers.)",
        "output": "{\"INFO\": [\"#TARGET_REF demonstrated how given a suffix array, frequencies of occurrence for all substrings can be ascertained in linear time. More precisely, by doing O(N) preprocessing, frequency information about any substring can be obtained in O(log N) time.\", \"their technique works by partitioning substrings into at most 2N classes which have unique collection frequency, the number of times the string occurs in the text, and document frequency, the number of separate documents the string occurs in.\"], \"PERCEPT\": [\"Irrespective of how the suffix array is created,\"], \"BACK\": [\"Enumerating over all substrings naturally requires quadratic time.\", \"(The text may contain special end-of-document markers.)\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "context,",
                "the",
                "main",
                "question",
                "then",
                "arises:",
                "shouldn't",
                "machine",
                "translation",
                "be",
                "multilingual",
                "for",
                "languages",
                "spoken",
                "in",
                "a",
                "multilingual",
                "country",
                "like",
                "Peru?",
                "By",
                "taking",
                "advantage",
                "of",
                "few",
                "resources,",
                "and",
                "other",
                "strategies",
                "such",
                "as",
                "multilingual",
                "unsupervised",
                "subword",
                "segmentation",
                "models",
                "#TARGET_REF",
                ",",
                "pretraining",
                "with",
                "high",
                "resource",
                "language-pairs",
                "#REF",
                ",",
                "back-translation",
                "#REF",
                ",",
                "and",
                "fine-tuning",
                "#REF",
                ",",
                "we",
                "deployed",
                "the",
                "first",
                "many-to-one",
                "and",
                "one-to-many",
                "multilingual",
                "NMT",
                "models",
                "(paired",
                "with",
                "Spanish)",
                "for",
                "four",
                "indigenous",
                "languages:",
                "Aymara,",
                "Ashaninka,",
                "Quechua",
                "and",
                "Shipibo-Konibo."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "In this context, the main question then arises: shouldn't machine translation be multilingual for languages spoken in a multilingual country like Peru? By taking advantage of few resources, and other strategies such as multilingual unsupervised subword segmentation models #TARGET_REF , pretraining with high resource language-pairs #REF , back-translation #REF , and fine-tuning #REF , we deployed the first many-to-one and one-to-many multilingual NMT models (paired with Spanish) for four indigenous languages: Aymara, Ashaninka, Quechua and Shipibo-Konibo.",
        "output": "{\"INFO\": [\"multilingual unsupervised subword segmentation models #TARGET_REF\"], \"PERCEPT\": [\"In this context, the main question then arises: shouldn't machine translation be multilingual for languages spoken in a multilingual country like Peru? By taking advantage of few resources, and other strategies\", \"we deployed the first many-to-one and one-to-many multilingual NMT models (paired with Spanish) for four indigenous languages: Aymara, Ashaninka, Quechua and Shipibo-Konibo.\"], \"BACK\": [\"such as\", \", pretraining with high resource language-pairs #REF , back-translation #REF , and fine-tuning #REF ,\"]}"
    },
    {
        "gold": {
            "text": [
                "was",
                "almost",
                "absent",
                "from",
                "the",
                "repertoire",
                "of",
                "Indian",
                "corporates",
                "and",
                "public",
                "figures",
                "#REF",
                ".",
                "Even",
                "written",
                "apologies",
                "were",
                "very",
                "few",
                "and",
                "were",
                "offered",
                "only",
                "when",
                "there",
                "was",
                "a",
                "strong",
                "demand",
                "from",
                "different",
                "sections",
                "of",
                "society.",
                "However,",
                "the",
                "new",
                "generation",
                "e-commerce",
                "companies",
                "seem",
                "to",
                "be",
                "heralding",
                "an",
                "attitudinal",
                "change",
                "in",
                "this",
                "corporate",
                "practice.",
                "This",
                "could",
                "be",
                "due",
                "to",
                "the",
                "increasing",
                "digital",
                "customer",
                "base",
                "for",
                "India",
                "Inc.",
                "India's",
                "internet",
                "user",
                "base",
                "has",
                "grown",
                "to",
                "324.95",
                "million",
                "in",
                "September",
                "2015,",
                "a",
                "27.73%",
                "YOY",
                "growth",
                "(TRAI,",
                "2016).",
                "On",
                "social",
                "media",
                "platforms",
                "situations",
                "can",
                "escalate",
                "rapidly,",
                "breaking",
                "down",
                "the",
                "traditional",
                "barriers",
                "of",
                "time,",
                "location,",
                "and",
                "gatekeepers",
                "of",
                "information",
                "#REF",
                ".",
                "Thus,",
                "in",
                "stark",
                "contrast",
                "to",
                "the",
                "past,",
                "we",
                "see",
                "a",
                "spate",
                "of",
                "apology",
                "e-mails,",
                "tweets",
                "and",
                "blog",
                "posts",
                "being",
                "offered",
                "by",
                "e-commerce",
                "players",
                "(ibid).",
                "Figure",
                "1",
                "shows",
                "the",
                "rising",
                "trend",
                "of",
                "apologies",
                "being",
                "given",
                "publicly",
                "in",
                "the",
                "written",
                "digital",
                "media,",
                "with",
                "a",
                "sharp",
                "increase",
                "from",
                "the",
                "year",
                "2016",
                "to",
                "2017.",
                "Since",
                "the",
                "practice",
                "of",
                "offering",
                "a",
                "public",
                "apology",
                "is",
                "relatively",
                "new",
                "for",
                "Indian",
                "businesses,",
                "it",
                "is",
                "to",
                "be",
                "understood",
                "that",
                "an",
                "apology",
                "not",
                "delivered",
                "effectively",
                "rather",
                "than",
                "mitigating",
                "the",
                "damage,",
                "can",
                "escalate",
                "the",
                "damage",
                "done.",
                "In",
                "this",
                "context,",
                "it",
                "is",
                "important",
                "to",
                "analyze",
                "the",
                "lexical",
                "choice",
                "made",
                "in",
                "these",
                "apologies",
                "and",
                "the",
                "implications",
                "thereof."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "was almost absent from the repertoire of Indian corporates and public figures #REF . Even written apologies were very few and were offered only when there was a strong demand from different sections of society. However, the new generation e-commerce companies seem to be heralding an attitudinal change in this corporate practice. This could be due to the increasing digital customer base for India Inc. India's internet user base has grown to 324.95 million in September 2015, a 27.73% YOY growth (TRAI, 2016). On social media platforms situations can escalate rapidly, breaking down the traditional barriers of time, location, and gatekeepers of information #REF . Thus, in stark contrast to the past, we see a spate of apology e-mails, tweets and blog posts being offered by e-commerce players (ibid). Figure 1 shows the rising trend of apologies being given publicly in the written digital media, with a sharp increase from the year 2016 to 2017. Since the practice of offering a public apology is relatively new for Indian businesses, it is to be understood that an apology not delivered effectively rather than mitigating the damage, can escalate the damage done. In this context, it is important to analyze the lexical choice made in these apologies and the implications thereof.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "examine",
                "the",
                "effect",
                "that",
                "alignment",
                "link",
                "visualization",
                "has",
                "on",
                "each",
                "bilingual",
                "post-editor",
                "in",
                "Figure",
                "5",
                "on",
                "the",
                "next",
                "page.",
                "In",
                "the",
                "Russian-English",
                "condition,",
                "where",
                "overall",
                "MT",
                "quality",
                "is",
                "poor,",
                "we",
                "observe",
                "that",
                "post-editing",
                "quality",
                "varies",
                "widely",
                "between",
                "post-editors",
                "(with",
                "PE2",
                "and",
                "PE3",
                "performing",
                "best).",
                "For",
                "all",
                "six",
                "bilingual",
                "post-editors,",
                "we",
                "observe",
                "higher",
                "mean",
                "adequacy",
                "scores",
                "when",
                "alignment",
                "links",
                "were",
                "presented",
                "than",
                "when",
                "they",
                "were",
                "omitted",
                "from",
                "the",
                "post-editing",
                "tool.",
                "We",
                "also",
                "note",
                "that",
                "when",
                "alignment",
                "links",
                "were",
                "absent,",
                "one",
                "bilingual",
                "post-editor",
                "(PE5)",
                "performed",
                "worse",
                "than",
                "the",
                "monolingual",
                "post-editor",
                "(PE0)",
                "from",
                "#TARGET_REF",
                ".",
                "On",
                "the",
                "other",
                "hand,",
                "in",
                "the",
                "Spanish-English",
                "condition,",
                "where",
                "overall",
                "MT",
                "quality",
                "is",
                "good,",
                "we",
                "observe",
                "relatively",
                "little",
                "variation",
                "in",
                "quality",
                "between",
                "the",
                "ten",
                "post-editors.",
                "When",
                "compared",
                "to",
                "the",
                "unedited",
                "machine",
                "trans-PE0",
                "PE1",
                "PE2",
                "PE3",
                "PE4",
                "PE5",
                "PE6",
                "lations,",
                "post-editing",
                "resulted",
                "in",
                "improved",
                "mean",
                "adequacy",
                "for",
                "all",
                "post-editors,",
                "both",
                "bilingual",
                "and",
                "monolingual."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We examine the effect that alignment link visualization has on each bilingual post-editor in Figure 5 on the next page. In the Russian-English condition, where overall MT quality is poor, we observe that post-editing quality varies widely between post-editors (with PE2 and PE3 performing best). For all six bilingual post-editors, we observe higher mean adequacy scores when alignment links were presented than when they were omitted from the post-editing tool. We also note that when alignment links were absent, one bilingual post-editor (PE5) performed worse than the monolingual post-editor (PE0) from #TARGET_REF . On the other hand, in the Spanish-English condition, where overall MT quality is good, we observe relatively little variation in quality between the ten post-editors. When compared to the unedited machine trans-PE0 PE1 PE2 PE3 PE4 PE5 PE6 lations, post-editing resulted in improved mean adequacy for all post-editors, both bilingual and monolingual.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"We also note that when alignment links were absent, one bilingual post-editor (PE5) performed worse than the monolingual post-editor (PE0) from\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "two",
                "obvious",
                "approaches",
                "to",
                "try",
                "and",
                "answer",
                "this",
                "question.",
                "The",
                "first",
                "is",
                "to",
                "simply",
                "consider",
                "transformer-based",
                "features",
                "(e.g.,",
                "BERT",
                "score,",
                "ColBERT",
                "score,",
                "etc.)",
                "as",
                "yet",
                "another",
                "feature",
                "within",
                "a",
                "learning-to-rank",
                "framework-for",
                "example,",
                "with",
                "gradient",
                "boosted",
                "decision",
                "trees",
                "#TARGET_REF",
                ".",
                "This",
                "is",
                "not",
                "the",
                "route",
                "that",
                "we",
                "take,",
                "because",
                "this",
                "approach",
                "has",
                "less",
                "bearing",
                "on",
                "our",
                "desire",
                "to",
                "increase",
                "the",
                "efficiency",
                "of",
                "transformer-based",
                "models.",
                "Instead,",
                "we",
                "take",
                "the",
                "alternative",
                "approach",
                "of",
                "using",
                "learningto-rank",
                "techniques",
                "as",
                "a",
                "\"filtering\"",
                "stage",
                "in",
                "a",
                "multistage",
                "ranking",
                "architecture",
                "to",
                "reduce",
                "the",
                "number",
                "of",
                "candidates",
                "under",
                "consideration",
                "by",
                "BERT.",
                "More",
                "concretely,",
                "we",
                "find",
                "that",
                "a",
                "design",
                "based",
                "on",
                "this",
                "idea",
                "achieves",
                "the",
                "same",
                "level",
                "of",
                "effectiveness",
                "as",
                "a",
                "standard",
                "retrieve-and-rerank",
                "approach",
                "using",
                "BERT,",
                "but",
                "is",
                "up",
                "to",
                "18×",
                "faster.",
                "Other",
                "effectiveness-efficiency",
                "tradeoffs",
                "are",
                "possible,",
                "giving",
                "developers",
                "a",
                "rich",
                "design",
                "space",
                "to",
                "build",
                "systems",
                "tailored",
                "to",
                "different",
                "application",
                "scenarios."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There are two obvious approaches to try and answer this question. The first is to simply consider transformer-based features (e.g., BERT score, ColBERT score, etc.) as yet another feature within a learning-to-rank framework-for example, with gradient boosted decision trees #TARGET_REF . This is not the route that we take, because this approach has less bearing on our desire to increase the efficiency of transformer-based models. Instead, we take the alternative approach of using learningto-rank techniques as a \"filtering\" stage in a multistage ranking architecture to reduce the number of candidates under consideration by BERT. More concretely, we find that a design based on this idea achieves the same level of effectiveness as a standard retrieve-and-rerank approach using BERT, but is up to 18× faster. Other effectiveness-efficiency tradeoffs are possible, giving developers a rich design space to build systems tailored to different application scenarios.",
        "output": "{\"INFO\": [\"gradient boosted decision trees #TARGET_REF\"], \"PERCEPT\": [\"There are two obvious approaches to try and answer this question. The first is to simply consider transformer-based features\", \"as yet another feature within a learning-to-rank framework-for example, with\", \"This is not the route that we take, because this approach has less bearing on our desire to increase the efficiency of transformer-based models.\"], \"BACK\": [\"(e.g., BERT score, ColBERT score, etc.)\"]}"
    },
    {
        "gold": {
            "text": [
                "n",
                "positive",
                "signifiers",
                "n",
                "words",
                "NCR",
                "VAD",
                "Lexicon",
                "This",
                "measure",
                "is",
                "based",
                "on",
                "a",
                "list",
                "of",
                "words",
                "rated",
                "on",
                "the",
                "emotional",
                "dimensions",
                "of",
                "valence,",
                "arousal,",
                "and",
                "dominance",
                "which",
                "has",
                "been",
                "used",
                "in",
                "gender",
                "bias",
                "research.",
                "In",
                "particular,",
                "weakness",
                "(low",
                "dominance),",
                "passiveness",
                "(low",
                "arousal",
                "or",
                "agency),",
                "and",
                "badness",
                "(valence)",
                "may",
                "be",
                "associated",
                "with",
                "a",
                "female",
                "stereotype",
                "#TARGET_REF",
                ".",
                "Given",
                "the",
                "size",
                "of",
                "the",
                "lexicon",
                "and",
                "its",
                "overlap",
                "of",
                "up",
                "to",
                "100%",
                "with",
                "other",
                "word",
                "lists,",
                "we",
                "only",
                "counted",
                "words",
                "with",
                "either",
                "a",
                "valence,",
                "arousal,",
                "or",
                "dominance",
                "rating",
                "&gt,",
                "0.75",
                "on",
                "a",
                "scale",
                "from",
                "0",
                "to",
                "1.",
                "The",
                "calculation",
                "is:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "n positive signifiers n words NCR VAD Lexicon This measure is based on a list of words rated on the emotional dimensions of valence, arousal, and dominance which has been used in gender bias research. In particular, weakness (low dominance), passiveness (low arousal or agency), and badness (valence) may be associated with a female stereotype #TARGET_REF . Given the size of the lexicon and its overlap of up to 100% with other word lists, we only counted words with either a valence, arousal, or dominance rating &gt, 0.75 on a scale from 0 to 1. The calculation is:",
        "output": "{\"INFO\": [\"weakness (low dominance), passiveness (low arousal or agency), and badness (valence) may be associated with a female stereotype #TARGET_REF .\"], \"PERCEPT\": [\"In particular,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "SDG",
                "task",
                "is",
                "challenging",
                "because",
                "it",
                "requires",
                "a",
                "model",
                "to",
                "learn",
                "from",
                "a",
                "standard",
                "dictionary",
                "containing",
                "complex",
                "definitions",
                "and",
                "then",
                "generate",
                "simple",
                "ones,",
                "and",
                "hence",
                "fully",
                "unsupervised.",
                "A",
                "seemingly",
                "feasible",
                "solution",
                "is",
                "to",
                "generate",
                "definitions",
                "first",
                "and",
                "then",
                "simplify",
                "them,",
                "i.e.,",
                "the",
                "generationsimplification",
                "pipeline.",
                "However,",
                "the",
                "simplification",
                "task",
                "requires",
                "dataset",
                "with",
                "complex-simple",
                "sentence",
                "pairs,",
                "and",
                "such",
                "data",
                "is",
                "also",
                "difficult",
                "to",
                "find",
                "in",
                "languages",
                "other",
                "than",
                "English",
                "#TARGET_REF",
                ".",
                "Besides,",
                "the",
                "pipeline",
                "methods",
                "do",
                "not",
                "perform",
                "well",
                "due",
                "to",
                "accumulated",
                "errors",
                "(Section",
                "6.1)."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The SDG task is challenging because it requires a model to learn from a standard dictionary containing complex definitions and then generate simple ones, and hence fully unsupervised. A seemingly feasible solution is to generate definitions first and then simplify them, i.e., the generationsimplification pipeline. However, the simplification task requires dataset with complex-simple sentence pairs, and such data is also difficult to find in languages other than English #TARGET_REF . Besides, the pipeline methods do not perform well due to accumulated errors (Section 6.1).",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"the simplification task requires dataset with complex-simple sentence pairs, and such data is also difficult to find in languages other than English\", \"the pipeline methods do not perform well due to accumulated errors (Section 6.1).\"], \"BACK\": [\"The SDG task is challenging because it requires a model to learn from a standard dictionary containing complex definitions and then generate simple ones, and hence fully unsupervised. A seemingly feasible solution is to generate definitions first and then simplify them, i.e., the generationsimplification pipeline.\"]}"
    },
    {
        "gold": {
            "text": [
                "Simultaneous",
                "translation",
                "#TARGET_REF",
                "consists",
                "in",
                "generating",
                "a",
                "translation",
                "before",
                "the",
                "source",
                "speaker",
                "finishes",
                "speaking.",
                "It",
                "is",
                "widely",
                "used",
                "in",
                "many",
                "real-time",
                "scenarios",
                "such",
                "as",
                "international",
                "conferences,",
                "business",
                "negotiations",
                "and",
                "legal",
                "proceedings.",
                "The",
                "challenge",
                "of",
                "Simultaneous",
                "machine",
                "translation",
                "is",
                "to",
                "find",
                "a",
                "read-write",
                "policy",
                "that",
                "balances",
                "translation",
                "quality",
                "and",
                "latency.",
                "The",
                "translation",
                "quality",
                "will",
                "decline",
                "if",
                "the",
                "machine",
                "translation",
                "system",
                "reads",
                "insufficient",
                "source",
                "information.",
                "When",
                "reading",
                "wider",
                "source",
                "text,",
                "latency",
                "will",
                "increase."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Simultaneous translation #TARGET_REF consists in generating a translation before the source speaker finishes speaking. It is widely used in many real-time scenarios such as international conferences, business negotiations and legal proceedings. The challenge of Simultaneous machine translation is to find a read-write policy that balances translation quality and latency. The translation quality will decline if the machine translation system reads insufficient source information. When reading wider source text, latency will increase.",
        "output": "{\"INFO\": [\"Simultaneous translation #TARGET_REF consists in generating a translation before the source speaker finishes speaking.\"], \"PERCEPT\": [\"It is widely used in many real-time scenarios\", \"The challenge of Simultaneous machine translation is to find a read-write policy that balances translation quality and latency.\"], \"BACK\": [\"such as international conferences, business negotiations and legal proceedings.\", \"The translation quality will decline if the machine translation system reads insufficient source information.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "future",
                "work,",
                "we",
                "would",
                "like",
                "to",
                "include",
                "linguistic",
                "features",
                "at",
                "the",
                "source",
                "language.",
                "It",
                "is",
                "known",
                "that",
                "this",
                "can",
                "be",
                "helpful",
                "for",
                "NMT",
                "#TARGET_REF",
                ".",
                "Extending",
                "the",
                "approach",
                "with",
                "input",
                "factors",
                "could",
                "make",
                "the",
                "target",
                "language",
                "factors",
                "generation",
                "better.",
                "Furthermore,",
                "different",
                "attention",
                "mechanisms",
                "for",
                "each",
                "output",
                "will",
                "be",
                "explored",
                "because",
                "they",
                "could",
                "be",
                "aligned",
                "to",
                "different",
                "source",
                "words.",
                "The",
                "proposed",
                "FNMT",
                "architecture",
                "could",
                "even",
                "show",
                "better",
                "performance",
                "if",
                "applied",
                "when",
                "we",
                "translate",
                "to",
                "highly",
                "inflected",
                "languages",
                "like",
                "German,",
                "Arabic,",
                "Czech",
                "or",
                "Russian.",
                "Finally,",
                "FNMT",
                "approach",
                "will",
                "be",
                "explored",
                "in",
                "multimodal",
                "and",
                "multilingual",
                "tasks."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For future work, we would like to include linguistic features at the source language. It is known that this can be helpful for NMT #TARGET_REF . Extending the approach with input factors could make the target language factors generation better. Furthermore, different attention mechanisms for each output will be explored because they could be aligned to different source words. The proposed FNMT architecture could even show better performance if applied when we translate to highly inflected languages like German, Arabic, Czech or Russian. Finally, FNMT approach will be explored in multimodal and multilingual tasks.",
        "output": "{\"INFO\": [\"to include linguistic features at the source language. It is known that this can be helpful for NMT #TARGET_REF .\"], \"PERCEPT\": [\"For future work, we would like\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "model",
                "the",
                "relational",
                "information",
                "in",
                "the",
                "commonsen",
                "KG,",
                "we",
                "employ",
                "the",
                "relational",
                "graph",
                "convolutional",
                "network",
                "(R-GCN)",
                "#TARGET_REF",
                "which",
                "generalizes",
                "GCN",
                "with",
                "relation",
                "specific",
                "weight",
                "matrices.",
                "We",
                "follow",
                "#REF",
                "and",
                "#REF",
                "to",
                "use",
                "a",
                "non-parametric",
                "compositional",
                "operation",
                "ϕ(•)",
                "to",
                "combine",
                "the",
                "concept",
                "node",
                "embedding",
                "and",
                "the",
                "relation",
                "embedding.",
                "Specifically,",
                "given",
                "the",
                "input",
                "subgraph",
                "G",
                "x",
                "=",
                "{V",
                "x",
                ",",
                "E",
                "x",
                "}",
                "and",
                "an",
                "R-GCN",
                "with",
                "L",
                "layers,",
                "we",
                "update",
                "the",
                "embedding",
                "of",
                "each",
                "node",
                "v",
                "∈",
                "V",
                "x",
                "at",
                "the",
                "(l+1)-th",
                "layer",
                "by",
                "aggregating",
                "information",
                "from",
                "the",
                "embeddings",
                "of",
                "its",
                "neighbours",
                "in",
                "N",
                "(v)",
                "at",
                "the",
                "l-th",
                "layer:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To model the relational information in the commonsen KG, we employ the relational graph convolutional network (R-GCN) #TARGET_REF which generalizes GCN with relation specific weight matrices. We follow #REF and #REF to use a non-parametric compositional operation ϕ(•) to combine the concept node embedding and the relation embedding. Specifically, given the input subgraph G x = {V x , E x } and an R-GCN with L layers, we update the embedding of each node v ∈ V x at the (l+1)-th layer by aggregating information from the embeddings of its neighbours in N (v) at the l-th layer:",
        "output": "{\"INFO\": [\"the relational graph convolutional network (R-GCN) #TARGET_REF which generalizes GCN with relation specific weight matrices.\"], \"PERCEPT\": [\"To model the relational information in the commonsen KG, we employ\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Attack",
                "success",
                "rate",
                "(first-order).",
                "We",
                "quantify",
                "first-order",
                "robustness",
                "through",
                "attack",
                "success",
                "rate,",
                "which",
                "measures",
                "the",
                "ratio",
                "of",
                "test",
                "examples",
                "that",
                "an",
                "adversarial",
                "example",
                "can",
                "be",
                "found.",
                "We",
                "use",
                "firstorder",
                "attacks",
                "as",
                "a",
                "reference",
                "due",
                "to",
                "the",
                "lack",
                "of",
                "a",
                "direct",
                "baseline.",
                "We",
                "experiment",
                "with",
                "two",
                "black-box",
                "attacks:",
                "(1)",
                "The",
                "Genetic",
                "attack",
                "#TARGET_REF",
                ")",
                "uses",
                "a",
                "population-based",
                "op-timization",
                "algorithm",
                "that",
                "generates",
                "both",
                "syntactically",
                "and",
                "semantically",
                "similar",
                "adversarial",
                "examples,",
                "by",
                "replacing",
                "words",
                "within",
                "the",
                "list",
                "of",
                "counterfitted",
                "synonyms."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Attack success rate (first-order). We quantify first-order robustness through attack success rate, which measures the ratio of test examples that an adversarial example can be found. We use firstorder attacks as a reference due to the lack of a direct baseline. We experiment with two black-box attacks: (1) The Genetic attack #TARGET_REF ) uses a population-based op-timization algorithm that generates both syntactically and semantically similar adversarial examples, by replacing words within the list of counterfitted synonyms.",
        "output": "{\"INFO\": [\"The Genetic attack #TARGET_REF ) uses a population-based op-timization algorithm that generates both syntactically and semantically similar adversarial examples, by replacing words within the list of counterfitted synonyms.\"], \"PERCEPT\": [\"We experiment with two black-box attacks: (1)\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "model",
                "#REF",
                "which",
                "has",
                "6",
                "layers",
                "each",
                "in",
                "the",
                "three",
                "components:",
                "encoder",
                "self-attention",
                "(ES),",
                "encoderdecoder",
                "cross-attention",
                "(ED),",
                "and",
                "decoder",
                "selfattention",
                "(DS).",
                "In",
                "each",
                "layer",
                "of",
                "each",
                "of",
                "the",
                "three",
                "components,",
                "we",
                "have",
                "8",
                "attention",
                "heads,",
                "totalling",
                "to",
                "3",
                "×",
                "6",
                "×",
                "8",
                "=",
                "144",
                "attention",
                "heads.",
                "We",
                "train",
                "the",
                "mod-els",
                "with",
                "2.5",
                "million",
                "sentence",
                "pairs",
                "each",
                "from",
                "the",
                "WMT'14",
                "English-Russian",
                "(EN-RU)",
                "and",
                "English-German",
                "(EN-DE)",
                "datasets.",
                "We",
                "report",
                "BLEU",
                "scores",
                "on",
                "WMT's",
                "newstest2014.",
                "We",
                "use",
                "Adam",
                "optimizer",
                "(Kingma",
                "and",
                "Ba,",
                "2014)",
                "with",
                "parameters",
                "β",
                "1",
                "=",
                "0.9,",
                "β",
                "2",
                "=",
                "0.997,",
                "and",
                "=",
                "10",
                "−9",
                ".",
                "We",
                "vary",
                "the",
                "learning",
                "rate",
                "according",
                "to",
                "the",
                "formula",
                "described",
                "in",
                "#REF",
                "with",
                "warmup",
                "steps",
                "=",
                "16k.",
                "We",
                "use",
                "large",
                "batch",
                "sizes",
                "of",
                "32k",
                "and",
                "25k",
                "for",
                "EN-RU",
                "and",
                "EN-DE,",
                "respectively,",
                "as",
                "it",
                "has",
                "been",
                "established",
                "that",
                "large",
                "batch",
                "sizes",
                "are",
                "inherent",
                "to",
                "the",
                "performance",
                "of",
                "Transformers",
                "#TARGET_REF",
                ".",
                "We",
                "achieve",
                "effectively",
                "large",
                "batch",
                "sizes",
                "using",
                "the",
                "technique",
                "of",
                "gradient",
                "accumulation",
                "on",
                "single",
                "NVIDIA",
                "V100",
                "and",
                "1080Ti",
                "GPUs."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "model #REF which has 6 layers each in the three components: encoder self-attention (ES), encoderdecoder cross-attention (ED), and decoder selfattention (DS). In each layer of each of the three components, we have 8 attention heads, totalling to 3 × 6 × 8 = 144 attention heads. We train the mod-els with 2.5 million sentence pairs each from the WMT'14 English-Russian (EN-RU) and English-German (EN-DE) datasets. We report BLEU scores on WMT's newstest2014. We use Adam optimizer (Kingma and Ba, 2014) with parameters β 1 = 0.9, β 2 = 0.997, and = 10 −9 . We vary the learning rate according to the formula described in #REF with warmup steps = 16k. We use large batch sizes of 32k and 25k for EN-RU and EN-DE, respectively, as it has been established that large batch sizes are inherent to the performance of Transformers #TARGET_REF . We achieve effectively large batch sizes using the technique of gradient accumulation on single NVIDIA V100 and 1080Ti GPUs.",
        "output": "{\"INFO\": [\"large batch sizes are inherent to the performance of Transformers #TARGET_REF .\"], \"PERCEPT\": [\"We use large batch sizes of 32k and 25k for EN-RU and EN-DE, respectively, as it has been established that\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "These",
                "methods",
                "directly",
                "incorporate",
                "handengineered",
                "features",
                "and",
                "personal",
                "traits",
                "of",
                "users",
                "or",
                "their",
                "communities",
                "in",
                "order",
                "to",
                "model",
                "the",
                "likelihood",
                "of",
                "abusive",
                "language",
                "in",
                "the",
                "users'",
                "comments,",
                "a",
                "process",
                "known",
                "as",
                "profiling",
                "#REF",
                ".",
                "#TARGET_REF",
                "included",
                "the",
                "age",
                "of",
                "users",
                "alongside",
                "other",
                "traditional",
                "lexicon-based",
                "features",
                "to",
                "detect",
                "cyber-bullying,",
                "while",
                "Galán-García",
                "et",
                "al.",
                "(",
                "2016)",
                "utilized",
                "the",
                "time",
                "of",
                "publication,",
                "geo-position,",
                "and",
                "language",
                "in",
                "the",
                "profile",
                "of",
                "Twitter",
                "users.",
                "#REF",
                "exploited",
                "gender",
                "of",
                "Twitter",
                "users",
                "on",
                "top",
                "of",
                "character",
                "n-gram",
                "counts",
                "to",
                "improve",
                "detection",
                "of",
                "sexism",
                "and",
                "racism",
                "in",
                "a",
                "dataset",
                "comprising",
                "racist,",
                "sexist",
                "and",
                "benign",
                "tweets",
                "-they",
                "noted",
                "that",
                "the",
                "F",
                "1",
                "increased",
                "slightly",
                "from",
                "73.89%",
                "to",
                "73.93%",
                "when",
                "the",
                "gender",
                "feature",
                "was",
                "included.",
                "Using",
                "the",
                "same",
                "setup,",
                "Unsvåg",
                "and",
                "Gambäck",
                "(2018)",
                "showed",
                "that",
                "the",
                "inclusion",
                "of",
                "social",
                "community",
                "(i.e.,",
                "number",
                "of",
                "followers",
                "and",
                "friends)",
                "and",
                "activity",
                "(i.e.,",
                "number",
                "of",
                "status",
                "updates",
                "and",
                "favorites)",
                "features",
                "of",
                "users",
                "alongside",
                "their",
                "gender",
                "further",
                "enhanced",
                "performance",
                "by",
                "3",
                "F",
                "1",
                "points",
                "over",
                "the",
                "n-gram",
                "baseline."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "These methods directly incorporate handengineered features and personal traits of users or their communities in order to model the likelihood of abusive language in the users' comments, a process known as profiling #REF . #TARGET_REF included the age of users alongside other traditional lexicon-based features to detect cyber-bullying, while Galán-García et al. ( 2016) utilized the time of publication, geo-position, and language in the profile of Twitter users. #REF exploited gender of Twitter users on top of character n-gram counts to improve detection of sexism and racism in a dataset comprising racist, sexist and benign tweets -they noted that the F 1 increased slightly from 73.89% to 73.93% when the gender feature was included. Using the same setup, Unsvåg and Gambäck (2018) showed that the inclusion of social community (i.e., number of followers and friends) and activity (i.e., number of status updates and favorites) features of users alongside their gender further enhanced performance by 3 F 1 points over the n-gram baseline.",
        "output": "{\"INFO\": [\"#TARGET_REF included the age of users alongside other traditional lexicon-based features to detect cyber-bullying,\"], \"PERCEPT\": [], \"BACK\": [\"while Gal\\u00e1n-Garc\\u00eda et al. ( 2016) utilized the time of publication, geo-position, and language in the profile of Twitter users.\"]}"
    },
    {
        "gold": {
            "text": [
                "Attention-guided",
                "Grounding",
                "A",
                "cross-attention",
                "matrix",
                "is",
                "generated",
                "in",
                "shape",
                "(N,",
                "T,",
                "L,",
                "H)",
                "during",
                "the",
                "transformer's",
                "decoding",
                "steps.",
                "Here",
                "N",
                "denotes",
                "the",
                "number",
                "of",
                "pre-detected",
                "visual",
                "objects,",
                "T",
                "denotes",
                "the",
                "number",
                "of",
                "tokens",
                "in",
                "a",
                "caption",
                "sentence",
                "after",
                "padding,",
                "L",
                "denotes",
                "the",
                "number",
                "of",
                "transformer",
                "layers,",
                "and",
                "H",
                "denotes",
                "the",
                "number",
                "of",
                "attention",
                "heads",
                "in",
                "transformer",
                "layers.",
                "Two",
                "linear",
                "projections",
                "and",
                "layer",
                "normalization",
                "#TARGET_REF",
                "are",
                "applied",
                "sequentially",
                "on",
                "dimension",
                "L",
                "and",
                "H,",
                "respectively",
                "reducing",
                "the",
                "dimension",
                "to",
                "1.",
                "Thus,",
                "for",
                "a",
                "single",
                "instance,",
                "we",
                "eventually",
                "calculate",
                "an",
                "attention",
                "matrix",
                "A",
                "∈",
                "R",
                "N",
                "×T",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Attention-guided Grounding A cross-attention matrix is generated in shape (N, T, L, H) during the transformer's decoding steps. Here N denotes the number of pre-detected visual objects, T denotes the number of tokens in a caption sentence after padding, L denotes the number of transformer layers, and H denotes the number of attention heads in transformer layers. Two linear projections and layer normalization #TARGET_REF are applied sequentially on dimension L and H, respectively reducing the dimension to 1. Thus, for a single instance, we eventually calculate an attention matrix A ∈ R N ×T .",
        "output": "{\"INFO\": [\"layer normalization #TARGET_REF\"], \"PERCEPT\": [\"and\", \"are applied sequentially on dimension L and H, respectively reducing the dimension to 1. Thus, for a single instance, we eventually calculate an attention matrix A \\u2208 R N \\u00d7T .\"], \"BACK\": [\"L denotes the number of transformer layers, and H denotes the number of attention heads in transformer layers. Two linear projections\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "generator",
                "is",
                "based",
                "on",
                "a",
                "Relational",
                "Memory",
                "with",
                "self-attention",
                "#TARGET_REF",
                ".",
                "This",
                "model",
                "updates",
                "its",
                "\"internal",
                "values\"",
                "and",
                "produces",
                "its",
                "final",
                "output",
                "by",
                "selecting",
                "from",
                "its",
                "memory",
                "cells",
                "with",
                "a",
                "self-attention",
                "mechanism.",
                "Leveraging",
                "an",
                "idea",
                "similar",
                "to",
                "that",
                "of",
                "image-based",
                "conditional",
                "GANs",
                "#REF",
                ",",
                "we",
                "introduce",
                "an",
                "external",
                "conditioning",
                "into",
                "the",
                "generator.",
                "First,",
                "given",
                "the",
                "conditioning",
                "input",
                "c",
                "2",
                "R",
                "d",
                ",",
                "the",
                "model",
                "computes",
                "an",
                "embedding",
                "t",
                "for",
                "c",
                "using",
                "functionf",
                "✓",
                ":",
                "R",
                "d",
                "!",
                "R",
                "m",
                ",",
                "with",
                "m",
                "&lt,",
                "d.Function",
                "f",
                "✓",
                "has",
                "been",
                "implemented",
                "using",
                "a",
                "feed-forward",
                "neural",
                "network",
                "with",
                "a",
                "self-attention",
                "layer.",
                "The",
                "conditioning",
                "vector",
                "c",
                "may",
                "originate",
                "from",
                "any",
                "type",
                "of",
                "different",
                "source",
                "as",
                "long",
                "as",
                "it",
                "remains",
                "consistent",
                "during",
                "the",
                "individual",
                "training.",
                "Depending",
                "on",
                "the",
                "required",
                "task,",
                "as",
                "shown",
                "in",
                "the",
                "experiment",
                "phase,",
                "it",
                "will",
                "change.",
                "This",
                "vector",
                "c",
                "is",
                "the",
                "only",
                "link",
                "between",
                "the",
                "conditioning",
                "and",
                "the",
                "generative",
                "model,",
                "its",
                "influence",
                "on",
                "the",
                "final",
                "output",
                "will",
                "be",
                "crucial",
                "for",
                "the",
                "conditioning",
                "of",
                "the",
                "generated",
                "sentence.",
                "f",
                "✓",
                "has",
                "been",
                "adopted",
                "to",
                "give",
                "the",
                "model",
                "the",
                "ability",
                "to",
                "learn",
                "the",
                "best",
                "manipulation",
                "of",
                "the",
                "conditioning",
                "vector",
                "to",
                "insert",
                "into",
                "the",
                "memory."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The generator is based on a Relational Memory with self-attention #TARGET_REF . This model updates its \"internal values\" and produces its final output by selecting from its memory cells with a self-attention mechanism. Leveraging an idea similar to that of image-based conditional GANs #REF , we introduce an external conditioning into the generator. First, given the conditioning input c 2 R d , the model computes an embedding t for c using functionf ✓ : R d ! R m , with m &lt, d.Function f ✓ has been implemented using a feed-forward neural network with a self-attention layer. The conditioning vector c may originate from any type of different source as long as it remains consistent during the individual training. Depending on the required task, as shown in the experiment phase, it will change. This vector c is the only link between the conditioning and the generative model, its influence on the final output will be crucial for the conditioning of the generated sentence. f ✓ has been adopted to give the model the ability to learn the best manipulation of the conditioning vector to insert into the memory.",
        "output": "{\"INFO\": [\"a Relational Memory with self-attention #TARGET_REF .\"], \"PERCEPT\": [\"The generator is based on\", \"This model updates its \\\"internal values\\\" and produces its final output by selecting from its memory cells with a self-attention mechanism.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "DMSNAP",
                "complete",
                "parsing",
                "in",
                "the",
                "order",
                "of",
                "milliseconds.",
                "While",
                "actual",
                "SNAP",
                "hardware",
                "is",
                "now",
                "being",
                "assembled",
                "and",
                "to",
                "be",
                "fully",
                "operational",
                "by",
                "May",
                "1991,",
                "this",
                "section",
                "provides",
                "performance",
                "estimation",
                "with",
                "precise",
                "simulation",
                "of",
                "the",
                "SNAP",
                "machine.",
                "Simulations",
                "of",
                "the",
                "DMSNAP",
                "algorithm",
                "have",
                "been",
                "performed",
                "on",
                "a",
                "SUN",
                "3/280",
                "using",
                "the",
                "SNAP",
                "simulator",
                "which",
                "has",
                "been",
                "developed",
                "at",
                "USC",
                "#TARGET_REF",
                "].",
                "The",
                "simulator",
                "is",
                "implemented",
                "in",
                "both",
                "SUN",
                "Common",
                "LISP",
                "and",
                "C,",
                "and",
                "simulates",
                "the",
                "SNAP",
                "machine",
                "at",
                "the",
                "processor",
                "level.",
                "The",
                "LISP",
                "version",
                "of",
                "the",
                "simulators",
                "also",
                "provides",
                "information",
                "about",
                "the",
                "number",
                "of",
                "SNAP",
                "clock",
                "cycles",
                "required",
                "to",
                "perform",
                "the",
                "simulation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "DMSNAP complete parsing in the order of milliseconds. While actual SNAP hardware is now being assembled and to be fully operational by May 1991, this section provides performance estimation with precise simulation of the SNAP machine. Simulations of the DMSNAP algorithm have been performed on a SUN 3/280 using the SNAP simulator which has been developed at USC #TARGET_REF ]. The simulator is implemented in both SUN Common LISP and C, and simulates the SNAP machine at the processor level. The LISP version of the simulators also provides information about the number of SNAP clock cycles required to perform the simulation.",
        "output": "{\"INFO\": [\"the SNAP simulator which has been developed at USC #TARGET_REF ].\"], \"PERCEPT\": [\"Simulations of the DMSNAP algorithm have been performed on a SUN 3/280 using\"], \"BACK\": [\"The simulator is implemented in both SUN Common LISP and C, and simulates the SNAP machine at the processor level.\"]}"
    },
    {
        "gold": {
            "text": [
                "took",
                "all",
                "in-coverage",
                "sentences",
                "from",
                "Susanne",
                "of",
                "length",
                "8-40",
                "words",
                "inclusive",
                "containing",
                "internal",
                "punctuation,",
                "a",
                "total",
                "of",
                "2449",
                "sentences.",
                "The",
                "APB",
                "for",
                "this",
                "set",
                "was",
                "1.273,",
                "mean",
                "length",
                "22.5",
                "words,",
                "giving",
                "an",
                "expected",
                "number",
                "of",
                "analyses",
                "for",
                "an",
                "average",
                "sentence",
                "of",
                "225.",
                "We",
                "then",
                "re-moved",
                "all",
                "sentence-internal",
                "punctuation",
                "from",
                "this",
                "set",
                "and",
                "re-parsed",
                "it.",
                "Around",
                "8%",
                "of",
                "sentences",
                "now",
                "failed",
                "to",
                "receive",
                "an",
                "analysis.",
                "For",
                "those",
                "that",
                "did",
                "(mean",
                "length",
                "20.7",
                "words),",
                "the",
                "APB",
                "was",
                "now",
                "1",
                ".320,",
                "so",
                "an",
                "average",
                "sentence",
                "would",
                "be",
                "assigned",
                "310",
                "analyses,",
                "38%",
                "more",
                "than",
                "before.",
                "On",
                "closer",
                "inspection,",
                "the",
                "increase",
                "in",
                "ambiguity",
                "is",
                "due",
                "to",
                "two",
                "factors:",
                "a)",
                "a",
                "significant",
                "proportion",
                "of",
                "sentences",
                "that",
                "previously",
                "received",
                "1",
                "...:..",
                "9",
                "analyses",
                "now",
                "receive",
                "more,",
                "and",
                "b)",
                "there",
                "is",
                "a",
                "much",
                "more",
                "substantial",
                "tail",
                "in",
                "the",
                "distribution",
                "of",
                "sentence",
                "length",
                "vs.",
                "number",
                "of",
                "parses,",
                "due",
                "to",
                "some",
                "longer",
                "sentences",
                "being",
                "assigned",
                "many",
                "more",
                "parses.",
                "Manual",
                "examination",
                "of",
                "100",
                "depunctuated",
                "examples",
                "revealed",
                "that",
                "in",
                "around",
                "a",
                "third",
                "of",
                "cases,",
                "although",
                "the",
                "system",
                "returned",
                "global",
                "analyses,",
                "the",
                "correct",
                "one",
                "was",
                "not",
                "in",
                "this",
                "set",
                "#TARGET_REF",
                ".",
                "With",
                "a",
                "more",
                "constrained",
                "(sub",
                "categorised)",
                "syntactic",
                "grammar,",
                "many",
                "of",
                "these",
                "examples",
                "would",
                "not",
                "have",
                "received",
                "any",
                "global",
                "syntactic",
                "analysis."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "took all in-coverage sentences from Susanne of length 8-40 words inclusive containing internal punctuation, a total of 2449 sentences. The APB for this set was 1.273, mean length 22.5 words, giving an expected number of analyses for an average sentence of 225. We then re-moved all sentence-internal punctuation from this set and re-parsed it. Around 8% of sentences now failed to receive an analysis. For those that did (mean length 20.7 words), the APB was now 1 .320, so an average sentence would be assigned 310 analyses, 38% more than before. On closer inspection, the increase in ambiguity is due to two factors: a) a significant proportion of sentences that previously received 1 ...:.. 9 analyses now receive more, and b) there is a much more substantial tail in the distribution of sentence length vs. number of parses, due to some longer sentences being assigned many more parses. Manual examination of 100 depunctuated examples revealed that in around a third of cases, although the system returned global analyses, the correct one was not in this set #TARGET_REF . With a more constrained (sub categorised) syntactic grammar, many of these examples would not have received any global syntactic analysis.",
        "output": "{\"INFO\": [\"Manual examination of 100 depunctuated examples revealed that in around a third of cases, although the system returned global analyses, the correct one was not in this set #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"With a more constrained\", \"syntactic grammar, many of these examples would not have received any global syntactic analysis.\"]}"
    },
    {
        "gold": {
            "text": [
                "Compared",
                "to",
                "prior",
                "methods,",
                "top-k",
                "attention",
                "has",
                "multiple",
                "attractive",
                "properties:",
                "•",
                "Top-k",
                "attention",
                "has",
                "the",
                "same",
                "memory",
                "footprint",
                "as",
                "Performer",
                "#TARGET_REF",
                ",",
                "a",
                "stateof-the-art",
                "attention",
                "variant",
                "with",
                "linear",
                "time",
                "and",
                "memory",
                "complexity,",
                "on",
                "very",
                "long",
                "inputs",
                "(orange",
                "curve,",
                "Fig.",
                "1,",
                "top-right),",
                "while",
                "being",
                "as",
                "fast",
                "as",
                "vanilla",
                "attention,",
                "and",
                "even",
                "faster",
                "than",
                "linear",
                "variants",
                "on",
                "inputs",
                "of",
                "length",
                "up",
                "to",
                "4K",
                "(Figure",
                "1,",
                "bottom-left).",
                "This",
                "allows",
                "us,",
                "e.g.,",
                "to",
                "train",
                "a",
                "typical",
                "12-layer",
                "Transformer",
                "decoder",
                "over",
                "32K-long",
                "inputs",
                "on",
                "a",
                "30GiB",
                "GPU",
                "(Figure",
                "3a)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Compared to prior methods, top-k attention has multiple attractive properties: • Top-k attention has the same memory footprint as Performer #TARGET_REF , a stateof-the-art attention variant with linear time and memory complexity, on very long inputs (orange curve, Fig. 1, top-right), while being as fast as vanilla attention, and even faster than linear variants on inputs of length up to 4K (Figure 1, bottom-left). This allows us, e.g., to train a typical 12-layer Transformer decoder over 32K-long inputs on a 30GiB GPU (Figure 3a).",
        "output": "{\"INFO\": [\"Performer #TARGET_REF , a stateof-the-art attention variant with linear time and memory complexity,\"], \"PERCEPT\": [\"Top-k attention has the same memory footprint as\", \"on very long inputs\", \"while being as fast as vanilla attention, and even faster than linear variants on inputs of length up to 4K\"], \"BACK\": [\"(orange curve, Fig. 1, top-right),\", \"(Figure 1, bottom-left).\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "recent",
                "explosion",
                "of",
                "explanation-centred",
                "datasets",
                "for",
                "multi-hop",
                "question",
                "answering",
                "#REF",
                ".",
                "However,",
                "most",
                "of",
                "these",
                "datasets",
                "require",
                "the",
                "aggregation",
                "of",
                "only",
                "two",
                "sentences",
                "or",
                "paragraphs,",
                "making",
                "it",
                "hard",
                "to",
                "evaluate",
                "the",
                "robustness",
                "of",
                "the",
                "models",
                "in",
                "terms",
                "of",
                "semantic",
                "drift.",
                "On",
                "the",
                "other",
                "hand,",
                "the",
                "WorldTree",
                "corpus",
                "#TARGET_REF",
                "used",
                "in",
                "this",
                "shared",
                "task",
                "is",
                "explicitly",
                "designed",
                "to",
                "test",
                "multi-hop",
                "inference",
                "models",
                "on",
                "the",
                "reconstruction",
                "of",
                "long",
                "inference",
                "chains",
                "requiring",
                "the",
                "aggregation",
                "of",
                "an",
                "average",
                "of",
                "6",
                "facts,",
                "and",
                "as",
                "many",
                "as",
                "16",
                "facts."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "There is a recent explosion of explanation-centred datasets for multi-hop question answering #REF . However, most of these datasets require the aggregation of only two sentences or paragraphs, making it hard to evaluate the robustness of the models in terms of semantic drift. On the other hand, the WorldTree corpus #TARGET_REF used in this shared task is explicitly designed to test multi-hop inference models on the reconstruction of long inference chains requiring the aggregation of an average of 6 facts, and as many as 16 facts.",
        "output": "{\"INFO\": [\"the WorldTree corpus #TARGET_REF\"], \"PERCEPT\": [\"used in this shared task is explicitly designed to test multi-hop inference models on the reconstruction of long inference chains requiring the aggregation of an average of 6 facts, and as many as 16 facts.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "have",
                "established",
                "that",
                "the",
                "performance",
                "of",
                "top-k",
                "attention",
                "is",
                "comparable",
                "to",
                "vanilla",
                "attention",
                "when",
                "training",
                "the",
                "model",
                "from",
                "scratch.",
                "In",
                "this",
                "set-up,",
                "several",
                "recently-proposed",
                "approaches",
                "have",
                "also",
                "reported",
                "competitive",
                "performances",
                "#REF",
                ".",
                "Now,",
                "we",
                "consider",
                "a",
                "different",
                "and",
                "more",
                "practical",
                "setup,",
                "where",
                "the",
                "starting",
                "point",
                "is",
                "using",
                "an",
                "already",
                "pre-trained",
                "language",
                "model",
                "#TARGET_REF",
                ".",
                "As",
                "such",
                "models",
                "were",
                "trained",
                "using",
                "vanilla",
                "attention,",
                "replacing",
                "it",
                "with",
                "a",
                "new",
                "attention",
                "variant",
                "typically",
                "requires",
                "a",
                "corrective",
                "pretraining",
                "stage",
                "to",
                "allow",
                "the",
                "model",
                "weights",
                "to",
                "adjust",
                "to",
                "the",
                "new",
                "variant,",
                "which",
                "can",
                "be",
                "expensive",
                "for",
                "large",
                "models.",
                "For",
                "example,",
                "#REF",
                "have",
                "shown",
                "that",
                "using",
                "random",
                "features",
                "without",
                "corrective",
                "pre-training",
                "leads",
                "to",
                "high",
                "error",
                "rates",
                "in",
                "a",
                "language",
                "modeling",
                "task.",
                "Moreover,",
                "as",
                "explained",
                "in",
                "§2.1,",
                "most",
                "past",
                "methods",
                "are",
                "incompatible",
                "with",
                "feed-forward",
                "layers.",
                "In",
                "the",
                "subsequent",
                "experiments",
                "we",
                "show",
                "that",
                "it",
                "is",
                "possible",
                "to",
                "replace",
                "vanilla",
                "with",
                "top-k",
                "attention,",
                "at",
                "multi-head",
                "attention",
                "and",
                "feed-forward",
                "layers,",
                "and",
                "perform",
                "inference",
                "and",
                "fine-tuning",
                "without",
                "any",
                "need",
                "for",
                "such",
                "correction."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We have established that the performance of top-k attention is comparable to vanilla attention when training the model from scratch. In this set-up, several recently-proposed approaches have also reported competitive performances #REF . Now, we consider a different and more practical setup, where the starting point is using an already pre-trained language model #TARGET_REF . As such models were trained using vanilla attention, replacing it with a new attention variant typically requires a corrective pretraining stage to allow the model weights to adjust to the new variant, which can be expensive for large models. For example, #REF have shown that using random features without corrective pre-training leads to high error rates in a language modeling task. Moreover, as explained in §2.1, most past methods are incompatible with feed-forward layers. In the subsequent experiments we show that it is possible to replace vanilla with top-k attention, at multi-head attention and feed-forward layers, and perform inference and fine-tuning without any need for such correction.",
        "output": "{\"INFO\": [\"where the starting point is using an already pre-trained language model #TARGET_REF .\"], \"PERCEPT\": [\"we consider a different and more practical setup,\"], \"BACK\": [\"As such models were trained using vanilla attention, replacing it with a new attention variant typically requires a corrective pretraining stage to allow the model weights to adjust to the new variant, which can be expensive for large models.\"]}"
    },
    {
        "gold": {
            "text": [
                "Coreference",
                "We",
                "follow",
                "#TARGET_REF",
                "and",
                "evaluate",
                "the",
                "coreference",
                "agreement",
                "scores",
                "after",
                "filtering",
                "singleton",
                "clusters.",
                "We",
                "report",
                "the",
                "standard",
                "CoNLL-2012",
                "score",
                "#REF",
                "that",
                "combines",
                "three",
                "coreference",
                "metric",
                "scores.",
                "The",
                "in-domain",
                "test",
                "score",
                "13",
                "is",
                "82.1,",
                "while",
                "in",
                "the",
                "OOD",
                "the",
                "score",
                "is",
                "77.1.",
                "For",
                "comparison",
                "with",
                "the",
                "most",
                "dominant",
                "coreference",
                "dataset,",
                "OntoNotes",
                "#REF",
                ",",
                "which",
                "only",
                "reported",
                "the",
                "MUC",
                "agreement",
                "score",
                "#REF",
                ",",
                "we",
                "also",
                "measure",
                "the",
                "MUC",
                "score",
                "on",
                "our",
                "dataset.",
                "The",
                "MUC",
                "score",
                "on",
                "our",
                "dataset",
                "is",
                "83.6,",
                "compared",
                "to",
                "78.4-89.4",
                "in",
                "OntoNotes,",
                "depending",
                "on",
                "the",
                "domain",
                "#REF",
                ".",
                "It",
                "is",
                "worth",
                "noting",
                "that",
                "on",
                "the",
                "Newswire",
                "domain",
                "of",
                "Onto-Notes",
                "#REF",
                "(the",
                "domain",
                "that",
                "is",
                "most",
                "similar",
                "to",
                "ours)",
                "the",
                "score",
                "is",
                "80.9,",
                "which",
                "indicates",
                "a",
                "high",
                "quality",
                "of",
                "annotation",
                "in",
                "our",
                "corpus.",
                "We",
                "expect",
                "the",
                "quality",
                "of",
                "our",
                "final",
                "coreference",
                "data",
                "to",
                "be",
                "even",
                "higher",
                "due",
                "to",
                "the",
                "consolidation",
                "step",
                "that",
                "was",
                "done",
                "by",
                "an",
                "expert",
                "on",
                "the",
                "test",
                "set",
                "and",
                "OOD",
                "splits."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Coreference We follow #TARGET_REF and evaluate the coreference agreement scores after filtering singleton clusters. We report the standard CoNLL-2012 score #REF that combines three coreference metric scores. The in-domain test score 13 is 82.1, while in the OOD the score is 77.1. For comparison with the most dominant coreference dataset, OntoNotes #REF , which only reported the MUC agreement score #REF , we also measure the MUC score on our dataset. The MUC score on our dataset is 83.6, compared to 78.4-89.4 in OntoNotes, depending on the domain #REF . It is worth noting that on the Newswire domain of Onto-Notes #REF (the domain that is most similar to ours) the score is 80.9, which indicates a high quality of annotation in our corpus. We expect the quality of our final coreference data to be even higher due to the consolidation step that was done by an expert on the test set and OOD splits.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"We follow #TARGET_REF and evaluate the coreference agreement scores after filtering singleton clusters.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Neural",
                "approaches",
                "to",
                "sequence",
                "tagging",
                "are",
                "common",
                "due",
                "to",
                "extensive",
                "developments",
                "in",
                "named",
                "entity",
                "recognition.",
                "#REF",
                "introduced",
                "and",
                "cultivated",
                "the",
                "use",
                "of",
                "bidirectional",
                "LSTMs",
                "to",
                "incorporate",
                "features",
                "that",
                "could",
                "be",
                "used",
                "for",
                "sequence",
                "tagging",
                "using",
                "a",
                "CRF.",
                "#REF",
                "'s",
                "architecture",
                "and",
                "the",
                "NeuroNER",
                "program",
                "#REF",
                "provided",
                "a",
                "basic",
                "architecture",
                "and",
                "influenced",
                "multiple",
                "developments",
                "to",
                "most",
                "sequence",
                "labeling",
                "tasks,",
                "including",
                "event",
                "#REF",
                ".",
                "The",
                "task",
                "of",
                "event",
                "extraction",
                "in",
                "any",
                "language",
                "involves",
                "the",
                "identification",
                "of",
                "the",
                "event",
                "nugget",
                "#TARGET_REF",
                ".",
                "Prominent",
                "work",
                "has",
                "been",
                "done",
                "to",
                "analyze",
                "the",
                "lexical",
                "and",
                "semantic",
                "features",
                "of",
                "event",
                "representation",
                "#REF",
                ",",
                "which",
                "served",
                "as",
                "a",
                "basis",
                "for",
                "neural",
                "event",
                "nugget",
                "detection",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Neural approaches to sequence tagging are common due to extensive developments in named entity recognition. #REF introduced and cultivated the use of bidirectional LSTMs to incorporate features that could be used for sequence tagging using a CRF. #REF 's architecture and the NeuroNER program #REF provided a basic architecture and influenced multiple developments to most sequence labeling tasks, including event #REF . The task of event extraction in any language involves the identification of the event nugget #TARGET_REF . Prominent work has been done to analyze the lexical and semantic features of event representation #REF , which served as a basis for neural event nugget detection #REF .",
        "output": "{\"INFO\": [\"The task of event extraction in any language involves the identification of the event nugget #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Prominent work has been done to analyze the lexical and semantic features of event representation #REF , which served as a basis for neural event nugget detection #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "ensure",
                "the",
                "task",
                "was",
                "as",
                "realistic",
                "as",
                "possible,",
                "we",
                "selected",
                "English",
                "documentation",
                "for",
                "a",
                "well-known",
                "online",
                "file",
                "storage",
                "and",
                "sharing",
                "service.",
                "We",
                "made",
                "an",
                "initial",
                "assumption",
                "that",
                "the",
                "original",
                "English",
                "instructions",
                "published",
                "by",
                "the",
                "developer",
                "were",
                "reasonably",
                "usable,",
                "given",
                "that",
                "the",
                "service",
                "has",
                "over",
                "50",
                "million",
                "users",
                "#TARGET_REF",
                ".",
                "As",
                "native",
                "speakers",
                "of",
                "English,",
                "both",
                "authors",
                "judged",
                "the",
                "documentation",
                "to",
                "be",
                "of",
                "reasonable",
                "quality",
                "and",
                "well-formed.",
                "These",
                "were",
                "initial",
                "assumptions",
                "which",
                "would",
                "be",
                "tested",
                "in",
                "the",
                "project."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To ensure the task was as realistic as possible, we selected English documentation for a well-known online file storage and sharing service. We made an initial assumption that the original English instructions published by the developer were reasonably usable, given that the service has over 50 million users #TARGET_REF . As native speakers of English, both authors judged the documentation to be of reasonable quality and well-formed. These were initial assumptions which would be tested in the project.",
        "output": "{\"INFO\": [\"the service has over 50 million users #TARGET_REF .\"], \"PERCEPT\": [\"We made an initial assumption that the original English instructions published by the developer were reasonably usable, given that\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Some",
                "research",
                "adopted",
                "argumentation",
                "schemes",
                "as",
                "a",
                "framework,",
                "making",
                "comparisons",
                "with",
                "discourse",
                "relations",
                "#REF",
                "and",
                "collecting",
                "and",
                "leveraging",
                "data",
                "at",
                "varying",
                "degrees",
                "of",
                "granularity.",
                "At",
                "a",
                "coarse",
                "level,",
                "prior",
                "studies",
                "annotated",
                "the",
                "presence",
                "of",
                "particular",
                "argumentation",
                "schemes",
                "in",
                "text",
                "#REF",
                "and",
                "developed",
                "models",
                "to",
                "classify",
                "different",
                "schemes",
                "#TARGET_REF",
                ".",
                "However,",
                "each",
                "scheme",
                "often",
                "accommodates",
                "both",
                "support",
                "and",
                "attack",
                "relations",
                "between",
                "statements,",
                "so",
                "classifying",
                "those",
                "relations",
                "requires",
                "semantically",
                "richer",
                "information",
                "within",
                "the",
                "scheme",
                "than",
                "just",
                "its",
                "presence.",
                "To",
                "that",
                "end,",
                "#REF",
                "annotated",
                "individual",
                "components",
                "within",
                "schemes,",
                "particularly",
                "emphasizing",
                "argument",
                "from",
                "consequences.",
                "Based",
                "on",
                "the",
                "logic",
                "behind",
                "this",
                "scheme,",
                "#REF",
                "developed",
                "an",
                "unsupervised",
                "method",
                "to",
                "classify",
                "the",
                "support",
                "and",
                "attack",
                "relations",
                "using",
                "syntactic",
                "rules",
                "and",
                "lexicons.",
                "Our",
                "work",
                "extends",
                "these",
                "studies",
                "by",
                "including",
                "other",
                "normative",
                "schemes",
                "(practical",
                "reasoning",
                "and",
                "property-based",
                "reasoning)",
                "and",
                "annotating",
                "richer",
                "information."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Some research adopted argumentation schemes as a framework, making comparisons with discourse relations #REF and collecting and leveraging data at varying degrees of granularity. At a coarse level, prior studies annotated the presence of particular argumentation schemes in text #REF and developed models to classify different schemes #TARGET_REF . However, each scheme often accommodates both support and attack relations between statements, so classifying those relations requires semantically richer information within the scheme than just its presence. To that end, #REF annotated individual components within schemes, particularly emphasizing argument from consequences. Based on the logic behind this scheme, #REF developed an unsupervised method to classify the support and attack relations using syntactic rules and lexicons. Our work extends these studies by including other normative schemes (practical reasoning and property-based reasoning) and annotating richer information.",
        "output": "{\"INFO\": [\"developed models to classify different schemes #TARGET_REF .\"], \"PERCEPT\": [\"At a coarse level, prior studies annotated the presence of particular argumentation schemes in text #REF and\"], \"BACK\": [\"each scheme often accommodates both support and attack relations between statements, so classifying those relations requires semantically richer information within the scheme than just its presence.\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "proposed",
                "SimpDefiner",
                "also",
                "takes",
                "the",
                "given",
                "word",
                "and",
                "context",
                "as",
                "input.",
                "Differently,",
                "our",
                "main",
                "focus",
                "is",
                "to",
                "generate",
                "definitions",
                "with",
                "appropriate",
                "complexity",
                "to",
                "better",
                "help",
                "language",
                "learners.",
                "Besides,",
                "our",
                "model",
                "is",
                "based",
                "on",
                "MASS",
                "#TARGET_REF",
                ",",
                "which",
                "is",
                "a",
                "pre-trained",
                "encoder-decoder",
                "model",
                "and",
                "is",
                "suitable",
                "for",
                "generation",
                "tasks."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Our proposed SimpDefiner also takes the given word and context as input. Differently, our main focus is to generate definitions with appropriate complexity to better help language learners. Besides, our model is based on MASS #TARGET_REF , which is a pre-trained encoder-decoder model and is suitable for generation tasks.",
        "output": "{\"INFO\": [\"MASS #TARGET_REF ,\"], \"PERCEPT\": [\"our main focus is to generate definitions with appropriate complexity to better help language learners.\", \"our model is based on\", \"which is a pre-trained encoder-decoder model and is suitable for generation tasks.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "follow",
                "the",
                "setup",
                "from",
                "the",
                "robust",
                "training",
                "literature",
                "#TARGET_REF",
                "and",
                "experiment",
                "with",
                "both",
                "the",
                "base",
                "(non-robust)",
                "and",
                "robustly",
                "trained",
                "models.",
                "We",
                "train",
                "the",
                "binary",
                "sentiment",
                "classifiers",
                "on",
                "the",
                "SST-2",
                "dataset",
                "with",
                "bag-ofwords",
                "(BoW),",
                "CNN,",
                "LSTM,",
                "and",
                "attention-basedOriginal:",
                "70%",
                "Negative",
                "Input",
                "Example:in",
                "its",
                "best",
                "moments",
                ",",
                "resembles",
                "a",
                "bad",
                "high",
                "school",
                "production",
                "of",
                "grease",
                ",",
                "without",
                "benefit",
                "of",
                "song",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We follow the setup from the robust training literature #TARGET_REF and experiment with both the base (non-robust) and robustly trained models. We train the binary sentiment classifiers on the SST-2 dataset with bag-ofwords (BoW), CNN, LSTM, and attention-basedOriginal: 70% Negative Input Example:in its best moments , resembles a bad high school production of grease , without benefit of song .",
        "output": "{\"INFO\": [\"the robust training literature #TARGET_REF\"], \"PERCEPT\": [\"We follow the setup from\", \"and experiment with both the base (non-robust) and robustly trained models.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "First,",
                "we",
                "observe",
                "from",
                "Table",
                "2",
                "that",
                "just",
                "having",
                "intermediate",
                "SQuAD",
                "pre-training",
                "in",
                "English,",
                "improves",
                "the",
                "overall",
                "Jaccard",
                "score",
                "significantly",
                "from",
                "0.44",
                "to",
                "0.5.",
                "Furthermore,",
                "we",
                "fine-tune",
                "by",
                "dividing",
                "translated",
                "and",
                "transliterated",
                "data",
                "into",
                "Indo-Aryan",
                "and",
                "Dravidian",
                "language",
                "families",
                "to",
                "study",
                "how",
                "translated",
                "and",
                "transliterated",
                "pairs",
                "serve",
                "as",
                "supervised",
                "cross-lingual",
                "signals",
                "when",
                "languages",
                "share",
                "semantics",
                "and",
                "structure",
                "#TARGET_REF",
                ".",
                "Although",
                "transliteration",
                "improves",
                "the",
                "Jaccard",
                "scores",
                "in",
                "certain",
                "cases",
                "compared",
                "to",
                "the",
                "baseline,",
                "the",
                "trend",
                "is",
                "not",
                "consistent.",
                "Moreover,",
                "contrastive",
                "training",
                "does",
                "not",
                "help",
                "in",
                "the",
                "case",
                "of",
                "transliteration",
                "as",
                "shown",
                "in",
                "Table",
                "3.",
                "This",
                "could",
                "be",
                "because",
                "the",
                "QA",
                "model",
                "is",
                "pre-trained",
                "only",
                "with",
                "regular",
                "text",
                "and",
                "not",
                "with",
                "transliteration",
                "style",
                "text."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "First, we observe from Table 2 that just having intermediate SQuAD pre-training in English, improves the overall Jaccard score significantly from 0.44 to 0.5. Furthermore, we fine-tune by dividing translated and transliterated data into Indo-Aryan and Dravidian language families to study how translated and transliterated pairs serve as supervised cross-lingual signals when languages share semantics and structure #TARGET_REF . Although transliteration improves the Jaccard scores in certain cases compared to the baseline, the trend is not consistent. Moreover, contrastive training does not help in the case of transliteration as shown in Table 3. This could be because the QA model is pre-trained only with regular text and not with transliteration style text.",
        "output": "{\"INFO\": [\"languages share semantics and structure #TARGET_REF .\"], \"PERCEPT\": [\"we fine-tune by dividing translated and transliterated data into Indo-Aryan and Dravidian language families to study how translated and transliterated pairs serve as supervised cross-lingual signals when\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "This",
                "paper",
                "describes",
                "our",
                "submission",
                "to",
                "SemEval-2021",
                "Task",
                "2",
                "#TARGET_REF",
                ".",
                "Our",
                "approach",
                "is",
                "mainly",
                "focused",
                "on",
                "transformer-based",
                "models",
                "with",
                "different",
                "text",
                "pair",
                "classification",
                "architectures.",
                "We",
                "remodel",
                "the",
                "default",
                "text",
                "pair",
                "classification",
                "architecture",
                "and",
                "introduce",
                "several",
                "strategies",
                "that",
                "outperform",
                "the",
                "default",
                "text",
                "pair",
                "classification",
                "architecture",
                "for",
                "this",
                "task.",
                "For",
                "effortless",
                "generalisation",
                "across",
                "the",
                "languages,",
                "we",
                "do",
                "not",
                "use",
                "any",
                "language-specific",
                "processing",
                "and",
                "resources.",
                "In",
                "the",
                "subtasks",
                "where",
                "only",
                "a",
                "few",
                "training",
                "instances",
                "were",
                "available,",
                "we",
                "use",
                "few-shot",
                "learning",
                "and",
                "in",
                "the",
                "subtasks",
                "where",
                "there",
                "were",
                "no",
                "training",
                "instances",
                "were",
                "available,",
                "we",
                "use",
                "zero-shot",
                "learning",
                "taking",
                "advantage",
                "of",
                "the",
                "cross-lingual",
                "nature",
                "of",
                "the",
                "multilingual",
                "transformer",
                "models."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "This paper describes our submission to SemEval-2021 Task 2 #TARGET_REF . Our approach is mainly focused on transformer-based models with different text pair classification architectures. We remodel the default text pair classification architecture and introduce several strategies that outperform the default text pair classification architecture for this task. For effortless generalisation across the languages, we do not use any language-specific processing and resources. In the subtasks where only a few training instances were available, we use few-shot learning and in the subtasks where there were no training instances were available, we use zero-shot learning taking advantage of the cross-lingual nature of the multilingual transformer models.",
        "output": "{\"INFO\": [\"This paper describes our submission to SemEval-2021 Task 2 #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Our approach is mainly focused on transformer-based models with different text pair classification architectures. We remodel the default text pair classification architecture and introduce several strategies that outperform the default text pair classification architecture for this task.\"]}"
    },
    {
        "gold": {
            "text": [
                "Figure",
                "1",
                "shows",
                "an",
                "example",
                "in",
                "the",
                "commonsense",
                "explanation",
                "generation",
                "(ComVE)",
                "task.",
                "The",
                "dataset",
                "has",
                "collected",
                "explanations",
                "to",
                "counterfactual",
                "statements",
                "for",
                "sense-making",
                "from",
                "three",
                "annotators",
                "#TARGET_REF",
                ".",
                "From",
                "the",
                "annotations,",
                "we",
                "observed",
                "that",
                "different",
                "annotators",
                "gave",
                "explanations",
                "to",
                "the",
                "unreasonable",
                "statement",
                "from",
                "different",
                "perspectives",
                "to",
                "make",
                "them",
                "diverse",
                "in",
                "terms",
                "of",
                "content,",
                "e.g.,",
                "wrong",
                "effect",
                "and",
                "inappropriate",
                "usage."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Figure 1 shows an example in the commonsense explanation generation (ComVE) task. The dataset has collected explanations to counterfactual statements for sense-making from three annotators #TARGET_REF . From the annotations, we observed that different annotators gave explanations to the unreasonable statement from different perspectives to make them diverse in terms of content, e.g., wrong effect and inappropriate usage.",
        "output": "{\"INFO\": [\"The dataset has collected explanations to counterfactual statements for sense-making from three annotators #TARGET_REF .\"], \"PERCEPT\": [\"From the annotations, we observed that different annotators gave explanations to the unreasonable statement from different perspectives to make them diverse in terms of content,\"], \"BACK\": [\"Figure 1 shows an example in the commonsense explanation generation (ComVE) task.\", \"e.g., wrong effect and inappropriate usage.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "swh",
                "pre-training",
                "data",
                "we",
                "use:",
                "(i)",
                "the",
                "\"Language",
                "Modeling",
                "Data",
                "for",
                "Swahili\"",
                "dataset",
                "(Shikali",
                "and",
                "Refuoe,",
                "2019)",
                "hosted",
                "on",
                "Hugging",
                "Face",
                "(which",
                "we",
                "refer",
                "to",
                "as",
                "the",
                "\"HF",
                "Swahili\"",
                "data",
                "set),",
                "and",
                "(ii)",
                "the",
                "ALFFA",
                "speech",
                "dataset",
                "#TARGET_REF",
                ".",
                "For",
                "ALFFA",
                "data",
                "we",
                "process",
                "both",
                "the",
                "audio",
                "files",
                "(using",
                "Allosaurus)",
                "and",
                "the",
                "original",
                "\"gold\"",
                "text",
                "transcriptions",
                "(using",
                "Epitran)."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For swh pre-training data we use: (i) the \"Language Modeling Data for Swahili\" dataset (Shikali and Refuoe, 2019) hosted on Hugging Face (which we refer to as the \"HF Swahili\" data set), and (ii) the ALFFA speech dataset #TARGET_REF . For ALFFA data we process both the audio files (using Allosaurus) and the original \"gold\" text transcriptions (using Epitran).",
        "output": "{\"INFO\": [\"the ALFFA speech dataset #TARGET_REF .\"], \"PERCEPT\": [\"For swh pre-training data we use:\", \"For ALFFA data we process both the audio files (using Allosaurus) and the original \\\"gold\\\" text transcriptions (using Epitran).\"], \"BACK\": [\"the \\\"Language Modeling Data for Swahili\\\" dataset\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "shown",
                "in",
                "previous",
                "work",
                "#TARGET_REF",
                ",",
                "increasing",
                "the",
                "depth",
                "of",
                "the",
                "Transformer",
                "encoder",
                "can",
                "substantially",
                "improve",
                "model",
                "performance,",
                "therefore",
                "we",
                "train",
                "the",
                "Transformer",
                "with",
                "deep",
                "encoder",
                "to",
                "obtain",
                "a",
                "better",
                "source",
                "representation."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "As shown in previous work #TARGET_REF , increasing the depth of the Transformer encoder can substantially improve model performance, therefore we train the Transformer with deep encoder to obtain a better source representation.",
        "output": "{\"INFO\": [\"As shown in previous work #TARGET_REF\", \"increasing the depth of the Transformer encoder can substantially improve model performance, therefore we train the Transformer with deep encoder to obtain a better source representation.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Parsing",
                "schemata",
                "are",
                "closely",
                "related",
                "to",
                "grammatical",
                "deduction",
                "systems",
                "#TARGET_REF",
                ",",
                "where",
                "items",
                "are",
                "called",
                "formula",
                "schemata,",
                "deduction",
                "steps",
                "are",
                "inference",
                "rules,",
                "hypothesis",
                "are",
                "axioms",
                "and",
                "final",
                "items",
                "are",
                "goal",
                "formulas."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Parsing schemata are closely related to grammatical deduction systems #TARGET_REF , where items are called formula schemata, deduction steps are inference rules, hypothesis are axioms and final items are goal formulas.",
        "output": "{\"INFO\": [\"grammatical deduction systems #TARGET_REF\"], \"PERCEPT\": [\"Parsing schemata are closely related to\", \", where items are called formula schemata, deduction steps are inference rules, hypothesis are axioms and final items are goal formulas.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Most",
                "of",
                "the",
                "works",
                "that",
                "study",
                "this",
                "task",
                "commonly",
                "point",
                "first",
                "to",
                "surface-level",
                "features,",
                "such",
                "as",
                "bag",
                "of",
                "words",
                "and",
                "lexicon-based",
                "approaches,",
                "with",
                "negative",
                "words",
                "as",
                "features",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "Most of the works that study this task commonly point first to surface-level features, such as bag of words and lexicon-based approaches, with negative words as features #TARGET_REF .",
        "output": "{\"INFO\": [\"negative words as features #TARGET_REF\"], \"PERCEPT\": [\"Most of the works that study this task commonly point first to surface-level features, such as bag of words and lexicon-based approaches, with\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Third,",
                "it",
                "is",
                "expensive",
                "to",
                "acquire",
                "large-scale",
                "training",
                "data",
                "for",
                "open-domain",
                "QA.",
                "MSMARCO",
                "and",
                "Natural",
                "Questions",
                "#TARGET_REF",
                "are",
                "two",
                "largest",
                "datasets",
                "for",
                "open-domain",
                "QA.",
                "They",
                "are",
                "created",
                "from",
                "commercial",
                "search",
                "engines,",
                "and",
                "have",
                "516K",
                "and",
                "300K",
                "annotated",
                "questions,",
                "respectively.",
                "However,",
                "it",
                "is",
                "still",
                "insufficient",
                "to",
                "cover",
                "all",
                "the",
                "topics",
                "of",
                "questions",
                "issued",
                "by",
                "users",
                "to",
                "search",
                "engines."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Third, it is expensive to acquire large-scale training data for open-domain QA. MSMARCO and Natural Questions #TARGET_REF are two largest datasets for open-domain QA. They are created from commercial search engines, and have 516K and 300K annotated questions, respectively. However, it is still insufficient to cover all the topics of questions issued by users to search engines.",
        "output": "{\"INFO\": [\"Natural Questions #TARGET_REF are two largest datasets for open-domain QA.\"], \"PERCEPT\": [], \"BACK\": [\"MSMARCO and\", \"They are created from commercial search engines, and have 516K and 300K annotated questions, respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "More",
                "recently,",
                "neural",
                "networks-based",
                "strategies",
                "and",
                "transformer-based",
                "architectures",
                "has",
                "been",
                "applied",
                "to",
                "hate",
                "speech",
                "detection",
                "due",
                "to",
                "the",
                "good",
                "results",
                "achieved",
                "in",
                "various",
                "tasks.",
                "#REF",
                "2021)",
                "compared",
                "two",
                "pre-trained",
                "language",
                "models,",
                "such",
                "as",
                "BERT",
                "#TARGET_REF",
                "and",
                "XLM",
                "(CONNEAU",
                "and",
                "Lample,",
                "2019)",
                "trained",
                "to",
                "detect",
                "hate",
                "speech",
                "in",
                "the",
                "Spanish",
                "language."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "More recently, neural networks-based strategies and transformer-based architectures has been applied to hate speech detection due to the good results achieved in various tasks. #REF 2021) compared two pre-trained language models, such as BERT #TARGET_REF and XLM (CONNEAU and Lample, 2019) trained to detect hate speech in the Spanish language.",
        "output": "{\"INFO\": [\"BERT #TARGET_REF\"], \"PERCEPT\": [\"#REF 2021) compared two pre-trained language models, such as\"], \"BACK\": [\"More recently, neural networks-based strategies and transformer-based architectures has been applied to hate speech detection due to the good results achieved in various tasks.\", \"and XLM (CONNEAU and Lample, 2019)\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "LIGHT",
                "Questing",
                "Environment.",
                "The",
                "LIGHT",
                "game",
                "environment",
                "#TARGET_REF",
                "1",
                "is",
                "a",
                "multi-user",
                "fantasy",
                "text-adventure",
                "game",
                "consisting",
                "of",
                "a",
                "rich,",
                "diverse",
                "set",
                "of",
                "1775",
                "characters,",
                "663",
                "locations,",
                "and",
                "3462",
                "objects.",
                "Characters",
                "are",
                "able",
                "to",
                "perform",
                "templated",
                "actions",
                "to",
                "interact",
                "with",
                "both",
                "objects",
                "and",
                "characters,",
                "and",
                "can",
                "speak",
                "to",
                "other",
                "characters",
                "through",
                "free",
                "form",
                "text",
                "dialogues.",
                "Actions",
                "in",
                "text",
                "games",
                "generally",
                "consist",
                "of",
                "verb",
                "phrases",
                "(VP)",
                "followed",
                "optionally",
                "by",
                "prepositional",
                "phrases",
                "(VP",
                "PP).",
                "For",
                "example,",
                "get",
                "OBJ,",
                "put",
                "OBJ,",
                "give",
                "OBJ",
                "to",
                "CHAR,",
                "etc..",
                "These",
                "actions",
                "change",
                "the",
                "state",
                "of",
                "the",
                "world",
                "which",
                "is",
                "expressed",
                "through",
                "text",
                "descriptions."
            ],
            "context": [
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The LIGHT Questing Environment. The LIGHT game environment #TARGET_REF 1 is a multi-user fantasy text-adventure game consisting of a rich, diverse set of 1775 characters, 663 locations, and 3462 objects. Characters are able to perform templated actions to interact with both objects and characters, and can speak to other characters through free form text dialogues. Actions in text games generally consist of verb phrases (VP) followed optionally by prepositional phrases (VP PP). For example, get OBJ, put OBJ, give OBJ to CHAR, etc.. These actions change the state of the world which is expressed through text descriptions.",
        "output": "{\"INFO\": [\"The LIGHT game environment #TARGET_REF 1 is a multi-user fantasy text-adventure game consisting of a rich, diverse set of 1775 characters, 663 locations, and 3462 objects.\"], \"PERCEPT\": [], \"BACK\": [\"The LIGHT Questing Environment.\", \"Characters are able to perform templated actions to interact with both objects and characters, and can speak to other characters through free form text dialogues. Actions in text games generally consist of verb phrases (VP) followed optionally by prepositional phrases (VP PP).\"]}"
    },
    {
        "gold": {
            "text": [
                "where,",
                "h",
                "i",
                "(f,",
                "e)",
                "denotes",
                "the",
                "different",
                "components",
                "for",
                "translating",
                "the",
                "source",
                "sentence",
                "f",
                "into",
                "the",
                "target",
                "sentence",
                "e.",
                "K",
                "is",
                "the",
                "number",
                "of",
                "components",
                "(or",
                "features)",
                "used",
                "and",
                "λ",
                "i",
                "are",
                "the",
                "corresponding",
                "weights",
                "of",
                "the",
                "components.",
                "The",
                "Moses",
                "SMT",
                "system",
                "#REF",
                ",",
                "which",
                "implements",
                "this",
                "particular",
                "model,",
                "was",
                "used",
                "for",
                "all",
                "our",
                "PBSMT",
                "translation",
                "experiments.",
                "Different",
                "component",
                "weights",
                "(λ",
                "i",
                ")",
                "were",
                "estimated",
                "using",
                "a",
                "discriminative",
                "training",
                "method",
                "known",
                "as",
                "Minimum",
                "Error",
                "Rate",
                "Training",
                "(MERT)",
                "#TARGET_REF",
                ",",
                "on",
                "a",
                "held",
                "out",
                "development",
                "set",
                "(devset)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "where, h i (f, e) denotes the different components for translating the source sentence f into the target sentence e. K is the number of components (or features) used and λ i are the corresponding weights of the components. The Moses SMT system #REF , which implements this particular model, was used for all our PBSMT translation experiments. Different component weights (λ i ) were estimated using a discriminative training method known as Minimum Error Rate Training (MERT) #TARGET_REF , on a held out development set (devset).",
        "output": "{\"INFO\": [\"a discriminative training method known as Minimum Error Rate Training (MERT) #TARGET_REF ,\"], \"PERCEPT\": [\"Different component weights (\\u03bb i ) were estimated using\", \"on a held out development set (devset).\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Schabes",
                "et",
                "al.",
                "#REF",
                "and",
                "#TARGET_REF",
                "report",
                "results",
                "using",
                "the",
                "GEIG",
                "evaluation",
                "scheme",
                "which",
                "are",
                "numerically",
                "superior",
                "to",
                "ours.",
                "However,",
                "their",
                "experiments",
                "are",
                "not",
                "strictly",
                "compati",
                "ble",
                "because",
                "they",
                "both",
                "utilise",
                "more",
                "homogeneous",
                "and",
                "probably",
                "simpler",
                "corpora.",
                "In",
                "addition,",
                "Schabes",
                "et",
                "al.",
                "do",
                "not",
                "recover",
                "tree",
                "labelling,",
                ",",
                "whilst",
                "Magerman",
                "has",
                "developed",
                "a",
                "parser",
                "designed",
                "to",
                "produce",
                "identical",
                "analyses",
                "to",
                "those",
                "used",
                "in",
                "the",
                "Penn",
                "'Ireebank,",
                "removing",
                "the",
                "problem",
                "of",
                "spurious",
                "errors",
                "due",
                "to",
                "grammatical",
                "incompatibility.",
                "Both",
                "these",
                "approaches",
                "achieve",
                "better",
                "cov",
                "erage",
                "by",
                "constructing",
                "the",
                "grammar",
                "fully",
                "automatically.",
                "No",
                "one",
                "has",
                "yet",
                "shown",
                "that",
                "any",
                "robust",
                "parser",
                "is",
                "practical",
                "and",
                "useful",
                "for",
                "some",
                "NLP",
                "task.",
                "However,",
                "it",
                "seems",
                "likely",
                "that",
                "say",
                "rule-to-rule",
                "semantic",
                "interpretation",
                "will",
                "be",
                "easier",
                "with",
                "hand-constructed",
                "grammars",
                "with",
                "an",
                "explicit,",
                "de",
                "terminate",
                "ruleset.",
                "A",
                "more",
                "meaningful",
                "comparison",
                "will",
                "require",
                "application",
                "of",
                "different",
                "parsers",
                "to",
                "an",
                "identical",
                "and",
                "extended",
                "test",
                "suite",
                "and",
                "utllisation",
                "of",
                "a",
                "more",
                "stringent",
                "standard",
                "evaluation",
                "procedure",
                "sensitive",
                "to",
                "node",
                "labellings."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Schabes et al. #REF and #TARGET_REF report results using the GEIG evaluation scheme which are numerically superior to ours. However, their experiments are not strictly compati ble because they both utilise more homogeneous and probably simpler corpora. In addition, Schabes et al. do not recover tree labelling, , whilst Magerman has developed a parser designed to produce identical analyses to those used in the Penn 'Ireebank, removing the problem of spurious errors due to grammatical incompatibility. Both these approaches achieve better cov erage by constructing the grammar fully automatically. No one has yet shown that any robust parser is practical and useful for some NLP task. However, it seems likely that say rule-to-rule semantic interpretation will be easier with hand-constructed grammars with an explicit, de terminate ruleset. A more meaningful comparison will require application of different parsers to an identical and extended test suite and utllisation of a more stringent standard evaluation procedure sensitive to node labellings.",
        "output": "{\"INFO\": [\"#TARGET_REF report results using the GEIG evaluation scheme\", \"Magerman has developed a parser designed to produce identical analyses to those used in the Penn 'Ireebank, removing the problem of spurious errors due to grammatical incompatibility.\"], \"PERCEPT\": [\"which are numerically superior to ours.\"], \"BACK\": [\"Schabes et al. #REF and\", \"Schabes et al. do not recover tree labelling, , whilst\"]}"
    },
    {
        "gold": {
            "text": [
                "sufficient",
                "to",
                "solve",
                "the",
                "task,",
                "as",
                "was",
                "also",
                "argued",
                "in",
                "#TARGET_REF",
                "and",
                "#REF",
                ".",
                "Finally,",
                "we",
                "note",
                "an",
                "interesting",
                "trend",
                "that",
                "the",
                "decoupled",
                "variant",
                "favors",
                "recall",
                "whereas",
                "the",
                "coupled",
                "variant",
                "favors",
                "precision,",
                "across",
                "all",
                "models.",
                "In",
                "summary,",
                "all",
                "models",
                "perform",
                "substantially",
                "below",
                "human",
                "agreement,",
                "leaving",
                "a",
                "large",
                "room",
                "for",
                "improvement."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "sufficient to solve the task, as was also argued in #TARGET_REF and #REF . Finally, we note an interesting trend that the decoupled variant favors recall whereas the coupled variant favors precision, across all models. In summary, all models perform substantially below human agreement, leaving a large room for improvement.",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"sufficient to solve the task, as was also argued in\", \"and #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "diversity",
                "of",
                "neural",
                "dialogue",
                "generation",
                "has",
                "been",
                "studied",
                "actively.",
                "#REF",
                "first",
                "addressed",
                "this",
                "problem",
                "using",
                "Maximum",
                "Mutual",
                "Information",
                "(MMI)",
                "as",
                "the",
                "objective",
                "function",
                "of",
                "the",
                "neural",
                "model.",
                "#REF",
                "used",
                "Positive",
                "Pointwise",
                "Mutual",
                "Information",
                "(PPMI)",
                "to",
                "identify",
                "keywords",
                "in",
                "the",
                "dialogue",
                "corpus",
                "that",
                "were",
                "likely",
                "to",
                "appear",
                "both",
                "in",
                "response",
                "utterances",
                "and",
                "their",
                "input",
                "utterances.",
                "#REF",
                "proposed",
                "a",
                "model",
                "that",
                "uses",
                "topic",
                "words",
                "extracted",
                "from",
                "conversations",
                "to",
                "simulate",
                "human",
                "prior",
                "knowledge,",
                "generating",
                "informative",
                "and",
                "interesting",
                "responses.",
                "In",
                "addition,",
                "Variational",
                "Au-toEncoder",
                "(VAE)",
                "and",
                "Generative",
                "Adversarial",
                "Network",
                "(GAN),",
                "which",
                "were",
                "proposed",
                "originally",
                "for",
                "image",
                "generation,",
                "have",
                "also",
                "been",
                "applied",
                "to",
                "text",
                "and",
                "dialogue",
                "generation",
                "#TARGET_REF",
                ".",
                "Although",
                "GAN",
                "helps",
                "to",
                "reduce",
                "response",
                "text",
                "ambiguity,",
                "their",
                "primary",
                "purpose",
                "was",
                "not",
                "diversity.",
                "#REF",
                "proposed",
                "and",
                "demonstrated",
                "the",
                "effectiveness",
                "of",
                "Adversarial",
                "Information",
                "Maximization",
                "(AIM)",
                "as",
                "a",
                "new",
                "method",
                "for",
                "generating",
                "informative",
                "and",
                "diverse",
                "conversational",
                "responses.",
                "Their",
                "work",
                "also",
                "resolved",
                "instability",
                "that",
                "arose",
                "when",
                "training",
                "the",
                "GAN",
                "model."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The diversity of neural dialogue generation has been studied actively. #REF first addressed this problem using Maximum Mutual Information (MMI) as the objective function of the neural model. #REF used Positive Pointwise Mutual Information (PPMI) to identify keywords in the dialogue corpus that were likely to appear both in response utterances and their input utterances. #REF proposed a model that uses topic words extracted from conversations to simulate human prior knowledge, generating informative and interesting responses. In addition, Variational Au-toEncoder (VAE) and Generative Adversarial Network (GAN), which were proposed originally for image generation, have also been applied to text and dialogue generation #TARGET_REF . Although GAN helps to reduce response text ambiguity, their primary purpose was not diversity. #REF proposed and demonstrated the effectiveness of Adversarial Information Maximization (AIM) as a new method for generating informative and diverse conversational responses. Their work also resolved instability that arose when training the GAN model.",
        "output": "{\"INFO\": [\"text and dialogue generation #TARGET_REF\"], \"PERCEPT\": [\"have also been applied to\"], \"BACK\": [\"Variational Au-toEncoder (VAE) and Generative Adversarial Network (GAN), which were proposed originally for image generation,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper,",
                "our",
                "metric",
                "of",
                "interest",
                "is",
                "BERTScore",
                "#TARGET_REF",
                ".",
                "To",
                "compute",
                "BERTScore,",
                "we",
                "first",
                "feed",
                "a",
                "reference",
                "and",
                "candidate",
                "translation",
                "for",
                "a",
                "given",
                "sentence",
                "into",
                "BERT,",
                "and",
                "retrieve",
                "their",
                "token",
                "level",
                "vector",
                "representations.",
                "Let",
                "z",
                "be",
                "the",
                "representations",
                "of",
                "the",
                "reference",
                "and",
                "ẑ",
                "those",
                "of",
                "the",
                "candidate.",
                "Then",
                "we",
                "compute",
                "the",
                "precision",
                "and",
                "recall",
                "metrics",
                "for",
                "BERTScore",
                "by",
                "comparing",
                "each",
                "token",
                "representation",
                "z",
                "i",
                "of",
                "the",
                "reference",
                "translation",
                "to",
                "each",
                "token",
                "representation",
                "ẑj",
                "of",
                "the",
                "candidate",
                "translation",
                "as",
                "follows:P",
                "BERT",
                "=",
                "1",
                "|ẑ|",
                "ẑj",
                "∈ẑ",
                "max",
                "z",
                "i",
                "∈z",
                "z",
                "i",
                "ẑj",
                "R",
                "BERT",
                "=",
                "1",
                "|z|",
                "z",
                "i",
                "∈z",
                "max",
                "ẑj",
                "∈ẑ",
                "z",
                "i",
                "ẑjThe",
                "F",
                "1",
                "score",
                "can",
                "be",
                "defined",
                "as",
                "usual.",
                "As",
                "BERTScore",
                "can",
                "range",
                "from",
                "-1",
                "to",
                "1,",
                "but",
                "most",
                "often",
                "inhabits",
                "the",
                "upper",
                "end",
                "of",
                "that",
                "range,",
                "its",
                "creators",
                "suggest",
                "the",
                "use",
                "of",
                "baseline",
                "scaling,",
                "which",
                "generally",
                "leaves",
                "BERTScore",
                "in",
                "the",
                "range",
                "[0,1],",
                "as",
                "desired",
                "for",
                "use",
                "with",
                "our",
                "prior",
                "formalization.",
                "Baseline",
                "rescaling",
                "is",
                "performed",
                "for",
                "P",
                "BERT",
                "asPBERT",
                "=",
                "P",
                "BERT",
                "−",
                "a",
                "1",
                "−",
                "aand",
                "likewise",
                "for",
                "R",
                "BERT",
                ",",
                "a",
                "is",
                "an",
                "empirical",
                "lower",
                "bound",
                "on",
                "observed",
                "BERTScore."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "In this paper, our metric of interest is BERTScore #TARGET_REF . To compute BERTScore, we first feed a reference and candidate translation for a given sentence into BERT, and retrieve their token level vector representations. Let z be the representations of the reference and ẑ those of the candidate. Then we compute the precision and recall metrics for BERTScore by comparing each token representation z i of the reference translation to each token representation ẑj of the candidate translation as follows:P BERT = 1 |ẑ| ẑj ∈ẑ max z i ∈z z i ẑj R BERT = 1 |z| z i ∈z max ẑj ∈ẑ z i ẑjThe F 1 score can be defined as usual. As BERTScore can range from -1 to 1, but most often inhabits the upper end of that range, its creators suggest the use of baseline scaling, which generally leaves BERTScore in the range [0,1], as desired for use with our prior formalization. Baseline rescaling is performed for P BERT asPBERT = P BERT − a 1 − aand likewise for R BERT , a is an empirical lower bound on observed BERTScore.",
        "output": "{\"INFO\": [\"BERTScore #TARGET_REF .\", \"its creators suggest the use of baseline scaling, which generally leaves BERTScore in the range [0,1],\"], \"PERCEPT\": [\"In this paper, our metric of interest is\", \"To compute BERTScore, we first feed a reference and candidate translation for a given sentence into BERT, and retrieve their token level vector representations.\", \"Then we compute the precision and recall metrics for BERTScore by comparing each token representation z i of the reference translation to each token representation \\u1e91j of the candidate translation\", \"as desired for use with our prior formalization. Baseline rescaling is performed for P BERT asPBERT = P BERT \\u2212 a 1 \\u2212 aand likewise for R BERT , a is an empirical lower bound on observed BERTScore.\"], \"BACK\": [\"Let z be the representations of the reference and \\u1e91 those of the candidate.\", \"as follows:P BERT = 1 |\\u1e91| \\u1e91j \\u2208\\u1e91 max z i \\u2208z z i \\u1e91j R BERT = 1 |z| z i \\u2208z max \\u1e91j \\u2208\\u1e91 z i \\u1e91jThe\", \"As BERTScore can range from -1 to 1, but most often inhabits the upper end of that range,\"]}"
    },
    {
        "gold": {
            "text": [
                "Some",
                "emotions",
                "are",
                "also",
                "harder",
                "to",
                "detect,",
                "even",
                "for",
                "humans.",
                "#REF",
                "show",
                "that",
                "the",
                "emotions",
                "of",
                "admiration,",
                "approval,",
                "annoyance,",
                "gratitude",
                "had",
                "the",
                "highest",
                "interrater",
                "correlations",
                "at",
                "around",
                "0.6,",
                "and",
                "grief,",
                "relief,",
                "pride,",
                "nervousness,",
                "embarrassment",
                "had",
                "the",
                "lowest",
                "interrater",
                "correlations",
                "between",
                "0-0.2,",
                "with",
                "a",
                "vast",
                "majority",
                "of",
                "emotions",
                "falling",
                "in",
                "the",
                "range",
                "of",
                "0.3-0.5",
                "for",
                "interrater",
                "correlation.",
                "Emotions",
                "are",
                "also",
                "expressed",
                "differently",
                "in",
                "text",
                "with",
                "anger",
                "and",
                "disgust",
                "expressed",
                "explicitly,",
                "and",
                "surprise",
                "in",
                "context",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Some emotions are also harder to detect, even for humans. #REF show that the emotions of admiration, approval, annoyance, gratitude had the highest interrater correlations at around 0.6, and grief, relief, pride, nervousness, embarrassment had the lowest interrater correlations between 0-0.2, with a vast majority of emotions falling in the range of 0.3-0.5 for interrater correlation. Emotions are also expressed differently in text with anger and disgust expressed explicitly, and surprise in context #TARGET_REF .",
        "output": "{\"INFO\": [\"Emotions are also expressed differently in text with anger and disgust expressed explicitly, and surprise in context #TARGET_REF .\"], \"PERCEPT\": [\"Some emotions are also harder to detect, even for humans.\"], \"BACK\": [\"#REF show that the emotions of admiration, approval, annoyance, gratitude had the highest interrater correlations at around 0.6, and grief, relief, pride, nervousness, embarrassment had the lowest interrater correlations between 0-0.2, with a vast majority of emotions falling in the range of 0.3-0.5 for interrater correlation.\"]}"
    },
    {
        "gold": {
            "text": [
                "Feed-forward",
                "as",
                "attention",
                "In",
                "the",
                "feed-forward",
                "layer,",
                "a",
                "1-hidden",
                "layer",
                "fully-connected",
                "network",
                "is",
                "applied",
                "identically",
                "to",
                "every",
                "input",
                "token.",
                "As",
                "observed",
                "in",
                "past",
                "work",
                "#TARGET_REF",
                ",",
                "a",
                "feed-forward",
                "layer",
                "can",
                "be",
                "cast",
                "into",
                "the",
                "query-key-value",
                "framework",
                "as:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Feed-forward as attention In the feed-forward layer, a 1-hidden layer fully-connected network is applied identically to every input token. As observed in past work #TARGET_REF , a feed-forward layer can be cast into the query-key-value framework as:",
        "output": "{\"INFO\": [\"As observed in past work #TARGET_REF , a feed-forward layer can be cast into the query-key-value framework as:\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "(2)",
                "The",
                "BAE",
                "attack",
                "#TARGET_REF",
                "generates",
                "coherent",
                "adversarial",
                "examples",
                "by",
                "masking",
                "and",
                "replacing",
                "words",
                "using",
                "BERT.",
                "For",
                "both",
                "methods",
                "we",
                "use",
                "the",
                "implementation",
                "provided",
                "by",
                "TextAttack",
                "#REF",
                "."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "(2) The BAE attack #TARGET_REF generates coherent adversarial examples by masking and replacing words using BERT. For both methods we use the implementation provided by TextAttack #REF .",
        "output": "{\"INFO\": [\"The BAE attack #TARGET_REF generates coherent adversarial examples by masking and replacing words using BERT.\"], \"PERCEPT\": [\"For both methods we use the implementation provided by TextAttack #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "As",
                "seen",
                "in",
                "Figure",
                "1,",
                "we",
                "focus",
                "on",
                "creating",
                "agents",
                "in",
                "#TARGET_REF",
                ",",
                "a",
                "large-scale",
                "crowdsourced",
                "fantasy",
                "text-adventure",
                "game,",
                "consisting",
                "of",
                "rich",
                "textual",
                "worlds-locations,",
                "objects,",
                "and",
                "characters",
                "with",
                "personas,",
                "and",
                "quests-motivations",
                "for",
                "each",
                "character.",
                "To",
                "complete",
                "these",
                "quests,",
                "an",
                "agent",
                "must:",
                "(1)",
                "maintain",
                "character",
                "via",
                "its",
                "persona,",
                "and",
                "(2)",
                "reason",
                "in",
                "a",
                "partially",
                "observable",
                "world",
                "about",
                "potential",
                "actions",
                "and",
                "utterances",
                "based",
                "on",
                "incomplete",
                "descriptions",
                "of",
                "the",
                "locations,",
                "objects,",
                "and",
                "other",
                "characters.",
                "This",
                "requires",
                "several",
                "human",
                "like",
                "competencies",
                "such",
                "as",
                "commonsense",
                "reasoning,",
                "dynamic",
                "natural",
                "language",
                "understanding,",
                "and",
                "operating",
                "in",
                "combinatorially",
                "sized",
                "language-based",
                "stateaction",
                "spaces.",
                "Although",
                "recent",
                "work",
                "has",
                "provided",
                "evidence",
                "showing",
                "that",
                "interactive",
                "language",
                "learning",
                "via",
                "reinforcement",
                "learning",
                "(RL)",
                "in",
                "text",
                "games",
                "can",
                "be",
                "significantly",
                "more",
                "sample",
                "efficient",
                "than",
                "static",
                "supervised",
                "learning",
                "#REF",
                "when",
                "creating",
                "goal-driven",
                "natural",
                "language",
                "agents,",
                "their",
                "ability",
                "to",
                "robustly",
                "generalize",
                "to",
                "novel",
                "scenarios",
                "is",
                "limited."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "As seen in Figure 1, we focus on creating agents in #TARGET_REF , a large-scale crowdsourced fantasy text-adventure game, consisting of rich textual worlds-locations, objects, and characters with personas, and quests-motivations for each character. To complete these quests, an agent must: (1) maintain character via its persona, and (2) reason in a partially observable world about potential actions and utterances based on incomplete descriptions of the locations, objects, and other characters. This requires several human like competencies such as commonsense reasoning, dynamic natural language understanding, and operating in combinatorially sized language-based stateaction spaces. Although recent work has provided evidence showing that interactive language learning via reinforcement learning (RL) in text games can be significantly more sample efficient than static supervised learning #REF when creating goal-driven natural language agents, their ability to robustly generalize to novel scenarios is limited.",
        "output": "{\"INFO\": [\"#TARGET_REF , a large-scale crowdsourced fantasy text-adventure game, consisting of rich textual worlds-locations, objects, and characters with personas, and quests-motivations for each character.\"], \"PERCEPT\": [\"we focus on creating agents in\"], \"BACK\": [\"As seen in Figure 1,\", \"To complete these quests, an agent must: (1) maintain character via its persona, and (2) reason in a partially observable world about potential actions and utterances based on incomplete descriptions of the locations, objects, and other characters. This requires several human like competencies such as commonsense reasoning, dynamic natural language understanding, and operating in combinatorially sized language-based stateaction spaces.\"]}"
    },
    {
        "gold": {
            "text": [
                "Consequently,",
                "explainability",
                "has",
                "a",
                "bigger",
                "role",
                "to",
                "play",
                "here",
                "than",
                "simply",
                "being",
                "a",
                "tool",
                "that",
                "provides",
                "interpretability",
                "to",
                "designers",
                "or",
                "offers",
                "justifications",
                "to",
                "users.",
                "Operationalizing",
                "explainability",
                "in",
                "a",
                "manner",
                "that",
                "spreads",
                "awareness",
                "about",
                "existing",
                "stereotypes",
                "and",
                "fills",
                "the",
                "information",
                "gap",
                "can",
                "be",
                "very",
                "effective",
                "#REF",
                ".",
                "One",
                "way",
                "to",
                "achieve",
                "this",
                "is",
                "by",
                "having",
                "generative",
                "explanations",
                "in",
                "conjunction",
                "with",
                "information",
                "retrieval",
                "techniques",
                "that",
                "fulfill",
                "the",
                "property",
                "of",
                "elucidating",
                "stereotypes",
                "in",
                "a",
                "human-understandable",
                "way",
                "#TARGET_REF",
                "while",
                "offering",
                "references",
                "to",
                "reliable",
                "sources",
                "on",
                "the",
                "stereotypes.",
                "In",
                "fact,",
                "such",
                "an",
                "operationalization",
                "that",
                "elucidates",
                "stereotypes",
                "or",
                "frames",
                "of",
                "bias",
                "#REF",
                "in",
                "abusive",
                "comments",
                "at",
                "a",
                "community",
                "level,",
                "while",
                "providing",
                "information",
                "to",
                "debunk",
                "the",
                "stereotypes",
                "themselves,",
                "can",
                "offer",
                "validation",
                "to",
                "the",
                "victims",
                "of",
                "abuse",
                "by",
                "communities,",
                "e.g.,",
                "minority",
                "groups,",
                "and",
                "help",
                "them",
                "feel",
                "safer",
                "on",
                "the",
                "platform."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Consequently, explainability has a bigger role to play here than simply being a tool that provides interpretability to designers or offers justifications to users. Operationalizing explainability in a manner that spreads awareness about existing stereotypes and fills the information gap can be very effective #REF . One way to achieve this is by having generative explanations in conjunction with information retrieval techniques that fulfill the property of elucidating stereotypes in a human-understandable way #TARGET_REF while offering references to reliable sources on the stereotypes. In fact, such an operationalization that elucidates stereotypes or frames of bias #REF in abusive comments at a community level, while providing information to debunk the stereotypes themselves, can offer validation to the victims of abuse by communities, e.g., minority groups, and help them feel safer on the platform.",
        "output": "{\"INFO\": [\"having generative explanations in conjunction with information retrieval techniques that fulfill the property of elucidating stereotypes in a human-understandable way #TARGET_REF\"], \"PERCEPT\": [\"One way to achieve this is by\", \"while offering references to reliable sources on the stereotypes.\"], \"BACK\": [\"Operationalizing explainability in a manner that spreads awareness about existing stereotypes and fills the information gap can be very effective #REF .\", \"In fact, such an operationalization that elucidates stereotypes or frames of bias #REF in abusive comments at a community level, while providing information to debunk the stereotypes themselves, can offer validation to the victims of abuse by communities, e.g., minority groups, and help them feel safer on the platform.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Langage",
                "identification",
                "(langid)",
                "#TARGET_REF",
                "):",
                "We",
                "use",
                "fastText",
                "5",
                "for",
                "language",
                "identification",
                "filtering,",
                "which",
                "removes",
                "sentence",
                "pairs",
                "that",
                "are",
                "not",
                "predicted",
                "as",
                "the",
                "correct",
                "language",
                "on",
                "either",
                "side."
            ],
            "context": [
                0,
                0,
                0,
                1,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "• Langage identification (langid) #TARGET_REF ): We use fastText 5 for language identification filtering, which removes sentence pairs that are not predicted as the correct language on either side.",
        "output": "{\"INFO\": [\"(langid)\"], \"PERCEPT\": [\"We use fastText 5 for language identification filtering, which removes sentence pairs that are not predicted as the correct language on either side.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "POS",
                "tagger",
                "from",
                "Totale",
                "#TARGET_REF",
                ")",
                "was",
                "also",
                "used",
                "as",
                "the",
                "disambiguation",
                "module",
                "instead",
                "of",
                "the",
                "original",
                "apertium",
                "tagger."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "POS tagger from Totale #TARGET_REF ) was also used as the disambiguation module instead of the original apertium tagger.",
        "output": "{\"INFO\": [\"POS tagger from Totale #TARGET_REF )\"], \"PERCEPT\": [\"was also used as the disambiguation module instead of the original apertium tagger.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "consider",
                "z",
                "as",
                "a",
                "disentangled",
                "representation",
                "for",
                "x,",
                "if",
                "the",
                "changes",
                "in",
                "single",
                "latent",
                "dimensions",
                "of",
                "z",
                "are",
                "sensitive",
                "to",
                "changes",
                "in",
                "single",
                "generative",
                "factors",
                "of",
                "x",
                "while",
                "being",
                "relatively",
                "invariant",
                "to",
                "changes",
                "in",
                "other",
                "factors",
                "#TARGET_REF",
                ".",
                "Several",
                "probabilistic",
                "models",
                "are",
                "designed",
                "to",
                "reveal",
                "this",
                "process,",
                "here",
                "we",
                "look",
                "at",
                "some",
                "of",
                "the",
                "most",
                "widely",
                "used",
                "ones."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We consider z as a disentangled representation for x, if the changes in single latent dimensions of z are sensitive to changes in single generative factors of x while being relatively invariant to changes in other factors #TARGET_REF . Several probabilistic models are designed to reveal this process, here we look at some of the most widely used ones.",
        "output": "{\"INFO\": [\"in other factors #TARGET_REF .\"], \"PERCEPT\": [\"We consider z as a disentangled representation for x, if the changes in single latent dimensions of z are sensitive to changes in single generative factors of x while being relatively invariant to changes\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "domain",
                "in",
                "which",
                "WM",
                "databases",
                "have",
                "been",
                "used",
                "is",
                "terminology.",
                "In",
                "collaboration",
                "with",
                "the",
                "UBS",
                "bank,",
                "a",
                "module",
                "was",
                "developed",
                "which",
                "recognizes",
                "banking",
                "terminology",
                "in",
                "unseen",
                "text",
                "and",
                "provides",
                "an",
                "on-line",
                "link",
                "to",
                "the",
                "relevant",
                "entry",
                "in",
                "a",
                "terminological",
                "database,",
                "cf.",
                "#TARGET_REF",
                ".",
                "Here",
                "the",
                "WFRules",
                "are",
                "used",
                "not",
                "only",
                "as",
                "a",
                "structuring",
                "device",
                "of",
                "the",
                "terminological",
                "lexicon,",
                "but",
                "also",
                "as",
                "a",
                "way",
                "for",
                "recognizing",
                "terms",
                "when",
                "they",
                "are",
                "'hidden'",
                "in",
                "nominalizations,",
                "compounds,",
                "etc.",
                "Thus,",
                "Verwaltungsrat",
                "('board",
                "of",
                "directors')",
                "is",
                "also",
                "recognized",
                "in",
                "Verwaltungsratsvakanz",
                "('vacancy",
                "in",
                "the",
                "board",
                "of",
                "directors').",
                "One",
                "of",
                "the",
                "reasons",
                "why",
                "WM",
                "is",
                "particularly",
                "suited",
                "to",
                "this",
                "task",
                "in",
                "a",
                "multilingual",
                "system",
                "(German,",
                "English,",
                "Italian)",
                "is",
                "that",
                "it",
                "can",
                "treat",
                "singleword",
                "and",
                "multi-word",
                "terms",
                "equally."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Another domain in which WM databases have been used is terminology. In collaboration with the UBS bank, a module was developed which recognizes banking terminology in unseen text and provides an on-line link to the relevant entry in a terminological database, cf. #TARGET_REF . Here the WFRules are used not only as a structuring device of the terminological lexicon, but also as a way for recognizing terms when they are 'hidden' in nominalizations, compounds, etc. Thus, Verwaltungsrat ('board of directors') is also recognized in Verwaltungsratsvakanz ('vacancy in the board of directors'). One of the reasons why WM is particularly suited to this task in a multilingual system (German, English, Italian) is that it can treat singleword and multi-word terms equally.",
        "output": "{\"INFO\": [\"In collaboration with the UBS bank, a module was developed which recognizes banking terminology in unseen text and provides an on-line link to the relevant entry in a terminological database, cf. #TARGET_REF . Here the WFRules are used not only as a structuring device of the terminological lexicon, but also as a way for recognizing terms when they are 'hidden' in nominalizations, compounds, etc.\"], \"PERCEPT\": [], \"BACK\": [\"Another domain in which WM databases have been used is terminology.\", \"Verwaltungsrat ('board of directors') is also recognized in Verwaltungsratsvakanz ('vacancy in the board of directors').\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "type",
                "of",
                "information",
                "recovered",
                "by",
                "the",
                "NP",
                "Enrichment",
                "task",
                "complements",
                "well-established",
                "core",
                "NLP",
                "tasks",
                "such",
                "as",
                "entity",
                "typing,",
                "entity",
                "linking,",
                "coreference",
                "resolution,",
                "and",
                "semantic-role",
                "labeling",
                "#REF",
                ".",
                "We",
                "believe",
                "it",
                "serves",
                "as",
                "an",
                "important",
                "and",
                "much-needed",
                "building",
                "block",
                "for",
                "downstream",
                "applications",
                "that",
                "require",
                "text",
                "understanding,",
                "including",
                "information",
                "retrieval,",
                "relation",
                "extraction",
                "and",
                "event",
                "extraction,",
                "question",
                "answering,",
                "and",
                "so",
                "on.",
                "In",
                "particular,",
                "the",
                "NP",
                "Enrichment",
                "task",
                "neatly",
                "encapsulates",
                "much",
                "of",
                "the",
                "long-range",
                "information",
                "that",
                "is",
                "often",
                "required",
                "by",
                "such",
                "applications.",
                "Take",
                "for",
                "example",
                "a",
                "system",
                "that",
                "attempts",
                "to",
                "extract",
                "reports",
                "on",
                "police",
                "shooting",
                "incidents",
                "#TARGET_REF",
                ",",
                "with",
                "the",
                "following",
                "challenging,",
                "but",
                "not",
                "uncommon,",
                "passage:",
                "2"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The type of information recovered by the NP Enrichment task complements well-established core NLP tasks such as entity typing, entity linking, coreference resolution, and semantic-role labeling #REF . We believe it serves as an important and much-needed building block for downstream applications that require text understanding, including information retrieval, relation extraction and event extraction, question answering, and so on. In particular, the NP Enrichment task neatly encapsulates much of the long-range information that is often required by such applications. Take for example a system that attempts to extract reports on police shooting incidents #TARGET_REF , with the following challenging, but not uncommon, passage: 2",
        "output": "{\"INFO\": [\"a system that attempts to extract reports on police shooting incidents #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "vi",
                "Entity",
                "Pool",
                "Strategy",
                "-To",
                "effectively",
                "deal",
                "with",
                "rare",
                "words,",
                "transformer",
                "models",
                "use",
                "sub-word",
                "units",
                "or",
                "WordPiece",
                "tokens",
                "as",
                "the",
                "input",
                "to",
                "build",
                "the",
                "models",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "there",
                "is",
                "a",
                "possibility",
                "that",
                "one",
                "target",
                "word",
                "can",
                "be",
                "separated",
                "into",
                "several",
                "sub-words.",
                "In",
                "this",
                "strategy,",
                "we",
                "generate",
                "separate",
                "fixed-length",
                "embeddings",
                "for",
                "each",
                "target",
                "word",
                "by",
                "passing",
                "its",
                "sub-word",
                "outputs",
                "through",
                "a",
                "pooling",
                "layer.",
                "The",
                "pooled",
                "outputs",
                "are",
                "concatenated",
                "and",
                "fed",
                "into",
                "a",
                "softmax",
                "layer",
                "to",
                "predict",
                "the",
                "labels",
                "(Figure",
                "2e)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "vi Entity Pool Strategy -To effectively deal with rare words, transformer models use sub-word units or WordPiece tokens as the input to build the models #TARGET_REF . Therefore, there is a possibility that one target word can be separated into several sub-words. In this strategy, we generate separate fixed-length embeddings for each target word by passing its sub-word outputs through a pooling layer. The pooled outputs are concatenated and fed into a softmax layer to predict the labels (Figure 2e).",
        "output": "{\"INFO\": [\"-To effectively deal with rare words, transformer models use sub-word units or WordPiece tokens as the input to build the models #TARGET_REF .\"], \"PERCEPT\": [\"Therefore, there is a possibility that one target word can be separated into several sub-words. In this strategy, we generate separate fixed-length embeddings for each target word by passing its sub-word outputs through a pooling layer.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "will",
                "describe",
                "parsing",
                "algorithms",
                "using",
                "Parsing",
                "Schemata,",
                "a",
                "framework",
                "for",
                "high-level",
                "description",
                "of",
                "parsing",
                "algorithms",
                "#TARGET_REF",
                ".",
                "An",
                "interesting",
                "application",
                "of",
                "this",
                "framework",
                "is",
                "the",
                "analysis",
                "of",
                "the",
                "relations",
                "between",
                "different",
                "parsing",
                "algorithms",
                "by",
                "studying",
                "the",
                "formal",
                "relations",
                "between",
                "their",
                "underlying",
                "parsing",
                "schemata."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "We will describe parsing algorithms using Parsing Schemata, a framework for high-level description of parsing algorithms #TARGET_REF . An interesting application of this framework is the analysis of the relations between different parsing algorithms by studying the formal relations between their underlying parsing schemata.",
        "output": "{\"INFO\": [\"Parsing Schemata, a framework for high-level description of parsing algorithms #TARGET_REF\"], \"PERCEPT\": [\"An interesting application of this framework is\"], \"BACK\": [\"the analysis of the relations between different parsing algorithms by studying the formal relations between their underlying parsing schemata.\"]}"
    },
    {
        "gold": {
            "text": [
                "Among",
                "four",
                "submitted",
                "systems,",
                "MaChAmp",
                "(der",
                "Goot,",
                "2022)",
                "and",
                "AN(L)P",
                "#REF",
                "teams",
                "used",
                "the",
                "default",
                "tokenizer",
                "from",
                "either",
                "BERT",
                "or",
                "mBERT,",
                "which",
                "are",
                "not",
                "designed",
                "for",
                "scientific",
                "documents.",
                "Consequently,",
                "they",
                "are",
                "unable",
                "to",
                "correctly",
                "segment",
                "the",
                "mathematic",
                "source,",
                "hence,",
                "they",
                "#TARGET_REF",
                "and",
                "JBNU-CCLab",
                "(Lee",
                "and",
                "Na,",
                "2022)",
                "achieved",
                "much",
                "higher",
                "performances",
                "thanks",
                "to",
                "SciBERT",
                "tokenizer",
                "because",
                "it",
                "is",
                "trained",
                "on",
                "scientific",
                "literature.",
                "However,",
                "the",
                "SciBERT",
                "tokenizer",
                "is",
                "far",
                "from",
                "perfect",
                "such",
                "that",
                "JBNU-CCLab",
                "further",
                "proposed",
                "to",
                "tokenize",
                "the",
                "mathematical",
                "formulae",
                "using",
                "a",
                "customized",
                "rule-based",
                "tokenizer",
                "based",
                "on",
                "capital",
                "letters,",
                "numbers,",
                "and",
                "special",
                "characters(e.g.",
                "%,",
                "$,",
                "{,",
                "}).",
                "Hence,",
                "they",
                "achieved",
                "state-of-the-art",
                "performance",
                "on",
                "both",
                "NER",
                "and",
                "RE",
                "subtasks."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Among four submitted systems, MaChAmp (der Goot, 2022) and AN(L)P #REF teams used the default tokenizer from either BERT or mBERT, which are not designed for scientific documents. Consequently, they are unable to correctly segment the mathematic source, hence, they #TARGET_REF and JBNU-CCLab (Lee and Na, 2022) achieved much higher performances thanks to SciBERT tokenizer because it is trained on scientific literature. However, the SciBERT tokenizer is far from perfect such that JBNU-CCLab further proposed to tokenize the mathematical formulae using a customized rule-based tokenizer based on capital letters, numbers, and special characters(e.g. %, $, {, }). Hence, they achieved state-of-the-art performance on both NER and RE subtasks.",
        "output": "{\"INFO\": [\"they #TARGET_REF\"], \"PERCEPT\": [\"they are unable to correctly segment the mathematic source,\", \"achieved much higher performances thanks to SciBERT tokenizer because it is trained on scientific literature.\"], \"BACK\": [\"Among four submitted systems, MaChAmp (der Goot, 2022) and AN(L)P #REF teams used the default tokenizer from either BERT or mBERT, which are not designed for scientific documents.\", \"and JBNU-CCLab (Lee and Na, 2022)\"]}"
    },
    {
        "gold": {
            "text": [
                "Apertium,",
                "the",
                "open-source",
                "MT",
                "platform",
                "that",
                "was",
                "used",
                "as",
                "basis",
                "in",
                "the",
                "case",
                "study,",
                "is",
                "described",
                "in",
                "the",
                "first",
                "section",
                "following",
                "the",
                "introduction.",
                "Materials",
                "and",
                "methods",
                "describe",
                "already",
                "available",
                "language",
                "processing",
                "tools",
                "and",
                "materials,",
                "mainly",
                "corpora.",
                "The",
                "newly",
                "developed",
                "methods",
                "are",
                "described",
                "in",
                "the",
                "same",
                "section.",
                "Following",
                "section",
                "describes",
                "results",
                "and",
                "evaluation",
                "methods.",
                "The",
                "last",
                "section",
                "describes",
                "discussion",
                "and",
                "further",
                "work.",
                "The",
                "modules",
                "are",
                "shown",
                "on",
                "Figure",
                "1,",
                "where",
                "the",
                "specially",
                "addressed",
                "modules",
                "are",
                "marked",
                "with",
                "a",
                "new",
                "colour",
                "and",
                "the",
                "two",
                "newly",
                "added",
                "modules",
                "are",
                "inserted.",
                "Each",
                "group's",
                "data",
                "creation",
                "was",
                "addressed",
                "by",
                "a",
                "particular",
                "method,",
                "monolingual",
                "dictionaries",
                "were",
                "constructed",
                "using",
                "bilingual",
                "dictionary",
                "data",
                "and",
                "applying",
                "automatic",
                "paradigm",
                "tagging",
                "techniques,",
                "bilingual",
                "dictionary",
                "was",
                "constructed",
                "using",
                "available",
                "bilingual",
                "word-list",
                "but",
                "a",
                "few",
                "methods",
                "for",
                "automatic",
                "bilingual",
                "dictionary",
                "construction",
                "were",
                "investigated,",
                "a",
                "method",
                "for",
                "automatic",
                "structural",
                "shallow-transfer",
                "rule",
                "construction",
                "(Sánchez-",
                "#TARGET_REF",
                "will",
                "be",
                "used",
                "to",
                "construct",
                "a",
                "set",
                "of",
                "structural",
                "transfer",
                "rules."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Apertium, the open-source MT platform that was used as basis in the case study, is described in the first section following the introduction. Materials and methods describe already available language processing tools and materials, mainly corpora. The newly developed methods are described in the same section. Following section describes results and evaluation methods. The last section describes discussion and further work. The modules are shown on Figure 1, where the specially addressed modules are marked with a new colour and the two newly added modules are inserted. Each group's data creation was addressed by a particular method, monolingual dictionaries were constructed using bilingual dictionary data and applying automatic paradigm tagging techniques, bilingual dictionary was constructed using available bilingual word-list but a few methods for automatic bilingual dictionary construction were investigated, a method for automatic structural shallow-transfer rule construction (Sánchez- #TARGET_REF will be used to construct a set of structural transfer rules.",
        "output": "{\"INFO\": [\"a method for automatic structural shallow-transfer rule construction (S\\u00e1nchez- #TARGET_REF\"], \"PERCEPT\": [\"will be used to construct a set of structural transfer rules.\"], \"BACK\": [\"Each group's data creation was addressed by a particular method,\"]}"
    },
    {
        "gold": {
            "text": [
                "Thus",
                "there",
                "are",
                "a",
                "number",
                "of",
                "situations",
                "in",
                "which",
                "gCNs",
                "are",
                "not",
                "sufficient.",
                "Given",
                "that",
                "gCNs",
                "can",
                "be",
                "represented",
                "by",
                "Tree",
                "Substitution",
                "Grammars,",
                "as",
                "in",
                "#TARGET_REF",
                ",",
                "which",
                "are",
                "in",
                "fact",
                "TAGs",
                "that",
                "do",
                "not",
                "allow",
                "precisely",
                "the",
                "kind",
                "of",
                "unbounded",
                "phenomena",
                "described",
                "by",
                "TAGs,",
                "this",
                "would",
                "suggest",
                "that",
                "using",
                "a",
                "TAG",
                "grammar",
                "to",
                "describe",
                "the",
                "gNCNs",
                "in",
                "order",
                "to",
                "decompose",
                "the",
                "trees",
                "would",
                "be",
                "feasible,",
                "and",
                "this",
                "is",
                "further",
                "an",
                "interesting",
                "question",
                "for",
                "theoretical",
                "reasons",
                "described",
                "below."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Thus there are a number of situations in which gCNs are not sufficient. Given that gCNs can be represented by Tree Substitution Grammars, as in #TARGET_REF , which are in fact TAGs that do not allow precisely the kind of unbounded phenomena described by TAGs, this would suggest that using a TAG grammar to describe the gNCNs in order to decompose the trees would be feasible, and this is further an interesting question for theoretical reasons described below.",
        "output": "{\"INFO\": [\"gCNs can be represented by Tree Substitution Grammars,\", \"which are in fact TAGs that do not allow precisely the kind of unbounded phenomena described by TAGs,\"], \"PERCEPT\": [\"Given that\", \"as in #TARGET_REF ,\", \"this would suggest that using a TAG grammar to describe the gNCNs in order to decompose the trees would be feasible,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Unsupervised",
                "systems",
                "Majority",
                "of",
                "the",
                "unsupervised",
                "WSD",
                "systems",
                "use",
                "external",
                "knowledge",
                "bases",
                "like",
                "WordNet",
                "#REF",
                "and",
                "BabelNet",
                "#REF",
                ".",
                "For",
                "each",
                "input",
                "word,",
                "its",
                "correct",
                "meaning",
                "according",
                "to",
                "the",
                "context",
                "can",
                "be",
                "found",
                "using",
                "graph-based",
                "techniques",
                "from",
                "those",
                "external",
                "knowledge",
                "bases.",
                "However,",
                "these",
                "approaches",
                "are",
                "only",
                "limited",
                "to",
                "the",
                "languages",
                "supported",
                "by",
                "used",
                "knowledge",
                "bases.",
                "More",
                "recent",
                "works",
                "like",
                "Hettiarachchi",
                "and",
                "Ranasinghe",
                "(2020a),",
                "#REF",
                "propose",
                "to",
                "use",
                "stacked",
                "word",
                "embeddings",
                "#REF",
                "obtained",
                "by",
                "general",
                "purpose",
                "pretrained",
                "contextualised",
                "word",
                "embedding",
                "models",
                "such",
                "as",
                "BERT",
                "#REF",
                "and",
                "Flair",
                "#TARGET_REF",
                "for",
                "unsupervised",
                "WSD.",
                "Despite",
                "their",
                "ability",
                "to",
                "scale",
                "over",
                "different",
                "languages,",
                "unsupervised",
                "approaches",
                "fall",
                "behind",
                "supervised",
                "systems",
                "in",
                "terms",
                "of",
                "accuracy."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Unsupervised systems Majority of the unsupervised WSD systems use external knowledge bases like WordNet #REF and BabelNet #REF . For each input word, its correct meaning according to the context can be found using graph-based techniques from those external knowledge bases. However, these approaches are only limited to the languages supported by used knowledge bases. More recent works like Hettiarachchi and Ranasinghe (2020a), #REF propose to use stacked word embeddings #REF obtained by general purpose pretrained contextualised word embedding models such as BERT #REF and Flair #TARGET_REF for unsupervised WSD. Despite their ability to scale over different languages, unsupervised approaches fall behind supervised systems in terms of accuracy.",
        "output": "{\"INFO\": [\"Flair #TARGET_REF for unsupervised WSD.\"], \"PERCEPT\": [], \"BACK\": [\"More recent works like Hettiarachchi and Ranasinghe (2020a), #REF propose to use stacked word embeddings #REF obtained by general purpose pretrained contextualised word embedding models such as BERT #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "Coreference",
                "Arc",
                "Prediction",
                "(CAP)",
                "We",
                "use",
                "the",
                "English",
                "CAP",
                "dataset",
                "derived",
                "from",
                "PreCo",
                "#TARGET_REF",
                "by",
                "#REF",
                ".",
                "The",
                "creators",
                "of",
                "the",
                "dataset",
                "partition",
                "the",
                "data",
                "by",
                "cosine",
                "similarity",
                "of",
                "GloVe",
                "#REF",
                "embeddings",
                "of",
                "mention",
                "spans",
                "and",
                "balance",
                "the",
                "number",
                "of",
                "positive",
                "and",
                "negative",
                "examples",
                "in",
                "each",
                "bucket,",
                "so",
                "that",
                "models",
                "do",
                "not",
                "solve",
                "the",
                "task",
                "by",
                "capturing",
                "surface",
                "features",
                "of",
                "entity",
                "mention",
                "spans.",
                "The",
                "original",
                "data",
                "split",
                "provides",
                "8k",
                "examples",
                "for",
                "each",
                "of",
                "the",
                "training,",
                "development,",
                "and",
                "test",
                "sets."
            ],
            "context": [
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Coreference Arc Prediction (CAP) We use the English CAP dataset derived from PreCo #TARGET_REF by #REF . The creators of the dataset partition the data by cosine similarity of GloVe #REF embeddings of mention spans and balance the number of positive and negative examples in each bucket, so that models do not solve the task by capturing surface features of entity mention spans. The original data split provides 8k examples for each of the training, development, and test sets.",
        "output": "{\"INFO\": [\"PreCo #TARGET_REF\"], \"PERCEPT\": [\"We use the English CAP dataset derived from\", \"by #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "1.",
                "The",
                "TempEval-3",
                "TimeBank",
                "dataset",
                "was",
                "used",
                "for",
                "English",
                "#REF",
                ".",
                "The",
                "corpus",
                "consists",
                "of",
                "61,418",
                "tokens",
                "for",
                "training",
                "and",
                "6,756",
                "event",
                "mentions.",
                "3.",
                "For",
                "Italian,",
                "we",
                "use",
                "Ita-TimeBank's",
                "ILC",
                "corpus",
                "#TARGET_REF",
                "the",
                "Italian",
                "corpus",
                "annotated",
                "using",
                "ISO-TimeML",
                "rules",
                "for",
                "events",
                "and",
                "temporal",
                "information.",
                "The",
                "corpus",
                "consists",
                "of",
                "68,000",
                "tokens",
                "and",
                "10,591",
                "event",
                "mentions."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "1. The TempEval-3 TimeBank dataset was used for English #REF . The corpus consists of 61,418 tokens for training and 6,756 event mentions. 3. For Italian, we use Ita-TimeBank's ILC corpus #TARGET_REF the Italian corpus annotated using ISO-TimeML rules for events and temporal information. The corpus consists of 68,000 tokens and 10,591 event mentions.",
        "output": "{\"INFO\": [\"Ita-TimeBank's ILC corpus #TARGET_REF\"], \"PERCEPT\": [\"we use\"], \"BACK\": [\"For Italian,\", \"the Italian corpus annotated using ISO-TimeML rules for events and temporal information. The corpus consists of 68,000 tokens and 10,591 event mentions.\"]}"
    },
    {
        "gold": {
            "text": [
                "Algorithm",
                "1",
                "Metric",
                "of",
                "#TARGET_REF",
                "1",
                ":",
                "D",
                "=",
                "∅",
                "2:",
                "for",
                "f",
                "i",
                "∈",
                "F",
                "do",
                "3:",
                "for",
                "n",
                "=",
                "1,",
                "2,",
                ".",
                ".",
                ".",
                ",",
                "N",
                "do",
                "4:",
                "Sample",
                "s",
                "n",
                "from",
                "j",
                "S",
                "ij",
                "5:",
                "Find",
                "the",
                "value",
                "v",
                "ij",
                "on",
                "f",
                "i",
                "for",
                "s",
                "n",
                "6:",
                "Sample",
                "(z",
                "(1)",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "(1)",
                "L",
                ")",
                "from",
                "R",
                "ij",
                "7:",
                "Sample",
                "(z",
                "(2)",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "(2)",
                "L",
                ")",
                "from",
                "R",
                "ij",
                "8:",
                "z",
                "n",
                "=",
                "1",
                "L",
                "L",
                "l=1",
                "|z",
                "(1)",
                "l",
                "−",
                "z",
                "(2)",
                "l",
                "|",
                "9:",
                "D",
                "=",
                "{(z",
                "n",
                ",",
                "f",
                "i",
                ")}",
                "D",
                "10:",
                "Split",
                "D",
                "into"
            ],
            "context": [
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Algorithm 1 Metric of #TARGET_REF 1 : D = ∅ 2: for f i ∈ F do 3: for n = 1, 2, . . . , N do 4: Sample s n from j S ij 5: Find the value v ij on f i for s n 6: Sample (z (1) 1 , . . . , z (1) L ) from R ij 7: Sample (z (2) 1 , . . . , z (2) L ) from R ij 8: z n = 1 L L l=1 |z (1) l − z (2) l | 9: D = {(z n , f i )} D 10: Split D into",
        "output": "{\"INFO\": [\"Metric of #TARGET_REF 1 : D = \\u2205 2: for f i \\u2208 F do 3: for n = 1, 2, . . . , N do 4: Sample s n from j S ij 5: Find the value v ij on f i for s n 6: Sample (z (1) 1 , . . . , z (1) L ) from R ij 7: Sample (z (2) 1 , . . . , z (2) L ) from R ij 8: z n = 1 L L l=1 |z (1) l \\u2212 z (2) l | 9: D = {(z n , f i )} D 10: Split D into\"], \"PERCEPT\": [], \"BACK\": [\"Algorithm 1\"]}"
    },
    {
        "gold": {
            "text": [
                "completeness,",
                "which",
                "measures",
                "whether",
                "a",
                "generative",
                "factor",
                "is",
                "only",
                "captured",
                "by",
                "one",
                "latent",
                "variable,",
                "informativeness,",
                "which",
                "measures",
                "the",
                "degree",
                "by",
                "which",
                "representations",
                "capture",
                "exact",
                "values",
                "of",
                "the",
                "generative",
                "factors.",
                "2",
                "They",
                "design",
                "a",
                "series",
                "of",
                "classification",
                "tasks",
                "to",
                "predict",
                "the",
                "value",
                "of",
                "a",
                "generative",
                "factor",
                "based",
                "on",
                "the",
                "latent",
                "code,",
                "and",
                "extract",
                "the",
                "relative",
                "importance",
                "of",
                "each",
                "latent",
                "code",
                "for",
                "each",
                "task",
                "to",
                "calculate",
                "disentanglement",
                "and",
                "completeness",
                "scores.",
                "Informativeness",
                "score",
                "is",
                "measured",
                "by",
                "the",
                "accuracy",
                "of",
                "the",
                "classifier",
                "directly.",
                "Other",
                "existing",
                "metrics",
                "reflect",
                "at",
                "least",
                "one",
                "of",
                "these",
                "three",
                "criteria,",
                "as",
                "summarised",
                "in",
                "Table",
                "1",
                "#REF",
                "focus",
                "on",
                "disentanglement",
                "and",
                "propose",
                "to",
                "use",
                "the",
                "absolute",
                "difference",
                "of",
                "two",
                "groups",
                "of",
                "representations",
                "with",
                "the",
                "same",
                "value",
                "on",
                "one",
                "generative",
                "factor",
                "to",
                "predict",
                "this",
                "generative",
                "factor.",
                "For",
                "perfectly",
                "disentangled",
                "representations,",
                "latent",
                "dimensions",
                "not",
                "encoding",
                "information",
                "about",
                "this",
                "generative",
                "factor",
                "would",
                "have",
                "zero",
                "difference.",
                "Hence,",
                "even",
                "simple",
                "linear",
                "classifiers",
                "could",
                "easily",
                "identify",
                "the",
                "generative",
                "factors",
                "based",
                "on",
                "the",
                "changes",
                "of",
                "values.",
                "#REF",
                "consider",
                "both",
                "disentanglement",
                "and",
                "completeness",
                "by",
                "first",
                "finding",
                "the",
                "dimension",
                "which",
                "has",
                "the",
                "largest",
                "variance",
                "when",
                "fixing",
                "the",
                "value",
                "on",
                "one",
                "generative",
                "factor,",
                "and",
                "then",
                "using",
                "the",
                "found",
                "dimension",
                "to",
                "predict",
                "that",
                "generative",
                "factor.",
                "#REF",
                "propose",
                "a",
                "series",
                "of",
                "classification",
                "tasks",
                "each",
                "of",
                "which",
                "uses",
                "a",
                "single",
                "latent",
                "variable",
                "to",
                "predict",
                "the",
                "value",
                "of",
                "a",
                "generative",
                "factor",
                "and",
                "treat",
                "the",
                "average",
                "of",
                "the",
                "difference",
                "between",
                "the",
                "top",
                "two",
                "accuracy",
                "scores",
                "for",
                "each",
                "generative",
                "factor",
                "as",
                "the",
                "final",
                "disentanglement",
                "score."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "completeness, which measures whether a generative factor is only captured by one latent variable, informativeness, which measures the degree by which representations capture exact values of the generative factors. 2 They design a series of classification tasks to predict the value of a generative factor based on the latent code, and extract the relative importance of each latent code for each task to calculate disentanglement and completeness scores. Informativeness score is measured by the accuracy of the classifier directly. Other existing metrics reflect at least one of these three criteria, as summarised in Table 1 #REF focus on disentanglement and propose to use the absolute difference of two groups of representations with the same value on one generative factor to predict this generative factor. For perfectly disentangled representations, latent dimensions not encoding information about this generative factor would have zero difference. Hence, even simple linear classifiers could easily identify the generative factors based on the changes of values. #REF consider both disentanglement and completeness by first finding the dimension which has the largest variance when fixing the value on one generative factor, and then using the found dimension to predict that generative factor. #REF propose a series of classification tasks each of which uses a single latent variable to predict the value of a generative factor and treat the average of the difference between the top two accuracy scores for each generative factor as the final disentanglement score.",
        "output": "{\"INFO\": [\"They\"], \"PERCEPT\": [], \"BACK\": [\"completeness, which measures whether a generative factor is only captured by one latent variable, informativeness, which measures the degree by which representations capture exact values of the generative factors.\", \"design a series of classification tasks to predict the value of a generative factor based on the latent code, and extract the relative importance of each latent code for each task to calculate disentanglement and completeness scores.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "comparison",
                "with",
                "previous",
                "research",
                "#TARGET_REF",
                ",",
                "we",
                "decoded",
                "word",
                "length,",
                "frequency",
                "and",
                "class",
                "with",
                "linear",
                "SVMs",
                "in",
                "a",
                "temporally-resolved",
                "fashion",
                "from",
                "0",
                "to",
                "700",
                "ms",
                "poststimulus",
                "EEG,",
                "recorded",
                "during",
                "sentence",
                "reading."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For comparison with previous research #TARGET_REF , we decoded word length, frequency and class with linear SVMs in a temporally-resolved fashion from 0 to 700 ms poststimulus EEG, recorded during sentence reading.",
        "output": "{\"INFO\": [\"previous research #TARGET_REF ,\"], \"PERCEPT\": [\"For comparison with\", \"we decoded word length, frequency and class with linear SVMs in a temporally-resolved fashion from 0 to 700 ms poststimulus EEG, recorded during sentence reading.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "previous",
                "step,",
                "we",
                "first",
                "search",
                "counter-fitting",
                "word",
                "vectors",
                "to",
                "find",
                "synonyms",
                "with",
                "cosine",
                "similarity",
                "larger",
                "than",
                "a",
                "threshold",
                "4",
                "τ",
                ".",
                "Additionally",
                "we",
                "search",
                "in",
                "WordNet",
                "and",
                "DBpedia",
                "to",
                "obtain",
                "a",
                "maximum",
                "of",
                "N",
                "synonyms",
                "for",
                "each",
                "token",
                "t.",
                "Then",
                "we",
                "extract",
                "a",
                "subset",
                "S",
                "t",
                "from",
                "D,",
                "which",
                "consists",
                "of",
                "sentences",
                "containing",
                "t.",
                "We",
                "perturb",
                "all",
                "sentences",
                "in",
                "S",
                "t",
                "by",
                "replacing",
                "t",
                "with",
                "its",
                "synonyms.",
                "The",
                "resulted",
                "perturbed",
                "set",
                "S",
                "′",
                "t",
                "is",
                "N",
                "times",
                "of",
                "the",
                "original",
                "set",
                "S",
                "t",
                ".",
                "We",
                "apply",
                "model",
                "f",
                "on",
                "S",
                "t",
                "and",
                "S",
                "′",
                "t",
                "and",
                "obtain",
                "accuracy",
                "acc",
                "t",
                "and",
                "acc",
                "′",
                "t",
                ".",
                "Since",
                "we",
                "only",
                "perturb",
                "S",
                "t",
                "with",
                "t's",
                "synonyms,",
                "the",
                "semantic",
                "meaning",
                "of",
                "perturbed",
                "sentences",
                "should",
                "stay",
                "close",
                "to",
                "the",
                "original",
                "sentences.",
                "Thus,",
                "if",
                "t",
                "is",
                "a",
                "genuine",
                "token,",
                "acc",
                "′",
                "t",
                "is",
                "expected",
                "to",
                "be",
                "close",
                "to",
                "acc",
                "t",
                ".",
                "On",
                "the",
                "other",
                "hand,",
                "if",
                "t",
                "is",
                "a",
                "shortcut,",
                "model",
                "prediction",
                "can",
                "be",
                "different",
                "even",
                "the",
                "semantic",
                "meaning",
                "of",
                "the",
                "sentence",
                "does",
                "not",
                "change",
                "a",
                "lot",
                "(see",
                "examples",
                "in",
                "Table",
                "2).",
                "Thus,",
                "we",
                "assume",
                "tokens",
                "with",
                "larger",
                "differences",
                "between",
                "acc",
                "t",
                "and",
                "acc",
                "′",
                "t",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "shortcuts",
                "and",
                "tokens",
                "with",
                "smaller",
                "differences",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "domain",
                "specific",
                "\"genuine\"",
                "words.",
                "From",
                "the",
                "potential",
                "shortcut",
                "token",
                "list",
                "computed",
                "in",
                "Sec",
                "3.2,",
                "we",
                "remove",
                "tokens",
                "with",
                "performance",
                "difference",
                "smaller",
                "than",
                "δ",
                "to",
                "further",
                "filter",
                "domain",
                "specific",
                "\"geniue\"",
                "tokens",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "previous step, we first search counter-fitting word vectors to find synonyms with cosine similarity larger than a threshold 4 τ . Additionally we search in WordNet and DBpedia to obtain a maximum of N synonyms for each token t. Then we extract a subset S t from D, which consists of sentences containing t. We perturb all sentences in S t by replacing t with its synonyms. The resulted perturbed set S ′ t is N times of the original set S t . We apply model f on S t and S ′ t and obtain accuracy acc t and acc ′ t . Since we only perturb S t with t's synonyms, the semantic meaning of perturbed sentences should stay close to the original sentences. Thus, if t is a genuine token, acc ′ t is expected to be close to acc t . On the other hand, if t is a shortcut, model prediction can be different even the semantic meaning of the sentence does not change a lot (see examples in Table 2). Thus, we assume tokens with larger differences between acc t and acc ′ t are more likely to be shortcuts and tokens with smaller differences are more likely to be domain specific \"genuine\" words. From the potential shortcut token list computed in Sec 3.2, we remove tokens with performance difference smaller than δ to further filter domain specific \"geniue\" tokens .",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "An",
                "already",
                "trained",
                "and",
                "tested",
                "POS",
                "tagger",
                "#REF",
                "was",
                "available",
                "for",
                "Slovenian",
                "language.",
                "Words",
                "were",
                "tagged",
                "using",
                "full",
                "MSD",
                "descriptions",
                "#TARGET_REF",
                "and",
                "grouped",
                "into",
                "classes",
                "with",
                "same",
                "descriptions",
                "(words",
                "that",
                "had",
                "the",
                "same",
                "POS",
                "tag",
                "were",
                "grouped",
                "together).",
                "This",
                "process",
                "produced",
                "312",
                "classes",
                "in",
                "Slovene",
                "and",
                "274",
                "classes",
                "in",
                "Serbian",
                "language,",
                "see",
                "Table",
                "1",
                "for",
                "details.",
                "A",
                "linguist",
                "manually",
                "tagged",
                "the",
                "classes",
                "to",
                "paradigms."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "An already trained and tested POS tagger #REF was available for Slovenian language. Words were tagged using full MSD descriptions #TARGET_REF and grouped into classes with same descriptions (words that had the same POS tag were grouped together). This process produced 312 classes in Slovene and 274 classes in Serbian language, see Table 1 for details. A linguist manually tagged the classes to paradigms.",
        "output": "{\"INFO\": [\"full MSD descriptions #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "existing",
                "approach",
                "to",
                "convert",
                "coreference",
                "annotations",
                "into",
                "(question,",
                "context,",
                "answer)",
                "tuples,",
                "which",
                "is",
                "used",
                "to",
                "improve",
                "coreference",
                "resolution",
                "performance",
                "#TARGET_REF",
                ",",
                "is",
                "to",
                "use",
                "the",
                "sentence",
                "of",
                "the",
                "anaphor",
                "as",
                "a",
                "declarative",
                "query,",
                "and",
                "its",
                "closest",
                "antecedent",
                "as",
                "the",
                "answer.",
                "The",
                "format",
                "of",
                "these",
                "queries",
                "is",
                "not",
                "compatible",
                "with",
                "questions",
                "in",
                "MRC",
                "datasets,",
                "and",
                "therefore,",
                "the",
                "impact",
                "of",
                "this",
                "data",
                "on",
                "MRC",
                "models",
                "may",
                "be",
                "limited.",
                "In",
                "this",
                "work,",
                "we",
                "instead",
                "generate",
                "questions",
                "from",
                "those",
                "declarative",
                "queries",
                "using",
                "an",
                "automatic",
                "question",
                "generation",
                "model.",
                "We",
                "use",
                "the",
                "BART",
                "model",
                "#REF",
                "that",
                "is",
                "one",
                "of",
                "the",
                "state-of-the-art",
                "text",
                "generation",
                "models.",
                "Below",
                "we",
                "explain",
                "the",
                "details",
                "of",
                "each",
                "of",
                "these",
                "two",
                "approaches",
                "for",
                "creating",
                "QA",
                "data",
                "from",
                "CoNLL-2012.",
                "Table",
                "4",
                "shows",
                "examples",
                "from",
                "both",
                "approaches.",
                "2019)",
                "choose",
                "a",
                "sentence",
                "that",
                "contains",
                "an",
                "anaphor",
                "as",
                "a",
                "declarative",
                "query,",
                "the",
                "closest",
                "nonpronominal",
                "antecedent",
                "of",
                "that",
                "anaphor",
                "as",
                "the",
                "answer,",
                "and",
                "the",
                "corresponding",
                "document",
                "of",
                "the",
                "expressions",
                "as",
                "the",
                "context.",
                "10",
                "We",
                "remove",
                "the",
                "tuples",
                "in",
                "which",
                "the",
                "anaphor",
                "and",
                "its",
                "antecedent",
                "are",
                "identical.",
                "The",
                "reason",
                "is",
                "that",
                "(1)",
                "Quoref",
                "already",
                "contains",
                "many",
                "examples",
                "in",
                "which",
                "the",
                "coreference",
                "relation",
                "is",
                "between",
                "two",
                "mentions",
                "with",
                "the",
                "same",
                "string,",
                "and",
                "(2)",
                "even",
                "after",
                "removing",
                "such",
                "examples,",
                "CoNLL",
                "dec",
                "contains",
                "around",
                "four",
                "times",
                "more",
                "QA",
                "pairs",
                "than",
                "the",
                "Quoref",
                "training",
                "data."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The existing approach to convert coreference annotations into (question, context, answer) tuples, which is used to improve coreference resolution performance #TARGET_REF , is to use the sentence of the anaphor as a declarative query, and its closest antecedent as the answer. The format of these queries is not compatible with questions in MRC datasets, and therefore, the impact of this data on MRC models may be limited. In this work, we instead generate questions from those declarative queries using an automatic question generation model. We use the BART model #REF that is one of the state-of-the-art text generation models. Below we explain the details of each of these two approaches for creating QA data from CoNLL-2012. Table 4 shows examples from both approaches. 2019) choose a sentence that contains an anaphor as a declarative query, the closest nonpronominal antecedent of that anaphor as the answer, and the corresponding document of the expressions as the context. 10 We remove the tuples in which the anaphor and its antecedent are identical. The reason is that (1) Quoref already contains many examples in which the coreference relation is between two mentions with the same string, and (2) even after removing such examples, CoNLL dec contains around four times more QA pairs than the Quoref training data.",
        "output": "{\"INFO\": [\"coreference resolution performance #TARGET_REF , is to use the sentence of the anaphor as a declarative query, and its closest antecedent as the answer.\"], \"PERCEPT\": [], \"BACK\": [\"The existing approach to convert coreference annotations into (question, context, answer) tuples, which is used to improve\"]}"
    },
    {
        "gold": {
            "text": [
                "If",
                "we",
                "fine-tune",
                "a",
                "RoBERTa-large",
                "model",
                "on",
                "Quoref,",
                "it",
                "achieves",
                "78",
                "F1",
                "score",
                "while",
                "the",
                "estimated",
                "human",
                "performance",
                "is",
                "around",
                "93",
                "F1",
                "score",
                "#REF",
                ".",
                "This",
                "high",
                "performance,",
                "given",
                "that",
                "RoBERTa",
                "can",
                "only",
                "predict",
                "continuous",
                "span",
                "answers",
                "while",
                "Quoref",
                "also",
                "contains",
                "discontinuous",
                "answers,",
                "indicates",
                "that",
                "either",
                "(1)",
                "Quoref",
                "presents",
                "coreference-aware",
                "QA",
                "very",
                "well",
                "so",
                "that",
                "the",
                "model",
                "can",
                "properly",
                "learn",
                "coreference",
                "reasoning",
                "from",
                "the",
                "training",
                "data,",
                "(2)",
                "pretrained",
                "transformer-based",
                "models",
                "have",
                "already",
                "learned",
                "coreference",
                "reasoning",
                "during",
                "their",
                "pre-training,",
                "e.g.,",
                "as",
                "suggested",
                "by",
                "#TARGET_REF",
                "and",
                "#REF",
                ",",
                "or",
                "(3)",
                "coreference",
                "reasoning",
                "is",
                "not",
                "necessarily",
                "required",
                "for",
                "solving",
                "most",
                "examples."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "If we fine-tune a RoBERTa-large model on Quoref, it achieves 78 F1 score while the estimated human performance is around 93 F1 score #REF . This high performance, given that RoBERTa can only predict continuous span answers while Quoref also contains discontinuous answers, indicates that either (1) Quoref presents coreference-aware QA very well so that the model can properly learn coreference reasoning from the training data, (2) pretrained transformer-based models have already learned coreference reasoning during their pre-training, e.g., as suggested by #TARGET_REF and #REF , or (3) coreference reasoning is not necessarily required for solving most examples.",
        "output": "{\"INFO\": [\"pretrained transformer-based models have already learned coreference reasoning during their pre-training,\"], \"PERCEPT\": [\"This high performance,\", \"indicates that either\", \"(2)\", \"as suggested by #TARGET_REF\"], \"BACK\": [\"(1) Quoref presents coreference-aware QA very well so that the model can properly learn coreference reasoning from the training data,\", \"and #REF , or (3) coreference reasoning is not necessarily required for solving most examples.\"]}"
    },
    {
        "gold": {
            "text": [
                "of",
                "our",
                "parser,",
                "every",
                "token",
                "is",
                "mapped",
                "to",
                "one",
                "of",
                "a",
                "finite",
                "number",
                "of",
                "meaning",
                "fragments",
                "(unlike",
                "a",
                "sequence-to-sequence",
                "system",
                "where",
                "a",
                "single",
                "token",
                "can",
                "in",
                "principle",
                "give",
                "rise",
                "to",
                "an",
                "unbounded",
                "number",
                "of",
                "output",
                "symbols),",
                "every",
                "clause",
                "belongs",
                "to",
                "one",
                "of",
                "these",
                "fragments",
                "(unlike",
                "a",
                "sequence-to-sequence",
                "system",
                "where",
                "the",
                "output",
                "is",
                "not",
                "usually",
                "anchored),",
                "and",
                "there",
                "is",
                "a",
                "straightforward",
                "rule",
                "that",
                "combines",
                "fragments",
                "into",
                "utterance",
                "meanings",
                "(unlike",
                "sequence-to-sequence",
                "systems",
                "where",
                "the",
                "interactions",
                "between",
                "tokens",
                "are",
                "opaque).",
                "This",
                "type",
                "of",
                "transparency",
                "is",
                "especially",
                "important",
                "in",
                "human-in-the-loop",
                "annotation,",
                "where",
                "parsers",
                "produce",
                "an",
                "initial",
                "annotation",
                "and",
                "annotators",
                "correct",
                "them.",
                "To",
                "do",
                "this",
                "efficiently",
                "and",
                "consistenly,",
                "annotators",
                "need",
                "to",
                "pinpoint",
                "where",
                "an",
                "error",
                "arises,",
                "and",
                "word-meaning",
                "pairings",
                "with",
                "a",
                "finite",
                "number",
                "of",
                "meanings",
                "seem",
                "a",
                "good",
                "handle",
                "on",
                "that.",
                "#TARGET_REF",
                "make",
                "a",
                "similar",
                "argument",
                "about",
                "grammar-based",
                "sembanking,",
                "pointing",
                "out",
                "the",
                "consistency,",
                "comprehensiveness,",
                "and",
                "scalability",
                "that",
                "compositionality",
                "afford.",
                "sequence-to-sequence",
                "ones",
                "is",
                "a",
                "big",
                "step",
                "ahead",
                "towards",
                "transparent",
                "DRS",
                "parsing.",
                "It",
                "is",
                "also",
                "worth",
                "noting",
                "that",
                "our",
                "sequence",
                "encoding",
                "scheme",
                "is",
                "equally",
                "applicable",
                "to",
                "incremental",
                "parsers,",
                "which",
                "potentailly",
                "afford",
                "a",
                "greater",
                "degree",
                "of",
                "psycholinguistic",
                "plausibility.",
                "In",
                "addition,",
                "the",
                "multi-task",
                "architecture",
                "of",
                "our",
                "approach",
                "is",
                "modular",
                "and",
                "allows",
                "for",
                "arbitrary",
                "additional",
                "sequence",
                "labeling",
                "tasks",
                "and",
                "factorizations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "of our parser, every token is mapped to one of a finite number of meaning fragments (unlike a sequence-to-sequence system where a single token can in principle give rise to an unbounded number of output symbols), every clause belongs to one of these fragments (unlike a sequence-to-sequence system where the output is not usually anchored), and there is a straightforward rule that combines fragments into utterance meanings (unlike sequence-to-sequence systems where the interactions between tokens are opaque). This type of transparency is especially important in human-in-the-loop annotation, where parsers produce an initial annotation and annotators correct them. To do this efficiently and consistenly, annotators need to pinpoint where an error arises, and word-meaning pairings with a finite number of meanings seem a good handle on that. #TARGET_REF make a similar argument about grammar-based sembanking, pointing out the consistency, comprehensiveness, and scalability that compositionality afford. sequence-to-sequence ones is a big step ahead towards transparent DRS parsing. It is also worth noting that our sequence encoding scheme is equally applicable to incremental parsers, which potentailly afford a greater degree of psycholinguistic plausibility. In addition, the multi-task architecture of our approach is modular and allows for arbitrary additional sequence labeling tasks and factorizations.",
        "output": "{\"INFO\": [\"#TARGET_REF make\", \"about grammar-based sembanking, pointing out the consistency, comprehensiveness, and scalability that compositionality afford.\"], \"PERCEPT\": [\"a similar argument\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Because",
                "OPUS",
                "open",
                "subtitles",
                "is",
                "a",
                "parallel",
                "corpus",
                "we",
                "are",
                "able",
                "to",
                "evaluate",
                "our",
                "annotated",
                "datasets",
                "across",
                "languages",
                "and",
                "at",
                "identical",
                "levels",
                "of",
                "granularity.",
                "Although",
                "the",
                "subtitles",
                "might",
                "be",
                "translated",
                "using",
                "different",
                "translation",
                "philosophies",
                "(favoring",
                "e.g.",
                "meaning,",
                "mood,",
                "or",
                "idiomatic",
                "language",
                "as",
                "the",
                "prime",
                "objective)",
                "#REF",
                ",",
                "we",
                "expect",
                "the",
                "translations",
                "to",
                "have",
                "aimed",
                "at",
                "capturing",
                "the",
                "sentiments",
                "and",
                "emotions",
                "originally",
                "expressed",
                "in",
                "the",
                "film",
                "based",
                "on",
                "previous",
                "studies",
                "(e.g.",
                "#REF",
                ",",
                "#TARGET_REF",
                ",",
                "#REF",
                ",",
                "#REF",
                "and",
                "Kajava",
                "et",
                "al.",
                "(",
                "2020))."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Because OPUS open subtitles is a parallel corpus we are able to evaluate our annotated datasets across languages and at identical levels of granularity. Although the subtitles might be translated using different translation philosophies (favoring e.g. meaning, mood, or idiomatic language as the prime objective) #REF , we expect the translations to have aimed at capturing the sentiments and emotions originally expressed in the film based on previous studies (e.g. #REF , #TARGET_REF , #REF , #REF and Kajava et al. ( 2020)).",
        "output": "{\"INFO\": [\"previous studies (e.g. #REF , #TARGET_REF , #REF , #REF and Kajava et al. ( 2020)).\"], \"PERCEPT\": [\"Although the subtitles might be translated using different translation philosophies\", \"#REF , we expect the translations to have aimed at capturing the sentiments and emotions originally expressed in the film based on\"], \"BACK\": [\"Because OPUS open subtitles is a parallel corpus we are able to evaluate our annotated datasets\", \"(favoring e.g. meaning, mood, or idiomatic language as the prime objective)\"]}"
    },
    {
        "gold": {
            "text": [
                "with",
                "respect",
                "to",
                "BLEU",
                "#REF",
                ".",
                "We",
                "used",
                "5-gram",
                "language",
                "models",
                "in",
                "all",
                "our",
                "experiments",
                "created",
                "using",
                "the",
                "IRSTLM",
                "language",
                "modelling",
                "toolkit",
                "#REF",
                "using",
                "Modified",
                "Kneser-Ney",
                "smoothing",
                "#REF",
                ".",
                "Mixture",
                "adaptation",
                "of",
                "language",
                "models",
                "mentioned",
                "in",
                "Section",
                "2.2",
                "was",
                "also",
                "performed",
                "using",
                "the",
                "features",
                "of",
                "the",
                "IRSTLM",
                "toolkit.",
                "Results",
                "of",
                "translations",
                "in",
                "every",
                "phase",
                "of",
                "our",
                "experiments",
                "were",
                "evaluated",
                "using",
                "BLEU,",
                "METEOR",
                "#TARGET_REF",
                "and",
                "TER",
                "#REF",
                "metrics.",
                "The",
                "datasets",
                "used",
                "for",
                "the",
                "experiments",
                "included",
                "the",
                "specific",
                "datasets",
                "released",
                "by",
                "the",
                "IWSLT",
                "2011",
                "evaluation",
                "campaign.",
                "The",
                "primary",
                "bi-lingual",
                "training",
                "data",
                "comprised",
                "of",
                "a",
                "collection",
                "of",
                "public",
                "speech",
                "transcriptions",
                "on",
                "a",
                "variety",
                "of",
                "topics",
                "from",
                "TED",
                "Talks.",
                "The",
                "development",
                "data",
                "released",
                "for",
                "the",
                "task,",
                "comprised",
                "of",
                "both",
                "the",
                "IWSLT-2010",
                "4",
                "development",
                "and",
                "test",
                "sets.",
                "However,",
                "for",
                "experiments",
                "reported",
                "in",
                "this",
                "paper,",
                "the",
                "IWSLT-2010",
                "development",
                "set",
                "and",
                "test",
                "sets",
                "were",
                "used",
                "for",
                "tuning",
                "and",
                "testing",
                "respectively.",
                "As",
                "an",
                "auxiliary",
                "out-of-domain",
                "source",
                "of",
                "bi-lingual",
                "training",
                "data,",
                "the",
                "Multi-UN",
                "corpus",
                "was",
                "also",
                "released.",
                "The",
                "monolingual",
                "data",
                "required",
                "to",
                "train",
                "lan-guage",
                "models",
                "also",
                "comprised",
                "of",
                "data",
                "from",
                "both",
                "Multi-UN",
                "and",
                "TED",
                "Talks.",
                "Table",
                "1",
                "shows",
                "the",
                "exact",
                "sentence",
                "counts",
                "of",
                "the",
                "different",
                "datasets",
                "used",
                "in",
                "the",
                "experiments."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                1,
                1,
                3,
                3,
                3,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "with respect to BLEU #REF . We used 5-gram language models in all our experiments created using the IRSTLM language modelling toolkit #REF using Modified Kneser-Ney smoothing #REF . Mixture adaptation of language models mentioned in Section 2.2 was also performed using the features of the IRSTLM toolkit. Results of translations in every phase of our experiments were evaluated using BLEU, METEOR #TARGET_REF and TER #REF metrics. The datasets used for the experiments included the specific datasets released by the IWSLT 2011 evaluation campaign. The primary bi-lingual training data comprised of a collection of public speech transcriptions on a variety of topics from TED Talks. The development data released for the task, comprised of both the IWSLT-2010 4 development and test sets. However, for experiments reported in this paper, the IWSLT-2010 development set and test sets were used for tuning and testing respectively. As an auxiliary out-of-domain source of bi-lingual training data, the Multi-UN corpus was also released. The monolingual data required to train lan-guage models also comprised of data from both Multi-UN and TED Talks. Table 1 shows the exact sentence counts of the different datasets used in the experiments.",
        "output": "{\"INFO\": [\"METEOR #TARGET_REF\", \"metrics.\"], \"PERCEPT\": [\"Results of translations in every phase of our experiments were evaluated using\"], \"BACK\": [\"BLEU,\", \"and TER #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "compare",
                "the",
                "linguistic",
                "annotation",
                "performance,",
                "we",
                "prepared",
                "a",
                "pipeline",
                "system,",
                "i.e.,",
                "ASR",
                "followed",
                "by",
                "an",
                "NLP-based",
                "linguistic",
                "annotation.",
                "In",
                "the",
                "pipeline",
                "system,",
                "the",
                "separated",
                "model",
                "of",
                "CTC+Transformer",
                "first",
                "predicts",
                "graphemic",
                "sequences.",
                "Then,",
                "the",
                "linear",
                "SVM",
                "with",
                "L2",
                "normalization,",
                "trained",
                "using",
                "KyTea",
                "#TARGET_REF",
                ",",
                "predicts",
                "word",
                "boundaries",
                "and",
                "linguistic",
                "annotation",
                "from",
                "the",
                "predicted",
                "sequences.",
                "To",
                "train",
                "KyTea,",
                "we",
                "only",
                "used",
                "the",
                "transcriptions",
                "in",
                "the",
                "ASR",
                "training",
                "set",
                "to",
                "perform",
                "a",
                "fair",
                "comparison",
                "to",
                "the",
                "proposed",
                "method."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "To compare the linguistic annotation performance, we prepared a pipeline system, i.e., ASR followed by an NLP-based linguistic annotation. In the pipeline system, the separated model of CTC+Transformer first predicts graphemic sequences. Then, the linear SVM with L2 normalization, trained using KyTea #TARGET_REF , predicts word boundaries and linguistic annotation from the predicted sequences. To train KyTea, we only used the transcriptions in the ASR training set to perform a fair comparison to the proposed method.",
        "output": "{\"INFO\": [\"KyTea #TARGET_REF ,\"], \"PERCEPT\": [\"we only used the transcriptions in the ASR training set to perform a fair comparison to the proposed method.\"], \"BACK\": [\"the linear SVM with L2 normalization, trained using\", \"predicts word boundaries and linguistic annotation from the predicted sequences. To train KyTea,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "combination",
                "of",
                "lexical",
                "knowledge",
                "and",
                "rule",
                "knowledge",
                "enables",
                "WM",
                "to",
                "function",
                "as",
                "a",
                "full",
                "morphological",
                "component.",
                "As",
                "shown",
                "by",
                "ten",
                "Hacken",
                "(1998),",
                "the",
                "effects",
                "of",
                "this",
                "coverage",
                "are",
                "particularly",
                "striking",
                "in",
                "the",
                "domain",
                "of",
                "word",
                "formation,",
                "for",
                "which",
                "a",
                "system",
                "taking",
                "a",
                "lexicon",
                "as",
                "modelled",
                "in",
                "Fig.",
                "2B",
                "as",
                "a",
                "basis",
                "lacks",
                "the",
                "procedural",
                "component.",
                "Thus",
                "a",
                "formalism",
                "such",
                "as",
                "DATR,",
                "as",
                "described",
                "by",
                "#TARGET_REF",
                ",",
                "though",
                "able",
                "to",
                "represent",
                "word",
                "formation",
                "relationships,",
                "cannot",
                "deal",
                "with",
                "unseen",
                "words",
                "without",
                "a",
                "separate",
                "recognition",
                "module.",
                "In",
                "WM,",
                "word",
                "formation",
                "rules",
                "are",
                "at",
                "the",
                "same",
                "time",
                "available",
                "declaratively,",
                "as",
                "the",
                "structural",
                "backbone",
                "of",
                "the",
                "database,",
                "and",
                "procedurally",
                "for",
                "the",
                "recognition",
                "of",
                "new",
                "words."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component. As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component. Thus a formalism such as DATR, as described by #TARGET_REF , though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module. In WM, word formation rules are at the same time available declaratively, as the structural backbone of the database, and procedurally for the recognition of new words.",
        "output": "{\"INFO\": [\"DATR, as described by #TARGET_REF ,\"], \"PERCEPT\": [\"As shown by ten Hacken (1998), the effects of this coverage are particularly striking in the domain of word formation, for which a system taking a lexicon as modelled in Fig. 2B as a basis lacks the procedural component.\", \"a formalism such as\", \"though able to represent word formation relationships, cannot deal with unseen words without a separate recognition module.\"], \"BACK\": [\"The combination of lexical knowledge and rule knowledge enables WM to function as a full morphological component.\"]}"
    },
    {
        "gold": {
            "text": [
                "mini-batches)",
                "2",
                ",",
                "we",
                "can",
                "indeed",
                "obtain",
                "A×B",
                "−1",
                "negatives",
                "for",
                "a",
                "given",
                "question,",
                "which",
                "is",
                "approximately",
                "A",
                "times",
                "as",
                "many",
                "as",
                "the",
                "original",
                "number",
                "of",
                "in-batch",
                "negatives.",
                "In",
                "this",
                "way,",
                "we",
                "can",
                "use",
                "more",
                "negatives",
                "in",
                "the",
                "training",
                "objective",
                "of",
                "Equation",
                "2,",
                "so",
                "that",
                "the",
                "results",
                "are",
                "expected",
                "to",
                "be",
                "improved.",
                "Denoised",
                "Hard",
                "Negatives",
                "Although",
                "the",
                "above",
                "strategy",
                "can",
                "increase",
                "the",
                "number",
                "of",
                "negatives,",
                "most",
                "of",
                "negatives",
                "are",
                "easy",
                "ones,",
                "which",
                "can",
                "be",
                "easily",
                "discriminated.",
                "While,",
                "hard",
                "negatives",
                "are",
                "shown",
                "to",
                "be",
                "important",
                "to",
                "train",
                "a",
                "dual-encoder",
                "#TARGET_REF",
                ".",
                "To",
                "obtain",
                "hard",
                "negatives,",
                "a",
                "straightforward",
                "method",
                "is",
                "to",
                "select",
                "the",
                "top-ranked",
                "passages",
                "(excluding",
                "the",
                "labeled",
                "positive",
                "passages)",
                "as",
                "negative",
                "samples.",
                "However,",
                "it",
                "is",
                "likely",
                "to",
                "bring",
                "false",
                "negatives",
                "(i.e.,",
                "unlabeled",
                "positives),",
                "since",
                "the",
                "annotators",
                "can",
                "only",
                "annotate",
                "a",
                "few",
                "top-retrieved",
                "passages",
                "(as",
                "discussed",
                "in",
                "Section",
                "1).",
                "Another",
                "note",
                "is",
                "that",
                "previous",
                "work",
                "mainly",
                "focuses",
                "on",
                "factoid",
                "questions,",
                "to",
                "which",
                "the",
                "answers",
                "are",
                "short",
                "and",
                "concise.",
                "Hence,",
                "it",
                "is",
                "not",
                "challenging",
                "to",
                "filter",
                "false",
                "negatives",
                "by",
                "using",
                "the",
                "short",
                "answers",
                "#REF",
                ".",
                "However,",
                "it",
                "cannot",
                "apply",
                "to",
                "non-factoid",
                "questions.",
                "In",
                "this",
                "paper,",
                "we",
                "aim",
                "to",
                "learn",
                "dense",
                "passage",
                "retrieval",
                "for",
                "both",
                "factoid",
                "questions",
                "and",
                "non-factoid",
                "questions,",
                "which",
                "needs",
                "a",
                "more",
                "effective",
                "way",
                "for",
                "denoising",
                "hard",
                "negatives."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "mini-batches) 2 , we can indeed obtain A×B −1 negatives for a given question, which is approximately A times as many as the original number of in-batch negatives. In this way, we can use more negatives in the training objective of Equation 2, so that the results are expected to be improved. Denoised Hard Negatives Although the above strategy can increase the number of negatives, most of negatives are easy ones, which can be easily discriminated. While, hard negatives are shown to be important to train a dual-encoder #TARGET_REF . To obtain hard negatives, a straightforward method is to select the top-ranked passages (excluding the labeled positive passages) as negative samples. However, it is likely to bring false negatives (i.e., unlabeled positives), since the annotators can only annotate a few top-retrieved passages (as discussed in Section 1). Another note is that previous work mainly focuses on factoid questions, to which the answers are short and concise. Hence, it is not challenging to filter false negatives by using the short answers #REF . However, it cannot apply to non-factoid questions. In this paper, we aim to learn dense passage retrieval for both factoid questions and non-factoid questions, which needs a more effective way for denoising hard negatives.",
        "output": "{\"INFO\": [\"hard negatives are shown to be important to train a dual-encoder #TARGET_REF .\"], \"PERCEPT\": [\"To obtain hard negatives, a straightforward method is to select the top-ranked passages\", \"as negative samples.\"], \"BACK\": [\"(excluding the labeled positive passages)\"]}"
    },
    {
        "gold": {
            "text": [
                "Translation-based",
                "features",
                "Capturing",
                "semantic",
                "relationships",
                "between",
                "a",
                "query",
                "and",
                "a",
                "document",
                "is",
                "also",
                "crucial",
                "to",
                "improving",
                "retrieval",
                "accuracy.",
                "To",
                "incorporate",
                "such",
                "features,",
                "we",
                "can",
                "use",
                "a",
                "translation",
                "model",
                "#TARGET_REF",
                "to",
                "measure",
                "the",
                "log",
                "translation",
                "probability",
                "between",
                "queries",
                "and",
                "documents.",
                "The",
                "conditional",
                "probability",
                "we",
                "need",
                "p(q|d",
                "n",
                ")",
                "is",
                "generated",
                "by",
                "the",
                "IBM",
                "Model",
                "1",
                "translation",
                "model,",
                "and",
                "the",
                "final",
                "query-document",
                "feature",
                "is",
                "the",
                "sum",
                "of",
                "all",
                "individual",
                "conditional",
                "query",
                "probabilities."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Translation-based features Capturing semantic relationships between a query and a document is also crucial to improving retrieval accuracy. To incorporate such features, we can use a translation model #TARGET_REF to measure the log translation probability between queries and documents. The conditional probability we need p(q|d n ) is generated by the IBM Model 1 translation model, and the final query-document feature is the sum of all individual conditional query probabilities.",
        "output": "{\"INFO\": [\"a translation model #TARGET_REF\"], \"PERCEPT\": [\"To incorporate such features, we can use\", \"to measure the log translation probability between queries and documents.\", \"we need\"], \"BACK\": [\"Translation-based features Capturing semantic relationships between a query and a document is also crucial to improving retrieval accuracy.\", \"The conditional probability\", \"p(q|d n ) is generated by the IBM Model 1 translation model, and the final query-document feature is the sum of all individual conditional query probabilities.\"]}"
    },
    {
        "gold": {
            "text": [
                "(3)",
                "the",
                "subword",
                "field,",
                "which",
                "breaks",
                "tokens",
                "into",
                "subwords,",
                "and",
                "(4)",
                "the",
                "d2q",
                "field,",
                "which",
                "includes",
                "the",
                "stemmed",
                "tokens",
                "from",
                "the",
                "concatenated",
                "docTTTTTquery",
                "predictions",
                "(for",
                "the",
                "d2q",
                "variants).",
                "For",
                "each",
                "querydocument",
                "pair,",
                "feature",
                "extraction",
                "is",
                "repeated",
                "over",
                "all",
                "applicable",
                "fields.",
                "In",
                "total,",
                "there",
                "are",
                "83",
                "different",
                "features",
                "(per",
                "field)",
                "plus",
                "four",
                "translation-based",
                "features",
                "that",
                "are",
                "only",
                "available",
                "in",
                "the",
                "raw",
                "and",
                "subword",
                "fields.",
                "We",
                "additionally",
                "test",
                "on",
                "the",
                "MS",
                "MARCO",
                "document",
                "ranking",
                "task",
                "#TARGET_REF",
                "in",
                "a",
                "zeroshot",
                "manner.",
                "For",
                "this,",
                "we",
                "segment",
                "each",
                "document",
                "into",
                "multiple",
                "passages",
                "as",
                "the",
                "neural",
                "models",
                "cannot",
                "process",
                "long",
                "documents.",
                "Specifically,",
                "we",
                "use",
                "the",
                "sliding",
                "window",
                "strategy",
                "of",
                "#REF",
                ",",
                "where",
                "the",
                "window",
                "length",
                "is",
                "ten",
                "sentences",
                "with",
                "a",
                "stride",
                "of",
                "five",
                "sentences.",
                "Retrieval",
                "is",
                "performed",
                "at",
                "the",
                "passage",
                "level,",
                "and",
                "the",
                "document",
                "score",
                "is",
                "computed",
                "based",
                "on",
                "the",
                "highest",
                "relevance",
                "score",
                "among",
                "its",
                "passages."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "(3) the subword field, which breaks tokens into subwords, and (4) the d2q field, which includes the stemmed tokens from the concatenated docTTTTTquery predictions (for the d2q variants). For each querydocument pair, feature extraction is repeated over all applicable fields. In total, there are 83 different features (per field) plus four translation-based features that are only available in the raw and subword fields. We additionally test on the MS MARCO document ranking task #TARGET_REF in a zeroshot manner. For this, we segment each document into multiple passages as the neural models cannot process long documents. Specifically, we use the sliding window strategy of #REF , where the window length is ten sentences with a stride of five sentences. Retrieval is performed at the passage level, and the document score is computed based on the highest relevance score among its passages.",
        "output": "{\"INFO\": [\"the MS MARCO document ranking task #TARGET_REF\"], \"PERCEPT\": [\"We additionally test on\", \"in a zeroshot manner.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "several",
                "reports",
                "in",
                "the",
                "literature",
                "showing",
                "that",
                "a",
                "careful",
                "design",
                "of",
                "the",
                "interface",
                "between",
                "automatic",
                "speech",
                "recognition",
                "(ASR)",
                "and",
                "machine",
                "translation",
                "can",
                "be",
                "important",
                "to",
                "limit",
                "the",
                "performance",
                "degradation",
                "observed",
                "when",
                "translating",
                "an",
                "automatic",
                "transcription",
                "(as",
                "opposed",
                "to",
                "a",
                "manual",
                "transcription).",
                "These",
                "works",
                "include",
                "the",
                "translation",
                "of",
                "richer",
                "data",
                "structures",
                "than",
                "the",
                "1-best",
                "ASR",
                "output,",
                "see",
                "for",
                "instance",
                "#TARGET_REF",
                "or",
                "various",
                "aspects",
                "of",
                "case,",
                "punctuation",
                "and",
                "word",
                "normalization",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "There are several reports in the literature showing that a careful design of the interface between automatic speech recognition (ASR) and machine translation can be important to limit the performance degradation observed when translating an automatic transcription (as opposed to a manual transcription). These works include the translation of richer data structures than the 1-best ASR output, see for instance #TARGET_REF or various aspects of case, punctuation and word normalization #REF .",
        "output": "{\"INFO\": [\"see for instance #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"various aspects of case, punctuation and word normalization #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "serve.",
                "Designers",
                "of",
                "the",
                "method.",
                "For",
                "the",
                "designers",
                "of",
                "the",
                "detection",
                "method,",
                "explainability",
                "can",
                "serve",
                "as",
                "a",
                "principled",
                "mechanism",
                "for",
                "understanding",
                "and",
                "reasoning",
                "about",
                "the",
                "behavior",
                "of",
                "their",
                "method,",
                "which",
                "is",
                "important",
                "for",
                "multiple",
                "reasons.",
                "Firstly,",
                "if",
                "the",
                "detection",
                "method",
                "exhibits",
                "all",
                "the",
                "four",
                "properties",
                "of",
                "explain-ability,",
                "then",
                "the",
                "designers",
                "can",
                "easily",
                "gain",
                "insights",
                "into",
                "the",
                "factors",
                "that",
                "contributed",
                "to",
                "the",
                "decision",
                "made",
                "by",
                "the",
                "method",
                "given",
                "a",
                "comment.",
                "This",
                "can",
                "allow",
                "the",
                "designers",
                "to",
                "recognize",
                "when",
                "the",
                "method",
                "may",
                "be",
                "overly",
                "relying",
                "on",
                "a",
                "specific",
                "factor,",
                "e.g.,",
                "the",
                "demographic",
                "traits.",
                "In",
                "the",
                "case",
                "of",
                "social",
                "feature",
                "engineering",
                "and",
                "user",
                "embeddings",
                "based",
                "methods,",
                "operationalization",
                "of",
                "explainability",
                "via",
                "feature",
                "attribution",
                "such",
                "as",
                "LIME",
                "#REF",
                "and",
                "Integrated",
                "Gradients",
                "#TARGET_REF",
                "can",
                "be",
                "effective",
                "in",
                "offering",
                "such",
                "insights.",
                "For",
                "social",
                "graph",
                "based",
                "methods",
                "that",
                "employ",
                "graph",
                "neural",
                "networks,",
                "attribution",
                "techniques",
                "like",
                "GNNExplainer",
                "#REF",
                "can",
                "be",
                "used",
                "instead.",
                "The",
                "second",
                "reason",
                "why",
                "explainability",
                "is",
                "important",
                "for",
                "the",
                "designers",
                "is",
                "because",
                "it",
                "can",
                "allow",
                "them",
                "to",
                "optimize",
                "the",
                "method",
                "by",
                "removing",
                "inputs",
                "that",
                "do",
                "not",
                "contribute",
                "significantly.",
                "Here",
                "again,",
                "explainability",
                "via",
                "feature",
                "attribution",
                "can",
                "be",
                "effective.",
                "Lastly,",
                "explainability",
                "is",
                "also",
                "important",
                "for",
                "the",
                "designers",
                "to",
                "understand",
                "how",
                "their",
                "method",
                "would",
                "perform",
                "in",
                "cases",
                "where",
                "a",
                "user",
                "may",
                "try",
                "obfuscate",
                "abusive",
                "language",
                "#REF",
                ".",
                "Counterfactual",
                "explanations",
                "can",
                "constitute",
                "an",
                "effective",
                "operationalization",
                "for",
                "the",
                "designers",
                "to",
                "identify",
                "the",
                "parts",
                "of",
                "their",
                "method",
                "that",
                "are",
                "most",
                "vulnerable",
                "to",
                "obfuscations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "serve. Designers of the method. For the designers of the detection method, explainability can serve as a principled mechanism for understanding and reasoning about the behavior of their method, which is important for multiple reasons. Firstly, if the detection method exhibits all the four properties of explain-ability, then the designers can easily gain insights into the factors that contributed to the decision made by the method given a comment. This can allow the designers to recognize when the method may be overly relying on a specific factor, e.g., the demographic traits. In the case of social feature engineering and user embeddings based methods, operationalization of explainability via feature attribution such as LIME #REF and Integrated Gradients #TARGET_REF can be effective in offering such insights. For social graph based methods that employ graph neural networks, attribution techniques like GNNExplainer #REF can be used instead. The second reason why explainability is important for the designers is because it can allow them to optimize the method by removing inputs that do not contribute significantly. Here again, explainability via feature attribution can be effective. Lastly, explainability is also important for the designers to understand how their method would perform in cases where a user may try obfuscate abusive language #REF . Counterfactual explanations can constitute an effective operationalization for the designers to identify the parts of their method that are most vulnerable to obfuscations.",
        "output": "{\"INFO\": [\"Integrated Gradients #TARGET_REF\"], \"PERCEPT\": [\"can be effective in offering such insights.\"], \"BACK\": [\"operationalization of explainability via feature attribution such as LIME #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "two",
                "approaches",
                "to",
                "assessing",
                "the",
                "productivity",
                "of",
                "a",
                "word",
                "formation",
                "rule:",
                "the",
                "qualitative",
                "and",
                "the",
                "quantitative",
                "approach.",
                "For",
                "a",
                "full",
                "understanding,",
                "a",
                "combination",
                "of",
                "both",
                "perspectives",
                "is",
                "necessary.",
                "In",
                "the",
                "qualitative",
                "approach,",
                "all",
                "the",
                "restrictions",
                "and",
                "linguistic",
                "properties",
                "of",
                "the",
                "rule",
                "are",
                "described",
                "(see",
                "the",
                "next",
                "paragraph",
                "for",
                "some",
                "examples).",
                "The",
                "qualitative",
                "description",
                "does",
                "not",
                "exhaust",
                "our",
                "intuition",
                "of",
                "productivity,",
                "there",
                "is",
                "also",
                "a",
                "quantitative",
                "element",
                "involved:",
                "intuitively",
                "one",
                "could",
                "say",
                "that",
                "some",
                "word",
                "formation",
                "rules",
                "seem",
                "to",
                "produce",
                "new",
                "words",
                "more",
                "readily",
                "than",
                "others",
                "-an",
                "intuition",
                "which",
                "cannot",
                "be",
                "formalized.",
                "In",
                "quantitative",
                "studies",
                "this",
                "intuition",
                "is",
                "approximated",
                "by",
                "the",
                "question:",
                "how",
                "probable",
                "is",
                "it",
                "that",
                "we",
                "will",
                "see",
                "a",
                "new",
                "type",
                "(lexeme)",
                "produced",
                "by",
                "word",
                "formation",
                "process",
                "X",
                "after",
                "we",
                "have",
                "sampled",
                "a",
                "certain",
                "amount",
                "of",
                "text?",
                "Quantitative",
                "studies",
                "of",
                "the",
                "productivity",
                "of",
                "word",
                "formation",
                "processes",
                "are",
                "important",
                "for",
                "the",
                "design",
                "of",
                "word",
                "formation",
                "systems",
                "if",
                "the",
                "resources",
                "are",
                "limited",
                "and",
                "one",
                "has",
                "to",
                "concentrate",
                "on",
                "the",
                "most",
                "productive",
                "word",
                "formation",
                "processes",
                "(on",
                "the",
                "quantitative",
                "aspects",
                "of",
                "productivity",
                "see",
                "for",
                "example",
                "#REF",
                ",",
                "for",
                "a",
                "discussion",
                "of",
                "some",
                "corpus",
                "related",
                "problems",
                "in",
                "calculating",
                "productivity",
                "indices",
                "see",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "There are two approaches to assessing the productivity of a word formation rule: the qualitative and the quantitative approach. For a full understanding, a combination of both perspectives is necessary. In the qualitative approach, all the restrictions and linguistic properties of the rule are described (see the next paragraph for some examples). The qualitative description does not exhaust our intuition of productivity, there is also a quantitative element involved: intuitively one could say that some word formation rules seem to produce new words more readily than others -an intuition which cannot be formalized. In quantitative studies this intuition is approximated by the question: how probable is it that we will see a new type (lexeme) produced by word formation process X after we have sampled a certain amount of text? Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes (on the quantitative aspects of productivity see for example #REF , for a discussion of some corpus related problems in calculating productivity indices see #TARGET_REF .",
        "output": "{\"INFO\": [\"some corpus related problems in calculating productivity indices see #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Quantitative studies of the productivity of word formation processes are important for the design of word formation systems if the resources are limited and one has to concentrate on the most productive word formation processes\", \"for a discussion of\"]}"
    },
    {
        "gold": {
            "text": [
                "An",
                "efficient",
                "and",
                "effective",
                "document",
                "retriever",
                "is",
                "required",
                "since",
                "the",
                "Wikipedia",
                "dump",
                "containing",
                "millions",
                "of",
                "pages.",
                "We",
                "first",
                "narrow",
                "the",
                "search",
                "space",
                "to",
                "several",
                "hundred",
                "pages",
                "(m",
                "0",
                ")",
                "with",
                "an",
                "efficient",
                "information",
                "retrieval",
                "method",
                "based",
                "on",
                "TF-IDF,",
                "namely,",
                "DRQA",
                "#REF",
                ".",
                "A",
                "RoBERTa-based",
                "re-ranker",
                "#TARGET_REF",
                "and",
                "a",
                "BM25-based",
                "re-ranker",
                "are",
                "then",
                "applied",
                "in",
                "parallel",
                "to",
                "re-rank",
                "the",
                "m",
                "0",
                "document",
                "candidates.",
                "We",
                "combine",
                "the",
                "results",
                "of",
                "two",
                "re-rankers",
                "and",
                "keep",
                "top",
                "m",
                "documents",
                "since",
                "BM25",
                "focuses",
                "more",
                "on",
                "entity",
                "matching",
                "and",
                "RoBERTa-based",
                "re-ranker",
                "pays",
                "more",
                "attention",
                "to",
                "the",
                "overall",
                "sentence",
                "structure.",
                "The",
                "document",
                "scores",
                "are",
                "calculated",
                "as",
                "the",
                "sum",
                "of",
                "their",
                "rankings",
                "in",
                "the",
                "two",
                "re-rankers.",
                "Documents",
                "with",
                "lower",
                "scores",
                "have",
                "higher",
                "priority."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "An efficient and effective document retriever is required since the Wikipedia dump containing millions of pages. We first narrow the search space to several hundred pages (m 0 ) with an efficient information retrieval method based on TF-IDF, namely, DRQA #REF . A RoBERTa-based re-ranker #TARGET_REF and a BM25-based re-ranker are then applied in parallel to re-rank the m 0 document candidates. We combine the results of two re-rankers and keep top m documents since BM25 focuses more on entity matching and RoBERTa-based re-ranker pays more attention to the overall sentence structure. The document scores are calculated as the sum of their rankings in the two re-rankers. Documents with lower scores have higher priority.",
        "output": "{\"INFO\": [\"A RoBERTa-based re-ranker #TARGET_REF\"], \"PERCEPT\": [\"are then applied in parallel to re-rank the m 0 document candidates. We combine the results of two re-rankers and keep top m documents since BM25 focuses more on entity matching and RoBERTa-based re-ranker pays more attention to the overall sentence structure.\"], \"BACK\": [\"and a BM25-based re-ranker\"]}"
    },
    {
        "gold": {
            "text": [
                "Mitigation",
                "Multiple",
                "approaches",
                "have",
                "been",
                "proposed",
                "to",
                "mitigate",
                "shortcut",
                "learning",
                "and",
                "data",
                "biases",
                "#REF",
                ",",
                "through",
                "data",
                "augmentation",
                "#REF",
                ",",
                "domain",
                "adaptation",
                "#REF",
                ",",
                "and",
                "multi-task",
                "learning",
                "#REF",
                ".",
                "#TARGET_REF",
                "proposes",
                "to",
                "mitigate",
                "shortcuts",
                "by",
                "suppressing",
                "model's",
                "prediction",
                "on",
                "examples",
                "with",
                "a",
                "large",
                "shortcut",
                "degree.",
                "Recent",
                "study",
                "has",
                "also",
                "shown",
                "removing",
                "spurious",
                "correlations",
                "can",
                "sometimes",
                "hurt",
                "model's",
                "accuracy",
                "#REF",
                ".",
                "Orthogonal",
                "to",
                "existing",
                "works,",
                "we",
                "propose",
                "to",
                "first",
                "identify",
                "unrobust",
                "correlations",
                "in",
                "an",
                "NLP",
                "model",
                "and",
                "then",
                "propose",
                "a",
                "targeted",
                "mitigation",
                "to",
                "encourage",
                "the",
                "model",
                "to",
                "rely",
                "less",
                "on",
                "those",
                "unrobust",
                "correlations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Mitigation Multiple approaches have been proposed to mitigate shortcut learning and data biases #REF , through data augmentation #REF , domain adaptation #REF , and multi-task learning #REF . #TARGET_REF proposes to mitigate shortcuts by suppressing model's prediction on examples with a large shortcut degree. Recent study has also shown removing spurious correlations can sometimes hurt model's accuracy #REF . Orthogonal to existing works, we propose to first identify unrobust correlations in an NLP model and then propose a targeted mitigation to encourage the model to rely less on those unrobust correlations.",
        "output": "{\"INFO\": [\"proposes to mitigate shortcuts by suppressing model's prediction on examples with a large shortcut degree.\"], \"PERCEPT\": [], \"BACK\": [\"Mitigation Multiple approaches have been proposed to mitigate shortcut learning and data biases #REF , through data augmentation #REF , domain adaptation #REF , and multi-task learning #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "E",
                "q",
                "φ",
                "(z|x)",
                "log",
                "p",
                "θ",
                "(x|z)",
                "−",
                "β",
                "|D",
                "KL",
                "(q",
                "φ",
                "(z|x),",
                "p(z))",
                "−",
                "C|where",
                "C",
                "is",
                "a",
                "positive",
                "real",
                "value",
                "which",
                "represents",
                "the",
                "target",
                "KL-divergence",
                "term",
                "value.",
                "This",
                "has",
                "an",
                "information-theoretic",
                "interpretation,",
                "where",
                "the",
                "placed",
                "constraint",
                "C",
                "on",
                "the",
                "KL",
                "term",
                "is",
                "seen",
                "as",
                "the",
                "amount",
                "of",
                "information",
                "transmitted",
                "from",
                "a",
                "sender",
                "(encoder)",
                "to",
                "a",
                "receiver",
                "(decoder)",
                "via",
                "the",
                "message",
                "(z)",
                "#REF",
                ",",
                "and",
                "impacts",
                "the",
                "sharpness",
                "of",
                "the",
                "posterior",
                "distribution",
                "#TARGET_REF",
                ".",
                "This",
                "constraint",
                "allows",
                "the",
                "model",
                "to",
                "prioritize",
                "underlying",
                "factors",
                "of",
                "data",
                "according",
                "to",
                "the",
                "availability",
                "of",
                "channel",
                "capacity",
                "and",
                "their",
                "contributions",
                "to",
                "the",
                "reconstruction",
                "loss",
                "improvement.",
                "#REF",
                "introduces",
                "an",
                "additional",
                "term",
                "to",
                "β-VAE,",
                "D",
                "M",
                "M",
                "D",
                "(q",
                "φ",
                "(z),",
                "p",
                "θ",
                "(z)),"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "E q φ (z|x) log p θ (x|z) − β |D KL (q φ (z|x), p(z)) − C|where C is a positive real value which represents the target KL-divergence term value. This has an information-theoretic interpretation, where the placed constraint C on the KL term is seen as the amount of information transmitted from a sender (encoder) to a receiver (decoder) via the message (z) #REF , and impacts the sharpness of the posterior distribution #TARGET_REF . This constraint allows the model to prioritize underlying factors of data according to the availability of channel capacity and their contributions to the reconstruction loss improvement. #REF introduces an additional term to β-VAE, D M M D (q φ (z), p θ (z)),",
        "output": "{\"INFO\": [\"impacts the sharpness of the posterior distribution #TARGET_REF .\"], \"PERCEPT\": [\"This has an information-theoretic interpretation,\", \"and\"], \"BACK\": [\"C is a positive real value which represents the target KL-divergence term value.\"]}"
    },
    {
        "gold": {
            "text": [
                "translations",
                "uniformly",
                "at",
                "random",
                "and",
                "form",
                "a",
                "translated",
                "batch",
                "(B",
                "p",
                ")",
                "of",
                "the",
                "same",
                "size",
                "n.",
                "It",
                "is",
                "important",
                "to",
                "note",
                "that",
                "B",
                "o",
                "itself",
                "is",
                "taken",
                "from",
                "the",
                "combined",
                "dataset",
                "of",
                "source",
                "instances",
                "and",
                "translated",
                "instances.",
                "The",
                "two",
                "batches",
                "that",
                "form",
                "a",
                "pair",
                "are",
                "denoted",
                "as",
                "original",
                "batch",
                "and",
                "pair",
                "batch,",
                "respectively,",
                "in",
                "Figure",
                "4.",
                "We",
                "use",
                "the",
                "same",
                "mBERT",
                "network",
                "up",
                "to",
                "a",
                "specific",
                "layer",
                "as",
                "our",
                "encoder",
                "(enc)",
                "to",
                "transform",
                "B",
                "o",
                "and",
                "B",
                "p",
                "to",
                "get",
                "the",
                "embeddings,",
                "E",
                "o",
                ",",
                "E",
                "p",
                "∈",
                "R",
                "n",
                "*",
                "t",
                "*",
                "d",
                ",",
                "respectively.",
                "Then,",
                "we",
                "apply",
                "a",
                "global",
                "average",
                "pooling",
                "(gap)",
                "operation",
                "to",
                "aggregate",
                "the",
                "vector",
                "representations",
                "of",
                "t",
                "tokens",
                "into",
                "a",
                "single",
                "vector",
                "representation",
                "of",
                "dimension",
                "d",
                "for",
                "each",
                "instance",
                "in",
                "each",
                "batch.",
                "This",
                "will",
                "result",
                "in",
                "the",
                "aggregated",
                "embeddings",
                "O,",
                "P",
                "∈",
                "R",
                "n",
                "*",
                "d",
                "for",
                "B",
                "o",
                "and",
                "B",
                "p",
                ",",
                "respectively.",
                "With",
                "these",
                "n",
                "feature",
                "vectors",
                "in",
                "the",
                "original",
                "and",
                "the",
                "translated",
                "batch,",
                "we",
                "follow",
                "the",
                "CLIP",
                "#TARGET_REF",
                "approach",
                "and",
                "compute",
                "the",
                "contrastive",
                "loss",
                "using",
                "the",
                "cross-entropy",
                "loss",
                "(L",
                "ce",
                ").",
                "Specifically,",
                "we",
                "multiply",
                "the",
                "matrices",
                "O",
                "and",
                "P",
                "T",
                "to",
                "get",
                "the",
                "logits",
                "matrix",
                "Q",
                "∈",
                "R",
                "n",
                "*",
                "n",
                ".",
                "Then,",
                "we",
                "apply",
                "the",
                "cross-entropy",
                "loss",
                "L",
                "ce",
                "row-wise",
                "and",
                "column-wise",
                "to",
                "the",
                "logits",
                "matrix",
                "Q,",
                "with",
                "its",
                "diagonal",
                "locations",
                "as",
                "original",
                "classes",
                "for",
                "each",
                "row",
                "and",
                "column,",
                "respectively.O",
                "=",
                "gap(enc(B",
                "o",
                ")),(2)"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "translations uniformly at random and form a translated batch (B p ) of the same size n. It is important to note that B o itself is taken from the combined dataset of source instances and translated instances. The two batches that form a pair are denoted as original batch and pair batch, respectively, in Figure 4. We use the same mBERT network up to a specific layer as our encoder (enc) to transform B o and B p to get the embeddings, E o , E p ∈ R n * t * d , respectively. Then, we apply a global average pooling (gap) operation to aggregate the vector representations of t tokens into a single vector representation of dimension d for each instance in each batch. This will result in the aggregated embeddings O, P ∈ R n * d for B o and B p , respectively. With these n feature vectors in the original and the translated batch, we follow the CLIP #TARGET_REF approach and compute the contrastive loss using the cross-entropy loss (L ce ). Specifically, we multiply the matrices O and P T to get the logits matrix Q ∈ R n * n . Then, we apply the cross-entropy loss L ce row-wise and column-wise to the logits matrix Q, with its diagonal locations as original classes for each row and column, respectively.O = gap(enc(B o )),(2)",
        "output": "{\"INFO\": [\"the CLIP #TARGET_REF approach\"], \"PERCEPT\": [\"We use the same mBERT network up to a specific layer as our encoder (enc) to transform B o and B p to get the embeddings, E o , E p \\u2208 R n * t * d , respectively. Then, we apply a global average pooling (gap) operation to aggregate the vector representations of t tokens into a single vector representation of dimension d for each instance in each batch. This will result in the aggregated embeddings O, P \\u2208 R n * d for B o and B p\", \"With these n feature vectors in the original and the translated batch, we follow\", \"and compute the contrastive loss using the cross-entropy loss (L ce ).\", \"we multiply the matrices O and P T to get the logits matrix Q \\u2208 R n * n .\", \"we apply the cross-entropy loss L ce row-wise and column-wise to the logits matrix Q, with its diagonal locations as original classes for each row and column, respectively.O = gap(enc(B o )),(2)\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "backbone",
                "of",
                "our",
                "PyTorch",
                "#TARGET_REF",
                "implementation",
                "is",
                "the",
                "Transformer",
                "and",
                "WordpieceTokenizer",
                "classes",
                "offered",
                "by",
                "Hugging",
                "Face",
                "#REF",
                ".",
                "We",
                "use",
                "pre-trained",
                "BERT",
                "models",
                "provided",
                "on",
                "huggingface.co:",
                "bert-base-cased,",
                "dbmz/bert-base-german-cased,",
                "dbmz/bert-base-italian-cased,",
                "and",
                "Geotrend/BERT-base-nl-cased",
                "#REF",
                ",",
                "keeping",
                "their",
                "default",
                "configuration.",
                "The",
                "only",
                "hyperparameters",
                "we",
                "choose",
                "ourselves",
                "are",
                "the",
                "batch",
                "size",
                "(",
                "24),",
                "the",
                "learning",
                "rate,",
                "and",
                "the",
                "number",
                "of",
                "epochs.",
                "We",
                "used",
                "the",
                "Adam",
                "optimizer",
                "to",
                "train",
                "all",
                "the",
                "parameters",
                "in",
                "our",
                "model",
                "including",
                "the",
                "pretrained",
                "BERT.",
                "To",
                "ensure",
                "stability",
                "and",
                "avoid",
                "overfitting,",
                "we",
                "used",
                "a",
                "linear",
                "scheduler",
                "with",
                "no",
                "warm-up",
                "step,",
                "which",
                "gradually",
                "reduces",
                "the",
                "learning",
                "rate",
                "from",
                "0.0015",
                "to",
                "0",
                "for",
                "each",
                "training",
                "iteration.",
                "During",
                "preliminary",
                "experiments",
                "on",
                "the",
                "development",
                "set,",
                "we",
                "found",
                "that",
                "training",
                "loss",
                "barely",
                "changed",
                "after",
                "five",
                "epochs."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The backbone of our PyTorch #TARGET_REF implementation is the Transformer and WordpieceTokenizer classes offered by Hugging Face #REF . We use pre-trained BERT models provided on huggingface.co: bert-base-cased, dbmz/bert-base-german-cased, dbmz/bert-base-italian-cased, and Geotrend/BERT-base-nl-cased #REF , keeping their default configuration. The only hyperparameters we choose ourselves are the batch size ( 24), the learning rate, and the number of epochs. We used the Adam optimizer to train all the parameters in our model including the pretrained BERT. To ensure stability and avoid overfitting, we used a linear scheduler with no warm-up step, which gradually reduces the learning rate from 0.0015 to 0 for each training iteration. During preliminary experiments on the development set, we found that training loss barely changed after five epochs.",
        "output": "{\"INFO\": [\"PyTorch #TARGET_REF\"], \"PERCEPT\": [\"The backbone of our\", \"implementation is the Transformer and WordpieceTokenizer classes offered by Hugging Face #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "baseline",
                "model",
                "is",
                "inspired",
                "by",
                "a",
                "hypernym",
                "classification",
                "model",
                "proposed",
                "by",
                "#TARGET_REF",
                ",",
                "also",
                "using",
                "a",
                "pair",
                "of",
                "terms",
                "with",
                "a",
                "set",
                "of",
                "support",
                "sentences",
                "where",
                "the",
                "terms",
                "co-occur."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Our baseline model is inspired by a hypernym classification model proposed by #TARGET_REF , also using a pair of terms with a set of support sentences where the terms co-occur.",
        "output": "{\"INFO\": [\"a hypernym classification model proposed by #TARGET_REF ,\", \"using a pair of terms with a set of support sentences where the terms co-occur.\"], \"PERCEPT\": [\"Our baseline model is inspired by\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "the",
                "Chinese",
                "sentences",
                "as",
                "system",
                "input",
                "and",
                "their",
                "corresponding",
                "English",
                "translations",
                "as",
                "the",
                "reference",
                "translations.",
                "We",
                "use",
                "the",
                "open",
                "source",
                "statistical",
                "machine",
                "translation",
                "decoder",
                "Moses",
                "(?)",
                "for",
                "the",
                "experiments,",
                "translating",
                "the",
                "PropBank",
                "Chinese",
                "sentences",
                "into",
                "English",
                "with",
                "the",
                "same",
                "model",
                "trained",
                "for",
                "our",
                "participation",
                "in",
                "the",
                "IWSLT",
                "2007",
                "evaluation",
                "campaign",
                "#TARGET_REF",
                ".The",
                "English",
                "translations",
                "generated",
                "by",
                "the",
                "decoder",
                "are",
                "the",
                "system",
                "output.",
                "Based",
                "on",
                "the",
                "system",
                "input",
                "and",
                "the",
                "reference",
                "We",
                "first",
                "randomly",
                "select",
                "50",
                "bi-sentences,",
                "without",
                "any",
                "constraint",
                "on",
                "the",
                "translation",
                "accuracy",
                "of",
                "the",
                "predicate",
                "verbs,",
                "to",
                "form",
                "the",
                "first",
                "observation",
                "data",
                "set",
                "(data",
                "set",
                "A)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use the Chinese sentences as system input and their corresponding English translations as the reference translations. We use the open source statistical machine translation decoder Moses (?) for the experiments, translating the PropBank Chinese sentences into English with the same model trained for our participation in the IWSLT 2007 evaluation campaign #TARGET_REF .The English translations generated by the decoder are the system output. Based on the system input and the reference We first randomly select 50 bi-sentences, without any constraint on the translation accuracy of the predicate verbs, to form the first observation data set (data set A).",
        "output": "{\"INFO\": [\"the IWSLT 2007 evaluation campaign #TARGET_REF\"], \"PERCEPT\": [\"We use the open source statistical machine translation decoder Moses (?) for the experiments, translating the PropBank Chinese sentences into English with the same model trained for our participation in\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "system",
                "outperforms",
                "the",
                "R-Net",
                "baseline",
                "(Rouge-L:",
                "40.22)",
                "used",
                "by",
                "#REF",
                ".",
                "Our",
                "system",
                "is",
                "supposed",
                "to",
                "be",
                "applied",
                "at",
                "the",
                "sentence",
                "level",
                "and",
                "the",
                "results",
                "indicate",
                "that",
                "a",
                "unsupervised",
                "system",
                "such",
                "as",
                "ours",
                "could",
                "outperform",
                "more",
                "complicated",
                "deep",
                "learning",
                "models.",
                "If",
                "there",
                "is",
                "a",
                "trade-off",
                "sought",
                "between",
                "computing",
                "time",
                "and",
                "accuracy,",
                "our",
                "system",
                "performs",
                "similar",
                "to",
                "or",
                "better",
                "than",
                "the",
                "baseline",
                "used",
                "by",
                "#TARGET_REF",
                "ROUGE",
                "score",
                "is",
                "not",
                "the",
                "best",
                "metric",
                "for",
                "tasks",
                "such",
                "as",
                "opinion",
                "question",
                "answering.",
                "We",
                "believe",
                "the",
                "cosine",
                "similarity",
                "is",
                "a",
                "better",
                "metric",
                "to",
                "measure",
                "how",
                "close",
                "the",
                "retrieved",
                "answer",
                "is",
                "to",
                "the",
                "gold",
                "standard.",
                "Overall",
                "the",
                "sim",
                "method",
                "is",
                "able",
                "to",
                "provide",
                "an",
                "answer",
                "more",
                "than",
                "70%",
                "similar",
                "to",
                "the",
                "gold",
                "standard",
                "answer",
                "91.5%",
                "of",
                "the",
                "time.",
                "From",
                "the",
                "sentences",
                "returned",
                "by",
                "our",
                "system",
                "as",
                "candidate",
                "answers,",
                "72%",
                "of",
                "the",
                "time",
                "at",
                "least",
                "half",
                "the",
                "candidate",
                "sentences",
                "are",
                "good",
                "answers.",
                "This",
                "shows",
                "that",
                "our",
                "system",
                "is",
                "consistent",
                "and",
                "accurate",
                "at",
                "providing",
                "good",
                "answers."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Our system outperforms the R-Net baseline (Rouge-L: 40.22) used by #REF . Our system is supposed to be applied at the sentence level and the results indicate that a unsupervised system such as ours could outperform more complicated deep learning models. If there is a trade-off sought between computing time and accuracy, our system performs similar to or better than the baseline used by #TARGET_REF ROUGE score is not the best metric for tasks such as opinion question answering. We believe the cosine similarity is a better metric to measure how close the retrieved answer is to the gold standard. Overall the sim method is able to provide an answer more than 70% similar to the gold standard answer 91.5% of the time. From the sentences returned by our system as candidate answers, 72% of the time at least half the candidate sentences are good answers. This shows that our system is consistent and accurate at providing good answers.",
        "output": "{\"INFO\": [\"the baseline used by #TARGET_REF\"], \"PERCEPT\": [\"If there is a trade-off sought between computing time and accuracy, our system performs similar to or better than\"], \"BACK\": [\"a unsupervised system such as ours could outperform more complicated deep learning models.\"]}"
    },
    {
        "gold": {
            "text": [
                "Word",
                "Sense",
                "Disambiguation",
                "(WSD)-based",
                "approaches",
                "were",
                "widely",
                "used",
                "by",
                "previous",
                "research",
                "to",
                "tackle",
                "this",
                "problem",
                "#REF",
                ".",
                "WSD",
                "associates",
                "the",
                "word",
                "in",
                "a",
                "text",
                "with",
                "its",
                "correct",
                "meaning",
                "from",
                "a",
                "predefined",
                "sense",
                "inventory",
                "#REF",
                ".",
                "As",
                "such",
                "inventories,",
                "WordNet",
                "#REF",
                "and",
                "Babel-Net",
                "#TARGET_REF",
                "were",
                "commonly",
                "used.",
                "However,",
                "these",
                "approaches",
                "fail",
                "to",
                "generalise",
                "into",
                "different",
                "languages",
                "as",
                "these",
                "inventories",
                "are",
                "often",
                "limited",
                "to",
                "high",
                "resource",
                "languages.",
                "Targeting",
                "this",
                "gap,",
                "SemEval-2021",
                "Task",
                "2:",
                "Multilingual",
                "and",
                "Cross-lingual",
                "Word-in-Context",
                "Disambiguation",
                "is",
                "designed",
                "to",
                "capture",
                "the",
                "word",
                "sense",
                "without",
                "relying",
                "on",
                "fixed",
                "sense",
                "inventories",
                "in",
                "both",
                "monolingual",
                "and",
                "cross-lingual",
                "setting.",
                "In",
                "summary,",
                "this",
                "task",
                "is",
                "designed",
                "as",
                "a",
                "binary",
                "classification",
                "problem",
                "which",
                "predicts",
                "whether",
                "the",
                "target",
                "word",
                "has",
                "the",
                "same",
                "meaning",
                "or",
                "different",
                "meaning",
                "in",
                "different",
                "contexts",
                "of",
                "the",
                "same",
                "language",
                "(monolingual",
                "setting)",
                "or",
                "different",
                "languages",
                "(cross-lingual",
                "setting)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Word Sense Disambiguation (WSD)-based approaches were widely used by previous research to tackle this problem #REF . WSD associates the word in a text with its correct meaning from a predefined sense inventory #REF . As such inventories, WordNet #REF and Babel-Net #TARGET_REF were commonly used. However, these approaches fail to generalise into different languages as these inventories are often limited to high resource languages. Targeting this gap, SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation is designed to capture the word sense without relying on fixed sense inventories in both monolingual and cross-lingual setting. In summary, this task is designed as a binary classification problem which predicts whether the target word has the same meaning or different meaning in different contexts of the same language (monolingual setting) or different languages (cross-lingual setting).",
        "output": "{\"INFO\": [\"a predefined sense inventory #REF .\", \"Babel-Net #TARGET_REF\"], \"PERCEPT\": [\"As such inventories,\", \"were commonly used.\", \"these approaches fail to generalise into different languages\"], \"BACK\": [\"WSD associates the word in a text with its correct meaning from\", \"WordNet #REF and\", \"as these inventories are often limited to high resource languages.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "2021",
                "instantiation",
                "of",
                "the",
                "Shared",
                "Task",
                "on",
                "Explanation",
                "Regeneration",
                "focuses",
                "on",
                "the",
                "theme",
                "of",
                "determining",
                "relevance",
                "in",
                "large",
                "multi-hop",
                "explanations.",
                "To",
                "this",
                "end,",
                "participants",
                "were",
                "given",
                "access",
                "to",
                "a",
                "large",
                "pre-release",
                "dataset",
                "of",
                "approximately",
                "250k",
                "explanatory",
                "relevancy",
                "ratings",
                "that",
                "augment",
                "the",
                "2020",
                "shared",
                "task",
                "data",
                "#TARGET_REF",
                ",",
                "and",
                "were",
                "tasked",
                "with",
                "ranking",
                "the",
                "facts",
                "most",
                "critical",
                "to",
                "assembling",
                "large",
                "explanations",
                "for",
                "a",
                "given",
                "question",
                "highest.",
                "Similarly",
                "to",
                "the",
                "previous",
                "instances",
                "of",
                "our",
                "competition,",
                "the",
                "shared",
                "task",
                "has",
                "been",
                "organized",
                "on",
                "the",
                "CodaLab",
                "platform.",
                "1",
                "We",
                "released",
                "train",
                "and",
                "development",
                "datasets",
                "along",
                "with",
                "the",
                "baseline",
                "solution",
                "in",
                "advance",
                "to",
                "allow",
                "one",
                "to",
                "get",
                "to",
                "know",
                "the",
                "task",
                "specifics.",
                "2",
                "We",
                "ran",
                "the",
                "practice",
                "phase",
                "from",
                "February",
                "15",
                "till",
                "March",
                "9,",
                "2021.",
                "Then",
                "we",
                "released",
                "the",
                "test",
                "dataset",
                "without",
                "answers",
                "and",
                "ran",
                "the",
                "official",
                "evaluation",
                "phase",
                "from",
                "March",
                "10",
                "till",
                "March",
                "24,",
                "2021.",
                "After",
                "that",
                "we",
                "established",
                "postcompetition",
                "phase",
                "to",
                "enable",
                "long-term",
                "evaluation",
                "of",
                "the",
                "methods",
                "beyond",
                "our",
                "shared",
                "task.",
                "Participating",
                "systems",
                "substantially",
                "increased",
                "task",
                "performance",
                "compared",
                "to",
                "a",
                "supplied",
                "baseline",
                "system",
                "by",
                "32%,",
                "while",
                "achieving",
                "moderate",
                "overall",
                "absolute",
                "task",
                "performance",
                "-highlighting",
                "both",
                "the",
                "success",
                "of",
                "this",
                "shared",
                "task,",
                "as",
                "well",
                "as",
                "the",
                "continued",
                "challenge",
                "of",
                "determining",
                "relevancy",
                "in",
                "large",
                "multi-hop",
                "inference",
                "problems."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "This 2021 instantiation of the Shared Task on Explanation Regeneration focuses on the theme of determining relevance in large multi-hop explanations. To this end, participants were given access to a large pre-release dataset of approximately 250k explanatory relevancy ratings that augment the 2020 shared task data #TARGET_REF , and were tasked with ranking the facts most critical to assembling large explanations for a given question highest. Similarly to the previous instances of our competition, the shared task has been organized on the CodaLab platform. 1 We released train and development datasets along with the baseline solution in advance to allow one to get to know the task specifics. 2 We ran the practice phase from February 15 till March 9, 2021. Then we released the test dataset without answers and ran the official evaluation phase from March 10 till March 24, 2021. After that we established postcompetition phase to enable long-term evaluation of the methods beyond our shared task. Participating systems substantially increased task performance compared to a supplied baseline system by 32%, while achieving moderate overall absolute task performance -highlighting both the success of this shared task, as well as the continued challenge of determining relevancy in large multi-hop inference problems.",
        "output": "{\"INFO\": [\"2020 shared task data #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"participants were given access to a large pre-release dataset of approximately 250k explanatory relevancy ratings that augment the\", \"and were tasked with ranking the facts most critical to assembling large explanations for a given question highest.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "above",
                "conditions",
                "are,",
                "of",
                "course,",
                "far",
                "from",
                "reality,",
                "since",
                "such",
                "a",
                "distance",
                "function,",
                "which",
                "perfectly",
                "corresponds",
                "to",
                "the",
                "mental",
                "representations",
                "of",
                "all",
                "people,",
                "certainly",
                "does",
                "not",
                "exist.",
                "This",
                "is",
                "clear",
                "from",
                "the",
                "fact",
                "that",
                "in",
                "classical",
                "association",
                "tests,",
                "where",
                "the",
                "actual",
                "task",
                "is",
                "to",
                "find",
                "nearest",
                "neighbors,",
                "the",
                "subjects",
                "never",
                "give",
                "the",
                "same",
                "answer",
                "#TARGET_REF",
                ").",
                "However,",
                "it",
                "is",
                "a",
                "meaningful",
                "task",
                "to",
                "create",
                "a",
                "similarity",
                "function",
                "and",
                "construct",
                "a",
                "similarity",
                "matrix",
                "S",
                "∈",
                "R",
                "V",
                "×V",
                ",",
                "in",
                "which",
                "S",
                "ij",
                "=",
                "s(w",
                "i",
                ",",
                "w",
                "j",
                ")",
                "approximates",
                "the",
                "average",
                "similarity",
                "perceived",
                "by",
                "people."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The above conditions are, of course, far from reality, since such a distance function, which perfectly corresponds to the mental representations of all people, certainly does not exist. This is clear from the fact that in classical association tests, where the actual task is to find nearest neighbors, the subjects never give the same answer #TARGET_REF ). However, it is a meaningful task to create a similarity function and construct a similarity matrix S ∈ R V ×V , in which S ij = s(w i , w j ) approximates the average similarity perceived by people.",
        "output": "{\"INFO\": [\"the fact that in classical association tests, where the actual task is to find nearest neighbors, the subjects never give the same answer #TARGET_REF ).\"], \"PERCEPT\": [\"This is clear from\"], \"BACK\": [\"The above conditions are, of course, far from reality, since such a distance function, which perfectly corresponds to the mental representations of all people, certainly does not exist.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "organizers",
                "of",
                "IWSLT",
                "provide",
                "several",
                "task",
                "specific",
                "corpora",
                "that",
                "can",
                "be",
                "used",
                "to",
                "train",
                "and",
                "optimize",
                "the",
                "translation",
                "system.",
                "The",
                "characteristics",
                "of",
                "these",
                "corpora",
                "are",
                "summarized",
                "in",
                "Table",
                "1.",
                "It",
                "is",
                "known",
                "that",
                "the",
                "choice",
                "of",
                "the",
                "development",
                "and",
                "internal",
                "test",
                "data",
                "may",
                "have",
                "an",
                "important",
                "impact",
                "on",
                "the",
                "quality",
                "of",
                "the",
                "system,",
                "in",
                "particular",
                "when",
                "the",
                "available",
                "corpora",
                "have",
                "different",
                "characteristics",
                "(for",
                "instance",
                "what",
                "concerns",
                "the",
                "average",
                "sentence",
                "length).",
                "We",
                "decided",
                "to",
                "develop",
                ".",
                "Therefore,",
                "we",
                "decided",
                "to",
                "add",
                "the",
                "last",
                "two",
                "corpora",
                "to",
                "the",
                "training",
                "material",
                "after",
                "optimizing",
                "the",
                "system",
                "and",
                "to",
                "retrain",
                "the",
                "full",
                "system",
                "keeping",
                "all",
                "settings",
                "unmodified.",
                "This",
                "idea",
                "was",
                "already",
                "successfully",
                "proposed",
                "in",
                "previous",
                "IWSLT",
                "evaluations",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The organizers of IWSLT provide several task specific corpora that can be used to train and optimize the translation system. The characteristics of these corpora are summarized in Table 1. It is known that the choice of the development and internal test data may have an important impact on the quality of the system, in particular when the available corpora have different characteristics (for instance what concerns the average sentence length). We decided to develop . Therefore, we decided to add the last two corpora to the training material after optimizing the system and to retrain the full system keeping all settings unmodified. This idea was already successfully proposed in previous IWSLT evaluations #TARGET_REF .",
        "output": "{\"INFO\": [\"previous IWSLT evaluations #TARGET_REF .\"], \"PERCEPT\": [\"we decided to add the last two corpora to the training material after optimizing the system and to retrain the full system keeping all settings unmodified. This idea was already successfully proposed in\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "these",
                "experiments",
                "we",
                "have",
                "compared",
                "the",
                "conditioned",
                "text",
                "generation",
                "of",
                "CTERM-GAN",
                "with",
                "that",
                "of",
                "the",
                "state-of-the-art",
                "adversarial",
                "architectures",
                "-Se-qGAN",
                "#REF",
                ",",
                "RelGAN",
                "#TARGET_REF",
                ",",
                "and",
                "TGVAE",
                "#REF",
                "-and",
                "a",
                "classic",
                "auto-regressive",
                "LSTM",
                "language",
                "model",
                "with",
                "an",
                "initial",
                "conditioning,",
                "in",
                "terms",
                "of",
                "both",
                "syntactic",
                "and",
                "semantic",
                "quality.",
                "The",
                "main",
                "goal",
                "is",
                "to",
                "ensure",
                "a",
                "good",
                "quality",
                "for",
                "the",
                "generation",
                "by",
                "introducing",
                "a",
                "conditioning",
                "on",
                "the",
                "semantic",
                "of",
                "the",
                "sentence.",
                "In",
                "this",
                "task,",
                "the",
                "conditioning",
                "consists",
                "of",
                "the",
                "word",
                "distribution",
                "for",
                "a",
                "topic",
                "extracted",
                "from",
                "a",
                "sentence,",
                "either",
                "provided",
                "by",
                "the",
                "user",
                "or,",
                "as",
                "in",
                "our",
                "case,",
                "sampled",
                "from",
                "the",
                "dataset.",
                "Any",
                "type",
                "of",
                "topic",
                "model",
                "can",
                "be",
                "adopted:",
                "in",
                "our",
                "case,",
                "an",
                "LDA",
                "model",
                "#REF",
                "has",
                "been",
                "trained",
                "on",
                "a",
                "starting",
                "dataset",
                "in",
                "order",
                "to",
                "have",
                "a",
                "distribution",
                "of",
                "the",
                "topics",
                "covered",
                "within",
                "the",
                "corpus.",
                "The",
                "LDA",
                "model,",
                "both",
                "in",
                "training",
                "and",
                "in",
                "inference,",
                "given",
                "an",
                "input",
                "sentence,",
                "builds",
                "a",
                "distribution",
                "on",
                "the",
                "vocabulary.",
                "In",
                "turn,",
                "this",
                "distribution",
                "influences",
                "the",
                "model's",
                "sentence",
                "generation",
                "thanks",
                "to",
                "its",
                "inclusion",
                "in",
                "the",
                "generation",
                "process.",
                "Most",
                "likely,",
                "improving",
                "the",
                "quality",
                "of",
                "the",
                "topic",
                "extraction",
                "is",
                "likely",
                "to",
                "improve",
                "the",
                "final",
                "results",
                "of",
                "the",
                "model.",
                "Eventually,",
                "the",
                "extracted",
                "distribution",
                "is",
                "used",
                "as",
                "the",
                "condition-",
                "ing",
                "input,",
                "c,",
                "for",
                "the",
                "relational",
                "memory",
                "during",
                "the",
                "generation,",
                "as",
                "described",
                "in",
                "Section",
                "3."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                3,
                0,
                0,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In these experiments we have compared the conditioned text generation of CTERM-GAN with that of the state-of-the-art adversarial architectures -Se-qGAN #REF , RelGAN #TARGET_REF , and TGVAE #REF -and a classic auto-regressive LSTM language model with an initial conditioning, in terms of both syntactic and semantic quality. The main goal is to ensure a good quality for the generation by introducing a conditioning on the semantic of the sentence. In this task, the conditioning consists of the word distribution for a topic extracted from a sentence, either provided by the user or, as in our case, sampled from the dataset. Any type of topic model can be adopted: in our case, an LDA model #REF has been trained on a starting dataset in order to have a distribution of the topics covered within the corpus. The LDA model, both in training and in inference, given an input sentence, builds a distribution on the vocabulary. In turn, this distribution influences the model's sentence generation thanks to its inclusion in the generation process. Most likely, improving the quality of the topic extraction is likely to improve the final results of the model. Eventually, the extracted distribution is used as the condition- ing input, c, for the relational memory during the generation, as described in Section 3.",
        "output": "{\"INFO\": [\"RelGAN #TARGET_REF ,\"], \"PERCEPT\": [\"these experiments we have compared the conditioned text generation of CTERM-GAN with that of the state-of-the-art adversarial architectures\"], \"BACK\": [\"-Se-qGAN #REF ,\", \"and TGVAE #REF\", \"in terms of\", \"syntactic\", \"quality.\"]}"
    },
    {
        "gold": {
            "text": [
                ")where",
                "k",
                "is",
                "the",
                "number",
                "of",
                "language",
                "models",
                "which",
                "are",
                "being",
                "interpolated,",
                "µ",
                "i",
                "the",
                "interpolation",
                "weights",
                "and",
                "V",
                "is",
                "the",
                "vocabulary",
                "of",
                "the",
                "specific",
                "language",
                "model.",
                "The",
                "interpolation",
                "weights",
                "are",
                "estimated",
                "using",
                "Expectation",
                "Maximization",
                "(EM)",
                "#TARGET_REF",
                "over",
                "the",
                "log-likelihood",
                "in",
                "#REF",
                ":N",
                "t=1",
                "log",
                "k",
                "i=1",
                "µ",
                "i",
                "(f",
                "*",
                "i",
                "(w",
                "t",
                "|h",
                "t",
                ")",
                "+",
                "λ",
                "i",
                "(h",
                "t",
                ")P",
                "r",
                "mix",
                "(w",
                "t",
                "|",
                "ht",
                "))",
                "(6)where",
                "the",
                "index",
                "t",
                "scans",
                "over",
                "all",
                "the",
                "n-grams",
                "in",
                "the",
                "training",
                "corpora.",
                "This",
                "mixture",
                "model",
                "was",
                "used",
                "to",
                "combine",
                "the",
                "'in-domain'",
                "language",
                "model",
                "with",
                "an",
                "'out-of-domain'",
                "one,",
                "with",
                "the",
                "mixture",
                "weights",
                "being",
                "estimated",
                "on",
                "the",
                "'in-domain'",
                "training",
                "data",
                "by",
                "applying",
                "a",
                "cross-validation",
                "scheme.",
                "Further",
                "improvements",
                "on",
                "this",
                "mixture",
                "models",
                "were",
                "achieved",
                "using",
                "parameter",
                "tying",
                "to",
                "the",
                "most-recent",
                "context",
                "words",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": ")where k is the number of language models which are being interpolated, µ i the interpolation weights and V is the vocabulary of the specific language model. The interpolation weights are estimated using Expectation Maximization (EM) #TARGET_REF over the log-likelihood in #REF :N t=1 log k i=1 µ i (f * i (w t |h t ) + λ i (h t )P r mix (w t | ht )) (6)where the index t scans over all the n-grams in the training corpora. This mixture model was used to combine the 'in-domain' language model with an 'out-of-domain' one, with the mixture weights being estimated on the 'in-domain' training data by applying a cross-validation scheme. Further improvements on this mixture models were achieved using parameter tying to the most-recent context words #REF .",
        "output": "{\"INFO\": [\"Expectation Maximization (EM) #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The interpolation weights are estimated using\", \"over the log-likelihood in #REF :N t=1 log k i=1 \\u00b5 i (f * i (w t |h t ) + \\u03bb i (h t )P r mix (w t | ht ))\"]}"
    },
    {
        "gold": {
            "text": [
                "Inference",
                "In",
                "our",
                "implementation,",
                "we",
                "use",
                "FAISS",
                "#TARGET_REF",
                "to",
                "index",
                "the",
                "dense",
                "representations",
                "of",
                "all",
                "passages.",
                "Specifically,",
                "we",
                "use",
                "IndexFlatIP",
                "for",
                "indexing",
                "and",
                "the",
                "exact",
                "maximum",
                "inner",
                "product",
                "search",
                "for",
                "querying."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Inference In our implementation, we use FAISS #TARGET_REF to index the dense representations of all passages. Specifically, we use IndexFlatIP for indexing and the exact maximum inner product search for querying.",
        "output": "{\"INFO\": [\"FAISS #TARGET_REF\"], \"PERCEPT\": [\"In our implementation, we use\", \"to index the dense representations of all passages.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "syntax",
                "discriminator",
                "takes",
                "as",
                "input",
                "either",
                "a",
                "real",
                "sentence,",
                "r",
                "=",
                "(r",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "r",
                "n",
                "),",
                "or",
                "a",
                "generated",
                "one,g",
                "=",
                "(g",
                "1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "g",
                "n",
                ").Similarly",
                "to",
                "many",
                "other",
                "works",
                "(e.g.,",
                "#TARGET_REF",
                "),",
                "the",
                "discriminator",
                "first",
                "transforms",
                "its",
                "input",
                "into",
                "an",
                "embedding",
                "matrix.",
                "This",
                "embedding",
                "allows",
                "learning",
                "a",
                "transformation",
                "that",
                "condenses",
                "the",
                "information",
                "brought",
                "in",
                "by",
                "each",
                "word",
                "optimally",
                "for",
                "any",
                "given",
                "task.",
                "The",
                "syntax",
                "discriminator",
                "is",
                "then",
                "built",
                "using",
                "two",
                "convolutional",
                "layers",
                "with",
                "ReLU",
                "activation",
                "functions,",
                "followed",
                "by",
                "a",
                "self-attention",
                "layer,",
                "again",
                "followed",
                "by",
                "two",
                "other",
                "convolutional",
                "layers",
                "with",
                "ReLU",
                "activation",
                "functions.",
                "The",
                "selfattention",
                "layer",
                "is",
                "used",
                "to",
                "attend",
                "to",
                "the",
                "output",
                "of",
                "the",
                "previous",
                "convolutional",
                "layer",
                "and",
                "select",
                "the",
                "most",
                "useful",
                "features.",
                "The",
                "final",
                "layers",
                "generate",
                "the",
                "decision."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The syntax discriminator takes as input either a real sentence, r = (r 1 , . . . , r n ), or a generated one,g = (g 1 , . . . , g n ).Similarly to many other works (e.g., #TARGET_REF ), the discriminator first transforms its input into an embedding matrix. This embedding allows learning a transformation that condenses the information brought in by each word optimally for any given task. The syntax discriminator is then built using two convolutional layers with ReLU activation functions, followed by a self-attention layer, again followed by two other convolutional layers with ReLU activation functions. The selfattention layer is used to attend to the output of the previous convolutional layer and select the most useful features. The final layers generate the decision.",
        "output": "{\"INFO\": [\"many other works (e.g., #TARGET_REF ),\"], \"PERCEPT\": [\").Similarly to\", \"the discriminator first transforms its input into an embedding matrix.\"], \"BACK\": [\"This embedding allows learning a transformation that condenses the information brought in by each word optimally for any given task.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "latest",
                "article",
                "on",
                "the",
                "topic",
                "is",
                "#REF",
                ",",
                "in",
                "which,",
                "in",
                "addition",
                "to",
                "the",
                "previously",
                "used",
                "Skip-gram",
                "and",
                "GloVe",
                "word",
                "embeddings,",
                "to",
                "produce",
                "their",
                "similarity",
                "matrices",
                "they",
                "use",
                "•",
                "FastText",
                "#TARGET_REF",
                ","
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1
            ]
        },
        "input": "The latest article on the topic is #REF , in which, in addition to the previously used Skip-gram and GloVe word embeddings, to produce their similarity matrices they use • FastText #TARGET_REF ,",
        "output": "{\"INFO\": [\"FastText #TARGET_REF ,\"], \"PERCEPT\": [\"in which, in addition to the previously used Skip-gram and GloVe word embeddings, to produce their similarity matrices they use\"], \"BACK\": [\"The latest article on the topic is #REF ,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "order",
                "to",
                "create",
                "diversity,",
                "existing",
                "methods",
                "attempted",
                "to",
                "produce",
                "uncertainty",
                "by",
                "introducing",
                "random",
                "noise",
                "into",
                "a",
                "latent",
                "variable",
                "#TARGET_REF",
                "or",
                "sampling",
                "next",
                "token",
                "widely",
                "from",
                "the",
                "vo-",
                "cabulary",
                "#REF",
                ".",
                "However,",
                "these",
                "methods",
                "were",
                "not",
                "able",
                "to",
                "explicitly",
                "control",
                "varying",
                "semantics",
                "units",
                "and",
                "produce",
                "outputs",
                "of",
                "diverse",
                "content.",
                "Meanwhile,",
                "the",
                "input",
                "text",
                "alone",
                "contains",
                "too",
                "limited",
                "knowledge",
                "to",
                "support",
                "diverse",
                "reasoning",
                "and",
                "produce",
                "multiple",
                "reasonable",
                "outputs",
                "#REF",
                ".",
                "As",
                "an",
                "example,",
                "Table",
                "1",
                "shows",
                "the",
                "human",
                "evaluation",
                "results",
                "on",
                "two",
                "GCR",
                "tasks.",
                "While",
                "human",
                "annotators",
                "were",
                "able",
                "to",
                "produce",
                "2.60",
                "different",
                "yet",
                "reasonable",
                "explanations",
                "on",
                "the",
                "ComVE",
                "dataset,",
                "one",
                "SoTA",
                "diversity-promoting",
                "method",
                "(i.e.,",
                "nucleus",
                "sampling",
                "#REF",
                ")",
                "could",
                "produce",
                "only",
                "2.15",
                "reasonable",
                "explanations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In order to create diversity, existing methods attempted to produce uncertainty by introducing random noise into a latent variable #TARGET_REF or sampling next token widely from the vo- cabulary #REF . However, these methods were not able to explicitly control varying semantics units and produce outputs of diverse content. Meanwhile, the input text alone contains too limited knowledge to support diverse reasoning and produce multiple reasonable outputs #REF . As an example, Table 1 shows the human evaluation results on two GCR tasks. While human annotators were able to produce 2.60 different yet reasonable explanations on the ComVE dataset, one SoTA diversity-promoting method (i.e., nucleus sampling #REF ) could produce only 2.15 reasonable explanations.",
        "output": "{\"INFO\": [\"uncertainty by introducing random noise into a latent variable #TARGET_REF\"], \"PERCEPT\": [\"these methods were not able to explicitly control varying semantics units and produce outputs of diverse content.\", \"the input text alone contains too limited knowledge to support diverse reasoning and produce multiple reasonable outputs #REF\"], \"BACK\": [\"In order to create diversity, existing methods attempted to produce\", \"or sampling next token widely from the vo- cabulary #REF .\", \"Table 1 shows the human evaluation results on two GCR tasks.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "minimise",
                "confounds",
                "arising",
                "from",
                "the",
                "preceding",
                "word",
                "in",
                "the",
                "sentence,",
                "we",
                "balanced",
                "the",
                "test",
                "set",
                "with",
                "respect",
                "to",
                "the",
                "open/closed",
                "class",
                "status",
                "of",
                "the",
                "previous",
                "word.",
                "Similarly,",
                "we",
                "controlled",
                "the",
                "decoding",
                "of",
                "word",
                "frequency",
                "for",
                "word",
                "length,",
                "and",
                "the",
                "analysis",
                "of",
                "word",
                "length",
                "for",
                "word",
                "frequency,",
                "and",
                "both",
                "analyses",
                "for",
                "open/closed",
                "class",
                "and",
                "sentence",
                "position.",
                "2",
                "shows",
                "the",
                "mean",
                "accuracy",
                "values",
                "(averaged",
                "across",
                "10",
                "seed",
                "points)",
                "from",
                "the",
                "test",
                "set",
                "(centred",
                "on",
                "the",
                "last",
                "bin",
                "of",
                "each",
                "time",
                "window",
                "#TARGET_REF",
                ")",
                "with",
                "±",
                "68%",
                "CI.",
                "The",
                "classification",
                "responses",
                "for",
                "the",
                "test",
                "set",
                "from",
                "the",
                "model",
                "that",
                "performed",
                "best",
                "on",
                "the",
                "dev",
                "set",
                "were",
                "entered",
                "into",
                "a",
                "two-sided",
                "binomial",
                "test,",
                "separately",
                "for",
                "each",
                "time",
                "window.",
                "Solid",
                "lines",
                "in",
                "Figure",
                "2",
                "above",
                "the",
                "decoding",
                "accuracy",
                "time",
                "courses",
                "indicate",
                "time",
                "points",
                "that",
                "were",
                "significant",
                "at",
                "(p",
                "&lt,",
                "0.05)",
                "False",
                "Discovery",
                "Rate",
                "(FDR)",
                "corrected",
                "for",
                "multiple",
                "comparisons",
                "#REF",
                "across",
                "time",
                "(i.e.",
                "160",
                "tests)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To minimise confounds arising from the preceding word in the sentence, we balanced the test set with respect to the open/closed class status of the previous word. Similarly, we controlled the decoding of word frequency for word length, and the analysis of word length for word frequency, and both analyses for open/closed class and sentence position. 2 shows the mean accuracy values (averaged across 10 seed points) from the test set (centred on the last bin of each time window #TARGET_REF ) with ± 68% CI. The classification responses for the test set from the model that performed best on the dev set were entered into a two-sided binomial test, separately for each time window. Solid lines in Figure 2 above the decoding accuracy time courses indicate time points that were significant at (p &lt, 0.05) False Discovery Rate (FDR) corrected for multiple comparisons #REF across time (i.e. 160 tests).",
        "output": "{\"INFO\": [\"(centred on the last bin of each time window #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"2 shows the mean accuracy values\", \"from the test set\", \"with \\u00b1 68% CI. The classification responses for the test set from the model that performed best on the dev set were entered into a two-sided binomial test, separately for each time window.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "also",
                "compare",
                "with",
                "the",
                "semi-rule-based",
                "system",
                "used",
                "for",
                "pre-annotating",
                "the",
                "Parallel",
                "Meaning",
                "Bank",
                "#REF",
                ".",
                "#TARGET_REF",
                "call",
                "this",
                "system",
                "\"Pro",
                "Boxer\".",
                "In",
                "a",
                "sense,",
                "Pro",
                "Boxer",
                "is",
                "closest",
                "in",
                "approach",
                "to",
                "ours",
                "because",
                "it",
                "makes",
                "use",
                "of",
                "neural",
                "taggers",
                "for",
                "making",
                "token-level",
                "tagging",
                "predictions.",
                "It",
                "differs",
                "from",
                "ours",
                "and",
                "all",
                "other",
                "systems",
                "however",
                "in",
                "that",
                "it",
                "is",
                "not",
                "fully",
                "trainable",
                "from",
                "examples,",
                "the",
                "translation",
                "from",
                "tags",
                "to",
                "DRSs",
                "is",
                "done",
                "via",
                "hand-crafted",
                "rules.",
                "Moreover,",
                "it",
                "relies",
                "on",
                "a",
                "CCG",
                "parser",
                "that",
                "creates",
                "explicit",
                "syntactic",
                "representation",
                "which",
                "is",
                "perhaps",
                "more",
                "complexity",
                "than",
                "needed.",
                "As",
                "van",
                "Noord",
                "et",
                "al.",
                "also",
                "point",
                "out,",
                "the",
                "comparison",
                "with",
                "Pro",
                "Boxer",
                "is",
                "not",
                "quite",
                "fair",
                "because",
                "it",
                "is",
                "the",
                "system",
                "that",
                "produced",
                "the",
                "PMB",
                "pre-annotations",
                "and",
                "thus",
                "profits",
                "from",
                "anchoring",
                "bias."
            ],
            "context": [
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We also compare with the semi-rule-based system used for pre-annotating the Parallel Meaning Bank #REF . #TARGET_REF call this system \"Pro Boxer\". In a sense, Pro Boxer is closest in approach to ours because it makes use of neural taggers for making token-level tagging predictions. It differs from ours and all other systems however in that it is not fully trainable from examples, the translation from tags to DRSs is done via hand-crafted rules. Moreover, it relies on a CCG parser that creates explicit syntactic representation which is perhaps more complexity than needed. As van Noord et al. also point out, the comparison with Pro Boxer is not quite fair because it is the system that produced the PMB pre-annotations and thus profits from anchoring bias.",
        "output": "{\"INFO\": [\"#TARGET_REF call this system \\\"Pro Boxer\\\".\", \"it relies on a CCG parser that creates explicit syntactic representation which is perhaps more complexity than needed.\"], \"PERCEPT\": [\"In a sense, Pro Boxer is closest in approach to ours because it makes use of neural taggers for making token-level tagging predictions. It differs from ours and all other systems however in that it is not fully trainable from examples, the translation from tags to DRSs is done via hand-crafted rules.\"], \"BACK\": [\"the semi-rule-based system used for pre-annotating the Parallel Meaning Bank #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "graph,",
                "created",
                "as",
                "an",
                "alternative",
                "for",
                "word",
                "embeddings,",
                "is",
                "GraphGlove",
                "#REF",
                ",",
                "where",
                "the",
                "edges",
                "of",
                "the",
                "graph",
                "are",
                "optimized",
                "by",
                "the",
                "cost",
                "function",
                "of",
                "GloVe",
                "#TARGET_REF",
                ",",
                "so",
                "that",
                "the",
                "shortest",
                "path",
                "between",
                "two",
                "vertices",
                "gives",
                "the",
                "distance",
                "of",
                "the",
                "corresponding",
                "words."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Another graph, created as an alternative for word embeddings, is GraphGlove #REF , where the edges of the graph are optimized by the cost function of GloVe #TARGET_REF , so that the shortest path between two vertices gives the distance of the corresponding words.",
        "output": "{\"INFO\": [\"GloVe #TARGET_REF ,\"], \"PERCEPT\": [\"GraphGlove #REF , where the edges of the graph are optimized by the cost function of\"], \"BACK\": [\"so that the shortest path between two vertices gives the distance of the corresponding words.\"]}"
    },
    {
        "gold": {
            "text": [
                "Explainability",
                "is",
                "an",
                "important",
                "concept",
                "within",
                "abusive",
                "language",
                "detection.",
                "#TARGET_REF",
                "noted",
                "in",
                "their",
                "work",
                "that",
                "explainable",
                "ML",
                "techniques",
                "can",
                "promote",
                "restorative",
                "and",
                "procedural",
                "justice",
                "by",
                "surfacing",
                "the",
                "norms",
                "that",
                "have",
                "been",
                "violated",
                "and",
                "clarifying",
                "how",
                "they",
                "have",
                "been",
                "violated.",
                "That",
                "said,",
                "there",
                "has",
                "been",
                "limited",
                "discussion",
                "of",
                "the",
                "issue",
                "within",
                "the",
                "domain",
                "of",
                "abusive",
                "language",
                "detection.",
                "In",
                "this",
                "section,",
                "we",
                "first",
                "formalize",
                "the",
                "properties",
                "that",
                "an",
                "explainable",
                "detection",
                "method",
                "should",
                "aim",
                "to",
                "exhibit",
                "in",
                "order",
                "to",
                "thoroughly",
                "substantiate",
                "its",
                "decisions.",
                "We",
                "then",
                "describe",
                "how",
                "user",
                "and",
                "community",
                "information",
                "play",
                "an",
                "important",
                "role",
                "in",
                "the",
                "realization",
                "of",
                "each",
                "of",
                "the",
                "properties.",
                "Finally,",
                "we",
                "discuss",
                "what",
                "it",
                "means",
                "to",
                "operationalize",
                "explainability",
                "within",
                "abusive",
                "language",
                "detection",
                "in",
                "an",
                "effective",
                "manner."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Explainability is an important concept within abusive language detection. #TARGET_REF noted in their work that explainable ML techniques can promote restorative and procedural justice by surfacing the norms that have been violated and clarifying how they have been violated. That said, there has been limited discussion of the issue within the domain of abusive language detection. In this section, we first formalize the properties that an explainable detection method should aim to exhibit in order to thoroughly substantiate its decisions. We then describe how user and community information play an important role in the realization of each of the properties. Finally, we discuss what it means to operationalize explainability within abusive language detection in an effective manner.",
        "output": "{\"INFO\": [\"#TARGET_REF noted in their work that explainable ML techniques can promote restorative and procedural justice by surfacing the norms that have been violated and clarifying how they have been violated.\"], \"PERCEPT\": [], \"BACK\": [\"Explainability is an important concept within abusive language detection.\"]}"
    },
    {
        "gold": {
            "text": [
                "An",
                "important",
                "note",
                "before",
                "continuing:",
                "when",
                "I",
                "refer",
                "to",
                "IBM",
                "machine",
                "translation",
                "I",
                "mean",
                "only",
                "the",
                "systems",
                "referred",
                "to",
                "at",
                "the",
                "end",
                "by",
                "Brown",
                "et",
                "al.",
                "IBM",
                "as",
                "a",
                "whole",
                "supports",
                "many",
                "approaches",
                "to",
                "MT,",
                "including",
                "#TARGET_REF",
                "Prolog-based",
                "symbolic",
                "approach,",
                "as",
                "well",
                "as",
                "symbolic",
                "systems",
                "in",
                "Germany",
                "and",
                "Japan."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "An important note before continuing: when I refer to IBM machine translation I mean only the systems referred to at the end by Brown et al. IBM as a whole supports many approaches to MT, including #TARGET_REF Prolog-based symbolic approach, as well as symbolic systems in Germany and Japan.",
        "output": "{\"INFO\": [\"#TARGET_REF Prolog-based symbolic approach,\"], \"PERCEPT\": [\"when I refer to IBM machine translation I mean only the systems referred to at the end by Brown et al. IBM as a whole supports many approaches to MT, including\"], \"BACK\": [\"as well as symbolic systems in Germany and Japan.\"]}"
    },
    {
        "gold": {
            "text": [
                "All",
                "models",
                "are",
                "implemented",
                "based",
                "on",
                "the",
                "opensource",
                "transformers",
                "library",
                "of",
                "hugging",
                "face",
                "#TARGET_REF",
                ",",
                "which",
                "provides",
                "thousands",
                "of",
                "pretrained",
                "models",
                "that",
                "can",
                "be",
                "quickly",
                "downloaded",
                "and",
                "fine-tuned",
                "on",
                "specific",
                "tasks.",
                "of",
                "doing",
                "this",
                "in",
                "Table",
                "3",
                "and",
                "we",
                "can",
                "find",
                "that",
                "it",
                "is",
                "very",
                "effective",
                "by",
                "increasing",
                "0.02",
                "from",
                "base",
                "models."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "All models are implemented based on the opensource transformers library of hugging face #TARGET_REF , which provides thousands of pretrained models that can be quickly downloaded and fine-tuned on specific tasks. of doing this in Table 3 and we can find that it is very effective by increasing 0.02 from base models.",
        "output": "{\"INFO\": [\"transformers library of hugging face #TARGET_REF , which provides thousands of pretrained models that can be quickly downloaded and fine-tuned on specific tasks.\"], \"PERCEPT\": [], \"BACK\": [\"All models are implemented based on the opensource\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "addition,",
                "they",
                "introduce",
                "another",
                "method",
                "to",
                "score",
                "clues",
                "not",
                "only",
                "on",
                "the",
                "basis",
                "of",
                "word",
                "similarities,",
                "but",
                "also",
                "on",
                "the",
                "basis",
                "of",
                "their",
                "frequency",
                "and",
                "the",
                "similarity",
                "of",
                "Dict2vec",
                "vectors",
                "#TARGET_REF",
                "-but",
                "this",
                "is",
                "actually",
                "a",
                "modification",
                "of",
                "the",
                "original",
                "distance",
                "matrix."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "In addition, they introduce another method to score clues not only on the basis of word similarities, but also on the basis of their frequency and the similarity of Dict2vec vectors #TARGET_REF -but this is actually a modification of the original distance matrix.",
        "output": "{\"INFO\": [\"Dict2vec vectors #TARGET_REF\"], \"PERCEPT\": [\"they introduce another method to score clues not only on the basis of word similarities, but also on the basis of their frequency and the similarity of\"], \"BACK\": [\"-but this is actually a modification of the original distance matrix.\"]}"
    },
    {
        "gold": {
            "text": [
                "Designing",
                "neural",
                "diversity",
                "metrics.",
                "In",
                "spite",
                "of",
                "growing",
                "interest",
                "in",
                "NLG",
                "models",
                "that",
                "produce",
                "diverse",
                "outputs,",
                "there",
                "is",
                "currently",
                "no",
                "principled",
                "neu-ral",
                "method",
                "for",
                "evaluating",
                "the",
                "diversity",
                "of",
                "an",
                "NLG",
                "system.",
                "As",
                "described",
                "in",
                "#TARGET_REF",
                ",",
                "existing",
                "automatic",
                "diversity",
                "metrics",
                "(e.g.",
                "Self-BLEU)",
                "perform",
                "worse",
                "than",
                "humans",
                "on",
                "the",
                "task",
                "of",
                "estimating",
                "content",
                "diversity,",
                "indicating",
                "a",
                "low",
                "correlation",
                "between",
                "metrics",
                "and",
                "human",
                "judgments."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Designing neural diversity metrics. In spite of growing interest in NLG models that produce diverse outputs, there is currently no principled neu-ral method for evaluating the diversity of an NLG system. As described in #TARGET_REF , existing automatic diversity metrics (e.g. Self-BLEU) perform worse than humans on the task of estimating content diversity, indicating a low correlation between metrics and human judgments.",
        "output": "{\"INFO\": [\"#TARGET_REF ,\"], \"PERCEPT\": [\"spite of growing interest in NLG models that produce diverse outputs, there is currently no principled neu-ral method for evaluating the diversity of an NLG system. As described in\"], \"BACK\": [\"existing automatic diversity metrics (e.g. Self-BLEU) perform worse than humans on the task of estimating content diversity, indicating a low correlation between metrics and human judgments.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "semantics,",
                "the",
                "situation",
                "is",
                "even",
                "more",
                "complicated.",
                "While",
                "BERT's",
                "performance",
                "on",
                "natural",
                "language",
                "understanding",
                "tasks",
                "set",
                "a",
                "new",
                "state",
                "of",
                "the",
                "art,",
                "more",
                "targeted",
                "tests",
                "of",
                "its",
                "semantic",
                "abilities",
                "have",
                "yielded",
                "less",
                "positive",
                "results.",
                "BERT",
                "has",
                "limited",
                "knowledge",
                "of",
                "lexical",
                "semantic",
                "relations",
                "such",
                "as",
                "hypernymy",
                "#TARGET_REF",
                "and",
                "antonymy",
                "#REF",
                ".",
                "Moreover,",
                "it",
                "has",
                "fragile",
                "representations",
                "of",
                "named",
                "entities",
                "#REF",
                ",",
                "and",
                "imprecise",
                "representations",
                "of",
                "numbers",
                "#REF",
                ".",
                "These",
                "flaws",
                "comprise",
                "specific",
                "linguistic",
                "phenomena",
                "that",
                "BERTScore,",
                "due",
                "to",
                "its",
                "use",
                "of",
                "BERT,",
                "might",
                "be",
                "unable",
                "to",
                "handle,",
                "and",
                "thus",
                "merit",
                "investigation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For semantics, the situation is even more complicated. While BERT's performance on natural language understanding tasks set a new state of the art, more targeted tests of its semantic abilities have yielded less positive results. BERT has limited knowledge of lexical semantic relations such as hypernymy #TARGET_REF and antonymy #REF . Moreover, it has fragile representations of named entities #REF , and imprecise representations of numbers #REF . These flaws comprise specific linguistic phenomena that BERTScore, due to its use of BERT, might be unable to handle, and thus merit investigation.",
        "output": "{\"INFO\": [\"BERT has limited knowledge of lexical semantic relations such as hypernymy #TARGET_REF\"], \"PERCEPT\": [\"might be unable to handle, and thus merit investigation.\"], \"BACK\": [\"and antonymy #REF . Moreover, it has fragile representations of named entities #REF , and imprecise representations of numbers #REF . These flaws comprise specific linguistic phenomena that BERTScore, due to its use of BERT,\"]}"
    },
    {
        "gold": {
            "text": [
                "Although",
                "there",
                "are",
                "some",
                "efforts",
                "to",
                "detect",
                "nonacceptable",
                "language",
                "in",
                "Portuguese,",
                "they",
                "evaluate",
                "the",
                "developed",
                "approach",
                "in",
                "their",
                "own",
                "corpus,",
                "making",
                "a",
                "fair",
                "comparison",
                "among",
                "the",
                "models",
                "difficult.",
                "Moreover,",
                "these",
                "corpora",
                "are",
                "much",
                "smaller",
                "when",
                "compared",
                "to",
                "corpora",
                "of",
                "other",
                "languages",
                "#TARGET_REF",
                "and",
                "than",
                "the",
                "ToLD-Br",
                "corpus.",
                "This",
                "fact",
                "makes",
                "the",
                "development",
                "of",
                "robust",
                "strategies",
                "to",
                "handle",
                "toxic",
                "comments",
                "difficult,",
                "as",
                "they",
                "usually",
                "require",
                "a",
                "large",
                "corpus.",
                "As",
                "one",
                "can",
                "see",
                "in",
                "Table",
                "1,",
                "the",
                "corpus",
                "has",
                "a",
                "little",
                "more",
                "non-toxic",
                "than",
                "toxic",
                "tweets.",
                "In",
                "this",
                "paper,",
                "we",
                "adopted",
                "the",
                "binary",
                "version",
                "of",
                "the",
                "corpus,",
                "i.e.,",
                "our",
                "objective",
                "is",
                "to",
                "identify",
                "if",
                "a",
                "comment",
                "is",
                "toxic",
                "or",
                "non-toxic."
            ],
            "context": [
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Although there are some efforts to detect nonacceptable language in Portuguese, they evaluate the developed approach in their own corpus, making a fair comparison among the models difficult. Moreover, these corpora are much smaller when compared to corpora of other languages #TARGET_REF and than the ToLD-Br corpus. This fact makes the development of robust strategies to handle toxic comments difficult, as they usually require a large corpus. As one can see in Table 1, the corpus has a little more non-toxic than toxic tweets. In this paper, we adopted the binary version of the corpus, i.e., our objective is to identify if a comment is toxic or non-toxic.",
        "output": "{\"INFO\": [\"corpora of\", \"languages #TARGET_REF\"], \"PERCEPT\": [\"Moreover, these corpora are much smaller when compared to\", \"other\", \"This fact makes the development of robust strategies to handle toxic comments difficult, as they usually require a large corpus.\"], \"BACK\": [\"some efforts to detect nonacceptable language in Portuguese,\", \"and than the ToLD-Br corpus.\"]}"
    },
    {
        "gold": {
            "text": [
                "English-Spanish",
                "datasets",
                "We",
                "consider",
                "the",
                "Eu-roParl",
                "(1.7M",
                "sentences)",
                "#TARGET_REF",
                "and",
                "the",
                "NewsCommentary-v8",
                "(174k",
                "sentences)",
                "corpora",
                "for",
                "pre-training."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2
            ]
        },
        "input": "English-Spanish datasets We consider the Eu-roParl (1.7M sentences) #TARGET_REF and the NewsCommentary-v8 (174k sentences) corpora for pre-training.",
        "output": "{\"INFO\": [\"the Eu-roParl (1.7M sentences) #TARGET_REF\"], \"PERCEPT\": [\"English-Spanish datasets We consider\", \"corpora for pre-training.\"], \"BACK\": [\"and the NewsCommentary-v8 (174k sentences)\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "study",
                "uses",
                "a",
                "self-built",
                "corpus.",
                "Since",
                "the",
                "phenomenon",
                "of",
                "public",
                "apologies",
                "is",
                "relatively",
                "recent",
                "in",
                "India,",
                "we",
                "could",
                "only",
                "access",
                "a",
                "corpus",
                "of",
                "18",
                "apologies",
                "available",
                "in",
                "the",
                "digital",
                "public",
                "domain,",
                "offered",
                "during",
                "2007-2017.",
                "The",
                "corpus",
                "is",
                "in",
                "the",
                "English",
                "language",
                "as",
                "it",
                "is",
                "the",
                "second",
                "official",
                "language",
                "in",
                "India.",
                "It",
                "is",
                "the",
                "lingua",
                "franca",
                "spoken",
                "amongst",
                "a",
                "wide",
                "proportion",
                "of",
                "the",
                "population",
                "and",
                "has",
                "about",
                "125",
                "million",
                "speakers,",
                "which",
                "is,",
                "country-wise,",
                "the",
                "second",
                "highest",
                "in",
                "the",
                "world,",
                "only",
                "below",
                "United",
                "States",
                "of",
                "America",
                "4",
                ".",
                "We",
                "employ",
                "a",
                "close",
                "reading",
                "approach",
                "#TARGET_REF",
                "for",
                "the",
                "analysis.",
                "All",
                "of",
                "the",
                "selected",
                "apologies",
                "were",
                "delivered",
                "in",
                "India,",
                "by",
                "Indians",
                "so",
                "as",
                "to",
                "understand",
                "any",
                "cultural",
                "implication",
                "of",
                "the",
                "communication.",
                "All",
                "of",
                "these",
                "were",
                "offered",
                "by",
                "senior",
                "executives",
                "of",
                "the",
                "company",
                "or",
                "prominent",
                "public",
                "personalities",
                "in",
                "India.",
                "Of",
                "these",
                "two",
                "were",
                "electronic",
                "mails,",
                "seven",
                "were",
                "letters,",
                "four",
                "were",
                "blog",
                "posts,",
                "four",
                "were",
                "tweets",
                "out",
                "of",
                "which",
                "two",
                "are",
                "related",
                "to",
                "the",
                "same",
                "event,",
                "and",
                "one",
                "was",
                "a",
                "media",
                "statement.",
                "Out",
                "of",
                "the",
                "18",
                "apologies,",
                "11",
                "were",
                "given",
                "by",
                "individual(s)",
                "in",
                "a",
                "role,",
                "3",
                "were",
                "given",
                "by",
                "organizations",
                "and",
                "4",
                "were",
                "given",
                "by",
                "individuals.",
                "The",
                "gender-wise",
                "distribution",
                "of",
                "the",
                "apology",
                "givers",
                "is",
                "14",
                "males",
                "and",
                "4",
                "females.",
                "The",
                "apologies",
                "selected",
                "have",
                "been",
                "assigned",
                "a",
                "code",
                "number",
                "for",
                "easy",
                "reference."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The study uses a self-built corpus. Since the phenomenon of public apologies is relatively recent in India, we could only access a corpus of 18 apologies available in the digital public domain, offered during 2007-2017. The corpus is in the English language as it is the second official language in India. It is the lingua franca spoken amongst a wide proportion of the population and has about 125 million speakers, which is, country-wise, the second highest in the world, only below United States of America 4 . We employ a close reading approach #TARGET_REF for the analysis. All of the selected apologies were delivered in India, by Indians so as to understand any cultural implication of the communication. All of these were offered by senior executives of the company or prominent public personalities in India. Of these two were electronic mails, seven were letters, four were blog posts, four were tweets out of which two are related to the same event, and one was a media statement. Out of the 18 apologies, 11 were given by individual(s) in a role, 3 were given by organizations and 4 were given by individuals. The gender-wise distribution of the apology givers is 14 males and 4 females. The apologies selected have been assigned a code number for easy reference.",
        "output": "{\"INFO\": [\"close reading approach #TARGET_REF\"], \"PERCEPT\": [\"We employ a\", \"for the analysis.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Although",
                "many",
                "NLP",
                "methods",
                "have",
                "already",
                "been",
                "used",
                "to",
                "generate",
                "distance",
                "matrices,",
                "others",
                "are",
                "worth",
                "trying.",
                "Examples",
                "include",
                "graph",
                "embedding",
                "of",
                "associations",
                "#TARGET_REF",
                "and",
                "GraphGlove",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                0
            ]
        },
        "input": "Although many NLP methods have already been used to generate distance matrices, others are worth trying. Examples include graph embedding of associations #TARGET_REF and GraphGlove #REF .",
        "output": "{\"INFO\": [\"graph embedding of associations #TARGET_REF\"], \"PERCEPT\": [\"Although many NLP methods have already been used to generate distance matrices, others are worth trying. Examples include\"], \"BACK\": [\"and GraphGlove #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "set",
                "of",
                "30",
                "high-level",
                "instructions",
                "specific",
                "to",
                "semantic",
                "network",
                "processing",
                "are",
                "implemented",
                "directly",
                "in",
                "hardware.",
                "These",
                "include",
                "associative",
                "search,",
                "marker",
                "setting",
                "and",
                "propagation,",
                "logical/arithmetic",
                "operations",
                "involving",
                "markers,",
                "create",
                "and",
                "delete",
                "nodes",
                "and",
                "relations,",
                "and",
                "collect",
                "a",
                "list",
                "of",
                "nodes",
                "with",
                "a",
                "certain",
                "marker",
                "set.",
                "Currently,",
                "the",
                "instruction",
                "set",
                "can",
                "be",
                "called",
                "from",
                "C",
                "language",
                "so",
                "that",
                "users",
                "can",
                "develop",
                "applications",
                "with",
                "an",
                "extended",
                "version",
                "of",
                "C",
                "language.",
                "From",
                "the",
                "programming",
                "level,",
                "SNAP",
                "provides",
                "data-parallel",
                "programming",
                "environment",
                "similar",
                "to",
                "C*",
                "of",
                "the",
                "Connection",
                "Machine",
                "#TARGET_REF",
                "],",
                "but",
                "specialized",
                "for",
                "semantic",
                "network",
                "processing",
                "with",
                "marker",
                "passing."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "A set of 30 high-level instructions specific to semantic network processing are implemented directly in hardware. These include associative search, marker setting and propagation, logical/arithmetic operations involving markers, create and delete nodes and relations, and collect a list of nodes with a certain marker set. Currently, the instruction set can be called from C language so that users can develop applications with an extended version of C language. From the programming level, SNAP provides data-parallel programming environment similar to C* of the Connection Machine #TARGET_REF ], but specialized for semantic network processing with marker passing.",
        "output": "{\"INFO\": [\"the Connection Machine #TARGET_REF ],\"], \"PERCEPT\": [\"From the programming level, SNAP provides data-parallel programming environment similar to C* of\", \"specialized for semantic network processing with marker passing.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "PMB,",
                "for",
                "more",
                "consistent",
                "representation",
                "of",
                "predicates.b0",
                "REF",
                "x0",
                "b-1",
                "Name",
                "x-1",
                "\"tom\"",
                "b-1",
                "PRESUPPOSITION",
                "b0",
                "b-2",
                "male",
                "\"n.02\"",
                "x-1",
                "b-2",
                "REF",
                "t0",
                "b-1",
                "TPR",
                "t-1",
                "\"now\"",
                "b-1",
                "Time",
                "e-1",
                "t-1",
                "b-1",
                "time",
                "\"n.08\"",
                "t-1",
                "b-1",
                "REF",
                "e-1",
                "b-1",
                "Patient",
                "e-1",
                "x-1",
                "b-1",
                "trick",
                "\"v.01\"",
                "e-1",
                "(3)",
                "b0",
                "REF",
                "x0",
                "b-1",
                "Name",
                "x-1",
                "\"DUMMY\"",
                "b-1",
                "PRESUPPOSITION",
                "b0",
                "b-2",
                "male",
                "\"n.02\"",
                "x-1",
                "b-1",
                "REF",
                "t0",
                "b-1",
                "TPR",
                "t-1",
                "\"now\"",
                "b-1",
                "Time",
                "e-1",
                "t-1",
                "b-1",
                "time",
                "\"n.08\"",
                "t-1",
                "b-1",
                "REF",
                "e-1",
                "b-1",
                "Patient",
                "e-1",
                "x-1",
                "b-1",
                "DUMMY",
                "\"v.00\"",
                "e-1",
                "[b0",
                "e0",
                "n0",
                "p0",
                "s0",
                "t0",
                "x0]",
                "[b-1",
                "e0",
                "n0",
                "p0",
                "s0",
                "t0",
                "x0]",
                "[b0",
                "e0",
                "n0",
                "p0",
                "s0",
                "t0",
                "x0]",
                "tom",
                "-",
                "trick",
                "\"v.01\""
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "PMB, for more consistent representation of predicates.b0 REF x0 b-1 Name x-1 \"tom\" b-1 PRESUPPOSITION b0 b-2 male \"n.02\" x-1 b-2 REF t0 b-1 TPR t-1 \"now\" b-1 Time e-1 t-1 b-1 time \"n.08\" t-1 b-1 REF e-1 b-1 Patient e-1 x-1 b-1 trick \"v.01\" e-1 (3) b0 REF x0 b-1 Name x-1 \"DUMMY\" b-1 PRESUPPOSITION b0 b-2 male \"n.02\" x-1 b-1 REF t0 b-1 TPR t-1 \"now\" b-1 Time e-1 t-1 b-1 time \"n.08\" t-1 b-1 REF e-1 b-1 Patient e-1 x-1 b-1 DUMMY \"v.00\" e-1 [b0 e0 n0 p0 s0 t0 x0] [b-1 e0 n0 p0 s0 t0 x0] [b0 e0 n0 p0 s0 t0 x0] tom - trick \"v.01\"",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "where",
                "-5",
                "meant",
                "that",
                "the",
                "MT",
                "output",
                "had",
                "greatly",
                "hindered",
                "their",
                "work",
                "and",
                "5",
                "meant",
                "that",
                "the",
                "MT",
                "output",
                "had",
                "greatly",
                "helped",
                "their",
                "work",
                "(see",
                "Table",
                "5).",
                "Overall,",
                "users",
                "were",
                "more",
                "positive",
                "about",
                "having",
                "the",
                "MT",
                "output",
                "displayed",
                "when",
                "translating,",
                "with",
                "only",
                "one",
                "out",
                "of",
                "six",
                "claiming",
                "that",
                "it",
                "hindered",
                "the",
                "process.",
                "In",
                "the",
                "case",
                "of",
                "translators,",
                "however,",
                "three",
                "out",
                "of",
                "six",
                "heavily",
                "penalized",
                "its",
                "use,",
                "one",
                "reported",
                "that",
                "it",
                "was",
                "better",
                "than",
                "not",
                "having",
                "it,",
                "and",
                "two",
                "reported",
                "some",
                "benefit.",
                "T1",
                "commented",
                "that",
                "translation",
                "and",
                "post-editing",
                "required",
                "different",
                "skills",
                "and",
                "that",
                "should",
                "the",
                "same",
                "time",
                "be",
                "spent",
                "in",
                "post-editing",
                "and",
                "translating,",
                "the",
                "translation",
                "would",
                "most",
                "probably",
                "be",
                "of",
                "better",
                "quality.",
                "T6",
                "was",
                "the",
                "most",
                "positive",
                "of",
                "all",
                "with",
                "regards",
                "to",
                "MT",
                "and",
                "admitted",
                "that",
                "the",
                "output",
                "helped",
                "in",
                "acquiring",
                "the",
                "terminology",
                "but",
                "was",
                "hopeless",
                "with",
                "syntax,",
                "which",
                "needed",
                "a",
                "complete",
                "rework.",
                "T2,",
                "T3",
                "and",
                "T4",
                "indicated",
                "that",
                "the",
                "MT",
                "output",
                "had",
                "clearly",
                "interfered",
                "in",
                "their",
                "job.",
                "T2",
                "reported",
                "that",
                "MT",
                "output",
                "slowed",
                "down",
                "the",
                "process",
                "considerably",
                "because",
                "reading,",
                "understanding",
                "and",
                "considering",
                "what",
                "to",
                "reuse",
                "from",
                "it",
                "was",
                "very",
                "time-consuming.",
                "T3",
                "commented",
                "that",
                "translating",
                "from",
                "scratch",
                "was",
                "easier",
                "and",
                "faster,",
                "and",
                "that",
                "even",
                "checking",
                "the",
                "MT",
                "output",
                "for",
                "terminology",
                "would",
                "most",
                "often",
                "not",
                "help.",
                "T4",
                "claimed",
                "that",
                "the",
                "MT",
                "system",
                "did",
                "not",
                "translate",
                "the",
                "order",
                "of",
                "the",
                "phrases",
                "properly,",
                "which",
                "rendered",
                "the",
                "translation",
                "incomprehensible.",
                "Interestingly,",
                "T3",
                "and",
                "T4",
                "did",
                "benefit",
                "from",
                "postediting."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "where -5 meant that the MT output had greatly hindered their work and 5 meant that the MT output had greatly helped their work (see Table 5). Overall, users were more positive about having the MT output displayed when translating, with only one out of six claiming that it hindered the process. In the case of translators, however, three out of six heavily penalized its use, one reported that it was better than not having it, and two reported some benefit. T1 commented that translation and post-editing required different skills and that should the same time be spent in post-editing and translating, the translation would most probably be of better quality. T6 was the most positive of all with regards to MT and admitted that the output helped in acquiring the terminology but was hopeless with syntax, which needed a complete rework. T2, T3 and T4 indicated that the MT output had clearly interfered in their job. T2 reported that MT output slowed down the process considerably because reading, understanding and considering what to reuse from it was very time-consuming. T3 commented that translating from scratch was easier and faster, and that even checking the MT output for terminology would most often not help. T4 claimed that the MT system did not translate the order of the phrases properly, which rendered the translation incomprehensible. Interestingly, T3 and T4 did benefit from postediting.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "Spanish-English",
                "example,",
                "the",
                "clitic",
                "can",
                "climb",
                "over",
                "an",
                "unlimited",
                "number",
                "of",
                "'trigger",
                "verbs'",
                "#TARGET_REF",
                ")",
                "(indicated",
                "by",
                "the",
                "ellipses",
                "in",
                "the",
                "example),",
                "and",
                "for",
                "certain",
                "TAG",
                "grammars",
                "this",
                "can",
                "correspond",
                "to",
                "a",
                "pair",
                "of",
                "derivation",
                "trees",
                "as",
                "in",
                "Figure",
                "2.",
                "In",
                "this",
                "pair",
                "of",
                "trees,",
                "his",
                "corresponds",
                "to",
                "both",
                "los",
                "and",
                "the",
                "clitic",
                "le.",
                "Both",
                "his",
                "and",
                "los",
                "are",
                "fixed",
                "in",
                "relation",
                "to",
                "the",
                "root",
                "of",
                "the",
                "tree,",
                "but",
                "le",
                "is",
                "an",
                "unbounded",
                "distance",
                "from",
                "it,",
                "so",
                "it",
                "is",
                "not",
                "possible",
                "to",
                "form",
                "a",
                "gCN",
                "in",
                "the",
                "Spanish",
                "tree",
                "for",
                "pairing",
                "without",
                "the",
                "unbounded",
                "and",
                "unrelated",
                "recursively-inserted",
                "verbs,",
                "hence",
                "requiring",
                "infinitely",
                "many",
                "transfer",
                "rules."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this Spanish-English example, the clitic can climb over an unlimited number of 'trigger verbs' #TARGET_REF ) (indicated by the ellipses in the example), and for certain TAG grammars this can correspond to a pair of derivation trees as in Figure 2. In this pair of trees, his corresponds to both los and the clitic le. Both his and los are fixed in relation to the root of the tree, but le is an unbounded distance from it, so it is not possible to form a gCN in the Spanish tree for pairing without the unbounded and unrelated recursively-inserted verbs, hence requiring infinitely many transfer rules.",
        "output": "{\"INFO\": [\"an unlimited number of 'trigger verbs' #TARGET_REF )\"], \"PERCEPT\": [\"In this Spanish-English example, the clitic can climb over\", \"and for certain TAG grammars this can correspond to a pair of derivation trees as in\"], \"BACK\": [\"(indicated by the ellipses in the example),\", \"Figure 2.\"]}"
    },
    {
        "gold": {
            "text": [
                "GLOVE",
                "#REF",
                "71.9",
                "ELMO",
                "#TARGET_REF",
                "80.2",
                "BERT",
                "BASE",
                "→",
                "LR",
                "#REF",
                "80.6",
                "BERT",
                "LARGE",
                "→",
                "LR",
                "#REF",
                "79",
                "BERT-base",
                "by",
                "adding",
                "an",
                "internal",
                "entity",
                "linker."
            ],
            "context": [
                0,
                0,
                0,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "GLOVE #REF 71.9 ELMO #TARGET_REF 80.2 BERT BASE → LR #REF 80.6 BERT LARGE → LR #REF 79 BERT-base by adding an internal entity linker.",
        "output": "{\"INFO\": [\"ELMO #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "of",
                "the",
                "[CLS]",
                "token",
                "and",
                "average",
                "them",
                "across",
                "different",
                "heads.",
                "If",
                "p",
                "pos",
                "i",
                "&gt,",
                "p",
                "neg",
                "i",
                ",",
                "we",
                "obtain",
                "the",
                "updated",
                "attention",
                "score",
                "ãj",
                "i",
                "=",
                "a",
                "j",
                "i",
                "*",
                "p",
                "pos",
                "i",
                ",",
                "otherwiseãj",
                "i",
                "=",
                "−a",
                "j",
                "i",
                "*",
                "p",
                "neg",
                "i",
                ".For",
                "each",
                "token",
                "t",
                "in",
                "the",
                "vocabulary",
                "V,",
                "we",
                "compute",
                "the",
                "average",
                "attention",
                "score:āt",
                "=",
                "1",
                "mn",
                "•",
                "Σ",
                "n",
                "i=1",
                "Σ",
                "m",
                "j=1",
                "[ã",
                "j",
                "i",
                "•",
                "1(t",
                "j",
                "i",
                "=",
                "t)],where",
                "we",
                "aggregate",
                "the",
                "attention",
                "scores",
                "ãj",
                "i",
                "for",
                "token",
                "t,",
                "across",
                "all",
                "n",
                "sentences",
                "in",
                "the",
                "corpus.",
                "We",
                "then",
                "normalize",
                "the",
                "attention",
                "scores",
                "across",
                "the",
                "vocabulary",
                "to",
                "obtain",
                "the",
                "importance",
                "score",
                "for",
                "each",
                "token",
                "t:",
                "I",
                "t",
                "=",
                "āt",
                "/Σ",
                "t∈V",
                "āt",
                ".",
                "This",
                "can",
                "lead",
                "to",
                "very",
                "small",
                "I",
                "t",
                "for",
                "certain",
                "tokens,",
                "thus",
                "we",
                "take",
                "the",
                "log",
                "of",
                "all",
                "importance",
                "scores",
                "to",
                "avoid",
                "underflow,",
                "I",
                "′",
                "t",
                "=",
                "log(I",
                "t",
                ").",
                "So",
                "far,",
                "we",
                "have",
                "computed",
                "the",
                "importance",
                "score",
                "for",
                "each",
                "token.",
                "However,",
                "we",
                "observe",
                "that",
                "some",
                "tokens",
                "appearing",
                "only",
                "very",
                "a",
                "few",
                "times",
                "could",
                "accidentally",
                "have",
                "very",
                "high",
                "importance",
                "scores.",
                "Thus,",
                "we",
                "propose",
                "to",
                "penalize",
                "the",
                "tokens",
                "with",
                "low",
                "frequencies:Ît",
                "=",
                "I",
                "′",
                "t",
                "−",
                "λ/",
                "log(1",
                "+",
                "c",
                "t",
                "),",
                "where",
                "c",
                "t",
                "is",
                "the",
                "frequency",
                "of",
                "token",
                "t",
                "and",
                "λ",
                "is",
                "a",
                "temperature",
                "parameter",
                "to",
                "adjust",
                "the",
                "degree",
                "that",
                "we",
                "want",
                "to",
                "penalize",
                "over",
                "the",
                "frequency."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "of the [CLS] token and average them across different heads. If p pos i &gt, p neg i , we obtain the updated attention score ãj i = a j i * p pos i , otherwiseãj i = −a j i * p neg i .For each token t in the vocabulary V, we compute the average attention score:āt = 1 mn • Σ n i=1 Σ m j=1 [ã j i • 1(t j i = t)],where we aggregate the attention scores ãj i for token t, across all n sentences in the corpus. We then normalize the attention scores across the vocabulary to obtain the importance score for each token t: I t = āt /Σ t∈V āt . This can lead to very small I t for certain tokens, thus we take the log of all importance scores to avoid underflow, I ′ t = log(I t ). So far, we have computed the importance score for each token. However, we observe that some tokens appearing only very a few times could accidentally have very high importance scores. Thus, we propose to penalize the tokens with low frequencies:Ît = I ′ t − λ/ log(1 + c t ), where c t is the frequency of token t and λ is a temperature parameter to adjust the degree that we want to penalize over the frequency.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper",
                "we",
                "describe",
                "our",
                "Chinese-to-English",
                "simultaneous",
                "translation",
                "system,",
                "which",
                "uses",
                "a",
                "deep",
                "Transformer",
                "to",
                "improve",
                "translation",
                "quality",
                "and",
                "adopts",
                "wait-k",
                "policy",
                "#REF",
                "to",
                "reduce",
                "latency.",
                "Besides,",
                "for",
                "better",
                "domain",
                "adaption,",
                "we",
                "combined",
                "mixed",
                "fine-tuning",
                "#TARGET_REF",
                "with",
                "in-domain",
                "data",
                "filtering",
                "(Moore",
                "and",
                "Lewis,",
                "2010,",
                "#REF",
                "and",
                "proposed",
                "a",
                "new",
                "domain",
                "adaption",
                "method",
                "called",
                "\"in-domain",
                "mixed",
                "fine-tuning\",",
                "which",
                "is",
                "empirically",
                "more",
                "effective",
                "than",
                "fine-tuning",
                "and",
                "mixed",
                "fine-tuning."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this paper we describe our Chinese-to-English simultaneous translation system, which uses a deep Transformer to improve translation quality and adopts wait-k policy #REF to reduce latency. Besides, for better domain adaption, we combined mixed fine-tuning #TARGET_REF with in-domain data filtering (Moore and Lewis, 2010, #REF and proposed a new domain adaption method called \"in-domain mixed fine-tuning\", which is empirically more effective than fine-tuning and mixed fine-tuning.",
        "output": "{\"INFO\": [\"mixed fine-tuning #TARGET_REF\"], \"PERCEPT\": [\"In this paper we describe our Chinese-to-English simultaneous translation system, which uses a deep Transformer to improve translation quality and adopts wait-k policy #REF to reduce latency.\", \"for better domain adaption, we combined\", \"with in-domain data filtering (Moore and Lewis, 2010, #REF\"], \"BACK\": [\"and proposed a new domain adaption method called \\\"in-domain mixed fine-tuning\\\",\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "Figure",
                "4,",
                "we",
                "compare",
                "our",
                "dataset",
                "with",
                "other",
                "toxicity",
                "detection",
                "datasets",
                "using",
                "the",
                "metric",
                "of",
                "relative",
                "frequency",
                "of",
                "toxic",
                "utterances",
                "of",
                "each",
                "length.",
                "The",
                "datasets",
                "we",
                "compare",
                "with",
                "are",
                "1)",
                "Waseem",
                "#REF",
                "which",
                "consists",
                "of",
                "16.2k",
                "tweets",
                "binary",
                "classified",
                "as",
                "racism/sexism",
                "or",
                "other,",
                "2)",
                "FoxNews",
                "#TARGET_REF",
                "which",
                "is",
                "1.5k",
                "sentences",
                "from",
                "Fox",
                "News",
                "discussion",
                "threads",
                "classified",
                "as",
                "hateful/non-",
                "The",
                "distribution",
                "in",
                "CONDA",
                "is",
                "different",
                "to",
                "the",
                "other",
                "datasets",
                "in",
                "that",
                "the",
                "toxic",
                "utterances",
                "are",
                "shorter.",
                "This",
                "is",
                "due",
                "to",
                "the",
                "terseness",
                "of",
                "in-game",
                "chat",
                "during",
                "playing,",
                "with",
                "longer",
                "utterances",
                "occurring",
                "in",
                "pregame",
                "and",
                "post-game",
                "discussion.",
                "Waseem",
                "has",
                "a",
                "particular",
                "distribution",
                "due",
                "to",
                "the",
                "character",
                "limit",
                "in",
                "Twitter",
                "(140",
                "characters",
                "at",
                "the",
                "time).",
                "FoxNews",
                "and",
                "StormfrontWS",
                "are",
                "forums",
                "which",
                "foster",
                "the",
                "use",
                "of",
                "longer",
                "sentences."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In Figure 4, we compare our dataset with other toxicity detection datasets using the metric of relative frequency of toxic utterances of each length. The datasets we compare with are 1) Waseem #REF which consists of 16.2k tweets binary classified as racism/sexism or other, 2) FoxNews #TARGET_REF which is 1.5k sentences from Fox News discussion threads classified as hateful/non- The distribution in CONDA is different to the other datasets in that the toxic utterances are shorter. This is due to the terseness of in-game chat during playing, with longer utterances occurring in pregame and post-game discussion. Waseem has a particular distribution due to the character limit in Twitter (140 characters at the time). FoxNews and StormfrontWS are forums which foster the use of longer sentences.",
        "output": "{\"INFO\": [\"2) FoxNews #TARGET_REF which is 1.5k sentences from Fox News discussion threads classified as hateful/non-\"], \"PERCEPT\": [\"The datasets we compare with are\"], \"BACK\": [\"In Figure 4, we compare our dataset with other toxicity detection datasets using the metric of relative frequency of toxic utterances of each length.\", \"1) Waseem #REF which consists of 16.2k tweets binary classified as racism/sexism or other,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "general,",
                "for",
                "linguistic",
                "representation",
                "it",
                "is",
                "the",
                "derived",
                "tree",
                "that",
                "is",
                "used",
                "as",
                "the",
                "primary",
                "structure",
                "of",
                "representation,",
                "so",
                "the",
                "labels",
                "would",
                "represent",
                "words",
                "in",
                "a",
                "typical",
                "lexicalised",
                "grammar",
                "and",
                "the",
                "trees",
                "«",
                "½",
                ",",
                "«",
                "¾",
                "and",
                "¬",
                "½",
                "would",
                "represent",
                "argument",
                "structure",
                "of",
                "these",
                "words.",
                "However,",
                "we",
                "will",
                "use",
                "a",
                "TAG",
                "grammar",
                "as",
                "a",
                "way",
                "of",
                "characterising",
                "other",
                "sorts",
                "of",
                "trees,",
                "such",
                "as",
                "TAG",
                "derivation",
                "trees",
                "or",
                "dependency",
                "trees,",
                "this",
                "is",
                "thus",
                "in",
                "a",
                "sense",
                "an",
                "extension",
                "of",
                "the",
                "notion",
                "of",
                "the",
                "meta-level",
                "grammar",
                "of",
                "#TARGET_REF",
                ".",
                "The",
                "idea",
                "is",
                "then",
                "to",
                "use",
                "a",
                "TAG",
                "grammar",
                "to",
                "break",
                "down",
                "some",
                "tree",
                "representation-which",
                "may",
                "be",
                "a",
                "dependency",
                "tree,",
                "a",
                "TAG",
                "derivation",
                "tree,",
                "6",
                "or",
                "other-into",
                "component",
                "trees",
                "possibly",
                "representing",
                "non-contiguous",
                "groupings.",
                "The",
                "aim",
                "is",
                "not",
                "to",
                "describe",
                "every",
                "decomposition",
                "into",
                "non-contiguous",
                "groupings,",
                "only",
                "those",
                "such",
                "as",
                "the",
                "language-related",
                "cases",
                "presented",
                "in",
                "Section",
                "2,",
                "and",
                "the",
                "use",
                "of",
                "TAG",
                "as",
                "representation",
                "allows",
                "for",
                "the",
                "complexity",
                "results",
                "below.",
                "We",
                "now",
                "present",
                "an",
                "algorithm",
                "for",
                "the",
                "decomposition",
                "in",
                "Section",
                "4."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In general, for linguistic representation it is the derived tree that is used as the primary structure of representation, so the labels would represent words in a typical lexicalised grammar and the trees « ½ , « ¾ and ¬ ½ would represent argument structure of these words. However, we will use a TAG grammar as a way of characterising other sorts of trees, such as TAG derivation trees or dependency trees, this is thus in a sense an extension of the notion of the meta-level grammar of #TARGET_REF . The idea is then to use a TAG grammar to break down some tree representation-which may be a dependency tree, a TAG derivation tree, 6 or other-into component trees possibly representing non-contiguous groupings. The aim is not to describe every decomposition into non-contiguous groupings, only those such as the language-related cases presented in Section 2, and the use of TAG as representation allows for the complexity results below. We now present an algorithm for the decomposition in Section 4.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"we will use a TAG grammar as a way of characterising other sorts of trees, such as TAG derivation trees or dependency trees, this is thus in a sense an extension of the notion of the meta-level grammar of\", \"The idea is then to use a TAG grammar to break down some tree representation-which may be a dependency tree, a TAG derivation tree, 6 or other-into component trees possibly representing non-contiguous groupings. The aim is not to describe every decomposition into non-contiguous groupings, only those such as the language-related cases presented in Section 2, and the use of TAG as representation allows for the complexity results below.\"], \"BACK\": [\"for linguistic representation it is the derived tree that is used as the primary structure of representation, so the labels would represent words in a typical lexicalised grammar and the trees \\u00ab \\u00bd , \\u00ab \\u00be and \\u00ac \\u00bd would represent argument structure of these words.\"]}"
    },
    {
        "gold": {
            "text": [
                "Finally,",
                "to",
                "test",
                "whether",
                "the",
                "MT",
                "engine",
                "was",
                "better",
                "prepared",
                "to",
                "address",
                "Text",
                "A",
                "or",
                "Text",
                "B,",
                "we",
                "calculated",
                "perplexity",
                "and",
                "out-of-vocabulary",
                "(OOV)",
                "words.",
                "Perplexity",
                "is",
                "used",
                "as",
                "a",
                "mea-surement",
                "of",
                "how",
                "well",
                "the",
                "language",
                "model",
                "predicts",
                "the",
                "reference",
                "translations.",
                "The",
                "smaller",
                "the",
                "perplexity,",
                "the",
                "more",
                "and",
                "longer",
                "overlap",
                "exists",
                "between",
                "the",
                "reference",
                "and",
                "the",
                "language",
                "model",
                "in",
                "the",
                "MT",
                "system.",
                "This",
                "measurement",
                "shows",
                "that",
                "the",
                "MT",
                "engine",
                "is",
                "better",
                "suited",
                "to",
                "output",
                "a",
                "correct",
                "version",
                "for",
                "Text",
                "A",
                "than",
                "for",
                "Text",
                "B",
                "(see",
                "Table",
                "10).",
                "Note",
                "that",
                "the",
                "high",
                "perplexity",
                "values,",
                "calculated",
                "per",
                "word,",
                "are",
                "in",
                "line",
                "with",
                "those",
                "reported",
                "for",
                "morphologically",
                "rich",
                "languages",
                "(see",
                "#TARGET_REF",
                ".",
                "Table",
                "10.",
                "Perplexity",
                "calculated",
                "on",
                "5-grams."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Finally, to test whether the MT engine was better prepared to address Text A or Text B, we calculated perplexity and out-of-vocabulary (OOV) words. Perplexity is used as a mea-surement of how well the language model predicts the reference translations. The smaller the perplexity, the more and longer overlap exists between the reference and the language model in the MT system. This measurement shows that the MT engine is better suited to output a correct version for Text A than for Text B (see Table 10). Note that the high perplexity values, calculated per word, are in line with those reported for morphologically rich languages (see #TARGET_REF . Table 10. Perplexity calculated on 5-grams.",
        "output": "{\"INFO\": [\"the high perplexity values, calculated per word, are in line with those reported for morphologically rich languages\"], \"PERCEPT\": [], \"BACK\": [\"(see #TARGET_REF . Table 10. Perplexity calculated on 5-grams.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "linear",
                "SVM,",
                "we",
                "used",
                "an",
                "online",
                "learning",
                "implementation",
                "of",
                "SCIKIT-LEARN",
                "#REF",
                ",",
                "based",
                "on",
                "LIBSVM",
                "#TARGET_REF",
                ",",
                "with",
                "hinge",
                "loss",
                "and",
                "Stochastic",
                "Gradient",
                "Descent",
                "(SGD)",
                "optimiser.",
                "Hyperparameters",
                "were",
                "set",
                "to",
                "default",
                "except",
                "for",
                "the",
                "SGD",
                "regularisation",
                "parameter",
                "that",
                "was",
                "increased",
                "to",
                "α",
                "=",
                "0.75,",
                "which",
                "provided",
                "better",
                "classification",
                "accuracy",
                "on",
                "the",
                "dev",
                "set.",
                "The",
                "parameter",
                "α",
                "is",
                "inversely",
                "proportional",
                "to",
                "the",
                "C",
                "parameter",
                "in",
                "the",
                "standard",
                "SVM",
                "implementation.",
                "The",
                "online",
                "implementation",
                "also",
                "allowed",
                "us",
                "to",
                "select",
                "the",
                "best",
                "model",
                "using",
                "early",
                "stopping.",
                "The",
                "SVM",
                "was",
                "provided",
                "with",
                "EEG",
                "activity",
                "vectors",
                "as",
                "inputs,",
                "i.e.",
                "1",
                "x",
                "(EEG",
                "channels",
                "×",
                "time",
                "points)."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For linear SVM, we used an online learning implementation of SCIKIT-LEARN #REF , based on LIBSVM #TARGET_REF , with hinge loss and Stochastic Gradient Descent (SGD) optimiser. Hyperparameters were set to default except for the SGD regularisation parameter that was increased to α = 0.75, which provided better classification accuracy on the dev set. The parameter α is inversely proportional to the C parameter in the standard SVM implementation. The online implementation also allowed us to select the best model using early stopping. The SVM was provided with EEG activity vectors as inputs, i.e. 1 x (EEG channels × time points).",
        "output": "{\"INFO\": [\"LIBSVM #TARGET_REF , with hinge loss and Stochastic Gradient Descent (SGD) optimiser.\"], \"PERCEPT\": [\"For linear SVM, we used an online learning implementation of SCIKIT-LEARN #REF , based on\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "avoid",
                "the",
                "use",
                "of",
                "additional",
                "data",
                "structures,",
                "such",
                "as",
                "finite",
                "automata",
                "or",
                "precomputed",
                "relations,",
                "we",
                "have",
                "been",
                "inspired",
                "by",
                "the",
                "use",
                "of",
                "context-free",
                "grammars",
                "to",
                "represent",
                "the",
                "parse",
                "forest",
                "of",
                "tree",
                "adjoining",
                "grammars",
                "#TARGET_REF",
                "in",
                "order",
                "to",
                "capture",
                "the",
                "context-freeness",
                "of",
                "production",
                "application",
                "in",
                "the",
                "case",
                "of",
                "LIG."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "To avoid the use of additional data structures, such as finite automata or precomputed relations, we have been inspired by the use of context-free grammars to represent the parse forest of tree adjoining grammars #TARGET_REF in order to capture the context-freeness of production application in the case of LIG.",
        "output": "{\"INFO\": [\"to represent the parse forest of tree adjoining grammars #TARGET_REF\"], \"PERCEPT\": [\"we have been inspired by the use of context-free grammars\", \"in order to capture the context-freeness of production application in the case of LIG.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "achieve",
                "this",
                "goal,",
                "we",
                "investigate",
                "whether",
                "due",
                "to",
                "the",
                "similarity",
                "between",
                "idioms",
                "and",
                "rare-words",
                "Schick",
                "and",
                "Schütze's",
                "BERT",
                "for",
                "Attentive",
                "Mimicking",
                "#TARGET_REF",
                ")",
                "(BERTRAM)",
                "model,",
                "which",
                "was",
                "designed",
                "for",
                "use",
                "with",
                "rare-words,",
                "can",
                "be",
                "used",
                "to",
                "explicitly",
                "learn",
                "high-quality",
                "embeddings",
                "for",
                "idiomatic",
                "expressions.",
                "We",
                "also",
                "investigate",
                "how",
                "many",
                "examples",
                "of",
                "each",
                "idiom",
                "are",
                "required",
                "to",
                "create",
                "embeddings",
                "that",
                "perform",
                "well",
                "on",
                "the",
                "task,",
                "as",
                "well",
                "as",
                "how",
                "the",
                "quality",
                "of",
                "contexts",
                "fed",
                "to",
                "the",
                "BERTRAM",
                "model",
                "effects",
                "the",
                "representations",
                "and",
                "performance",
                "on",
                "the",
                "task."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To achieve this goal, we investigate whether due to the similarity between idioms and rare-words Schick and Schütze's BERT for Attentive Mimicking #TARGET_REF ) (BERTRAM) model, which was designed for use with rare-words, can be used to explicitly learn high-quality embeddings for idiomatic expressions. We also investigate how many examples of each idiom are required to create embeddings that perform well on the task, as well as how the quality of contexts fed to the BERTRAM model effects the representations and performance on the task.",
        "output": "{\"INFO\": [\"for Attentive Mimicking #TARGET_REF ) (BERTRAM) model, which was designed for use with rare-words, can be used to explicitly learn high-quality embeddings for idiomatic expressions.\"], \"PERCEPT\": [\"To achieve this goal, we investigate whether due to the similarity between idioms and rare-words Schick and Sch\\u00fctze's BERT\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "recent",
                "years",
                "there",
                "has",
                "been",
                "some",
                "revival",
                "of",
                "interest",
                "in",
                "computational",
                "lexicography",
                "that",
                "has",
                "fulfilled",
                "some",
                "of",
                "MMB's",
                "hopes",
                "and",
                "dreams.",
                "It",
                "has",
                "been",
                "driven",
                "to",
                "some",
                "extent",
                "by",
                "the",
                "availability",
                "from",
                "publishers",
                "of",
                "machine-readable",
                "English",
                "dictionaries,",
                "such",
                "as",
                "Longman's",
                "dictionary",
                "of",
                "contemporary",
                "English",
                "(LDOCE)",
                "and",
                "Collins-Birmingham",
                "University",
                "International",
                "Language",
                "Database",
                "(COBUILD),",
                "with",
                "definitions",
                "written",
                "in",
                "a",
                "semi-formal",
                "way.",
                "This",
                "makes",
                "it",
                "much",
                "easier",
                "for",
                "a",
                "computational",
                "parser",
                "to",
                "extract",
                "information",
                "from",
                "them.",
                "But",
                "the",
                "initial",
                "work",
                "in",
                "the",
                "current",
                "wave",
                "was",
                "done",
                "by",
                "#TARGET_REF",
                "at",
                "Texas",
                "using",
                "Webster's,",
                "an",
                "oldfashioned",
                "dinosaur",
                "of",
                "a",
                "dictionary.",
                "He",
                "developed",
                "a",
                "notion",
                "of",
                "'tangled",
                "hierarchies'",
                "which",
                "captures",
                "the",
                "notion",
                "MMB",
                "promoted",
                "so",
                "as",
                "to",
                "get",
                "away",
                "from",
                "straightforward",
                "tree-like",
                "hierarchies."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In recent years there has been some revival of interest in computational lexicography that has fulfilled some of MMB's hopes and dreams. It has been driven to some extent by the availability from publishers of machine-readable English dictionaries, such as Longman's dictionary of contemporary English (LDOCE) and Collins-Birmingham University International Language Database (COBUILD), with definitions written in a semi-formal way. This makes it much easier for a computational parser to extract information from them. But the initial work in the current wave was done by #TARGET_REF at Texas using Webster's, an oldfashioned dinosaur of a dictionary. He developed a notion of 'tangled hierarchies' which captures the notion MMB promoted so as to get away from straightforward tree-like hierarchies.",
        "output": "{\"INFO\": [\"at Texas using Webster's, an oldfashioned dinosaur of a dictionary. He developed a notion of 'tangled hierarchies' which captures the notion MMB promoted so as to get away from straightforward tree-like hierarchies.\"], \"PERCEPT\": [\"the initial work in the current wave was done by\"], \"BACK\": [\"In recent years there has been some revival of interest in computational lexicography that has fulfilled some of MMB's hopes and dreams.\"]}"
    },
    {
        "gold": {
            "text": [
                "ChrF",
                "#TARGET_REF",
                "a",
                "character",
                "n-gram",
                "precision",
                "and",
                "recall",
                "enhanced",
                "with",
                "word",
                "n-grams.",
                "Since",
                "answers",
                "are",
                "largely",
                "made",
                "up",
                "of",
                "entities,",
                "ChrF",
                "score",
                "integration",
                "is",
                "only",
                "performed",
                "when",
                "the",
                "answer",
                "span",
                "is",
                "not",
                "present",
                "in",
                "the",
                "related",
                "context.",
                "In",
                "order",
                "to",
                "evaluate",
                "the",
                "quality",
                "of",
                "the",
                "translation,",
                "we",
                "manually",
                "corrected",
                "the",
                "translation",
                "errors",
                "in",
                "the",
                "output",
                "of",
                "a",
                "subset",
                "of",
                "the",
                "corpus",
                "composed",
                "of",
                "890",
                "QA",
                "pairs",
                "and",
                "107",
                "contexts.",
                "We",
                "obtain",
                "a",
                "BLEU",
                "score",
                "#REF",
                "We",
                "also",
                "explore",
                "mixed",
                "datasets",
                "training",
                "strategy",
                "with",
                "SQuAD-en",
                "train",
                "+",
                "FQuAD",
                "train",
                "for",
                "training",
                "models",
                "on",
                "a",
                "concatenation",
                "of",
                "the",
                "training",
                "data",
                "covering",
                "French-English",
                "language",
                "pairs",
                "to",
                "test",
                "the",
                "crosslingual",
                "transfer",
                "ability",
                "of",
                "multilingual",
                "models."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "ChrF #TARGET_REF a character n-gram precision and recall enhanced with word n-grams. Since answers are largely made up of entities, ChrF score integration is only performed when the answer span is not present in the related context. In order to evaluate the quality of the translation, we manually corrected the translation errors in the output of a subset of the corpus composed of 890 QA pairs and 107 contexts. We obtain a BLEU score #REF We also explore mixed datasets training strategy with SQuAD-en train + FQuAD train for training models on a concatenation of the training data covering French-English language pairs to test the crosslingual transfer ability of multilingual models.",
        "output": "{\"INFO\": [\"ChrF #TARGET_REF a character n-gram precision and recall enhanced with word n-grams.\"], \"PERCEPT\": [], \"BACK\": [\"ChrF score integration is only performed when the answer span is not present in the related context.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "fact,",
                "deploying",
                "ever-larger",
                "models",
                "raises",
                "questions",
                "and",
                "concerns",
                "about",
                "the",
                "increasing",
                "magnitude",
                "of",
                "the",
                "temporal,",
                "financial,",
                "and",
                "environmental",
                "cost",
                "of",
                "training",
                "and",
                "usability",
                "#REF",
                ".",
                "Typically,",
                "due",
                "to",
                "their",
                "resource",
                "requirements,",
                "these",
                "models",
                "are",
                "trained",
                "and",
                "deployed",
                "for",
                "industrial",
                "operations",
                "on",
                "remote",
                "servers.",
                "This",
                "leads",
                "to",
                "a",
                "high",
                "use",
                "of",
                "over-the-air",
                "communications,",
                "which",
                "are",
                "particularly",
                "resourceintensive",
                "#TARGET_REF",
                ".",
                "In",
                "particular,",
                "some",
                "NLP",
                "applications",
                "(speech",
                "recognition,",
                "speech",
                "to",
                "text,",
                "etc.)",
                "have",
                "some",
                "known",
                "problems",
                "related",
                "to",
                "network",
                "latency,",
                "transmission",
                "path",
                "difficulties,",
                "or",
                "privacy",
                "concerns.",
                "To",
                "reduce",
                "the",
                "impact",
                "of",
                "these",
                "communications,",
                "there",
                "is",
                "a",
                "solution",
                "that",
                "is",
                "to",
                "allow",
                "these",
                "models",
                "to",
                "run",
                "directly",
                "on",
                "peripheral",
                "or",
                "mobile",
                "devices,",
                "that",
                "is,",
                "in",
                "environments",
                "with",
                "limited",
                "resources",
                "that",
                "require",
                "lightweight,",
                "responsive",
                "models",
                "and",
                "energy",
                "efficiency.",
                "Reducing",
                "the",
                "size",
                "of",
                "the",
                "models",
                "is",
                "therefore",
                "one",
                "of",
                "the",
                "increasingly",
                "favoured",
                "avenues,",
                "especially",
                "for",
                "the",
                "reduction",
                "of",
                "memory",
                "resources",
                "and",
                "computation",
                "time",
                "involved",
                "in",
                "training",
                "and",
                "use."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In fact, deploying ever-larger models raises questions and concerns about the increasing magnitude of the temporal, financial, and environmental cost of training and usability #REF . Typically, due to their resource requirements, these models are trained and deployed for industrial operations on remote servers. This leads to a high use of over-the-air communications, which are particularly resourceintensive #TARGET_REF . In particular, some NLP applications (speech recognition, speech to text, etc.) have some known problems related to network latency, transmission path difficulties, or privacy concerns. To reduce the impact of these communications, there is a solution that is to allow these models to run directly on peripheral or mobile devices, that is, in environments with limited resources that require lightweight, responsive models and energy efficiency. Reducing the size of the models is therefore one of the increasingly favoured avenues, especially for the reduction of memory resources and computation time involved in training and use.",
        "output": "{\"INFO\": [\"This leads to a high use of over-the-air communications, which are particularly resourceintensive #TARGET_REF .\"], \"PERCEPT\": [\"Typically, due to their resource requirements, these models are trained and deployed for industrial operations on remote servers.\"], \"BACK\": [\"In particular, some NLP applications\", \"have some known problems related to network latency, transmission path difficulties, or privacy concerns.\"]}"
    },
    {
        "gold": {
            "text": [
                "Improving",
                "content",
                "diversity",
                "in",
                "NLG.",
                "Most",
                "of",
                "the",
                "existing",
                "diversity-promoting",
                "work",
                "has",
                "focused",
                "on",
                "improving",
                "syntactic",
                "and",
                "lexical",
                "diversity,",
                "such",
                "as",
                "different",
                "language",
                "style",
                "in",
                "machine",
                "translation",
                "#TARGET_REF",
                "and",
                "word",
                "variability",
                "in",
                "paraphrase",
                "generation",
                "#REF",
                ".",
                "Nevertheless,",
                "methods",
                "for",
                "improving",
                "content",
                "diversity",
                "in",
                "NLG",
                "systems",
                "have",
                "been",
                "rarely",
                "studied",
                "in",
                "the",
                "existing",
                "literature.",
                "We",
                "believe",
                "that",
                "generating",
                "diverse",
                "content",
                "is",
                "one",
                "of",
                "the",
                "most",
                "promising",
                "aspects",
                "of",
                "machine",
                "intelligence,",
                "which",
                "can",
                "be",
                "applied",
                "to",
                "a",
                "wide",
                "range",
                "of",
                "real-world",
                "applications,",
                "not",
                "only",
                "limited",
                "to",
                "commonsense",
                "reasoning."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Improving content diversity in NLG. Most of the existing diversity-promoting work has focused on improving syntactic and lexical diversity, such as different language style in machine translation #TARGET_REF and word variability in paraphrase generation #REF . Nevertheless, methods for improving content diversity in NLG systems have been rarely studied in the existing literature. We believe that generating diverse content is one of the most promising aspects of machine intelligence, which can be applied to a wide range of real-world applications, not only limited to commonsense reasoning.",
        "output": "{\"INFO\": [\"different language style in machine translation #TARGET_REF\"], \"PERCEPT\": [\"Most of the existing diversity-promoting work has focused on improving syntactic and lexical diversity, such as\"], \"BACK\": [\"and word variability in paraphrase generation #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "original",
                "paper",
                "introducing",
                "BERTScore",
                "#TARGET_REF",
                "naturally",
                "compared",
                "BERTScore's",
                "correlations",
                "with",
                "human",
                "judgments",
                "to",
                "that",
                "of",
                "other",
                "metrics.",
                "However,",
                "various",
                "other",
                "surveys",
                "of",
                "MT",
                "metrics,",
                "as",
                "well",
                "as",
                "datasets",
                "and",
                "methodologies",
                "have",
                "been",
                "conducted,",
                "offering",
                "insights",
                "into",
                "how",
                "MT",
                "system",
                "and",
                "metric",
                "performance",
                "should",
                "be",
                "measured."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The original paper introducing BERTScore #TARGET_REF naturally compared BERTScore's correlations with human judgments to that of other metrics. However, various other surveys of MT metrics, as well as datasets and methodologies have been conducted, offering insights into how MT system and metric performance should be measured.",
        "output": "{\"INFO\": [\"The original paper introducing BERTScore #TARGET_REF naturally compared BERTScore's correlations with human judgments to that of other metrics.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "complexity,",
                "robustness",
                "to",
                "atypical",
                "input,",
                "utilization",
                "of",
                "off-the-shelf",
                "language",
                "models,",
                "conceptual",
                "simplicity)",
                "while",
                "also",
                "having",
                "a",
                "degree",
                "of",
                "compositionality,",
                "traditionally",
                "a",
                "property",
                "of",
                "grammar-based",
                "systems.",
                "Specifically,",
                "our",
                "system",
                "learns",
                "to",
                "assign",
                "each",
                "token",
                "of",
                "an",
                "utterance",
                "one",
                "of",
                "a",
                "finite",
                "set",
                "of",
                "abstract",
                "meaning",
                "fragments",
                "that",
                "are",
                "deterministically",
                "combined",
                "to",
                "give",
                "the",
                "meaning",
                "of",
                "the",
                "whole",
                "utterance.",
                "While",
                "our",
                "system",
                "may",
                "not",
                "fulfill",
                "all",
                "criteria",
                "of",
                "compositionality",
                "according",
                "to",
                "some",
                "definitions,",
                "it",
                "can",
                "arguably",
                "reap",
                "some",
                "of",
                "compositionality's",
                "benefits,",
                "which",
                "make",
                "it",
                "suitable",
                "for",
                "use",
                "in",
                "semi-automatic",
                "annotation",
                "workflows.",
                "We",
                "discuss",
                "this",
                "further",
                "in",
                "Section",
                "5.",
                "Previous",
                "work",
                "has",
                "introduced",
                "trainable",
                "compositional",
                "semantic",
                "parsers",
                "for",
                "AMR",
                "#TARGET_REF",
                "and",
                "DRS",
                "#REF",
                ".",
                "In",
                "this",
                "paper,",
                "we",
                "improve",
                "upon",
                "the",
                "latter",
                "parser",
                "using",
                "a",
                "novel",
                "way",
                "to",
                "encode",
                "anchored",
                "DRSs",
                "as",
                "sequences,",
                "and",
                "thereby",
                "cast",
                "DRS",
                "parsing",
                "simply",
                "as",
                "a",
                "sequence",
                "labeling",
                "task",
                "(",
                "§2).",
                "We",
                "use",
                "a",
                "standard",
                "transformer-based",
                "model",
                "to",
                "learn",
                "this",
                "task,",
                "followed",
                "by",
                "post-processing",
                "to",
                "ensure",
                "well-formed",
                "DRSs",
                "(",
                "§3).",
                "We",
                "use",
                "training",
                "data",
                "from",
                "the",
                "Parallel",
                "Meaning",
                "Bank",
                "(",
                "§4).",
                "The",
                "accuracy",
                "of",
                "our",
                "model",
                "approaches",
                "the",
                "state",
                "of",
                "the",
                "art",
                "with",
                "the",
                "additional",
                "benefit",
                "of",
                "being,",
                "to",
                "a",
                "degree,",
                "compositional",
                "(",
                "§5).",
                "We",
                "give",
                "an",
                "error",
                "analysis",
                "in",
                "§6",
                "and",
                "conclude",
                "in",
                "§7."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "complexity, robustness to atypical input, utilization of off-the-shelf language models, conceptual simplicity) while also having a degree of compositionality, traditionally a property of grammar-based systems. Specifically, our system learns to assign each token of an utterance one of a finite set of abstract meaning fragments that are deterministically combined to give the meaning of the whole utterance. While our system may not fulfill all criteria of compositionality according to some definitions, it can arguably reap some of compositionality's benefits, which make it suitable for use in semi-automatic annotation workflows. We discuss this further in Section 5. Previous work has introduced trainable compositional semantic parsers for AMR #TARGET_REF and DRS #REF . In this paper, we improve upon the latter parser using a novel way to encode anchored DRSs as sequences, and thereby cast DRS parsing simply as a sequence labeling task ( §2). We use a standard transformer-based model to learn this task, followed by post-processing to ensure well-formed DRSs ( §3). We use training data from the Parallel Meaning Bank ( §4). The accuracy of our model approaches the state of the art with the additional benefit of being, to a degree, compositional ( §5). We give an error analysis in §6 and conclude in §7.",
        "output": "{\"INFO\": [\"for AMR #TARGET_REF\"], \"PERCEPT\": [\"While our system may not fulfill all criteria of compositionality according to some definitions, it can arguably reap some of compositionality's benefits, which make it suitable for use in semi-automatic annotation workflows.\"], \"BACK\": [\"Previous work has introduced trainable compositional semantic parsers\", \"and DRS #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Natural",
                "Question",
                "(NQ)",
                "Kwiatkowski",
                "et",
                "al.",
                "(2019)",
                "introduces",
                "a",
                "large",
                "dataset",
                "for",
                "open-domain",
                "QA.",
                "The",
                "original",
                "dataset",
                "contains",
                "more",
                "than",
                "300,",
                "000",
                "questions",
                "collected",
                "from",
                "Google",
                "search",
                "logs.",
                "In",
                "#TARGET_REF",
                ",",
                "around",
                "62,",
                "000",
                "factoid",
                "questions",
                "are",
                "selected,",
                "and",
                "all",
                "the",
                "Wikipedia",
                "articles",
                "are",
                "processed",
                "as",
                "the",
                "collection",
                "of",
                "passages.",
                "There",
                "are",
                "more",
                "than",
                "21",
                "million",
                "passages",
                "in",
                "the",
                "corpus.",
                "In",
                "our",
                "experiments,",
                "we",
                "reuse",
                "the",
                "version",
                "of",
                "NQ",
                "created",
                "by",
                "#REF",
                ".",
                "Note",
                "that",
                "the",
                "dataset",
                "used",
                "in",
                "DPR",
                "contains",
                "empty",
                "negatives,",
                "and",
                "we",
                "discarded",
                "the",
                "empty",
                "ones."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Natural Question (NQ) Kwiatkowski et al. (2019) introduces a large dataset for open-domain QA. The original dataset contains more than 300, 000 questions collected from Google search logs. In #TARGET_REF , around 62, 000 factoid questions are selected, and all the Wikipedia articles are processed as the collection of passages. There are more than 21 million passages in the corpus. In our experiments, we reuse the version of NQ created by #REF . Note that the dataset used in DPR contains empty negatives, and we discarded the empty ones.",
        "output": "{\"INFO\": [\"around 62, 000 factoid questions are selected, and all the Wikipedia articles are processed as the collection of passages. There are more than 21 million passages in the corpus.\"], \"PERCEPT\": [\"In #TARGET_REF ,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "then",
                "use",
                "the",
                "highway",
                "network",
                "#REF",
                "on",
                "the",
                "combined",
                "hidden",
                "state",
                "vector",
                "h.",
                "This",
                "network",
                "adaptively",
                "\"carries\"",
                "some",
                "dimensions",
                "of",
                "h",
                "to",
                "the",
                "output",
                "for",
                "predicting",
                "the",
                "correct",
                "label",
                "sequence.",
                "Therefore,",
                "the",
                "hidden",
                "states",
                "undergo",
                "the",
                "following",
                "transformation",
                "#TARGET_REF",
                ":h",
                "i",
                "=",
                "ρ(h",
                "i",
                ")",
                "g(W",
                "H",
                "•",
                "hi",
                "+b",
                "H",
                ")+(1−ρ(h))",
                "hi",
                "(9)The",
                "function",
                "ρ(h",
                "w",
                ")",
                "=",
                "σ(W",
                "ρ",
                "•",
                "h",
                "i",
                "+",
                "b",
                "ρ",
                "),",
                "which",
                "is",
                "a",
                "simple",
                "activation",
                "function.",
                "g",
                "is",
                "any",
                "non-linear",
                "function,",
                "such",
                "as",
                "sigmoid",
                "or",
                "hyperbolic",
                "tangent.",
                "Following",
                "the",
                "highway",
                "network's",
                "output,",
                "we",
                "pass",
                "the",
                "hidden",
                "embeddings",
                "to",
                "a",
                "dropout",
                "layer,",
                "which",
                "effectively",
                "reduces",
                "the",
                "number",
                "of",
                "hidden",
                "units",
                "by",
                "a",
                "fraction",
                "d,",
                "so",
                "h",
                "drop",
                "∈",
                "R",
                "k/d×l",
                ",",
                "and",
                "a",
                "linear",
                "layer,",
                "which",
                "maps",
                "the",
                "h",
                "drop",
                "to",
                "a",
                "smaller",
                "embedding",
                "space.",
                "We",
                "label",
                "this",
                "space",
                "h",
                "∈",
                "R",
                "k/d×f",
                "(f",
                "being",
                "the",
                "dimensions",
                "of",
                "the",
                "feature",
                "space)",
                "for",
                "brevity."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We then use the highway network #REF on the combined hidden state vector h. This network adaptively \"carries\" some dimensions of h to the output for predicting the correct label sequence. Therefore, the hidden states undergo the following transformation #TARGET_REF :h i = ρ(h i ) g(W H • hi +b H )+(1−ρ(h)) hi (9)The function ρ(h w ) = σ(W ρ • h i + b ρ ), which is a simple activation function. g is any non-linear function, such as sigmoid or hyperbolic tangent. Following the highway network's output, we pass the hidden embeddings to a dropout layer, which effectively reduces the number of hidden units by a fraction d, so h drop ∈ R k/d×l , and a linear layer, which maps the h drop to a smaller embedding space. We label this space h ∈ R k/d×f (f being the dimensions of the feature space) for brevity.",
        "output": "{\"INFO\": [\"transformation #TARGET_REF\"], \"PERCEPT\": [\"Therefore, the hidden states undergo the following\"], \"BACK\": [\"This network adaptively \\\"carries\\\" some dimensions of h to the output for predicting the correct label sequence.\", \":h i = \\u03c1(h i ) g(W H \\u2022 hi +b H )+(1\\u2212\\u03c1(h)) hi (9)The function \\u03c1(h w ) = \\u03c3(W \\u03c1 \\u2022 h i + b \\u03c1 ), which is a simple activation function. g is any non-linear function, such as sigmoid or hyperbolic tangent.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "standard",
                "and",
                "probably",
                "the",
                "most",
                "common",
                "method",
                "to",
                "calculate",
                "word",
                "relatedness",
                "from",
                "co-occurrences",
                "is",
                "computing",
                "the",
                "pointwise",
                "mutual",
                "information",
                "(PMI)",
                "of",
                "two",
                "words.",
                "However,",
                "PMI",
                "has",
                "wellknown",
                "shortcomings,",
                "such",
                "as",
                "overvaluing",
                "the",
                "relatedness",
                "of",
                "rare",
                "words,",
                "and",
                "lacking",
                "a",
                "fixed",
                "upper",
                "and",
                "lower",
                "bound.",
                "#TARGET_REF",
                "introduced",
                "normalized",
                "PMI",
                "as",
                "PMI",
                "norm",
                "(x,",
                "y)",
                "=",
                "ln",
                "p(x,",
                "y)",
                "p(x)p(y)",
                "−",
                "ln",
                "p(x,",
                "y),"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "A standard and probably the most common method to calculate word relatedness from co-occurrences is computing the pointwise mutual information (PMI) of two words. However, PMI has wellknown shortcomings, such as overvaluing the relatedness of rare words, and lacking a fixed upper and lower bound. #TARGET_REF introduced normalized PMI as PMI norm (x, y) = ln p(x, y) p(x)p(y) − ln p(x, y),",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"A standard and probably the most common method to calculate word relatedness from co-occurrences is computing the pointwise mutual information (PMI) of two words.\", \"PMI has wellknown shortcomings,\"], \"BACK\": [\"such as overvaluing the relatedness of rare words, and lacking a fixed upper and lower bound. #TARGET_REF introduced normalized PMI as PMI norm (x, y) = ln p(x, y) p(x)p(y) \\u2212 ln p(x, y),\"]}"
    },
    {
        "gold": {
            "text": [
                "Previous",
                "studies",
                "on",
                "symbol-description",
                "extraction",
                "rely",
                "on",
                "pattern",
                "matching",
                "#TARGET_REF",
                "and",
                "rule-based",
                "algorithms",
                "#REF",
                ".",
                "These",
                "methods",
                "might",
                "work",
                "for",
                "observed",
                "patterns",
                "with",
                "an",
                "assumption",
                "of",
                "close",
                "proximity",
                "between",
                "symbol",
                "and",
                "description.",
                "They",
                "may",
                "fail",
                "to",
                "capture",
                "distant",
                "symboldescription",
                "pairs",
                "and",
                "symbols",
                "in",
                "very",
                "complex",
                "structures",
                "such",
                "as",
                "algorithms",
                "in",
                "computer",
                "science",
                "literature."
            ],
            "context": [
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Previous studies on symbol-description extraction rely on pattern matching #TARGET_REF and rule-based algorithms #REF . These methods might work for observed patterns with an assumption of close proximity between symbol and description. They may fail to capture distant symboldescription pairs and symbols in very complex structures such as algorithms in computer science literature.",
        "output": "{\"INFO\": [\"symbol-description extraction rely on pattern matching #TARGET_REF\"], \"PERCEPT\": [\"These methods might work for observed patterns with an assumption of close proximity between symbol and description. They may fail to capture distant symboldescription pairs and symbols in very complex structures such as algorithms in computer science literature.\"], \"BACK\": [\"Previous studies on\", \"and rule-based algorithms #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "challenge",
                "aims",
                "at",
                "identifying",
                "the",
                "reliability",
                "of",
                "information",
                "shared",
                "on",
                "social",
                "network",
                "sites",
                "(SNSs).",
                "With",
                "the",
                "blazing-fast",
                "spurt",
                "of",
                "SNSs",
                "(e.g.",
                "Facebook,",
                "Zalo",
                "and",
                "Lotus),",
                "there",
                "are",
                "approximately",
                "65",
                "million",
                "Vietnamese",
                "users",
                "on",
                "board",
                "with",
                "the",
                "annual",
                "growth",
                "of",
                "2.7",
                "million",
                "in",
                "the",
                "recent",
                "year,",
                "as",
                "reported",
                "by",
                "the",
                "Digital",
                "2020",
                "1",
                ".",
                "SNSs",
                "have",
                "become",
                "widely",
                "accessible",
                "for",
                "users",
                "to",
                "not",
                "only",
                "connect",
                "friends",
                "but",
                "also",
                "freely",
                "create",
                "and",
                "share",
                "diverse",
                "content",
                "#REF",
                ".",
                "A",
                "number",
                "of",
                "users,",
                "1",
                "https://wearesocial.com/digital-2020",
                "however,",
                "has",
                "exploited",
                "these",
                "social",
                "platforms",
                "to",
                "distribute",
                "fake",
                "news",
                "and",
                "unreliable",
                "information",
                "to",
                "fulfill",
                "their",
                "personal",
                "or",
                "political",
                "purposes",
                "(e.g.",
                "US",
                "election",
                "2016",
                "#REF",
                ").",
                "It",
                "is",
                "not",
                "easy",
                "for",
                "other",
                "ordinary",
                "users",
                "to",
                "realize",
                "the",
                "unreliability,",
                "hence,",
                "they",
                "keep",
                "spreading",
                "the",
                "fake",
                "content",
                "to",
                "their",
                "friends.",
                "The",
                "problem",
                "becomes",
                "more",
                "seriously",
                "once",
                "the",
                "unreliable",
                "post",
                "becomes",
                "popular",
                "and",
                "gains",
                "belief",
                "among",
                "the",
                "community.",
                "Therefore,",
                "it",
                "raises",
                "an",
                "urgent",
                "need",
                "for",
                "detecting",
                "whether",
                "a",
                "piece",
                "of",
                "news",
                "on",
                "SNSs",
                "is",
                "reliable",
                "or",
                "not.",
                "This",
                "task",
                "has",
                "gained",
                "significant",
                "attention",
                "recently",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "This challenge aims at identifying the reliability of information shared on social network sites (SNSs). With the blazing-fast spurt of SNSs (e.g. Facebook, Zalo and Lotus), there are approximately 65 million Vietnamese users on board with the annual growth of 2.7 million in the recent year, as reported by the Digital 2020 1 . SNSs have become widely accessible for users to not only connect friends but also freely create and share diverse content #REF . A number of users, 1 https://wearesocial.com/digital-2020 however, has exploited these social platforms to distribute fake news and unreliable information to fulfill their personal or political purposes (e.g. US election 2016 #REF ). It is not easy for other ordinary users to realize the unreliability, hence, they keep spreading the fake content to their friends. The problem becomes more seriously once the unreliable post becomes popular and gains belief among the community. Therefore, it raises an urgent need for detecting whether a piece of news on SNSs is reliable or not. This task has gained significant attention recently #TARGET_REF .",
        "output": "{\"INFO\": [\"detecting whether a piece of news on SNSs is reliable or not.\"], \"PERCEPT\": [\"Therefore, it raises an urgent need for\", \"This task has gained significant attention recently #TARGET_REF .\"], \"BACK\": [\"It is not easy for other ordinary users to realize the unreliability,\"]}"
    },
    {
        "gold": {
            "text": [
                "Language",
                "Models:",
                "We",
                "experimented",
                "with",
                "BERTbase",
                "#REF",
                "and",
                "with",
                "the",
                "domainspecific",
                "Transformers,",
                "namely",
                "BioBERT",
                "and",
                "Bio-ClinicalBERT",
                "#TARGET_REF",
                ".",
                "After",
                "a",
                "preliminary",
                "fine-tuning",
                "on",
                "the",
                "subtask",
                "1a,",
                "the",
                "most",
                "promising",
                "results",
                "were",
                "obtained",
                "by",
                "BioBERT."
            ],
            "context": [
                3,
                3,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Language Models: We experimented with BERTbase #REF and with the domainspecific Transformers, namely BioBERT and Bio-ClinicalBERT #TARGET_REF . After a preliminary fine-tuning on the subtask 1a, the most promising results were obtained by BioBERT.",
        "output": "{\"INFO\": [\"the domainspecific Transformers,\", \"Bio-ClinicalBERT #TARGET_REF .\"], \"PERCEPT\": [\"We experimented with\", \"with\", \"After a preliminary fine-tuning on the subtask 1a, the most promising results were obtained by BioBERT.\"], \"BACK\": [\"Language Models:\", \"BERTbase #REF and\", \"namely BioBERT and\"]}"
    },
    {
        "gold": {
            "text": [
                "Pairwise",
                "diversity",
                "(⇓).",
                "Referred",
                "as",
                "\"self-\"",
                "(e.g.,",
                "self-BLEU)",
                "#TARGET_REF",
                ",",
                "it",
                "measures",
                "the",
                "within-distribution",
                "similarity.",
                "This",
                "metric",
                "computes",
                "the",
                "average",
                "of",
                "sentence-level",
                "metrics",
                "between",
                "all",
                "pairwise",
                "combinations",
                "of",
                "hypotheses",
                "{Y",
                "(1)",
                ",",
                "•",
                "•",
                "•",
                ",",
                "Y",
                "(K)",
                "}",
                "generated",
                "from",
                "each",
                "source",
                "sequence",
                "X.",
                "Lower",
                "pairwise",
                "metric",
                "indicates",
                "high",
                "diversity",
                "between",
                "generated",
                "hypotheses."
            ],
            "context": [
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Pairwise diversity (⇓). Referred as \"self-\" (e.g., self-BLEU) #TARGET_REF , it measures the within-distribution similarity. This metric computes the average of sentence-level metrics between all pairwise combinations of hypotheses {Y (1) , • • • , Y (K) } generated from each source sequence X. Lower pairwise metric indicates high diversity between generated hypotheses.",
        "output": "{\"INFO\": [\"Referred as \\\"self-\\\" (e.g., self-BLEU) #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"Pairwise diversity (\\u21d3).\", \"it measures the within-distribution similarity.\"]}"
    },
    {
        "gold": {
            "text": [
                "Besides,",
                "concept",
                "instance",
                "nodes",
                "(CI)",
                "and",
                "concept",
                "sequence",
                "instance",
                "structures",
                "(CSI)",
                "are",
                "dynamically",
                "created",
                "during",
                "parsing.",
                "Each",
                "CI",
                "or",
                "CSI",
                "is",
                "connected",
                "to",
                "the",
                "associated",
                "CC",
                "or",
                "CSC",
                "by",
                "INST",
                "link.",
                "CIs",
                "correspond",
                "to",
                "discourse",
                "entities",
                "proposed",
                "in",
                "#TARGET_REF",
                ".",
                "Three",
                "additional",
                "links",
                "are",
                "used",
                "to",
                "facilitate",
                "pragmatic",
                "inferences.",
                "They",
                "are",
                "CONTEXT",
                "links.",
                "CONSTRAINT",
                "links",
                "and",
                "EQROLE",
                "links.",
                "A",
                "CONTEXT",
                "link",
                "is",
                "a",
                "path",
                "of",
                "contextual",
                "priming",
                "which",
                "is",
                "crucial",
                "in",
                "word",
                "sense",
                "disambiguation.",
                "When",
                "a",
                "word",
                "is",
                "activated",
                "during",
                "processing,",
                "the",
                "activation",
                "spreads",
                "through",
                "CONTEXT",
                "links",
                "and",
                "impose",
                "contextual",
                "priming",
                "to",
                "relevant",
                "concepts.",
                "A",
                "CONSTRAINT",
                "link",
                "denotes",
                "an",
                "antecedent/consequence",
                "relationship",
                "between",
                "two",
                "events",
                "or",
                "states,",
                "which",
                "is",
                "created",
                "between",
                "two",
                "CSRs.",
                "An",
                "EQROLE",
                "link",
                "denotes",
                "the",
                "necessary",
                "argument",
                "matching",
                "condition",
                "for",
                "testing",
                "an",
                "antecedent/consequence",
                "relationship,",
                "which",
                "is",
                "created",
                "between",
                "two",
                "CSEs",
                "in",
                "different",
                "CSCs."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Besides, concept instance nodes (CI) and concept sequence instance structures (CSI) are dynamically created during parsing. Each CI or CSI is connected to the associated CC or CSC by INST link. CIs correspond to discourse entities proposed in #TARGET_REF . Three additional links are used to facilitate pragmatic inferences. They are CONTEXT links. CONSTRAINT links and EQROLE links. A CONTEXT link is a path of contextual priming which is crucial in word sense disambiguation. When a word is activated during processing, the activation spreads through CONTEXT links and impose contextual priming to relevant concepts. A CONSTRAINT link denotes an antecedent/consequence relationship between two events or states, which is created between two CSRs. An EQROLE link denotes the necessary argument matching condition for testing an antecedent/consequence relationship, which is created between two CSEs in different CSCs.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"CIs correspond to discourse entities proposed in\"]}"
    },
    {
        "gold": {
            "text": [
                "Recently,",
                "#TARGET_REF",
                "and",
                "#REF",
                "have",
                "nevertheless",
                "shown",
                "that",
                "the",
                "commonly",
                "adopted",
                "practices",
                "(the",
                "number",
                "of",
                "iterations,",
                "the",
                "choice",
                "of",
                "model",
                "layers)",
                "when",
                "fine-tuning",
                "Transformers-based",
                "langage",
                "models",
                "are",
                "inappropriate",
                "under",
                "resource",
                "constrained",
                "conditions",
                "and",
                "adversely",
                "affect",
                "the",
                "stability",
                "of",
                "models",
                "performances",
                "as",
                "overfitting,",
                "label",
                "noise",
                "memorization",
                "or",
                "catastrophic",
                "forgetting.",
                "Added",
                "to",
                "this,",
                "because",
                "the",
                "pretraining",
                "process",
                "is",
                "particularly",
                "constraining,",
                "various",
                "works",
                "have",
                "been",
                "oriented",
                "towards",
                "the",
                "research",
                "and",
                "training",
                "of",
                "efficient",
                "models,",
                "both",
                "in",
                "terms",
                "of",
                "available",
                "capacities",
                "and",
                "resources",
                "and",
                "in",
                "terms",
                "of",
                "environmental",
                "footprint."
            ],
            "context": [
                1,
                1,
                3,
                3,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Recently, #TARGET_REF and #REF have nevertheless shown that the commonly adopted practices (the number of iterations, the choice of model layers) when fine-tuning Transformers-based langage models are inappropriate under resource constrained conditions and adversely affect the stability of models performances as overfitting, label noise memorization or catastrophic forgetting. Added to this, because the pretraining process is particularly constraining, various works have been oriented towards the research and training of efficient models, both in terms of available capacities and resources and in terms of environmental footprint.",
        "output": "{\"INFO\": [\"Recently, #TARGET_REF\", \"have\", \"shown that the commonly adopted practices\", \"when fine-tuning Transformers-based langage models are inappropriate under resource constrained conditions and adversely affect the stability of models performances as overfitting, label noise memorization or catastrophic forgetting.\"], \"PERCEPT\": [], \"BACK\": [\"and #REF\", \"(the number of iterations, the choice of model layers)\", \"because the pretraining process is particularly constraining, various works have been oriented towards the research and training of efficient models,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "main",
                "motivation",
                "behind",
                "the",
                "TransWiC",
                "architecture",
                "is",
                "the",
                "success",
                "transformer-based",
                "architectures",
                "had",
                "in",
                "various",
                "natural",
                "language",
                "processing",
                "tasks",
                "like",
                "offensive",
                "language",
                "identification",
                "#TARGET_REF",
                ",",
                "offensive",
                "spans",
                "identification",
                "#REF",
                ",",
                "language",
                "detection",
                "#REF",
                "Lang."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The main motivation behind the TransWiC architecture is the success transformer-based architectures had in various natural language processing tasks like offensive language identification #TARGET_REF , offensive spans identification #REF , language detection #REF Lang.",
        "output": "{\"INFO\": [\"offensive language identification #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"The main motivation behind the TransWiC architecture is the success transformer-based architectures had in various natural language processing tasks like\", \"offensive spans identification #REF , language detection #REF Lang.\"]}"
    },
    {
        "gold": {
            "text": [
                "Following",
                "the",
                "SAMT",
                "approach,",
                "CCG-augmented",
                "HPB",
                "SMT",
                "#TARGET_REF",
                "uses",
                "CCG",
                "#REF",
                "to",
                "label",
                "non-terminals.",
                "CCG",
                "has",
                "distinct",
                "advantages",
                "over",
                "phrase-structure",
                "grammar",
                "in",
                "the",
                "general",
                "SMT",
                "context,",
                "particularly",
                "in",
                "extracting",
                "non-terminal",
                "labels",
                "in",
                "HPB",
                "SMT.",
                "This",
                "section",
                "gives",
                "a",
                "brief",
                "introduction",
                "to",
                "CCG",
                "followed",
                "by",
                "a",
                "description",
                "of",
                "the",
                "approach",
                "of",
                "extracting",
                "non-terminal",
                "labels",
                "using",
                "the",
                "same."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Following the SAMT approach, CCG-augmented HPB SMT #TARGET_REF uses CCG #REF to label non-terminals. CCG has distinct advantages over phrase-structure grammar in the general SMT context, particularly in extracting non-terminal labels in HPB SMT. This section gives a brief introduction to CCG followed by a description of the approach of extracting non-terminal labels using the same.",
        "output": "{\"INFO\": [\"CCG-augmented HPB SMT #TARGET_REF uses CCG #REF to label non-terminals.\"], \"PERCEPT\": [\"Following the SAMT approach,\", \"CCG has distinct advantages over phrase-structure grammar in the general SMT context, particularly in extracting non-terminal labels in HPB SMT.\"], \"BACK\": [\"This section gives a brief introduction to CCG\"]}"
    },
    {
        "gold": {
            "text": [
                "Integrating",
                "eye-movements",
                "of",
                "the",
                "speaker.",
                "Many",
                "eye-tracking",
                "technologies",
                "in",
                "the",
                "market",
                "employ",
                "a",
                "sufficient",
                "sampling",
                "frequency",
                "to",
                "enable",
                "gazecontingent",
                "applications.",
                "With",
                "advancements",
                "in",
                "the",
                "eye-tracking",
                "technology,",
                "incorporating",
                "eye",
                "movements",
                "of",
                "a",
                "speaker",
                "or",
                "a",
                "listener",
                "enables",
                "us",
                "to",
                "predict",
                "/",
                "resolve",
                "which",
                "entity",
                "is",
                "being",
                "referred",
                "to",
                "in",
                "a",
                "complex",
                "visual",
                "environment",
                "#TARGET_REF",
                ".",
                "However,",
                "these",
                "studies",
                "are",
                "limited",
                "to",
                "relatively",
                "simple",
                "scenes.",
                "Situated",
                "language",
                "understanding",
                "in",
                "a",
                "referentially",
                "complex",
                "environment",
                "or",
                "under",
                "noisy",
                "situations",
                "imposes",
                "a",
                "different",
                "level",
                "of",
                "challenge",
                "that",
                "we",
                "aim",
                "to",
                "address.",
                "The",
                "number",
                "of",
                "studies",
                "that",
                "utilize",
                "gaze",
                "features",
                "#REF",
                "is",
                "very",
                "limited.",
                "In",
                "this",
                "study,",
                "we",
                "propose",
                "to",
                "incorporate",
                "the",
                "eye-movements",
                "of",
                "the",
                "speaker",
                "to",
                "improve",
                "the",
                "crossmodal",
                "mapping",
                "performance.",
                "This",
                "additional",
                "deictic",
                "modality",
                "may",
                "improve",
                "the",
                "recovery",
                "of",
                "the",
                "intended",
                "meaning",
                "especially",
                "when",
                "the",
                "communication",
                "is",
                "noisy",
                "(acoustically",
                "or",
                "visually).",
                "The",
                "gaze",
                "embeddings",
                "will",
                "be",
                "created",
                "by",
                "using",
                "existing",
                "eyemovement",
                "datasets.",
                "However,",
                "there",
                "are",
                "only",
                "few",
                "big-size",
                "eye-movement",
                "datasets",
                "available",
                "#REF",
                ".",
                "Thus,",
                "to",
                "enlarge",
                "available",
                "data,",
                "we",
                "will",
                "conduct",
                "a",
                "set",
                "of",
                "experimental",
                "studies",
                "with",
                "increasing",
                "referential",
                "complexity.",
                "There,",
                "we",
                "will",
                "record",
                "participants'",
                "instructions",
                "on",
                "a",
                "task-oriented",
                "scenario",
                "and",
                "their",
                "eye-movements",
                "regarding",
                "target",
                "objects."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Integrating eye-movements of the speaker. Many eye-tracking technologies in the market employ a sufficient sampling frequency to enable gazecontingent applications. With advancements in the eye-tracking technology, incorporating eye movements of a speaker or a listener enables us to predict / resolve which entity is being referred to in a complex visual environment #TARGET_REF . However, these studies are limited to relatively simple scenes. Situated language understanding in a referentially complex environment or under noisy situations imposes a different level of challenge that we aim to address. The number of studies that utilize gaze features #REF is very limited. In this study, we propose to incorporate the eye-movements of the speaker to improve the crossmodal mapping performance. This additional deictic modality may improve the recovery of the intended meaning especially when the communication is noisy (acoustically or visually). The gaze embeddings will be created by using existing eyemovement datasets. However, there are only few big-size eye-movement datasets available #REF . Thus, to enlarge available data, we will conduct a set of experimental studies with increasing referential complexity. There, we will record participants' instructions on a task-oriented scenario and their eye-movements regarding target objects.",
        "output": "{\"INFO\": [\"With advancements in the eye-tracking technology, incorporating eye movements of a speaker or a listener enables us to predict / resolve which entity is being referred to in a complex visual environment #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Many eye-tracking technologies in the market employ a sufficient sampling frequency to enable gazecontingent applications.\"]}"
    },
    {
        "gold": {
            "text": [
                "One",
                "frequently",
                "used",
                "NN",
                "architecture",
                "#TARGET_REF",
                ")",
                "that",
                "maximizes",
                "Eq.",
                "(",
                "3)",
                "is",
                "the",
                "O2M",
                "model",
                "trained",
                "with",
                "multi-task",
                "learning.",
                "Fig.",
                "1(a)",
                "shows",
                "the",
                "architecture",
                "of",
                "the",
                "model.",
                "The",
                "O2M",
                "model",
                "outputs",
                "several",
                "types",
                "of",
                "sequences",
                "independently.",
                "In",
                "other",
                "words,",
                "multi-task",
                "learning",
                "is",
                "derived",
                "by",
                "assuming",
                "conditional",
                "independence",
                "of",
                "output",
                "token",
                "types",
                "for",
                "Eq.",
                "(",
                "3),",
                "as",
                "follows:"
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "One frequently used NN architecture #TARGET_REF ) that maximizes Eq. ( 3) is the O2M model trained with multi-task learning. Fig. 1(a) shows the architecture of the model. The O2M model outputs several types of sequences independently. In other words, multi-task learning is derived by assuming conditional independence of output token types for Eq. ( 3), as follows:",
        "output": "{\"INFO\": [\"NN architecture #TARGET_REF )\"], \"PERCEPT\": [\"One frequently used\", \"that maximizes Eq. ( 3) is the O2M model trained with multi-task learning.\"], \"BACK\": [\"Fig. 1(a) shows the architecture of the model.\"]}"
    },
    {
        "gold": {
            "text": [
                "Trained",
                "on",
                "ImageNet",
                "#TARGET_REF",
                ")",
                "YOLO",
                "#REF",
                "x",
                "Trained",
                "on",
                "ImageNet",
                "#REF",
                ")",
                "EfficientNet",
                "B7",
                "#REF",
                "x",
                "Trained",
                "on",
                "ImageNet",
                "#REF",
                "Table",
                "1:",
                "List",
                "of",
                "pre-trained",
                "models",
                "registered",
                "by",
                "all",
                "participants",
                "of",
                "ReINTEL",
                "challenge",
                "in",
                "2020."
            ],
            "context": [
                3,
                3,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Trained on ImageNet #TARGET_REF ) YOLO #REF x Trained on ImageNet #REF ) EfficientNet B7 #REF x Trained on ImageNet #REF Table 1: List of pre-trained models registered by all participants of ReINTEL challenge in 2020.",
        "output": "{\"INFO\": [\"ImageNet #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Trained on\", \"YOLO #REF x Trained on ImageNet #REF ) EfficientNet B7 #REF x Trained on ImageNet #REF Table 1: List of pre-trained models registered by all participants of ReINTEL challenge in 2020.\"]}"
    },
    {
        "gold": {
            "text": [
                "(2020)",
                "that",
                "focus",
                "on",
                "creating",
                "content",
                "especially",
                "for",
                "2D",
                "visual",
                "games",
                "via",
                "search",
                "or",
                "reinforcement",
                "learning",
                "based",
                "methods.",
                "#REF",
                "use",
                "knowledge",
                "graphs",
                "to",
                "ground",
                "language",
                "and",
                "produce",
                "worlds",
                "and",
                "quests",
                "separately",
                "for",
                "text",
                "games",
                "from",
                "existing",
                "corpora",
                "such",
                "as",
                "stories.",
                "#TARGET_REF",
                "leverage",
                "LIGHT",
                "to",
                "learn",
                "to",
                "generate",
                "interactive",
                "fiction",
                "worlds",
                "on",
                "the",
                "basis",
                "of",
                "locations,",
                "characters,",
                "and",
                "objects-this",
                "work",
                "is",
                "closest",
                "in",
                "spirit",
                "to",
                "our",
                "own",
                "World",
                "Generation",
                "module",
                "later",
                "on.",
                "They",
                "all",
                "focus",
                "on",
                "either",
                "generating",
                "or",
                "playing",
                "games."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "(2020) that focus on creating content especially for 2D visual games via search or reinforcement learning based methods. #REF use knowledge graphs to ground language and produce worlds and quests separately for text games from existing corpora such as stories. #TARGET_REF leverage LIGHT to learn to generate interactive fiction worlds on the basis of locations, characters, and objects-this work is closest in spirit to our own World Generation module later on. They all focus on either generating or playing games.",
        "output": "{\"INFO\": [\"#TARGET_REF leverage LIGHT to learn to generate interactive fiction worlds on the basis of locations, characters, and objects-this\"], \"PERCEPT\": [\"work is closest in spirit to our own World Generation module\", \"They all focus on either generating or playing games.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Distributional",
                "similarity",
                "information",
                "has",
                "been",
                "used",
                "to",
                "improve",
                "modeling",
                "of",
                "word",
                "co-occurrence",
                "probabilities",
                "in",
                "previous",
                "work.",
                "#REF",
                "defined",
                "a",
                "kernel-based",
                "interpolated",
                "language",
                "model",
                "where",
                "probability",
                "mass",
                "is",
                "explicitly",
                "spread",
                "over",
                "similar",
                "words,",
                "with",
                "variant",
                "models",
                "along",
                "these",
                "lines",
                "found",
                "in",
                "#REF",
                "and",
                "Yarlett",
                "#REF",
                ".",
                "These",
                "models",
                "leverage",
                "similarity",
                "information",
                "about",
                "target",
                "words",
                "but",
                "not",
                "context",
                "words.",
                "In",
                "contrast,",
                "#TARGET_REF",
                "proposed",
                "a",
                "method",
                "which",
                "uses",
                "similarity",
                "information",
                "about",
                "the",
                "context",
                "word",
                "but",
                "not",
                "the",
                "target",
                "word.",
                "#REF",
                "developed",
                "a",
                "method",
                "that",
                "can",
                "exploit",
                "similarity",
                "information",
                "about",
                "both",
                "target",
                "and",
                "context,",
                "using",
                "a",
                "Markov",
                "Chain",
                "algorithm",
                "incorporating",
                "distributional",
                "and",
                "WordNet",
                "similarities.",
                "None",
                "of",
                "this",
                "previous",
                "work",
                "derived",
                "word",
                "similarity",
                "information",
                "from",
                "pretrained",
                "embeddings,",
                "because",
                "such",
                "embeddings",
                "did",
                "not",
                "exist",
                "at",
                "the",
                "time."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Distributional similarity information has been used to improve modeling of word co-occurrence probabilities in previous work. #REF defined a kernel-based interpolated language model where probability mass is explicitly spread over similar words, with variant models along these lines found in #REF and Yarlett #REF . These models leverage similarity information about target words but not context words. In contrast, #TARGET_REF proposed a method which uses similarity information about the context word but not the target word. #REF developed a method that can exploit similarity information about both target and context, using a Markov Chain algorithm incorporating distributional and WordNet similarities. None of this previous work derived word similarity information from pretrained embeddings, because such embeddings did not exist at the time.",
        "output": "{\"INFO\": [\"#TARGET_REF proposed a method which uses similarity information about the context word but not the target word.\"], \"PERCEPT\": [\"These models leverage similarity information about target words but not context words. In contrast,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "It",
                "is",
                "not",
                "clear",
                "how",
                "much",
                "WordNet",
                "synsets",
                "should",
                "be",
                "expected",
                "to",
                "overlap",
                "with",
                "Levin",
                "classes,",
                "and",
                "preliminary",
                "indications",
                "are",
                "that",
                "there",
                "is",
                "a",
                "wide",
                "discrepancy",
                "#REF",
                ",",
                "#TARGET_REF",
                ",",
                "#REF",
                ".",
                "However,",
                "it",
                "would",
                "be",
                "useful",
                "for",
                "the",
                "WordNet",
                "synsets",
                "to",
                "have",
                "access",
                "to",
                "the",
                "detailed",
                "syntactic",
                "information",
                "that",
                "the",
                "Levin",
                "classes",
                "contain,",
                "and",
                "it",
                "would",
                "be",
                "equally",
                "useful",
                "to",
                "have",
                "more",
                "guidance",
                "as",
                "to",
                "when",
                "membership",
                "in",
                "a",
                "Levin",
                "class",
                "does",
                "in",
                "fact",
                "indicate",
                "shared",
                "semantic",
                "components.",
                "Identification",
                "of",
                "these",
                "components",
                "is",
                "critical",
                "to",
                "the",
                "use",
                "of",
                "classes",
                "and",
                "their",
                "semantic",
                "features",
                "for",
                "translation",
                "purposes,",
                "whether",
                "transfer-based",
                "or",
                "interlingua",
                "based.",
                "Although",
                "Levin",
                "classes",
                "group",
                "together",
                "verbs",
                "with",
                "similar",
                "argument",
                "structures,",
                "the",
                "meanings",
                "of",
                "the",
                "verbs",
                "are",
                "not",
                "necessarily",
                "synonymous.",
                "Some",
                "classes",
                "such",
                "as",
                "break",
                "(break,",
                "chip,",
                "crack,",
                "crash,",
                "crush,",
                "fracture,",
                "rip,",
                "shatter,",
                "smash,",
                "snap,",
                "splinter,",
                "tear)",
                "and",
                "cut",
                "(chip,",
                "clip,",
                "cut,",
                "hack,",
                "hew,",
                "saw,",
                "scrape,",
                "scratch,",
                "slash,",
                "snip)",
                "contain",
                "verbs",
                "that",
                "are",
                "quite",
                "synonymous,",
                "but",
                "others,",
                "such",
                "as",
                "braid",
                "(bob,",
                "braid,",
                "brush,",
                "clip,",
                "coldcream,",
                "comb,",
                "condition,",
                "crimp,",
                "crop,",
                "curl,",
                "etc.)",
                "do",
                "not,",
                "which",
                "at",
                "least",
                "partly",
                "explains",
                "the",
                "lack",
                "of",
                "overlap",
                "between",
                "Levin",
                "and",
                "WordNet."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "It is not clear how much WordNet synsets should be expected to overlap with Levin classes, and preliminary indications are that there is a wide discrepancy #REF , #TARGET_REF , #REF . However, it would be useful for the WordNet synsets to have access to the detailed syntactic information that the Levin classes contain, and it would be equally useful to have more guidance as to when membership in a Levin class does in fact indicate shared semantic components. Identification of these components is critical to the use of classes and their semantic features for translation purposes, whether transfer-based or interlingua based. Although Levin classes group together verbs with similar argument structures, the meanings of the verbs are not necessarily synonymous. Some classes such as break (break, chip, crack, crash, crush, fracture, rip, shatter, smash, snap, splinter, tear) and cut (chip, clip, cut, hack, hew, saw, scrape, scratch, slash, snip) contain verbs that are quite synonymous, but others, such as braid (bob, braid, brush, clip, coldcream, comb, condition, crimp, crop, curl, etc.) do not, which at least partly explains the lack of overlap between Levin and WordNet.",
        "output": "{\"INFO\": [\"It is not clear how much WordNet synsets should be expected to overlap with Levin classes, and preliminary indications are that there is a wide discrepancy #REF , #TARGET_REF , #REF .\"], \"PERCEPT\": [\"Identification of these components is critical to the use of classes and their semantic features for translation purposes, whether transfer-based or interlingua based. Although Levin classes group together verbs with similar argument structures, the meanings of the verbs are not necessarily synonymous.\"], \"BACK\": [\"it would be useful for the WordNet synsets to have access to the detailed syntactic information that the Levin classes contain, and it would be equally useful to have more guidance as to when membership in a Levin class does in fact indicate shared semantic components.\"]}"
    },
    {
        "gold": {
            "text": [
                "from",
                "which",
                "predicate-argument",
                "structure",
                "can",
                "be",
                "recovered,",
                "and",
                "which",
                "can",
                "support",
                "semantic",
                "interpretation.",
                "The",
                "requirement",
                "for",
                "a",
                "domain-independent",
                "analyser",
                "favours",
                "statistical",
                "techniques",
                "to",
                "resolve",
                "ambiguities,",
                "whilst",
                "the",
                "latter",
                "goal",
                "favours",
                "a",
                "more",
                "sophisticated",
                "grammatical",
                "formalism",
                "than",
                "is",
                "typical",
                "in",
                "statistical",
                "approaches",
                "to",
                "robust",
                "analysis",
                "of",
                "corpus",
                "material.",
                "#REF",
                "describe",
                "a",
                "probablistic",
                "parser",
                "using",
                "a",
                "wide-coverage",
                "unification",
                "based",
                "grammar",
                "of",
                "English",
                "written",
                "in",
                "the",
                "Alvey",
                "Natural",
                "Language",
                "To",
                "ols",
                "(ANLT)",
                "meta",
                "g",
                "rammat",
                "ical",
                "formalism",
                "#REF",
                ",",
                "generating",
                "around",
                "800",
                "rules",
                "in",
                "a",
                "syntactic",
                "variant",
                "of",
                "the",
                "Definite",
                "Clause",
                "Grammar",
                "formalism",
                "(DCG,",
                "#REF",
                "extended",
                "with",
                "iterative",
                "(Kleene)",
                "operators.",
                "The",
                "ANLT",
                "grammar",
                "is",
                "linked",
                "to",
                "a",
                "lexicon",
                "containing",
                "about",
                "64K",
                "entries",
                "for",
                "40K",
                "lexemes,",
                "including",
                "detailed",
                "subcategorisation",
                "information",
                "appropriate",
                "for",
                "the",
                "grammar,",
                "built",
                "semi-automatically",
                "from",
                "a",
                "learners'",
                "dictionary",
                "#REF",
                ".",
                "The",
                "resulting",
                "parser",
                "is",
                "efficient,",
                "capable",
                "of",
                "constructing",
                "a",
                "parse",
                "forest",
                "in",
                "what",
                "seems",
                "to",
                "be",
                "roughly",
                "quadratic",
                "time,",
                "and",
                "efficiently",
                "returning",
                "the",
                "ranked",
                "n-most",
                "likely",
                "analyses",
                "#TARGET_REF",
                ".",
                "The",
                "probabilistic",
                "model",
                "is",
                "a",
                "refinement",
                "of",
                "probabilistic",
                "context-free",
                "grammar",
                "(PCFG)",
                "conditioning",
                "CF",
                "'backbone'",
                "rule",
                "application",
                "on",
                "LR",
                "state",
                "and",
                "lookahead",
                "item.",
                "Unification",
                "of",
                "the",
                "'residue'"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "from which predicate-argument structure can be recovered, and which can support semantic interpretation. The requirement for a domain-independent analyser favours statistical techniques to resolve ambiguities, whilst the latter goal favours a more sophisticated grammatical formalism than is typical in statistical approaches to robust analysis of corpus material. #REF describe a probablistic parser using a wide-coverage unification based grammar of English written in the Alvey Natural Language To ols (ANLT) meta g rammat ical formalism #REF , generating around 800 rules in a syntactic variant of the Definite Clause Grammar formalism (DCG, #REF extended with iterative (Kleene) operators. The ANLT grammar is linked to a lexicon containing about 64K entries for 40K lexemes, including detailed subcategorisation information appropriate for the grammar, built semi-automatically from a learners' dictionary #REF . The resulting parser is efficient, capable of constructing a parse forest in what seems to be roughly quadratic time, and efficiently returning the ranked n-most likely analyses #TARGET_REF . The probabilistic model is a refinement of probabilistic context-free grammar (PCFG) conditioning CF 'backbone' rule application on LR state and lookahead item. Unification of the 'residue'",
        "output": "{\"INFO\": [\"the ranked n-most likely analyses #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The\", \"parser is efficient, capable of constructing a parse forest in what seems to be roughly quadratic time, and efficiently returning\"]}"
    },
    {
        "gold": {
            "text": [
                "Lexical",
                "complexity",
                "is",
                "one",
                "of",
                "the",
                "main",
                "reasons",
                "leading",
                "to",
                "overall",
                "text",
                "complexity",
                "and",
                "thus",
                "result",
                "in",
                "poor",
                "reading",
                "comprehension",
                "for",
                "readers",
                "#REF",
                ".",
                "Different",
                "from",
                "the",
                "Complex",
                "Word",
                "Identification",
                "(CWI)",
                "#REF",
                "task,",
                "which",
                "aims",
                "to",
                "predict",
                "whether",
                "a",
                "given",
                "word",
                "is",
                "complex",
                "or",
                "not,",
                "the",
                "goal",
                "of",
                "lexical",
                "complexity",
                "prediction",
                "(LCP)",
                "is",
                "to",
                "predict",
                "the",
                "complexity",
                "value",
                "of",
                "the",
                "given",
                "parts",
                "from",
                "contexts",
                "as",
                "shown",
                "in",
                "Figure",
                "1.",
                "The",
                "underlined",
                "parts",
                "of",
                "the",
                "sentence",
                "are",
                "the",
                "words",
                "that",
                "need",
                "to",
                "be",
                "predicted",
                "and",
                "the",
                "same",
                "words",
                "in",
                "different",
                "contexts",
                "may",
                "have",
                "different",
                "complexity",
                "scores.",
                "LCP",
                "plays",
                "an",
                "important",
                "role",
                "in",
                "the",
                "usual",
                "Lexical",
                "Simplification",
                "(LS)",
                "#TARGET_REF",
                "pipeline",
                "since",
                "it",
                "can",
                "help",
                "simplifiers",
                "find",
                "the",
                "challenging",
                "words",
                "and",
                "replace",
                "them",
                "with",
                "appropriate",
                "alternatives",
                "that",
                "easy",
                "to",
                "understand.",
                "Either",
                "LCP",
                "or",
                "CWI",
                "can",
                "not",
                "only",
                "be",
                "used",
                "as",
                "a",
                "component",
                "of",
                "LS",
                "systems",
                "but",
                "also",
                "as",
                "a",
                "stand-alone",
                "application",
                "within",
                "intelligent",
                "tutoring",
                "systems",
                "for",
                "second",
                "language",
                "learners",
                "or",
                "in",
                "reading",
                "devices",
                "for",
                "people",
                "with",
                "low",
                "literacy",
                "skills",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Lexical complexity is one of the main reasons leading to overall text complexity and thus result in poor reading comprehension for readers #REF . Different from the Complex Word Identification (CWI) #REF task, which aims to predict whether a given word is complex or not, the goal of lexical complexity prediction (LCP) is to predict the complexity value of the given parts from contexts as shown in Figure 1. The underlined parts of the sentence are the words that need to be predicted and the same words in different contexts may have different complexity scores. LCP plays an important role in the usual Lexical Simplification (LS) #TARGET_REF pipeline since it can help simplifiers find the challenging words and replace them with appropriate alternatives that easy to understand. Either LCP or CWI can not only be used as a component of LS systems but also as a stand-alone application within intelligent tutoring systems for second language learners or in reading devices for people with low literacy skills #REF .",
        "output": "{\"INFO\": [\"Lexical Simplification (LS) #TARGET_REF pipeline\"], \"PERCEPT\": [\"LCP plays an important role in the usual\", \"since it can help simplifiers find the challenging words and replace them with appropriate alternatives that easy to understand.\"], \"BACK\": [\"Either LCP or CWI can not only be used as a component of LS systems but also as a stand-alone application within intelligent tutoring systems for second language learners or in reading devices for people with low literacy skills #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Semantic",
                "Network",
                "Array",
                "Processor",
                "(SNAP)",
                "is",
                "a",
                "highly",
                "parallel",
                "array",
                "processor",
                "fully",
                "optimized",
                "for",
                "semantic",
                "network",
                "processing",
                "with",
                "marker-passing",
                "mechanism.",
                "In",
                "order",
                "to",
                "facilitate",
                "efficient",
                "propagation",
                "of",
                "markers",
                "and",
                "to",
                "ease",
                "development",
                "of",
                "applications,",
                "a",
                "set",
                "of",
                "marker",
                "propagation",
                "instructions",
                "has",
                "been",
                "microcoded.",
                "SNAP",
                "supports",
                "propagation",
                "of",
                "markers",
                "containing",
                "(1)",
                "bit-vectors.",
                "(2)",
                "address,",
                "and",
                "(3)",
                "numeric",
                "value.",
                "By",
                "limiting",
                "content",
                "of",
                "markers,",
                "significant",
                "reduction",
                "in",
                "cost",
                "and",
                "resource",
                "has",
                "been",
                "attained",
                "without",
                "undermining",
                "performance",
                "requirements",
                "for",
                "knowledge",
                "processing.",
                "Several",
                "AI",
                "applications",
                "such",
                "as",
                "natural",
                "language",
                "processing",
                "system,",
                "classification",
                "system",
                "#TARGET_REF",
                ",",
                "and",
                "rule-based",
                "system",
                "has",
                "been",
                "developed",
                "on",
                "SNAP."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The Semantic Network Array Processor (SNAP) is a highly parallel array processor fully optimized for semantic network processing with marker-passing mechanism. In order to facilitate efficient propagation of markers and to ease development of applications, a set of marker propagation instructions has been microcoded. SNAP supports propagation of markers containing (1) bit-vectors. (2) address, and (3) numeric value. By limiting content of markers, significant reduction in cost and resource has been attained without undermining performance requirements for knowledge processing. Several AI applications such as natural language processing system, classification system #TARGET_REF , and rule-based system has been developed on SNAP.",
        "output": "{\"INFO\": [\"classification system #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"natural language processing system,\", \"rule-based system has been developed on SNAP.\"]}"
    },
    {
        "gold": {
            "text": [
                "It",
                "is",
                "this",
                "very",
                "issue",
                "that",
                "the",
                "current",
                "wave",
                "of",
                "theories",
                "labelled",
                "'connectionist'",
                "(e.g.",
                "#TARGET_REF",
                "seeks",
                "to",
                "tackle:",
                "how",
                "underlying",
                "classifiers",
                "can",
                "emerge",
                "spontaneously",
                "from",
                "data",
                "by",
                "using",
                "no",
                "more",
                "than",
                "association",
                "and",
                "classification",
                "algorithms.",
                "MMB",
                "would",
                "have",
                "sympathised",
                "with",
                "its",
                "anti-logicism,",
                "but",
                "would",
                "have",
                "found",
                "its",
                "statistical",
                "basis",
                "only",
                "thin",
                "mathematics,",
                "and",
                "would",
                "have",
                "not",
                "been",
                "sympathetic",
                "to",
                "its",
                "anti-symbolic",
                "disposition."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "It is this very issue that the current wave of theories labelled 'connectionist' (e.g. #TARGET_REF seeks to tackle: how underlying classifiers can emerge spontaneously from data by using no more than association and classification algorithms. MMB would have sympathised with its anti-logicism, but would have found its statistical basis only thin mathematics, and would have not been sympathetic to its anti-symbolic disposition.",
        "output": "{\"INFO\": [\"#TARGET_REF seeks to tackle: how underlying classifiers can emerge spontaneously from data by using no more than association and classification algorithms.\"], \"PERCEPT\": [], \"BACK\": [\"It is this very issue that the current wave of theories labelled 'connectionist' (e.g.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "a",
                "three-layer",
                "transformer",
                "#TARGET_REF",
                "with",
                "a",
                "hidden",
                "size",
                "of",
                "128",
                "and",
                "4",
                "heads",
                "as",
                "our",
                "base",
                "model",
                "for",
                "content",
                "planning",
                "and",
                "response",
                "generation,",
                "i.e.,",
                "p",
                "l",
                "(a|c)",
                "and",
                "p",
                "r",
                "(a,",
                "c)",
                ",",
                "respectively.",
                "We",
                "use",
                "grid",
                "search",
                "to",
                "find",
                "the",
                "best",
                "hyperparameters",
                "for",
                "the",
                "models",
                "based",
                "on",
                "validation",
                "performance,",
                "which",
                "we",
                "use",
                "a",
                "combination",
                "of",
                "Inform,",
                "Success",
                "and",
                "BLEU",
                "scores",
                "to",
                "measure.",
                "We",
                "choose",
                "the",
                "embedding",
                "dimensionality",
                "d",
                "among",
                "{50,",
                "75,",
                "100,",
                "150,",
                "200},",
                "the",
                "hyperparameters",
                "α",
                "and",
                "β",
                "in",
                "[0.01,",
                "1.0]."
            ],
            "context": [
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use a three-layer transformer #TARGET_REF with a hidden size of 128 and 4 heads as our base model for content planning and response generation, i.e., p l (a|c) and p r (a, c) , respectively. We use grid search to find the best hyperparameters for the models based on validation performance, which we use a combination of Inform, Success and BLEU scores to measure. We choose the embedding dimensionality d among {50, 75, 100, 150, 200}, the hyperparameters α and β in [0.01, 1.0].",
        "output": "{\"INFO\": [\"a three-layer transformer #TARGET_REF with a hidden size of 128 and 4 heads as our base model for content planning and response generation, i.e., p l (a|c) and p r (a, c) , respectively.\"], \"PERCEPT\": [\"We use\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "cosine",
                "similarity",
                "in",
                "GloVe",
                "#TARGET_REF",
                ","
            ],
            "context": [
                0,
                2,
                2,
                2,
                1,
                1,
                1
            ]
        },
        "input": "• cosine similarity in GloVe #TARGET_REF ,",
        "output": "{\"INFO\": [\"GloVe #TARGET_REF ,\"], \"PERCEPT\": [\"cosine similarity in\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Byte-pair-encoding",
                "(BPE)",
                "#TARGET_REF",
                "6",
                ":",
                "For",
                "both",
                "the",
                "Chinese",
                "and",
                "English",
                "sides,",
                "we",
                "use",
                "BPE",
                "with",
                "32K",
                "operations."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• Byte-pair-encoding (BPE) #TARGET_REF 6 : For both the Chinese and English sides, we use BPE with 32K operations.",
        "output": "{\"INFO\": [\"Byte-pair-encoding (BPE) #TARGET_REF 6 : For both the Chinese and English sides,\", \"BPE with 32K operations.\"], \"PERCEPT\": [\"we use\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "work,",
                "we",
                "aim",
                "to",
                "design",
                "an",
                "E2E",
                "pretraining",
                "strategy",
                "for",
                "the",
                "VLP",
                "problem.",
                "To",
                "this",
                "end,",
                "we",
                "adopt",
                "a",
                "modular",
                "representation",
                "network,",
                "which",
                "takes",
                "image",
                "grid",
                "features",
                "from",
                "a",
                "CNN-based",
                "visual",
                "network",
                "and",
                "the",
                "corresponding",
                "text",
                "embeddings",
                "into",
                "a",
                "multi-modal",
                "Transformer",
                "#TARGET_REF",
                ".",
                "Our",
                "goal",
                "is",
                "to",
                "learn",
                "the",
                "visual",
                "network",
                "and",
                "the",
                "Transformer",
                "jointly,",
                "and",
                "yet",
                "to",
                "effectively",
                "encode",
                "object-level",
                "visual",
                "concepts",
                "in",
                "the",
                "multimodal",
                "representations.",
                "This",
                "enables",
                "us",
                "to",
                "capture",
                "rich",
                "cross-modal",
                "alignment",
                "between",
                "linguistic",
                "entities",
                "and",
                "visual",
                "semantic",
                "concepts",
                "for",
                "the",
                "downstream",
                "tasks,",
                "and",
                "meanwhile",
                "to",
                "enjoy",
                "the",
                "benefits",
                "of",
                "an",
                "efficient",
                "E2E",
                "network",
                "design",
                "without",
                "relying",
                "on",
                "detectors",
                "during",
                "fine-tuning",
                "and",
                "inference."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this work, we aim to design an E2E pretraining strategy for the VLP problem. To this end, we adopt a modular representation network, which takes image grid features from a CNN-based visual network and the corresponding text embeddings into a multi-modal Transformer #TARGET_REF . Our goal is to learn the visual network and the Transformer jointly, and yet to effectively encode object-level visual concepts in the multimodal representations. This enables us to capture rich cross-modal alignment between linguistic entities and visual semantic concepts for the downstream tasks, and meanwhile to enjoy the benefits of an efficient E2E network design without relying on detectors during fine-tuning and inference.",
        "output": "{\"INFO\": [\"a multi-modal Transformer\"], \"PERCEPT\": [\"To this end, we adopt a modular representation network, which takes image grid features from a CNN-based visual network and the corresponding text embeddings into\"], \"BACK\": [\"In this work, we aim to design an E2E pretraining strategy for the VLP problem.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "used",
                "the",
                "learning",
                "with",
                "Local",
                "and",
                "Global",
                "Consistence",
                "(LGC)",
                "#REF",
                "as",
                "a",
                "regularization",
                "method.",
                "The",
                "algorithm",
                "designs",
                "a",
                "classi-fying",
                "function",
                "that",
                "is",
                "sufficiently",
                "smooth",
                "concerning",
                "the",
                "intrinsic",
                "structure",
                "collectively",
                "revealed",
                "by",
                "known",
                "labeled",
                "and",
                "unlabeled",
                "points.",
                "Thus,",
                "the",
                "LGC",
                "lets",
                "every",
                "point",
                "iteratively",
                "spread",
                "its",
                "label",
                "information",
                "to",
                "its",
                "neighbors",
                "until",
                "a",
                "global",
                "stable",
                "state",
                "is",
                "achieved",
                "#TARGET_REF",
                ".",
                "Also,",
                "it",
                "allows",
                "the",
                "class",
                "information",
                "of",
                "the",
                "labeled",
                "objects",
                "to",
                "be",
                "changed",
                "during",
                "the",
                "classification",
                "as",
                "objects",
                "may",
                "be",
                "erroneously",
                "labeled",
                "and,",
                "consequently,",
                "decrease",
                "the",
                "performance",
                "of",
                "the",
                "classification.",
                "More",
                "than",
                "that,",
                "the",
                "algorithm",
                "diminished",
                "the",
                "influence",
                "of",
                "objects",
                "with",
                "a",
                "high",
                "degree",
                "(many",
                "neighboring",
                "objects),",
                "therefore,",
                "these",
                "objects",
                "do",
                "not",
                "have",
                "excessive",
                "influence",
                "in",
                "the",
                "classification."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We used the learning with Local and Global Consistence (LGC) #REF as a regularization method. The algorithm designs a classi-fying function that is sufficiently smooth concerning the intrinsic structure collectively revealed by known labeled and unlabeled points. Thus, the LGC lets every point iteratively spread its label information to its neighbors until a global stable state is achieved #TARGET_REF . Also, it allows the class information of the labeled objects to be changed during the classification as objects may be erroneously labeled and, consequently, decrease the performance of the classification. More than that, the algorithm diminished the influence of objects with a high degree (many neighboring objects), therefore, these objects do not have excessive influence in the classification.",
        "output": "{\"INFO\": [\"the LGC lets every point iteratively spread its label information to its neighbors until a global stable state is achieved #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"We used the learning with Local and Global Consistence (LGC) #REF as a regularization method.\"]}"
    },
    {
        "gold": {
            "text": [
                "Explicit",
                "vs.",
                "Implicit",
                "NP",
                "Relations",
                "Next,",
                "we",
                "analyze",
                "the",
                "composition",
                "of",
                "the",
                "relations",
                "in",
                "the",
                "dataset,",
                "as",
                "to",
                "whether",
                "these",
                "relations",
                "are",
                "implicit",
                "or",
                "explicit.",
                "While",
                "there",
                "is",
                "no",
                "accepted",
                "definition",
                "of",
                "explicit-implicit",
                "distinction",
                "in",
                "the",
                "literature",
                "#REF",
                ",",
                "here",
                "we",
                "adapt",
                "a",
                "definition",
                "originally",
                "used",
                "by",
                "#TARGET_REF",
                "for",
                "another",
                "phenomenon,",
                "implicit",
                "arguments:",
                "14",
                "In",
                "an",
                "implicit",
                "relation",
                "the",
                "anchor",
                "and",
                "the",
                "complement",
                "are",
                "not",
                "syntactically",
                "connected",
                "to",
                "each",
                "other",
                "and",
                "might",
                "not",
                "even",
                "appear",
                "in",
                "the",
                "same",
                "sentence.",
                "This",
                "implies,",
                "for",
                "example,",
                "that",
                "any",
                "inter-sentential",
                "relations",
                "are",
                "implicit",
                "15",
                ",",
                "while",
                "relations",
                "within",
                "one",
                "sentence",
                "can",
                "be",
                "either",
                "implicit",
                "or",
                "explicit.",
                "We",
                "sample",
                "three",
                "documents",
                "from",
                "the",
                "test-set,",
                "containing",
                "590",
                "links",
                "in",
                "total,",
                "and",
                "count",
                "the",
                "number",
                "of",
                "relations",
                "of",
                "each",
                "type.",
                "Our",
                "manual",
                "analysis",
                "reveals",
                "that",
                "89.8%",
                "of",
                "the",
                "relations",
                "are",
                "implicit."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Explicit vs. Implicit NP Relations Next, we analyze the composition of the relations in the dataset, as to whether these relations are implicit or explicit. While there is no accepted definition of explicit-implicit distinction in the literature #REF , here we adapt a definition originally used by #TARGET_REF for another phenomenon, implicit arguments: 14 In an implicit relation the anchor and the complement are not syntactically connected to each other and might not even appear in the same sentence. This implies, for example, that any inter-sentential relations are implicit 15 , while relations within one sentence can be either implicit or explicit. We sample three documents from the test-set, containing 590 links in total, and count the number of relations of each type. Our manual analysis reveals that 89.8% of the relations are implicit.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"While there is no accepted definition of explicit-implicit distinction in the literature #REF , here we adapt a definition originally used by #TARGET_REF for another phenomenon, implicit arguments:\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Cross-batch",
                "negatives",
                "3",
                "The",
                "cross-batch",
                "negative",
                "sampling",
                "is",
                "implemented",
                "with",
                "differentiable",
                "all-gather",
                "operation",
                "provided",
                "in",
                "FleetX",
                "#TARGET_REF",
                ",",
                "that",
                "is",
                "a",
                "highly",
                "scalable",
                "distributed",
                "training",
                "engine",
                "of",
                "PaddlePaddle.",
                "The",
                "all-gather",
                "operator",
                "makes",
                "representation",
                "of",
                "passages",
                "across",
                "all",
                "GPUs",
                "visible",
                "on",
                "each",
                "GPU",
                "and",
                "thus",
                "the",
                "cross-batch",
                "negative",
                "sampling",
                "approach",
                "can",
                "be",
                "applied",
                "globally."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Cross-batch negatives 3 The cross-batch negative sampling is implemented with differentiable all-gather operation provided in FleetX #TARGET_REF , that is a highly scalable distributed training engine of PaddlePaddle. The all-gather operator makes representation of passages across all GPUs visible on each GPU and thus the cross-batch negative sampling approach can be applied globally.",
        "output": "{\"INFO\": [\"FleetX #TARGET_REF\"], \"PERCEPT\": [\"The cross-batch negative sampling is implemented with differentiable all-gather operation provided in\", \"that is a highly scalable distributed training engine of PaddlePaddle.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Joint",
                "BERT",
                "directly",
                "utilizes",
                "the",
                "merit",
                "of",
                "pretrained",
                "BERT",
                "#TARGET_REF",
                "and",
                "nonrecursively",
                "conducts",
                "the",
                "joint",
                "prediction",
                "over",
                "the",
                "#REF",
                "token",
                "embedding",
                "for",
                "intent",
                "and",
                "the",
                "sequence",
                "of",
                "token",
                "embeddings",
                "for",
                "slots."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "• Joint BERT directly utilizes the merit of pretrained BERT #TARGET_REF and nonrecursively conducts the joint prediction over the #REF token embedding for intent and the sequence of token embeddings for slots.",
        "output": "{\"INFO\": [\"pretrained BERT #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Joint BERT directly utilizes the merit of\", \"and nonrecursively conducts the joint prediction over the #REF token embedding for intent and the sequence of token embeddings for slots.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "decoding",
                "analyses",
                "used",
                "linear",
                "support",
                "vector",
                "machines",
                "(SVM)",
                "#TARGET_REF",
                "and",
                "Transformers,",
                "which",
                "can",
                "capture",
                "complex",
                "interactions",
                "of",
                "EEG",
                "data",
                "across",
                "time",
                "points.",
                "All",
                "classifiers",
                "were",
                "trained",
                "on",
                "the",
                "EEG",
                "training",
                "data,",
                "assessed",
                "on",
                "the",
                "dev",
                "set",
                "and",
                "scored",
                "on",
                "the",
                "independent",
                "test",
                "set.",
                "Hyperparameters",
                "and",
                "early",
                "stopping",
                "were",
                "selected",
                "based",
                "on",
                "the",
                "dev",
                "set.",
                "We",
                "assessed",
                "linear",
                "SVMs",
                "and",
                "Transformers",
                "on",
                "the",
                "dev",
                "set",
                "using",
                "10",
                "different",
                "random",
                "seed",
                "points.",
                "We",
                "show",
                "mean",
                "classification",
                "accuracy",
                "with",
                "68%",
                "confidence",
                "intervals",
                "(CI)",
                "over",
                "those",
                "10",
                "replications",
                "on",
                "the",
                "dev",
                "(Table",
                "4,",
                "Figure",
                "3)",
                "resp.",
                "test",
                "set",
                "(Figure",
                "2,",
                "4,",
                "5).",
                "We",
                "compute",
                "statistics",
                "on",
                "test",
                "set",
                "classification",
                "responses",
                "from",
                "the",
                "model",
                "that",
                "scored",
                "the",
                "highest",
                "on",
                "the",
                "dev",
                "set",
                "(e.g.",
                "binomial",
                "or",
                "Wilcoxon",
                "signed",
                "rank",
                "tests)."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The decoding analyses used linear support vector machines (SVM) #TARGET_REF and Transformers, which can capture complex interactions of EEG data across time points. All classifiers were trained on the EEG training data, assessed on the dev set and scored on the independent test set. Hyperparameters and early stopping were selected based on the dev set. We assessed linear SVMs and Transformers on the dev set using 10 different random seed points. We show mean classification accuracy with 68% confidence intervals (CI) over those 10 replications on the dev (Table 4, Figure 3) resp. test set (Figure 2, 4, 5). We compute statistics on test set classification responses from the model that scored the highest on the dev set (e.g. binomial or Wilcoxon signed rank tests).",
        "output": "{\"INFO\": [\"linear support vector machines (SVM) #TARGET_REF\"], \"PERCEPT\": [\"The decoding analyses used\", \"We assessed linear SVMs and Transformers on the dev set using 10 different random seed points.\"], \"BACK\": [\"and Transformers,\"]}"
    },
    {
        "gold": {
            "text": [
                "Toxicity",
                "Datasets",
                "in",
                "Online",
                "Games",
                "In",
                "multiplayer",
                "online",
                "games,",
                "prior",
                "research",
                "focused",
                "on",
                "analysis",
                "of",
                "anti-social",
                "or",
                "disruptive",
                "behavior,",
                "socalled",
                "toxic",
                "behavior",
                "#TARGET_REF",
                "including",
                "cyberbullying",
                "#REF",
                "and",
                "griefing",
                "#REF",
                ".",
                "Although",
                "these",
                "terms",
                "contain",
                "similar",
                "elements,",
                "a",
                "single",
                "definition",
                "of",
                "toxic",
                "behavior",
                "is",
                "yet",
                "to",
                "emerge.",
                "Some",
                "studies",
                "have",
                "conducted",
                "data",
                "annotation",
                "using",
                "pre-defined",
                "lexicon",
                "categories",
                "#REF",
                "or",
                "toxic",
                "player",
                "information",
                "#REF",
                ".",
                "These",
                "annotation",
                "methods",
                "are",
                "not",
                "robust",
                "enough",
                "to",
                "handle",
                "unlabelled",
                "toxicity",
                "words",
                "or",
                "unreported",
                "toxic",
                "players."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Toxicity Datasets in Online Games In multiplayer online games, prior research focused on analysis of anti-social or disruptive behavior, socalled toxic behavior #TARGET_REF including cyberbullying #REF and griefing #REF . Although these terms contain similar elements, a single definition of toxic behavior is yet to emerge. Some studies have conducted data annotation using pre-defined lexicon categories #REF or toxic player information #REF . These annotation methods are not robust enough to handle unlabelled toxicity words or unreported toxic players.",
        "output": "{\"INFO\": [\"Toxicity Datasets in Online Games In multiplayer online games, prior research focused on analysis of anti-social or disruptive behavior, socalled toxic behavior #TARGET_REF\"], \"PERCEPT\": [\"these terms contain similar elements, a single definition of toxic behavior is yet to emerge. Some studies have conducted data annotation using pre-defined lexicon categories #REF or toxic player information #REF . These annotation methods are not robust enough to handle unlabelled toxicity words or unreported toxic players.\"], \"BACK\": [\"including cyberbullying #REF and griefing #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "memory-based",
                "approach",
                "is",
                "expected",
                "to",
                "offer",
                "solutions",
                "to",
                "these",
                "problems",
                "by",
                "allowing",
                "large",
                "numbers",
                "of",
                "cases",
                "to",
                "be",
                "stored",
                "in",
                "the",
                "memory,",
                "and",
                "make",
                "translation",
                "by",
                "using",
                "these",
                "cases.",
                "The",
                "memory-based",
                "translation",
                "essentially",
                "convert",
                "lime-complexity",
                "of",
                "rule",
                "application",
                "into",
                "space-complexity",
                "by",
                "preparing",
                "large",
                "examples",
                "of",
                "translation",
                "pairs.",
                "Since",
                "each",
                "case",
                "can",
                "be",
                "represented",
                "in",
                "a",
                "fairly",
                "context-sensitive",
                "manner",
                "with",
                "full",
                "semantic",
                "restrictions",
                "incorporated,",
                "the",
                "memorybased",
                "translation",
                "avoids",
                "expensive",
                "computations",
                "generally",
                "takes",
                "place",
                "in",
                "the",
                "rule-based",
                "translation",
                "system.",
                "In",
                "addition,",
                "the",
                "memory-based",
                "approach",
                "is",
                "expected",
                "to",
                "produce",
                "high",
                "quality",
                "translation",
                "due",
                "to",
                "its",
                "capability",
                "to",
                "reuse",
                "stylistic",
                "translation",
                "in",
                "the",
                "past.",
                "Since,",
                "detailed",
                "mechanisms",
                "and",
                "rationale",
                "for",
                "the",
                "memory-based",
                "translation",
                "approach",
                "has",
                "been",
                "discussed",
                "by",
                "relevant",
                "literatures",
                "(see",
                "#REF",
                ",",
                "#TARGET_REF",
                ",",
                "#REF",
                ",",
                "#REF",
                ",",
                "#REF",
                ",",
                "and",
                "#REF",
                "),",
                "we",
                "will",
                "simply",
                "focus",
                "on",
                "its",
                "massively",
                "parallel",
                "implementation",
                "and",
                "its",
                "performance."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The memory-based approach is expected to offer solutions to these problems by allowing large numbers of cases to be stored in the memory, and make translation by using these cases. The memory-based translation essentially convert lime-complexity of rule application into space-complexity by preparing large examples of translation pairs. Since each case can be represented in a fairly context-sensitive manner with full semantic restrictions incorporated, the memorybased translation avoids expensive computations generally takes place in the rule-based translation system. In addition, the memory-based approach is expected to produce high quality translation due to its capability to reuse stylistic translation in the past. Since, detailed mechanisms and rationale for the memory-based translation approach has been discussed by relevant literatures (see #REF , #TARGET_REF , #REF , #REF , #REF , and #REF ), we will simply focus on its massively parallel implementation and its performance.",
        "output": "{\"INFO\": [\"#TARGET_REF ,\"], \"PERCEPT\": [\"Since, detailed mechanisms and rationale for the memory-based translation approach has been discussed by relevant literatures\", \"we will simply focus on its massively parallel implementation and its performance.\"], \"BACK\": [\"Since each case can be represented in a fairly context-sensitive manner with full semantic restrictions incorporated, the memorybased translation avoids expensive computations generally takes place in the rule-based translation system. In addition, the memory-based approach is expected to produce high quality translation due to its capability to reuse stylistic translation in the past.\", \"(see #REF ,\", \"#REF , #REF , #REF , and #REF ),\"]}"
    },
    {
        "gold": {
            "text": [
                "other",
                "different",
                "automatic",
                "diacritization",
                "systems",
                "available",
                "online",
                "e.g.,",
                "#REF",
                "Some",
                "recent",
                "work",
                "in",
                "Arabic",
                "NLP",
                "has",
                "started",
                "to",
                "make",
                "use",
                "of",
                "such",
                "systems.",
                "For",
                "example,",
                "Al-Sallab",
                "et",
                "al.",
                "(",
                "2017)",
                "proposed",
                "AROMA,",
                "a",
                "recursive",
                "deep",
                "learning",
                "model",
                "for",
                "opinion",
                "mining",
                "in",
                "Arabic.",
                "Preprocessing",
                "in",
                "AROMA",
                "included",
                "morphological",
                "tokenization",
                "and",
                "automatic",
                "diacritization",
                "carried",
                "out",
                "by",
                "MADAMIRA",
                "#TARGET_REF",
                ".",
                "This",
                "resulted",
                "in",
                "improved",
                "performance",
                "in",
                "classifying",
                "opinion",
                "as",
                "positive",
                "or",
                "negative",
                "on",
                "a",
                "range",
                "of",
                "different",
                "Arabic",
                "corpora.",
                "Similarly,",
                "#REF",
                "used",
                "a",
                "Recursive",
                "Neural",
                "Tensor",
                "Network",
                "(RNTN)",
                "for",
                "sentiment",
                "analysis",
                "and",
                "reported",
                "that",
                "adding",
                "orthographic",
                "features",
                "such",
                "as",
                "diacritics",
                "improved",
                "the",
                "performance.",
                "They",
                "incorporated",
                "orthographic",
                "features",
                "such",
                "as",
                "diacritics",
                "by",
                "enlarging",
                "the",
                "vocabulary",
                "to",
                "have",
                "distinct",
                "word",
                "forms",
                "for",
                "different",
                "versions",
                "of",
                "the",
                "word",
                "(diacritized/undiacritized)",
                "and",
                "then",
                "deriving",
                "embeddings",
                "by",
                "training",
                "a",
                "Continuous",
                "Bag",
                "of",
                "Words",
                "(CBOW)",
                "model",
                "#REF",
                ".",
                "Similarly,",
                "#REF",
                "introduced",
                "automatic",
                "selective",
                "diacritization",
                "as",
                "a",
                "viable",
                "step",
                "in",
                "lexical",
                "disambiguation.",
                "They",
                "evaluated",
                "the",
                "system",
                "in",
                "downstream",
                "tasks",
                "including",
                "POS",
                "which",
                "improved",
                "from",
                "97.99%",
                "by",
                "baseline",
                "to",
                "98.70%.",
                "They",
                "trained",
                "word",
                "embeddings",
                "on",
                "selectively-diacritized",
                "dataset",
                "to",
                "enrich",
                "the",
                "vocabulary."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "other different automatic diacritization systems available online e.g., #REF Some recent work in Arabic NLP has started to make use of such systems. For example, Al-Sallab et al. ( 2017) proposed AROMA, a recursive deep learning model for opinion mining in Arabic. Preprocessing in AROMA included morphological tokenization and automatic diacritization carried out by MADAMIRA #TARGET_REF . This resulted in improved performance in classifying opinion as positive or negative on a range of different Arabic corpora. Similarly, #REF used a Recursive Neural Tensor Network (RNTN) for sentiment analysis and reported that adding orthographic features such as diacritics improved the performance. They incorporated orthographic features such as diacritics by enlarging the vocabulary to have distinct word forms for different versions of the word (diacritized/undiacritized) and then deriving embeddings by training a Continuous Bag of Words (CBOW) model #REF . Similarly, #REF introduced automatic selective diacritization as a viable step in lexical disambiguation. They evaluated the system in downstream tasks including POS which improved from 97.99% by baseline to 98.70%. They trained word embeddings on selectively-diacritized dataset to enrich the vocabulary.",
        "output": "{\"INFO\": [\"Preprocessing in AROMA included morphological tokenization and automatic diacritization carried out by MADAMIRA #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"This resulted in improved performance in classifying opinion as positive or negative on a range of different Arabic corpora.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "experiments,",
                "we",
                "used",
                "a",
                "Transformer-base",
                "model",
                "#TARGET_REF",
                "with",
                "the",
                "default",
                "configuration",
                "in",
                "Marian",
                "NMT",
                "#REF",
                ".",
                "The",
                "steps",
                "are",
                "as",
                "follows:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For the experiments, we used a Transformer-base model #TARGET_REF with the default configuration in Marian NMT #REF . The steps are as follows:",
        "output": "{\"INFO\": [\"a Transformer-base model #TARGET_REF\"], \"PERCEPT\": [\"For the experiments, we used\", \"with the default configuration in Marian NMT #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Note",
                "that",
                "the",
                "difference",
                "between",
                "total",
                "annotations",
                "excluding",
                "neutral",
                "(24,164)",
                "and",
                "the",
                "combined",
                "number",
                "of",
                "annotations",
                "#TARGET_REF",
                "differ",
                "because",
                "once",
                "the",
                "dataset",
                "was",
                "saved",
                "as",
                "a",
                "Python",
                "dictionary,",
                "identical",
                "lines",
                "were",
                "merged",
                "as",
                "one",
                "(i.e.",
                "some",
                "common",
                "movie",
                "lines",
                "like",
                "\"All",
                "right",
                "then!\"",
                "and",
                "\"I",
                "love",
                "you\"",
                "appeared",
                "multiple",
                "times",
                "from",
                "different",
                "sources).",
                "Additionally,",
                "lines",
                "annotated",
                "as",
                "both",
                "neutral",
                "and",
                "an",
                "emotion",
                "were",
                "removed",
                "from",
                "the",
                "neutral",
                "set."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Note that the difference between total annotations excluding neutral (24,164) and the combined number of annotations #TARGET_REF differ because once the dataset was saved as a Python dictionary, identical lines were merged as one (i.e. some common movie lines like \"All right then!\" and \"I love you\" appeared multiple times from different sources). Additionally, lines annotated as both neutral and an emotion were removed from the neutral set.",
        "output": "{\"INFO\": [\"combined number of annotations #TARGET_REF\"], \"PERCEPT\": [\"Note that the difference between total annotations excluding neutral (24,164) and the\", \"differ because once the dataset was saved as a Python dictionary, identical lines were merged as one\"], \"BACK\": [\"(i.e. some common movie lines like \\\"All right then!\\\" and \\\"I love you\\\" appeared multiple times from different sources).\"]}"
    },
    {
        "gold": {
            "text": [
                "Second,",
                "we",
                "use",
                "the",
                "PE",
                "2",
                "rr",
                "dataset",
                "#TARGET_REF",
                ",",
                "which",
                "is",
                "a",
                "manually",
                "annotated",
                "error",
                "analysis",
                "of",
                "MT",
                "output.",
                "Each",
                "example",
                "in",
                "the",
                "dataset",
                "consists",
                "of",
                "a",
                "source",
                "sentence,",
                "one",
                "MT",
                "output,",
                "and",
                "two",
                "correct",
                "translations,",
                "along",
                "with",
                "two",
                "error",
                "annotations.",
                "These",
                "annotations",
                "are",
                "word-level",
                "annotations",
                "into",
                "8",
                "broadly",
                "non-linguistic",
                "classes,",
                "such",
                "as",
                "German",
                "Source:",
                "Frauen",
                ",",
                "die",
                "in",
                "Burkina",
                "Faso",
                "zu",
                "Hexen",
                "abgestempelt",
                "werden",
                ",",
                "weisen",
                "in",
                "der",
                "Regel",
                "einige",
                "gemeinsame",
                "gesellschaftliche",
                "Merkmale",
                "auf",
                ".",
                "Original",
                "Translation",
                "(Annotated):",
                "Women",
                "in",
                "Burkina",
                "Faso",
                "[miss]",
                "are",
                "branded",
                "as",
                "witches",
                ",",
                "usually",
                "[miss]",
                "some",
                "common",
                "social",
                "features",
                ".",
                "Post-edit:",
                "Women",
                "in",
                "Burkina",
                "Faso",
                "who",
                "are",
                "branded",
                "as",
                "witches",
                "usually",
                "have",
                "some",
                "common",
                "social",
                "features",
                ".",
                "Original",
                "Reference:",
                "Women",
                "declared",
                "as",
                "witches",
                "in",
                "Burkina",
                "Faso",
                "usually",
                "have",
                "several",
                "common",
                "characteristics",
                ".",
                "\"addition\",",
                "\"lexical",
                "error\",",
                "or",
                "\"untranslated\".",
                "See",
                "Figure",
                "2",
                "for",
                "an",
                "example."
            ],
            "context": [
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Second, we use the PE 2 rr dataset #TARGET_REF , which is a manually annotated error analysis of MT output. Each example in the dataset consists of a source sentence, one MT output, and two correct translations, along with two error annotations. These annotations are word-level annotations into 8 broadly non-linguistic classes, such as German Source: Frauen , die in Burkina Faso zu Hexen abgestempelt werden , weisen in der Regel einige gemeinsame gesellschaftliche Merkmale auf . Original Translation (Annotated): Women in Burkina Faso [miss] are branded as witches , usually [miss] some common social features . Post-edit: Women in Burkina Faso who are branded as witches usually have some common social features . Original Reference: Women declared as witches in Burkina Faso usually have several common characteristics . \"addition\", \"lexical error\", or \"untranslated\". See Figure 2 for an example.",
        "output": "{\"INFO\": [\"the PE 2 rr dataset #TARGET_REF , which is a manually annotated error analysis of MT output. Each example in the dataset consists of a source sentence, one MT output, and two correct translations, along with two error annotations. These annotations are word-level annotations into 8 broadly non-linguistic classes,\"], \"PERCEPT\": [\"we use\"], \"BACK\": [\"such as German Source: Frauen , die in Burkina Faso zu Hexen abgestempelt werden , weisen in der Regel einige gemeinsame gesellschaftliche Merkmale auf . Original Translation (Annotated): Women in Burkina Faso [miss] are branded as witches , usually [miss] some common social features . Post-edit: Women in Burkina Faso who are branded as witches usually have some common social features . Original Reference: Women declared as witches in Burkina Faso usually have several common characteristics . \\\"addition\\\", \\\"lexical error\\\", or \\\"untranslated\\\". See Figure 2 for an example.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "SemEval-2021",
                "Task-5,",
                "#REF",
                "provide",
                "a",
                "dataset",
                "of",
                "10k",
                "English",
                "texts",
                "filtered",
                "from",
                "Civil",
                "Comments",
                "#REF",
                "dataset.",
                "Each",
                "text",
                "is",
                "crowd-annotated",
                "with",
                "character",
                "offsets",
                "that",
                "make",
                "the",
                "text",
                "toxic.",
                "The",
                "task",
                "is",
                "to",
                "predict",
                "these",
                "character",
                "offsets",
                "given",
                "the",
                "text.",
                "The",
                "work",
                "presented",
                "in",
                "this",
                "paper",
                "aims",
                "to",
                "provide",
                "a",
                "comprehensive",
                "analysis",
                "of",
                "simple",
                "Token",
                "Classification",
                "(TC)",
                "and",
                "Span",
                "Prediction",
                "(SP)",
                "methods",
                "across",
                "multiple",
                "BERT-based",
                "models",
                "-BERT",
                "#TARGET_REF",
                ",",
                "RoBERTa",
                "#REF",
                "and",
                "SpanBERT",
                "#REF",
                ".",
                "Additionally,",
                "we",
                "experiment",
                "with",
                "a",
                "few",
                "hybrid",
                "approaches",
                "-Multi-Span",
                "(MSP),",
                "where",
                "the",
                "model",
                "is",
                "trained",
                "on",
                "multiple",
                "spans",
                "simultaneously,",
                "Span+Token",
                "(SP-TC),",
                "where",
                "the",
                "model",
                "is",
                "trained",
                "on",
                "both",
                "kinds",
                "of",
                "tasks",
                "simultaneously,",
                "LSTM-CRF",
                "(LC),",
                "which",
                "uses",
                "a",
                "LSTM",
                "and",
                "CRF",
                "layer",
                "on",
                "top",
                "of",
                "BERT-based",
                "models,",
                "and",
                "a",
                "combination",
                "of",
                "predicted",
                "offsets",
                "for",
                "above",
                "techniques",
                "using",
                "union/intersection.",
                "In",
                "Section",
                "2,",
                "we",
                "perform",
                "a",
                "compendious",
                "literature",
                "survey.",
                "Section",
                "3",
                "elucidates",
                "our",
                "approach,",
                "including",
                "the",
                "modelling",
                "aspect,",
                "the",
                "various",
                "variants",
                "of",
                "the",
                "base",
                "model,",
                "and",
                "the",
                "different",
                "Hybrid",
                "Systems.",
                "In",
                "Section",
                "4,",
                "we",
                "describe",
                "our",
                "experimental",
                "setup",
                "and",
                "hyperparameters",
                "used",
                "for",
                "our",
                "methods.",
                "Lastly,",
                "in",
                "Section",
                "5",
                "we",
                "analyze",
                "our",
                "results",
                "and",
                "perform",
                "ablative",
                "analysis",
                "on",
                "our",
                "systems."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In SemEval-2021 Task-5, #REF provide a dataset of 10k English texts filtered from Civil Comments #REF dataset. Each text is crowd-annotated with character offsets that make the text toxic. The task is to predict these character offsets given the text. The work presented in this paper aims to provide a comprehensive analysis of simple Token Classification (TC) and Span Prediction (SP) methods across multiple BERT-based models -BERT #TARGET_REF , RoBERTa #REF and SpanBERT #REF . Additionally, we experiment with a few hybrid approaches -Multi-Span (MSP), where the model is trained on multiple spans simultaneously, Span+Token (SP-TC), where the model is trained on both kinds of tasks simultaneously, LSTM-CRF (LC), which uses a LSTM and CRF layer on top of BERT-based models, and a combination of predicted offsets for above techniques using union/intersection. In Section 2, we perform a compendious literature survey. Section 3 elucidates our approach, including the modelling aspect, the various variants of the base model, and the different Hybrid Systems. In Section 4, we describe our experimental setup and hyperparameters used for our methods. Lastly, in Section 5 we analyze our results and perform ablative analysis on our systems.",
        "output": "{\"INFO\": [\"-BERT #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"The work presented in this paper aims to provide a comprehensive analysis of simple Token Classification (TC) and Span Prediction (SP) methods across multiple BERT-based models\", \"RoBERTa #REF and SpanBERT #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Equations",
                "7",
                "and",
                "8",
                "attempt",
                "to",
                "account",
                "for",
                "this",
                "by",
                "using",
                "a",
                "shared",
                "weight",
                "concatenation",
                "and",
                "a",
                "weighted",
                "concatenation",
                "respectively.",
                "In",
                "equation",
                "7,",
                "W",
                "∈",
                "R",
                "k×k",
                "is",
                "a",
                "weight",
                "matrix,",
                "where",
                "the",
                "values",
                "are",
                "scaled",
                "down",
                "to",
                "1,",
                "in",
                "order",
                "to",
                "capture",
                "the",
                "relative",
                "importance",
                "of",
                "each",
                "h",
                "c",
                "i",
                "and",
                "h",
                "w",
                "i",
                "∀h",
                "c",
                "i",
                "∈",
                "h",
                "c",
                ",",
                "h",
                "w",
                "i",
                "∈",
                "h",
                "w",
                ".",
                "This",
                "shared",
                "weighting",
                "is",
                "a",
                "modification",
                "of",
                "the",
                "concept",
                "of",
                "leaky",
                "integration",
                "#TARGET_REF",
                ".",
                "On",
                "the",
                "other",
                "hand,",
                "equation",
                "8",
                "uses",
                "two",
                "independent",
                "weight",
                "matrices,",
                "W",
                "c",
                ",",
                "W",
                "w",
                "∈",
                "R",
                "k×k",
                ",",
                "which",
                "does",
                "not",
                "constrain",
                "the",
                "network",
                "to",
                "use",
                "on",
                "other",
                "the",
                "other",
                "hidden",
                "representation.",
                "However,",
                "the",
                "gradients",
                "are",
                "still",
                "clipped",
                "at",
                "a",
                "low",
                "value",
                "(≈",
                "1)",
                "to",
                "avoid",
                "explosion."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Equations 7 and 8 attempt to account for this by using a shared weight concatenation and a weighted concatenation respectively. In equation 7, W ∈ R k×k is a weight matrix, where the values are scaled down to 1, in order to capture the relative importance of each h c i and h w i ∀h c i ∈ h c , h w i ∈ h w . This shared weighting is a modification of the concept of leaky integration #TARGET_REF . On the other hand, equation 8 uses two independent weight matrices, W c , W w ∈ R k×k , which does not constrain the network to use on other the other hidden representation. However, the gradients are still clipped at a low value (≈ 1) to avoid explosion.",
        "output": "{\"INFO\": [\"the concept of leaky integration #TARGET_REF\"], \"PERCEPT\": [\"This shared weighting is a modification of\"], \"BACK\": [\"Equations 7 and 8 attempt to account for this by using a shared weight concatenation and a weighted concatenation respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "Professional",
                "translations",
                "of",
                "Doc",
                "A",
                "into",
                "English",
                "and",
                "Doc",
                "B",
                "into",
                "Russian",
                "were",
                "commissioned",
                "as",
                "part",
                "of",
                "the",
                "WMT-14",
                "shared",
                "translation",
                "task",
                "#REF",
                ".",
                "The",
                "Russian",
                "version",
                "of",
                "each",
                "text",
                "was",
                "translated",
                "automatically",
                "using",
                "Moses",
                "#REF",
                "by",
                "#TARGET_REF",
                "as",
                "part",
                "of",
                "their",
                "WMT14",
                "shared",
                "task",
                "submission.",
                "As",
                "a",
                "side",
                "effect",
                "of",
                "the",
                "phrase-based",
                "MT",
                "process,",
                "Moses",
                "can",
                "be",
                "configured",
                "to",
                "produce",
                "alignment",
                "links,",
                "indicating",
                "which",
                "target",
                "language",
                "words",
                "were",
                "produced",
                "from",
                "which",
                "source",
                "language",
                "words.",
                "To",
                "enable",
                "maximal",
                "comparability",
                "with",
                "the",
                "post-editing",
                "results",
                "of",
                "#REF",
                ",",
                "we",
                "make",
                "use",
                "of",
                "Russian-English",
                "machine",
                "translation",
                "results",
                "and",
                "alignments",
                "from",
                "that",
                "work",
                "here."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Professional translations of Doc A into English and Doc B into Russian were commissioned as part of the WMT-14 shared translation task #REF . The Russian version of each text was translated automatically using Moses #REF by #TARGET_REF as part of their WMT14 shared task submission. As a side effect of the phrase-based MT process, Moses can be configured to produce alignment links, indicating which target language words were produced from which source language words. To enable maximal comparability with the post-editing results of #REF , we make use of Russian-English machine translation results and alignments from that work here.",
        "output": "{\"INFO\": [\"The Russian version of each text was translated automatically using Moses #REF by #TARGET_REF as part of their WMT14 shared task submission.\"], \"PERCEPT\": [], \"BACK\": [\"Moses can be configured to produce alignment links,\"]}"
    },
    {
        "gold": {
            "text": [
                "All",
                "baseline",
                "methods",
                "were",
                "built",
                "on",
                "the",
                "Transformer",
                "architecture",
                "with",
                "6-layer",
                "encoder",
                "and",
                "decoder,",
                "and",
                "initialized",
                "with",
                "pre-trained",
                "parameters",
                "from",
                "BARTbase",
                "#REF",
                ",",
                "which",
                "is",
                "one",
                "of",
                "the",
                "stateof-the-art",
                "pre-trained",
                "Transformer",
                "models",
                "for",
                "natural",
                "language",
                "generation",
                "#TARGET_REF",
                ".",
                "In",
                "our",
                "MoKGE,",
                "the",
                "Transformer",
                "parameters",
                "were",
                "also",
                "initialized",
                "by",
                "BART-base,",
                "in",
                "order",
                "to",
                "make",
                "fair",
                "comparison",
                "with",
                "all",
                "baseline",
                "methods.",
                "The",
                "R-GCN",
                "parameters",
                "were",
                "random",
                "initialized."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "All baseline methods were built on the Transformer architecture with 6-layer encoder and decoder, and initialized with pre-trained parameters from BARTbase #REF , which is one of the stateof-the-art pre-trained Transformer models for natural language generation #TARGET_REF . In our MoKGE, the Transformer parameters were also initialized by BART-base, in order to make fair comparison with all baseline methods. The R-GCN parameters were random initialized.",
        "output": "{\"INFO\": [\"the stateof-the-art pre-trained Transformer models for natural language generation #TARGET_REF .\"], \"PERCEPT\": [\"All baseline methods were built on the Transformer architecture with 6-layer encoder and decoder, and initialized with pre-trained parameters from BARTbase #REF , which is one of\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "language",
                "features,",
                "which",
                "can",
                "be",
                "fine-tuned",
                "for",
                "applications",
                "like",
                "semantic",
                "analysis",
                "and",
                "question",
                "answering.",
                "Multi-lingual-BERT",
                "(mBERT)",
                "is",
                "a",
                "BERT",
                "model",
                "pre-trained",
                "using",
                "the",
                "Wikipedia",
                "text",
                "corpus",
                "#TARGET_REF",
                "in",
                "more",
                "than",
                "100",
                "languages",
                "around",
                "the",
                "world.",
                "XLM-RoBERTa",
                "#REF",
                "scaled",
                "this",
                "idea",
                "with",
                "more",
                "than",
                "2",
                "terabytes",
                "of",
                "common",
                "crawl",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "language features, which can be fine-tuned for applications like semantic analysis and question answering. Multi-lingual-BERT (mBERT) is a BERT model pre-trained using the Wikipedia text corpus #TARGET_REF in more than 100 languages around the world. XLM-RoBERTa #REF scaled this idea with more than 2 terabytes of common crawl data.",
        "output": "{\"INFO\": [\"Multi-lingual-BERT (mBERT) is a BERT model pre-trained using the Wikipedia text corpus #TARGET_REF in more than 100 languages around the world.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "For",
                "each",
                "language,",
                "I",
                "use",
                "the",
                "fastText",
                "aligned",
                "word",
                "vectors",
                "#TARGET_REF",
                ",",
                "3",
                "limiting",
                "the",
                "vocabulary",
                "set",
                "V",
                "to",
                "the",
                "top",
                "200,000",
                "vectors",
                "by",
                "frequency.",
                "For",
                "the",
                "target",
                "word",
                "vocabulary",
                "W",
                ",",
                "I",
                "take",
                "the",
                "10,000",
                "most",
                "frequent",
                "wordforms",
                "among",
                "all",
                "attributive",
                "adjectives",
                "extracted",
                "from",
                "the",
                "entire",
                "CoNLL",
                "Wikipedia",
                "dataset."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For each language, I use the fastText aligned word vectors #TARGET_REF , 3 limiting the vocabulary set V to the top 200,000 vectors by frequency. For the target word vocabulary W , I take the 10,000 most frequent wordforms among all attributive adjectives extracted from the entire CoNLL Wikipedia dataset.",
        "output": "{\"INFO\": [\"the fastText aligned word vectors #TARGET_REF ,\"], \"PERCEPT\": [\"For each language, I use\", \"3 limiting the vocabulary set V to the top 200,000 vectors by frequency. For the target word vocabulary W , I take the 10,000 most frequent wordforms among all attributive adjectives extracted from the entire CoNLL Wikipedia dataset.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Of",
                "particular",
                "interest",
                "to",
                "us",
                "were",
                "the",
                "keywords",
                "apology",
                "(noun)",
                "and",
                "regret",
                "(verb).",
                "We",
                "compare",
                "the",
                "SentiWordNet",
                "scores",
                "and",
                "the",
                "WordNet-Affect",
                "labels",
                "of",
                "these",
                "two",
                "keywords.",
                "While",
                "emotion",
                "is",
                "defined",
                "as",
                "a",
                "relatively",
                "brief",
                "episode",
                "of",
                "response",
                "to",
                "the",
                "evaluation",
                "of",
                "an",
                "external",
                "or",
                "internal",
                "event",
                "as",
                "being",
                "of",
                "major",
                "significance.",
                "(such",
                "as",
                "angry,",
                "sad,",
                "joyful,",
                "fearful,",
                "ashamed,",
                "proud,",
                "elated,",
                "desperate),",
                "a",
                "sentiment",
                "is",
                "the",
                "positive",
                "or",
                "negative",
                "orientation",
                "that",
                "a",
                "person",
                "expresses",
                "toward",
                "some",
                "object",
                "or",
                "situation",
                "#TARGET_REF",
                ".",
                "Thus,",
                "we",
                "can",
                "posit",
                "that",
                "the",
                "word",
                "apology",
                "which",
                "has",
                "no",
                "emotion",
                "label,",
                "has",
                "no",
                "or",
                "weak",
                "emotional",
                "connect,",
                "which",
                "also",
                "aligns",
                "with",
                "our",
                "conclusion",
                "about",
                "the",
                "keyword",
                "apologize.",
                "In",
                "contrast,",
                "the",
                "verb",
                "regret",
                "helps",
                "to",
                "effectively",
                "communicate",
                "the",
                "emotion",
                "of",
                "repentance.",
                "Looking",
                "at",
                "the",
                "sentiment",
                "associated",
                "with",
                "these",
                "words,",
                "we",
                "conclude",
                "that",
                "the",
                "mental",
                "attitude",
                "of",
                "the",
                "writer",
                "is",
                "more",
                "objective",
                "to",
                "the",
                "situation",
                "in",
                "using",
                "the",
                "verb",
                "regret",
                "while",
                "it",
                "is",
                "highly",
                "negative",
                "in",
                "the",
                "case",
                "of",
                "the",
                "usage",
                "of",
                "the",
                "word",
                "apology.",
                "This",
                "further",
                "implies",
                "that",
                "a",
                "high",
                "negative",
                "sentiment",
                "score",
                "means",
                "that",
                "the",
                "writer",
                "of",
                "the",
                "apology",
                "realizes",
                "the",
                "gravity",
                "of",
                "the",
                "transgression",
                "and",
                "to",
                "some",
                "extent",
                "admits",
                "to",
                "the",
                "wrong",
                "done.",
                "However,",
                "a",
                "high",
                "objective",
                "score",
                "implies",
                "the",
                "writer",
                "taking",
                "a",
                "neutral",
                "stance",
                "to",
                "the",
                "situation",
                "and",
                "not",
                "necessarily",
                "admitting",
                "to",
                "any",
                "wrongdoing."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Of particular interest to us were the keywords apology (noun) and regret (verb). We compare the SentiWordNet scores and the WordNet-Affect labels of these two keywords. While emotion is defined as a relatively brief episode of response to the evaluation of an external or internal event as being of major significance. (such as angry, sad, joyful, fearful, ashamed, proud, elated, desperate), a sentiment is the positive or negative orientation that a person expresses toward some object or situation #TARGET_REF . Thus, we can posit that the word apology which has no emotion label, has no or weak emotional connect, which also aligns with our conclusion about the keyword apologize. In contrast, the verb regret helps to effectively communicate the emotion of repentance. Looking at the sentiment associated with these words, we conclude that the mental attitude of the writer is more objective to the situation in using the verb regret while it is highly negative in the case of the usage of the word apology. This further implies that a high negative sentiment score means that the writer of the apology realizes the gravity of the transgression and to some extent admits to the wrong done. However, a high objective score implies the writer taking a neutral stance to the situation and not necessarily admitting to any wrongdoing.",
        "output": "{\"INFO\": [\"a sentiment is the positive or negative orientation that a person expresses toward some object or situation #TARGET_REF .\"], \"PERCEPT\": [\"While emotion is defined as a relatively brief episode of response to the evaluation of an external or internal event as being of major significance.\", \"Thus, we can posit that the word apology which has no emotion label, has no or weak emotional connect,\"], \"BACK\": [\"(such as angry, sad, joyful, fearful, ashamed, proud, elated, desperate),\", \"which also aligns with our conclusion about the keyword apologize. In contrast, the verb regret helps to effectively communicate the emotion of repentance.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "memory",
                "component",
                "and",
                "action",
                "gate",
                "are",
                "endto-end",
                "trained",
                "in",
                "a",
                "self-supervised",
                "way,",
                "where",
                "the",
                "feedback",
                "is",
                "whether",
                "an",
                "utterance",
                "and",
                "its",
                "action",
                "representation",
                "lead",
                "to",
                "similar",
                "state",
                "transitions,",
                "We",
                "can",
                "measure",
                "such",
                "similarity",
                "using",
                "a",
                "dialogue",
                "state",
                "tracking",
                "(DST)",
                "model.",
                "However,",
                "a",
                "direct",
                "application",
                "of",
                "the",
                "DST",
                "model",
                "trained",
                "by",
                "Eqn.",
                "4",
                "might",
                "be",
                "prone",
                "to",
                "attribute",
                "changes",
                "between",
                "original",
                "utterances",
                "and",
                "compact",
                "natural",
                "language",
                "actions,",
                "which",
                "results",
                "in",
                "insufficient",
                "feedback.",
                "To",
                "address",
                "this",
                "issue,",
                "we",
                "adopt",
                "a",
                "denoising",
                "training",
                "strategy",
                "inspired",
                "by",
                "unsupervised",
                "machine",
                "translation",
                "#REF",
                ",",
                "and",
                "obtain",
                "a",
                "DST",
                "model",
                "that",
                "is",
                "more",
                "robust",
                "to",
                "the",
                "attribute",
                "transformation.",
                "Specifically,",
                "we",
                "apply",
                "a",
                "noise",
                "function",
                "g(x)",
                "to",
                "the",
                "utterances,",
                "and",
                "modify",
                "the",
                "DST",
                "model",
                "training",
                "loss",
                "as:L",
                "dst",
                "=",
                "d",
                "i",
                "−",
                "log(b",
                "t",
                "•",
                "p",
                "B",
                "(g(u",
                "t",
                "),",
                "g(x",
                "t−1",
                "),",
                "c",
                "t−1",
                "))",
                "(8)where",
                "the",
                "noise",
                "function",
                "corrupts",
                "the",
                "input",
                "utterance",
                "by",
                "performing",
                "word",
                "drops",
                "and",
                "word",
                "order",
                "shuffling",
                "as",
                "specified",
                "in",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The memory component and action gate are endto-end trained in a self-supervised way, where the feedback is whether an utterance and its action representation lead to similar state transitions, We can measure such similarity using a dialogue state tracking (DST) model. However, a direct application of the DST model trained by Eqn. 4 might be prone to attribute changes between original utterances and compact natural language actions, which results in insufficient feedback. To address this issue, we adopt a denoising training strategy inspired by unsupervised machine translation #REF , and obtain a DST model that is more robust to the attribute transformation. Specifically, we apply a noise function g(x) to the utterances, and modify the DST model training loss as:L dst = d i − log(b t • p B (g(u t ), g(x t−1 ), c t−1 )) (8)where the noise function corrupts the input utterance by performing word drops and word order shuffling as specified in #TARGET_REF .",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"(8)where the noise function corrupts the input utterance by performing word drops and word order shuffling as specified in #TARGET_REF .\"], \"BACK\": [\"The memory component and action gate are endto-end trained in a self-supervised way, where the feedback is whether an utterance and its action representation lead to similar state transitions,\", \"4 might be prone to attribute changes between original utterances and compact natural language actions, which results in insufficient feedback. To address this issue, we adopt a denoising training strategy inspired by unsupervised machine translation #REF , and obtain a DST model that is more robust to the attribute transformation.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "take",
                "advantage",
                "of",
                "the",
                "potential",
                "lexical",
                "sharing",
                "of",
                "the",
                "languages",
                "(e.g.",
                "loanwords)",
                "and",
                "address",
                "the",
                "polysynthetic",
                "nature",
                "of",
                "the",
                "indigenous",
                "languages,",
                "we",
                "trained",
                "a",
                "unique",
                "multilingual",
                "segmentation",
                "model",
                "by",
                "sampling",
                "all",
                "languages",
                "with",
                "a",
                "uniform",
                "distribution.",
                "We",
                "used",
                "the",
                "unigram",
                "model",
                "implementation",
                "in",
                "SentencePiece",
                "#TARGET_REF",
                "with",
                "a",
                "vocabulary",
                "size",
                "of",
                "32,000."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To take advantage of the potential lexical sharing of the languages (e.g. loanwords) and address the polysynthetic nature of the indigenous languages, we trained a unique multilingual segmentation model by sampling all languages with a uniform distribution. We used the unigram model implementation in SentencePiece #TARGET_REF with a vocabulary size of 32,000.",
        "output": "{\"INFO\": [\"in SentencePiece #TARGET_REF with a vocabulary size of 32,000.\"], \"PERCEPT\": [\"We used the unigram model implementation\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "marginal",
                "position",
                "of",
                "word",
                "formation",
                "is",
                "illustrated",
                "by",
                "the",
                "treatment",
                "in",
                "general",
                "surveys",
                "of",
                "computational",
                "linguistics.",
                "Surveys",
                "such",
                "as",
                "#REF",
                "and",
                "9",
                "Stem",
                "changes",
                "have",
                "been",
                "analysed",
                "in",
                "a",
                "number",
                "of",
                "different",
                "ways",
                "in",
                "the",
                "literature.",
                "Since",
                "many",
                "forms",
                "look",
                "like",
                "inflected",
                "forms",
                "(the",
                "so-called",
                "paradigmic",
                "forms)",
                "it",
                "is",
                "sometimes",
                "argued",
                "that",
                "these",
                "are",
                "inflected",
                "forms",
                "in",
                "word",
                "formation.",
                "There",
                "are",
                "good",
                "arguments",
                "against",
                "this",
                "view:",
                "(a)",
                "there",
                "are",
                "many",
                "stems",
                "that",
                "do",
                "not",
                "change",
                "in",
                "word",
                "formation,",
                "(b)",
                "changed",
                "stems",
                "do",
                "not",
                "necessarily",
                "have",
                "the",
                "semantics",
                "of",
                "the",
                "corresponding",
                "plural",
                "form",
                "and",
                "unchanged",
                "stems",
                "do",
                "not",
                "necessarily",
                "have",
                "the",
                "semantics",
                "of",
                "the",
                "singular,",
                "and",
                "(c)",
                "there",
                "are",
                "also",
                "non-paradigmic",
                "forms.",
                "See",
                "the",
                "discussions",
                "in",
                "#REF",
                "and",
                "#REF",
                ".",
                "The",
                "existence",
                "of",
                "stem",
                "changes",
                "is",
                "often",
                "used",
                "as",
                "an",
                "argument",
                "against",
                "the",
                "IA",
                "model,",
                "e.g.",
                "by",
                "#REF",
                ".",
                "An",
                "analysis",
                "in",
                "terms",
                "of",
                "\"stem",
                "formation\"",
                "is",
                "elaborated",
                "by",
                "ten",
                "Hacken",
                "(1994).",
                "#TARGET_REF",
                "do",
                "not",
                "even",
                "mention",
                "inflection",
                "and",
                "word",
                "formation",
                "as",
                "terms,",
                "let",
                "alone",
                "make",
                "the",
                "conceptual",
                "distinction.",
                "The",
                "starting",
                "point",
                "of",
                "the",
                "approaches",
                "they",
                "describe",
                "is",
                "clearly",
                "inflection.",
                "As",
                "far",
                "as",
                "word",
                "formation",
                "phenomena",
                "are",
                "treated,",
                "e.g.",
                "#REF",
                ",",
                "they",
                "are",
                "not",
                "considered",
                "from",
                "the",
                "perspective",
                "of",
                "the",
                "creation",
                "of",
                "new",
                "lexemes,",
                "but",
                "as",
                "examples",
                "of",
                "more",
                "difficult",
                "combinations",
                "of",
                "formatives."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The marginal position of word formation is illustrated by the treatment in general surveys of computational linguistics. Surveys such as #REF and 9 Stem changes have been analysed in a number of different ways in the literature. Since many forms look like inflected forms (the so-called paradigmic forms) it is sometimes argued that these are inflected forms in word formation. There are good arguments against this view: (a) there are many stems that do not change in word formation, (b) changed stems do not necessarily have the semantics of the corresponding plural form and unchanged stems do not necessarily have the semantics of the singular, and (c) there are also non-paradigmic forms. See the discussions in #REF and #REF . The existence of stem changes is often used as an argument against the IA model, e.g. by #REF . An analysis in terms of \"stem formation\" is elaborated by ten Hacken (1994). #TARGET_REF do not even mention inflection and word formation as terms, let alone make the conceptual distinction. The starting point of the approaches they describe is clearly inflection. As far as word formation phenomena are treated, e.g. #REF , they are not considered from the perspective of the creation of new lexemes, but as examples of more difficult combinations of formatives.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"#TARGET_REF do not even mention inflection and word formation as terms, let alone make the conceptual distinction.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Subjective",
                "evaluation",
                "was",
                "performed",
                "after",
                "first",
                "poor",
                "BLEU",
                "results",
                "triggered",
                "some",
                "distrust.",
                "Many",
                "authors",
                "agree",
                "that",
                "BLEU",
                "metric",
                "systematically",
                "penalizes",
                "RBMT",
                "systems",
                "#REF",
                "and",
                "it",
                "is",
                "not",
                "suited",
                "for",
                "highly",
                "inflexible",
                "languages.",
                "Authors",
                "of",
                "METEOR",
                "#TARGET_REF",
                ",",
                "#REF",
                ")",
                "state",
                "that",
                "their",
                "system",
                "fixes",
                "most",
                "of",
                "the",
                "problems",
                "encountered",
                "using",
                "BLEU",
                "metric,",
                "they",
                "state",
                "that",
                "METEOR",
                "correlates",
                "highly",
                "with",
                "human",
                "judgement.",
                "Unfortunately",
                "METEOR",
                "does",
                "not",
                "support",
                "our",
                "language",
                "pair,",
                "we",
                "hope",
                "to",
                "change",
                "this",
                "in",
                "the",
                "near",
                "future,",
                "see",
                "further",
                "work",
                "Separate",
                "scales",
                "for",
                "fluency",
                "and",
                "adequacy",
                "were",
                "developed",
                "under",
                "the",
                "assumption",
                "that",
                "a",
                "translation",
                "might",
                "be",
                "disfluent",
                "but",
                "contain",
                "all",
                "the",
                "information",
                "from",
                "the",
                "source."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Subjective evaluation was performed after first poor BLEU results triggered some distrust. Many authors agree that BLEU metric systematically penalizes RBMT systems #REF and it is not suited for highly inflexible languages. Authors of METEOR #TARGET_REF , #REF ) state that their system fixes most of the problems encountered using BLEU metric, they state that METEOR correlates highly with human judgement. Unfortunately METEOR does not support our language pair, we hope to change this in the near future, see further work Separate scales for fluency and adequacy were developed under the assumption that a translation might be disfluent but contain all the information from the source.",
        "output": "{\"INFO\": [\"METEOR #TARGET_REF ,\"], \"PERCEPT\": [\"Unfortunately METEOR does not support our language pair, we hope to change this in the near future, see further work Separate scales for fluency and adequacy were developed under the assumption that a translation might be disfluent but contain all the information from the source.\"], \"BACK\": [\"Subjective evaluation was performed after first poor BLEU results triggered some distrust. Many authors agree that BLEU metric systematically penalizes RBMT systems #REF and it is not suited for highly inflexible languages. Authors of\", \"#REF ) state that their system fixes most of the problems encountered using BLEU metric, they state that METEOR correlates highly with human judgement.\"]}"
    },
    {
        "gold": {
            "text": [
                "MMB",
                "must",
                "be",
                "credited",
                "with",
                "helping",
                "to",
                "keep",
                "belief",
                "in",
                "MT",
                "alive",
                "during",
                "long",
                "years",
                "of",
                "public",
                "scepticism,",
                "and",
                "above",
                "all",
                "with",
                "the",
                "belief",
                "that",
                "MT",
                "was",
                "an",
                "intellectually",
                "challenging",
                "and",
                "interesting",
                "task",
                "#TARGET_REF",
                ".",
                "I",
                "think",
                "that",
                "is",
                "now",
                "widely",
                "granted,",
                "although",
                "it",
                "was",
                "not",
                "conceded",
                "within",
                "artificial",
                "intelligence,",
                "for",
                "example,",
                "until",
                "relatively",
                "recently.",
                "There",
                "it",
                "was",
                "generally",
                "thought",
                "that,",
                "although",
                "language",
                "understanding",
                "in",
                "general",
                "required",
                "inference",
                "knowledge",
                "of",
                "the",
                "world",
                "and",
                "processing",
                "of",
                "almost",
                "arbitrary",
                "complexity,",
                "MT",
                "did",
                "not:",
                "it",
                "was",
                "a",
                "task",
                "that",
                "required",
                "only",
                "superficial",
                "processing",
                "of",
                "language.",
                "I",
                "think",
                "that",
                "now",
                "almost",
                "everyone",
                "concedes",
                "that",
                "that",
                "view",
                "is",
                "false."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "MMB must be credited with helping to keep belief in MT alive during long years of public scepticism, and above all with the belief that MT was an intellectually challenging and interesting task #TARGET_REF . I think that is now widely granted, although it was not conceded within artificial intelligence, for example, until relatively recently. There it was generally thought that, although language understanding in general required inference knowledge of the world and processing of almost arbitrary complexity, MT did not: it was a task that required only superficial processing of language. I think that now almost everyone concedes that that view is false.",
        "output": "{\"INFO\": [\"the belief that MT was an intellectually challenging and interesting task #TARGET_REF\"], \"PERCEPT\": [\"MMB must be credited with helping to keep belief in MT alive during long years of public scepticism, and above all with\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "A",
                "semantic",
                "analysis",
                "of",
                "the",
                "selected",
                "keywords",
                "was",
                "done",
                "using",
                "WordNet",
                "(3.1).",
                "We",
                "used",
                "semantic",
                "relations",
                "such",
                "as",
                "hypernymy,",
                "troponymy",
                "and",
                "entailment",
                "#TARGET_REF",
                "to",
                "find",
                "the",
                "implications",
                "that",
                "the",
                "keywords",
                "may",
                "have,",
                "as",
                "far",
                "as",
                "their",
                "communicative",
                "goals",
                "are",
                "concerned."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "A semantic analysis of the selected keywords was done using WordNet (3.1). We used semantic relations such as hypernymy, troponymy and entailment #TARGET_REF to find the implications that the keywords may have, as far as their communicative goals are concerned.",
        "output": "{\"INFO\": [\"entailment #TARGET_REF\"], \"PERCEPT\": [\"We used semantic relations such as\", \"to find the implications that the keywords may have, as far as their communicative goals are concerned.\"], \"BACK\": [\"hypernymy, troponymy and\"]}"
    },
    {
        "gold": {
            "text": [
                "One",
                "of",
                "the",
                "crucial",
                "issues",
                "regarding",
                "the",
                "evaluation",
                "of",
                "multi-hop",
                "inference",
                "models",
                "is",
                "the",
                "possibility",
                "to",
                "achieve",
                "strong",
                "overall",
                "performance",
                "without",
                "using",
                "real",
                "compositional",
                "methods",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "in",
                "order",
                "to",
                "evaluate",
                "multi-hop",
                "inference",
                "more",
                "explicitly,",
                "we",
                "break",
                "down",
                "the",
                "performance",
                "of",
                "each",
                "model",
                "with",
                "respect",
                "to",
                "the",
                "difficulty",
                "of",
                "accessing",
                "specific",
                "facts",
                "in",
                "an",
                "explanation",
                "via",
                "direct",
                "lexical",
                "overlap.",
                "This",
                "comes",
                "from",
                "the",
                "assumption",
                "that",
                "facts",
                "sharing",
                "many",
                "terms",
                "with",
                "question",
                "or",
                "answer",
                "are",
                "relatively",
                "easier",
                "to",
                "find",
                "and",
                "rank",
                "highly."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "One of the crucial issues regarding the evaluation of multi-hop inference models is the possibility to achieve strong overall performance without using real compositional methods #TARGET_REF . Therefore, in order to evaluate multi-hop inference more explicitly, we break down the performance of each model with respect to the difficulty of accessing specific facts in an explanation via direct lexical overlap. This comes from the assumption that facts sharing many terms with question or answer are relatively easier to find and rank highly.",
        "output": "{\"INFO\": [\"One of the crucial issues regarding the evaluation of multi-hop inference models is the possibility to achieve strong overall performance without using real compositional methods #TARGET_REF .\"], \"PERCEPT\": [\"in order to evaluate multi-hop inference more explicitly, we break down the performance of each model with respect to the difficulty of accessing specific facts in an explanation via direct lexical overlap.\"], \"BACK\": [\"This comes from the assumption that facts sharing many terms with question or answer are relatively easier to find and rank highly.\"]}"
    },
    {
        "gold": {
            "text": [
                "E",
                "q",
                "φ",
                "(z|x)",
                "[log",
                "p",
                "θ",
                "(x|z)]",
                "−",
                "βD",
                "KL",
                "(q",
                "φ",
                "(z|x),",
                "p(z))",
                "−λD",
                "M",
                "M",
                "D",
                "(q",
                "φ",
                "(z),",
                "p(z))where",
                "D",
                "M",
                "M",
                "D",
                "is",
                "computed",
                "using",
                "maximum",
                "mean",
                "discrepancy",
                "#REF",
                ",",
                "MMD)",
                "and",
                "λ",
                "is",
                "the",
                "scalar",
                "weight.",
                "This",
                "term",
                "regularises",
                "the",
                "aggregated",
                "posterior",
                "q",
                "φ",
                "(z)",
                "with",
                "a",
                "factorised",
                "spikeand-slab",
                "prior",
                "#TARGET_REF",
                ",",
                "which",
                "aims",
                "for",
                "disentanglement",
                "via",
                "clustering",
                "and",
                "sparsifying",
                "the",
                "representations",
                "of",
                "z."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "E q φ (z|x) [log p θ (x|z)] − βD KL (q φ (z|x), p(z)) −λD M M D (q φ (z), p(z))where D M M D is computed using maximum mean discrepancy #REF , MMD) and λ is the scalar weight. This term regularises the aggregated posterior q φ (z) with a factorised spikeand-slab prior #TARGET_REF , which aims for disentanglement via clustering and sparsifying the representations of z.",
        "output": "{\"INFO\": [\"prior #TARGET_REF\", \"which aims for disentanglement via clustering and sparsifying the representations of z.\"], \"PERCEPT\": [], \"BACK\": [\"This term regularises the aggregated posterior q \\u03c6 (z) with a factorised spikeand-slab\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "hypothesize",
                "that",
                "texts",
                "with",
                "alignment",
                "are",
                "less",
                "cognitively",
                "demanding",
                "to",
                "process,",
                "and",
                "so",
                "less",
                "effortful",
                "to",
                "post-edit",
                "than",
                "texts",
                "without",
                "alignment.",
                "If",
                "this",
                "is",
                "the",
                "case,",
                "shorter",
                "post-editing",
                "times",
                "for",
                "texts",
                "with",
                "alignment",
                "are",
                "consistent",
                "with",
                "previous",
                "findings",
                "by",
                "#TARGET_REF",
                ",",
                "who",
                "found",
                "that",
                "per",
                "word",
                "post-editing",
                "times",
                "were",
                "shorter",
                "for",
                "segments",
                "that",
                "were",
                "less",
                "cognitively",
                "demanding",
                "because",
                "of",
                "the",
                "linguistic",
                "structure.",
                "Related",
                "work",
                "on",
                "cognitive",
                "effort",
                "in",
                "post-editing",
                "#REF",
                "has",
                "also",
                "shown",
                "decreased",
                "densities",
                "of",
                "short",
                "pauses",
                "when",
                "less",
                "cognitively",
                "demanding",
                "segments",
                "are",
                "post-edited."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "We hypothesize that texts with alignment are less cognitively demanding to process, and so less effortful to post-edit than texts without alignment. If this is the case, shorter post-editing times for texts with alignment are consistent with previous findings by #TARGET_REF , who found that per word post-editing times were shorter for segments that were less cognitively demanding because of the linguistic structure. Related work on cognitive effort in post-editing #REF has also shown decreased densities of short pauses when less cognitively demanding segments are post-edited.",
        "output": "{\"INFO\": [\"by #TARGET_REF , who found that per word post-editing times were shorter for segments that were less cognitively demanding because of the linguistic structure.\"], \"PERCEPT\": [\"We hypothesize that texts with alignment are less cognitively demanding to process, and so less effortful to post-edit than texts without alignment. If this is the case, shorter post-editing times for texts with alignment are consistent with previous findings\"], \"BACK\": [\"Related work on cognitive effort in post-editing #REF has also shown decreased densities of short pauses when less cognitively demanding segments are post-edited.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "#REF",
                ",",
                "a",
                "multilingual",
                "dataset",
                "was",
                "provided",
                "containing",
                "English,",
                "German,",
                "Spanish",
                "and",
                "French",
                "and",
                "there",
                "were",
                "two",
                "subtasks:",
                "binary",
                "classification",
                "and",
                "probabilistic",
                "classification.",
                "The",
                "submitted",
                "systems",
                "mainly",
                "use",
                "traditional",
                "machine",
                "learning",
                "classifiers(e.g.",
                "SVM,",
                "Random",
                "Forests)",
                "with",
                "features",
                "#REF",
                ",",
                "deep",
                "learning",
                "methods",
                "#TARGET_REF",
                "and",
                "ensemble",
                "methods",
                "#REF",
                ".",
                "More",
                "recently,",
                "#REF",
                "propose",
                "a",
                "new",
                "perspective",
                "by",
                "treating",
                "CWI",
                "as",
                "a",
                "sequence",
                "labeling",
                "task",
                "that",
                "can",
                "detect",
                "both",
                "complex",
                "words",
                "and",
                "phrases.",
                "All",
                "these",
                "methods",
                "are",
                "different",
                "from",
                "ours",
                "which",
                "utilizes",
                "heterogeneous",
                "PLMs",
                "with",
                "various",
                "training",
                "strategies."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In #REF , a multilingual dataset was provided containing English, German, Spanish and French and there were two subtasks: binary classification and probabilistic classification. The submitted systems mainly use traditional machine learning classifiers(e.g. SVM, Random Forests) with features #REF , deep learning methods #TARGET_REF and ensemble methods #REF . More recently, #REF propose a new perspective by treating CWI as a sequence labeling task that can detect both complex words and phrases. All these methods are different from ours which utilizes heterogeneous PLMs with various training strategies.",
        "output": "{\"INFO\": [\"deep learning methods #TARGET_REF\"], \"PERCEPT\": [\"The submitted systems mainly use traditional machine learning classifiers(e.g.\", \"with\"], \"BACK\": [\"SVM, Random Forests)\", \"features #REF ,\", \"and ensemble methods #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "probabilistic",
                "LR",
                "parser",
                "was",
                "trained",
                "with",
                "the",
                "integrated",
                "grammar",
                "by",
                "exploiting",
                "the",
                "Susanne",
                "treebank",
                "bracketing.",
                "An",
                "LR",
                "parser",
                "#REF",
                "was",
                "applied",
                "to",
                "unlabelled",
                "brack",
                "eted",
                "sentences",
                "from",
                "the",
                "Susanne",
                "treebank,",
                "and",
                "a",
                "new",
                "treebank",
                "of",
                "1758",
                "correct",
                "and",
                "complete",
                "analyses",
                "with",
                "respect",
                "to",
                "the",
                "integrated",
                "grammar",
                "was",
                "constructed",
                "semi-automatically",
                "by",
                "manu",
                "ally•",
                "resolving",
                "the",
                "remaining",
                "ambiguities.",
                "250",
                "sentences",
                "from",
                "the",
                "new",
                "treebank",
                "were",
                "kept",
                "back",
                "for",
                "testing.",
                "The",
                "remainder,",
                "together",
                "with",
                "a",
                "further",
                "set",
                "of",
                "analyses",
                "from",
                "2285",
                "tree",
                "bank",
                "sentences",
                "that",
                "were",
                "not",
                "checked",
                "manually,",
                "were",
                "used",
                "to",
                "train",
                "a",
                "probabilistic",
                "version",
                "of",
                "the",
                "LR",
                "parser,",
                "using",
                "Good-Turing",
                "smoothing",
                "to",
                "estimate",
                "the",
                "probability",
                "of",
                "unseen",
                "transitions",
                "in",
                "the",
                "LALR(",
                "1",
                ")",
                "table",
                "#REF",
                ".",
                "The",
                "probabilistic",
                "parser",
                "can",
                "then",
                "return",
                "a",
                "ranking",
                "of",
                "all",
                "possible",
                "analyses",
                "for",
                "a",
                "sentence,",
                "or",
                "efficiently",
                "return",
                "just",
                "the",
                "n-most",
                "probable",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "A probabilistic LR parser was trained with the integrated grammar by exploiting the Susanne treebank bracketing. An LR parser #REF was applied to unlabelled brack eted sentences from the Susanne treebank, and a new treebank of 1758 correct and complete analyses with respect to the integrated grammar was constructed semi-automatically by manu ally• resolving the remaining ambiguities. 250 sentences from the new treebank were kept back for testing. The remainder, together with a further set of analyses from 2285 tree bank sentences that were not checked manually, were used to train a probabilistic version of the LR parser, using Good-Turing smoothing to estimate the probability of unseen transitions in the LALR( 1 ) table #REF . The probabilistic parser can then return a ranking of all possible analyses for a sentence, or efficiently return just the n-most probable #TARGET_REF .",
        "output": "{\"INFO\": [\"The probabilistic parser can then return a ranking of all possible analyses for a sentence, or efficiently return just the n-most probable #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "define",
                "text-level",
                "bias",
                "as",
                "the",
                "frequency",
                "of",
                "certain",
                "words",
                "which",
                "are",
                "recognised",
                "as",
                "favouring",
                "one",
                "gender",
                "over",
                "another.",
                "The",
                "problem",
                "is",
                "then",
                "in",
                "defining",
                "this",
                "list",
                "of",
                "words.",
                "To",
                "avoid",
                "overfitting",
                "to",
                "one",
                "axis",
                "of",
                "gender",
                "bias,",
                "we",
                "construct",
                "a",
                "composite",
                "score",
                "based",
                "on",
                "pre-existing",
                "lists",
                "which",
                "have",
                "in",
                "turn",
                "been",
                "defined",
                "through",
                "experiments",
                "and",
                "empirical",
                "assessments",
                "#TARGET_REF",
                ".",
                "The",
                "presence",
                "of",
                "words",
                "which",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "associated",
                "with",
                "one",
                "gender",
                "does",
                "not",
                "directly",
                "result",
                "in",
                "biased",
                "outcomes.",
                "Bias",
                "may",
                "be",
                "more",
                "accurately",
                "measured",
                "as",
                "the",
                "relative",
                "gender",
                "distribution",
                "of",
                "applicants",
                "who",
                "apply",
                "to",
                "a",
                "given",
                "ad.",
                "In",
                "this",
                "work,",
                "we",
                "focus",
                "on",
                "gendered",
                "word",
                "lists",
                "as",
                "one",
                "overt",
                "presentation",
                "of",
                "gender",
                "bias",
                "but",
                "encourage",
                "further",
                "research",
                "to",
                "empirically",
                "measure",
                "allocational",
                "harm,",
                "so",
                "long",
                "as",
                "any",
                "experiments",
                "consider",
                "the",
                "ethical",
                "issues",
                "of",
                "posting",
                "\"fake\"",
                "ads",
                "online."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We define text-level bias as the frequency of certain words which are recognised as favouring one gender over another. The problem is then in defining this list of words. To avoid overfitting to one axis of gender bias, we construct a composite score based on pre-existing lists which have in turn been defined through experiments and empirical assessments #TARGET_REF . The presence of words which are more likely to be associated with one gender does not directly result in biased outcomes. Bias may be more accurately measured as the relative gender distribution of applicants who apply to a given ad. In this work, we focus on gendered word lists as one overt presentation of gender bias but encourage further research to empirically measure allocational harm, so long as any experiments consider the ethical issues of posting \"fake\" ads online.",
        "output": "{\"INFO\": [\"pre-existing lists which have\", \"been defined through experiments and empirical assessments #TARGET_REF\"], \"PERCEPT\": [\"To avoid overfitting to one axis of gender bias, we construct a composite score based on\"], \"BACK\": [\"words which are recognised as favouring one gender over another. The problem is then in defining this list of words.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "second",
                "objective,",
                "we",
                "quantify",
                "the",
                "contribution",
                "of",
                "each",
                "modality",
                "and",
                "their",
                "aspects",
                "given",
                "the",
                "situation",
                "to",
                "mimic",
                "human",
                "heuristic",
                "processing",
                "capability.",
                "Language",
                "comprehension",
                "involves",
                "complex",
                "sequential",
                "decision",
                "making",
                "and",
                "is",
                "affected",
                "by",
                "both",
                "uncertainty",
                "about",
                "the",
                "current",
                "input",
                "and",
                "lack",
                "of",
                "knowledge",
                "about",
                "the",
                "upcoming",
                "material.",
                "Thus,",
                "people",
                "use",
                "-to",
                "a",
                "large",
                "extent",
                "-fast",
                "and",
                "frugal",
                "heuristics,",
                "i.e.",
                "choosing",
                "a",
                "good-enough",
                "representation",
                "#TARGET_REF",
                ".",
                "The",
                "heuristic",
                "view",
                "provides",
                "a",
                "valid",
                "explanation",
                "for",
                "scenarios",
                "with",
                "a",
                "conversation",
                "inside",
                "noisy",
                "conditions.",
                "Instead",
                "of",
                "waiting",
                "/",
                "asking",
                "for",
                "clarification,",
                "the",
                "model",
                "will",
                "reach",
                "a",
                "good-enough",
                "decision",
                "based",
                "on",
                "all",
                "information",
                "gathered",
                "through",
                "all",
                "available",
                "input",
                "channels.",
                "In",
                "order",
                "to",
                "do",
                "that,",
                "the",
                "set",
                "of",
                "important",
                "features",
                "given",
                "the",
                "situated",
                "setting",
                "should",
                "be",
                "chosen",
                "automatically."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the second objective, we quantify the contribution of each modality and their aspects given the situation to mimic human heuristic processing capability. Language comprehension involves complex sequential decision making and is affected by both uncertainty about the current input and lack of knowledge about the upcoming material. Thus, people use -to a large extent -fast and frugal heuristics, i.e. choosing a good-enough representation #TARGET_REF . The heuristic view provides a valid explanation for scenarios with a conversation inside noisy conditions. Instead of waiting / asking for clarification, the model will reach a good-enough decision based on all information gathered through all available input channels. In order to do that, the set of important features given the situated setting should be chosen automatically.",
        "output": "{\"INFO\": [\"choosing a good-enough representation #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Language comprehension involves complex sequential decision making and is affected by both uncertainty about the current input and lack of knowledge about the upcoming material. Thus, people use -to a large extent -fast and frugal heuristics, i.e.\"]}"
    },
    {
        "gold": {
            "text": [
                "by",
                "the",
                "parser",
                "overlaps",
                "with",
                "one",
                "from",
                "the",
                "treebank",
                "but",
                "neither",
                "is",
                "properly",
                "contained",
                "in",
                "the",
                "other,",
                "and",
                "minC,",
                "the",
                "number",
                "of",
                "sentences",
                "for",
                "which",
                "all",
                "of",
                "the",
                "analyses",
                "had",
                "one",
                "or",
                "more",
                "crossings.",
                "The",
                "table",
                "also",
                "gives",
                "an",
                "indication",
                "of",
                "the",
                "best",
                "and",
                "worst",
                "possible",
                "performance",
                "of",
                "the",
                "disambiguation",
                "component",
                "of",
                "the",
                "system,",
                "showing",
                "the",
                "results",
                "obtained",
                "when",
                "parse",
                "selection",
                "is",
                "replaced",
                "by",
                "a",
                "simple",
                "random",
                "choice,",
                "and",
                "the",
                "results",
                "of",
                "eval",
                "uating",
                "the",
                "manually-created",
                "treebank",
                "against",
                "the",
                "corresponding",
                "Susanne",
                "bracketings.",
                "In",
                "this",
                "latter",
                "figure,",
                "the",
                "mean",
                "number",
                "of",
                "crossings",
                "is",
                "greater",
                "than",
                "zero",
                "mainly",
                "because",
                "of",
                "compound",
                "noun",
                "bracketing",
                "ambiguity",
                "which",
                "our",
                "grammar",
                "does",
                "not",
                "attempt",
                "to",
                "resolve,",
                "always",
                "returning",
                "minC",
                "Crossings",
                "Recall",
                "(%)",
                "Precision",
                "(",
                "%",
                ")",
                "Probabilistic",
                "parser",
                "analyses",
                "#REF",
                "#REF",
                "uses",
                "the",
                "crossing",
                "brackets",
                "measure",
                "to",
                "define",
                "a",
                "notion",
                "of",
                "structural",
                "consistency,",
                "where",
                "the",
                "structural",
                "consistency",
                "rate",
                "for",
                "the",
                "grammar",
                "is",
                "defined",
                "as",
                "the",
                "proportion",
                "of",
                "sentences",
                "for",
                "which",
                "at",
                "least",
                "one",
                "analysis",
                "contains",
                "no",
                "crossing",
                "brackets,",
                "and",
                "reports",
                "a",
                "rate",
                "of",
                "around",
                "95%",
                "for",
                "the",
                "IBM",
                "grammar",
                "tested",
                "on",
                "the",
                "computer",
                "manual",
                "corpus.",
                "The",
                "problem",
                "with",
                "the",
                "GEIG",
                "scheme",
                "and",
                "with",
                "structural",
                "consistency",
                "is",
                "that",
                "both",
                "are",
                "still",
                "weak",
                "measures",
                "(",
                "designed",
                "to",
                "avoid",
                "problems",
                "of",
                "parser/treebank",
                "representational",
                "compatibility)",
                "which",
                "lead",
                "to",
                "unintuitive",
                "numbers",
                "whose",
                "significance",
                "still",
                "depends",
                "heavily",
                "on",
                "details",
                "of",
                "the",
                "relationship",
                "between",
                "the",
                "representations",
                "compared",
                "(c.f.",
                "the",
                "compound",
                "noun",
                "issue",
                "mentioned",
                "above)",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "by the parser overlaps with one from the treebank but neither is properly contained in the other, and minC, the number of sentences for which all of the analyses had one or more crossings. The table also gives an indication of the best and worst possible performance of the disambiguation component of the system, showing the results obtained when parse selection is replaced by a simple random choice, and the results of eval uating the manually-created treebank against the corresponding Susanne bracketings. In this latter figure, the mean number of crossings is greater than zero mainly because of compound noun bracketing ambiguity which our grammar does not attempt to resolve, always returning minC Crossings Recall (%) Precision ( % ) Probabilistic parser analyses #REF #REF uses the crossing brackets measure to define a notion of structural consistency, where the structural consistency rate for the grammar is defined as the proportion of sentences for which at least one analysis contains no crossing brackets, and reports a rate of around 95% for the IBM grammar tested on the computer manual corpus. The problem with the GEIG scheme and with structural consistency is that both are still weak measures ( designed to avoid problems of parser/treebank representational compatibility) which lead to unintuitive numbers whose significance still depends heavily on details of the relationship between the representations compared (c.f. the compound noun issue mentioned above) .",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"by the parser overlaps with one from the treebank but neither is properly contained in the other, and minC, the number of sentences for which all of the analyses had one or more crossings.\"]}"
    },
    {
        "gold": {
            "text": [
                "Varying",
                "Pruning",
                "Percentage.",
                "We",
                "randomly",
                "prune",
                "attention",
                "heads",
                "across",
                "all",
                "components",
                "and",
                "layers",
                "varying",
                "the",
                "percentage",
                "of",
                "pruning",
                "from",
                "25%",
                "to",
                "87%",
                "(Table",
                "1).",
                "We",
                "observed",
                "that",
                "in",
                "the",
                "case",
                "of",
                "extreme",
                "pruning,",
                "i.e.,",
                "keeping",
                "just",
                "one",
                "head",
                "in",
                "each",
                "layer",
                "of",
                "each",
                "of",
                "the",
                "three",
                "components",
                "(which",
                "corresponds",
                "to",
                "a",
                "pruning",
                "percentage",
                "of",
                "87%),",
                "the",
                "drop",
                "in",
                "BLEU",
                "was",
                "1.62",
                "(EN-RU)",
                "and",
                "1.03",
                "(EN-DE)",
                "as",
                "can",
                "be",
                "seen",
                "from",
                "Table",
                "1.",
                "Across",
                "both",
                "EN-RU",
                "and",
                "EN-DE",
                "tasks,",
                "60%",
                "of",
                "the",
                "attention",
                "heads",
                "can",
                "be",
                "pruned",
                "with",
                "a",
                "maximum",
                "drop",
                "in",
                "BLEU",
                "score",
                "by",
                "only",
                "0.15.",
                "As",
                "can",
                "be",
                "observed",
                "from",
                "Figure",
                "1,",
                "the",
                "drop",
                "is",
                "sharper",
                "as",
                "we",
                "increase",
                "the",
                "pruning",
                "percentage",
                "beyond",
                "60%.",
                "three",
                "layers,",
                "3",
                "in",
                "the",
                "fourth",
                "layer",
                "and",
                "2",
                "each",
                "in",
                "the",
                "last",
                "two",
                "layers.",
                "For",
                "each",
                "pruning",
                "percentage,",
                "the",
                "first",
                "row",
                "corresponds",
                "to",
                "the",
                "configuration",
                "in",
                "which",
                "heads",
                "considered",
                "important",
                "#TARGET_REF",
                "were",
                "retained",
                "and",
                "the",
                "second",
                "row",
                "corresponds",
                "to",
                "the",
                "adversarial",
                "configuration",
                "in",
                "which",
                "heads",
                "considered",
                "important",
                "were",
                "pruned.",
                "We",
                "identify",
                "no",
                "preference",
                "in",
                "pruning",
                "as",
                "for",
                "each",
                "pruning",
                "percentage",
                "the",
                "performance",
                "of",
                "both",
                "configurations",
                "is",
                "very",
                "similar."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Varying Pruning Percentage. We randomly prune attention heads across all components and layers varying the percentage of pruning from 25% to 87% (Table 1). We observed that in the case of extreme pruning, i.e., keeping just one head in each layer of each of the three components (which corresponds to a pruning percentage of 87%), the drop in BLEU was 1.62 (EN-RU) and 1.03 (EN-DE) as can be seen from Table 1. Across both EN-RU and EN-DE tasks, 60% of the attention heads can be pruned with a maximum drop in BLEU score by only 0.15. As can be observed from Figure 1, the drop is sharper as we increase the pruning percentage beyond 60%. three layers, 3 in the fourth layer and 2 each in the last two layers. For each pruning percentage, the first row corresponds to the configuration in which heads considered important #TARGET_REF were retained and the second row corresponds to the adversarial configuration in which heads considered important were pruned. We identify no preference in pruning as for each pruning percentage the performance of both configurations is very similar.",
        "output": "{\"INFO\": [\"the configuration in which heads considered important #TARGET_REF\"], \"PERCEPT\": [\"For each pruning percentage, the first row corresponds to\", \"were retained\"], \"BACK\": [\"and the second row corresponds to the adversarial configuration in which heads considered important were pruned.\"]}"
    },
    {
        "gold": {
            "text": [
                "Table",
                "5",
                "presents",
                "the",
                "results",
                "of",
                "evaluating",
                "the",
                "impact",
                "of",
                "using",
                "coreference",
                "annotations",
                "to",
                "improve",
                "coreference",
                "reasoning",
                "in",
                "MRC.",
                "We",
                "report",
                "the",
                "re-sults",
                "for",
                "both",
                "of",
                "the",
                "examined",
                "state-of-the-art",
                "models,",
                "i.",
                "#TARGET_REF",
                "and",
                "is",
                "then",
                "finetuned",
                "on",
                "Quoref."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Table 5 presents the results of evaluating the impact of using coreference annotations to improve coreference reasoning in MRC. We report the re-sults for both of the examined state-of-the-art models, i. #TARGET_REF and is then finetuned on Quoref.",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"We report the re-sults for both of the examined state-of-the-art models, i.\", \"and is then finetuned on Quoref.\"], \"BACK\": [\"the impact of using coreference annotations to improve coreference reasoning in MRC.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "acclaimed",
                "success",
                "of",
                "Transformer-based",
                "models",
                "across",
                "NLP",
                "tasks",
                "has",
                "been",
                "followed",
                "by",
                "two",
                "important",
                "directions",
                "of",
                "research.",
                "In",
                "the",
                "first",
                "direction,",
                "interpretability",
                "studies",
                "aim",
                "to",
                "understand",
                "how",
                "these",
                "models",
                "work.",
                "Given",
                "that",
                "multi-headed",
                "attention",
                "is",
                "an",
                "important",
                "feature",
                "of",
                "these",
                "models,",
                "researchers",
                "have",
                "focused",
                "on",
                "attention",
                "heads",
                "as",
                "the",
                "units",
                "of",
                "interpretation.",
                "These",
                "studies",
                "comment",
                "on",
                "the",
                "role",
                "of",
                "each",
                "attention",
                "head",
                "and",
                "the",
                "relation",
                "between",
                "a",
                "head's",
                "position",
                "and",
                "its",
                "significance",
                "#TARGET_REF",
                ".",
                "These",
                "studies",
                "show",
                "that",
                "certain",
                "heads",
                "are",
                "more",
                "important",
                "based",
                "on",
                "(i)",
                "their",
                "position",
                "in",
                "the",
                "network",
                "(top,",
                "middle,",
                "bottom),",
                "or",
                "(ii)",
                "the",
                "component",
                "to",
                "which",
                "they",
                "belong",
                "(encoder",
                "self-attention,",
                "decoder",
                "self-attention,",
                "encoder-decoder",
                "cross",
                "attention),",
                "or",
                "(iii)",
                "the",
                "functional",
                "role",
                "they",
                "play",
                "(e.g.,",
                "syntactic/semantic)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3
            ]
        },
        "input": "The acclaimed success of Transformer-based models across NLP tasks has been followed by two important directions of research. In the first direction, interpretability studies aim to understand how these models work. Given that multi-headed attention is an important feature of these models, researchers have focused on attention heads as the units of interpretation. These studies comment on the role of each attention head and the relation between a head's position and its significance #TARGET_REF . These studies show that certain heads are more important based on (i) their position in the network (top, middle, bottom), or (ii) the component to which they belong (encoder self-attention, decoder self-attention, encoder-decoder cross attention), or (iii) the functional role they play (e.g., syntactic/semantic).",
        "output": "{\"INFO\": [\"These studies comment on the role of each attention head and the relation between a head's position and its significance #TARGET_REF . These studies show that certain heads are more important based on (i) their position in the network\", \"or (ii) the component to which they belong\", \"or (iii) the functional role they play\"], \"PERCEPT\": [\"Given that multi-headed attention is an important feature of these models, researchers have focused on attention heads as the units of interpretation.\"], \"BACK\": [\"(top, middle, bottom),\", \"(encoder self-attention, decoder self-attention, encoder-decoder cross attention),\", \"(e.g., syntactic/semantic).\"]}"
    },
    {
        "gold": {
            "text": [
                "reality",
                "or",
                "truth",
                "of.",
                "One",
                "of",
                "its",
                "troponym",
                "is",
                "to",
                "concede,",
                "profess,",
                "confess",
                "which",
                "is",
                "defined",
                "as",
                "to",
                "admit",
                "(to",
                "a",
                "wrongdoing).",
                "The",
                "superordinate",
                "concept",
                "of",
                "this",
                "chain",
                "is",
                "the",
                "verb",
                "think,",
                "cogitate,",
                "cerebrate",
                "which",
                "is",
                "defined",
                "as-to",
                "use",
                "or",
                "exercise",
                "the",
                "mind",
                "or",
                "one's",
                "power",
                "of",
                "reason",
                "in",
                "order",
                "to",
                "make",
                "inferences,",
                "decisions,",
                "or",
                "arrive",
                "at",
                "a",
                "solution",
                "or",
                "judgments.",
                "Thus,",
                "it",
                "is",
                "clear",
                "from",
                "the",
                "semantic",
                "hierarchy",
                "that",
                "to",
                "apologize",
                "is",
                "to",
                "undergo",
                "a",
                "logical",
                "thought",
                "process,",
                "the",
                "natural",
                "entailment",
                "of",
                "which",
                "is",
                "to",
                "admit",
                "to",
                "a",
                "wrong.",
                "Once",
                "the",
                "wrongdoing",
                "is",
                "admitted",
                "the",
                "natural",
                "consequence",
                "should",
                "be",
                "to",
                "take",
                "responsibility",
                "and",
                "offer",
                "amends.",
                "For",
                "instance,",
                "apology",
                "number",
                "2",
                "says-I",
                "sincerely",
                "apologize",
                "to",
                "all",
                "Satyamites",
                "and",
                "stakeholders.",
                "This",
                "is",
                "a",
                "clear",
                "admission",
                "of",
                "wrongdoing.",
                "The",
                "selected",
                "concept",
                "of",
                "the",
                "verb",
                "regret",
                "is",
                "defined",
                "as",
                "to",
                "feel",
                "remorse",
                "for,",
                "feel",
                "sorry",
                "for",
                "or",
                "be",
                "contrite",
                "about.",
                "Its",
                "inherited",
                "hypernymy",
                "is",
                "to",
                "feel,",
                "experience,",
                "which",
                "is",
                "defined",
                "as",
                "to",
                "undergo",
                "an",
                "emotional",
                "sensation",
                "or",
                "be",
                "in",
                "a",
                "particular",
                "state",
                "of",
                "mind.",
                "Thus,",
                "to",
                "regret",
                "is",
                "to",
                "undergo",
                "a",
                "feeling",
                "by",
                "the",
                "offender",
                "about",
                "the",
                "wrongdoing.",
                "In",
                "the",
                "corpus",
                "apology",
                "number",
                "10,",
                "the",
                "Amazon",
                "India",
                "letter",
                "states,",
                "To",
                "the",
                "extent",
                "that",
                "these",
                "items",
                "offered",
                "by",
                "a",
                "third-party",
                "seller",
                "in",
                "Canada",
                "offended",
                "Indian",
                "sensibilities,",
                "Amazon",
                "regrets",
                "the",
                "same."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "reality or truth of. One of its troponym is to concede, profess, confess which is defined as to admit (to a wrongdoing). The superordinate concept of this chain is the verb think, cogitate, cerebrate which is defined as-to use or exercise the mind or one's power of reason in order to make inferences, decisions, or arrive at a solution or judgments. Thus, it is clear from the semantic hierarchy that to apologize is to undergo a logical thought process, the natural entailment of which is to admit to a wrong. Once the wrongdoing is admitted the natural consequence should be to take responsibility and offer amends. For instance, apology number 2 says-I sincerely apologize to all Satyamites and stakeholders. This is a clear admission of wrongdoing. The selected concept of the verb regret is defined as to feel remorse for, feel sorry for or be contrite about. Its inherited hypernymy is to feel, experience, which is defined as to undergo an emotional sensation or be in a particular state of mind. Thus, to regret is to undergo a feeling by the offender about the wrongdoing. In the corpus apology number 10, the Amazon India letter states, To the extent that these items offered by a third-party seller in Canada offended Indian sensibilities, Amazon regrets the same.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "large",
                "body",
                "of",
                "work",
                "in",
                "the",
                "literature",
                "showing",
                "that",
                "a",
                "morphological",
                "decomposition",
                "of",
                "the",
                "Arabic",
                "words",
                "can",
                "improve",
                "the",
                "word",
                "coverage",
                "and",
                "by",
                "these",
                "means",
                "the",
                "translation",
                "quality,",
                "see",
                "for",
                "instance",
                "#TARGET_REF",
                ".",
                "This",
                "is",
                "in",
                "particular",
                "true",
                "for",
                "under-resourced",
                "tasks",
                "like",
                "this",
                "evaluation.",
                "Most",
                "of",
                "the",
                "published",
                "work",
                "is",
                "based",
                "on",
                "the",
                "freely",
                "available",
                "tools,",
                "like",
                "the",
                "Buckwalter",
                "transliterator",
                "and",
                "the",
                "MADA",
                "and",
                "TOKAN",
                "tools",
                "for",
                "morphological",
                "analysis",
                "from",
                "Columbia",
                "University."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "There is a large body of work in the literature showing that a morphological decomposition of the Arabic words can improve the word coverage and by these means the translation quality, see for instance #TARGET_REF . This is in particular true for under-resourced tasks like this evaluation. Most of the published work is based on the freely available tools, like the Buckwalter transliterator and the MADA and TOKAN tools for morphological analysis from Columbia University.",
        "output": "{\"INFO\": [\"a morphological decomposition of the Arabic words can improve the word coverage and by these means the translation quality,\"], \"PERCEPT\": [\"see for instance #TARGET_REF . This is in particular true for under-resourced tasks like this evaluation.\"], \"BACK\": [\"There is a large body of work in the literature showing that\", \"Most of the published work is based on the freely available tools, like the Buckwalter transliterator and the MADA and TOKAN tools for morphological analysis from Columbia University.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "cosine",
                "similarity",
                "calculation,we",
                "use",
                "word2vec",
                "to",
                "calculate",
                "the",
                "sentence",
                "vector",
                "as",
                "sum",
                "of",
                "the",
                "word",
                "vectors",
                "of",
                "the",
                "words",
                "in",
                "the",
                "sentence.",
                "The",
                "calculation",
                "of",
                "sentence",
                "vector",
                "was",
                "to",
                "take",
                "advantage",
                "of",
                "the",
                "compositionality",
                "property",
                "using",
                "word2vec",
                "#TARGET_REF",
                ".",
                "We",
                "used",
                "word",
                "vectors",
                "of",
                "dimension",
                "100",
                "trained",
                "on",
                "the",
                "2015",
                "wikidump."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For the cosine similarity calculation,we use word2vec to calculate the sentence vector as sum of the word vectors of the words in the sentence. The calculation of sentence vector was to take advantage of the compositionality property using word2vec #TARGET_REF . We used word vectors of dimension 100 trained on the 2015 wikidump.",
        "output": "{\"INFO\": [\"The calculation of sentence vector was to take advantage of the compositionality property using word2vec #TARGET_REF .\"], \"PERCEPT\": [\"For the cosine similarity calculation,we use word2vec to calculate the sentence vector as sum of the word vectors of the words in the sentence.\", \"We used word vectors of dimension 100 trained on the 2015 wikidump.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Fact",
                "Verification",
                "over",
                "Structured",
                "and",
                "Unstructured",
                "Evidence",
                "FEVEROUS",
                "#TARGET_REF",
                "is",
                "the",
                "first",
                "dataset",
                "of",
                "fact",
                "verification",
                "on",
                "structured",
                "and",
                "unstructured",
                "evidence.",
                "Many",
                "previous",
                "works",
                "follow",
                "the",
                "baseline",
                "settings",
                "and",
                "convert",
                "all",
                "evidence",
                "to",
                "text",
                "format",
                "to",
                "perform",
                "evidence",
                "interaction.",
                "They",
                "transform",
                "each",
                "cell",
                "to",
                "header-value",
                "pairs",
                "#REF",
                "or",
                "in",
                "a",
                "cell",
                "location",
                "indication",
                "type",
                "#REF",
                ".",
                "They",
                "pay",
                "less",
                "attention",
                "to",
                "making",
                "the",
                "converted",
                "text",
                "more",
                "consistent",
                "with",
                "natural",
                "language",
                "expressions",
                "or",
                "identifying",
                "what",
                "the",
                "context",
                "cells",
                "represent.",
                "#REF",
                "propose",
                "to",
                "convert",
                "all",
                "evidence",
                "to",
                "tables.",
                "They",
                "simply",
                "convert",
                "each",
                "sentence",
                "to",
                "a",
                "2-cell",
                "table",
                "with",
                "the",
                "Wikipedia",
                "title",
                "and",
                "itself",
                "instead",
                "of",
                "packing",
                "closely-tied",
                "evidence",
                "and",
                "building",
                "a",
                "global",
                "evidence",
                "table.",
                "There",
                "are",
                "also",
                "works",
                "focusing",
                "on",
                "the",
                "first",
                "two",
                "steps",
                "two",
                "improve",
                "the",
                "final",
                "results.",
                "#REF",
                "propose",
                "to",
                "add",
                "a",
                "document",
                "re-ranker",
                "to",
                "strengthen",
                "the",
                "document",
                "retrieval.",
                "Multi-hop",
                "Dense",
                "Retriever",
                "#REF",
                "and",
                "T5",
                "generator",
                "#REF",
                "are",
                "introduced",
                "to",
                "better",
                "extract",
                "multi-hop",
                "evidence."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Fact Verification over Structured and Unstructured Evidence FEVEROUS #TARGET_REF is the first dataset of fact verification on structured and unstructured evidence. Many previous works follow the baseline settings and convert all evidence to text format to perform evidence interaction. They transform each cell to header-value pairs #REF or in a cell location indication type #REF . They pay less attention to making the converted text more consistent with natural language expressions or identifying what the context cells represent. #REF propose to convert all evidence to tables. They simply convert each sentence to a 2-cell table with the Wikipedia title and itself instead of packing closely-tied evidence and building a global evidence table. There are also works focusing on the first two steps two improve the final results. #REF propose to add a document re-ranker to strengthen the document retrieval. Multi-hop Dense Retriever #REF and T5 generator #REF are introduced to better extract multi-hop evidence.",
        "output": "{\"INFO\": [\"FEVEROUS #TARGET_REF\"], \"PERCEPT\": [\"is the first dataset of fact verification on structured and unstructured evidence.\"], \"BACK\": [\"Many previous works follow the baseline settings and convert all evidence to text format to perform evidence interaction.\"]}"
    },
    {
        "gold": {
            "text": [
                "Technical",
                "Details",
                "All",
                "neural",
                "models",
                "are",
                "trained",
                "using",
                "cross-entropy",
                "loss",
                "and",
                "optimized",
                "with",
                "Adam",
                "(Kingma",
                "and",
                "Ba,",
                "2015),",
                "using",
                "the",
                "AllenNLP",
                "library",
                "#REF",
                ".",
                "We",
                "train",
                "using",
                "a",
                "1e",
                "−",
                "5",
                "learning",
                "rate",
                "for",
                "40",
                "epochs,",
                "with",
                "early",
                "stopping",
                "based",
                "the",
                "F1",
                "metric",
                "on",
                "the",
                "development",
                "set.",
                "We",
                "use",
                "SpanBERT",
                "#TARGET_REF",
                "as",
                "the",
                "pretrained",
                "MLM,",
                "as",
                "it",
                "was",
                "found",
                "to",
                "work",
                "well",
                "on",
                "span-based",
                "tasks",
                "with",
                "its",
                "base",
                "and",
                "the",
                "large",
                "variants.",
                "The",
                "anchor",
                "and",
                "complement",
                "encoding",
                "MLPs",
                "have",
                "one",
                "500-dim",
                "hidden",
                "layer",
                "and",
                "output",
                "500dim",
                "representations.",
                "The",
                "prediction",
                "MLPs",
                "have",
                "one",
                "100-dim",
                "hidden",
                "layer.",
                "All",
                "MLPs",
                "use",
                "the",
                "ReLU",
                "activation.",
                "We",
                "used",
                "the",
                "same",
                "hyperparameters",
                "for",
                "all",
                "baselines",
                "and",
                "did",
                "not",
                "tune",
                "them.",
                "18"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Technical Details All neural models are trained using cross-entropy loss and optimized with Adam (Kingma and Ba, 2015), using the AllenNLP library #REF . We train using a 1e − 5 learning rate for 40 epochs, with early stopping based the F1 metric on the development set. We use SpanBERT #TARGET_REF as the pretrained MLM, as it was found to work well on span-based tasks with its base and the large variants. The anchor and complement encoding MLPs have one 500-dim hidden layer and output 500dim representations. The prediction MLPs have one 100-dim hidden layer. All MLPs use the ReLU activation. We used the same hyperparameters for all baselines and did not tune them. 18",
        "output": "{\"INFO\": [\"We use SpanBERT #TARGET_REF as the pretrained MLM, as it was found to work well on span-based tasks with its base and the large variants.\"], \"PERCEPT\": [], \"BACK\": [\"Technical Details All neural models are trained using cross-entropy loss and optimized with Adam (Kingma and Ba, 2015), using the AllenNLP library #REF . We train using a 1e \\u2212 5 learning rate for 40 epochs, with early stopping based the F1 metric on the development set.\"]}"
    },
    {
        "gold": {
            "text": [
                "Following",
                "#TARGET_REF",
                ",",
                "we",
                "use",
                "λ",
                "=",
                "0.5",
                "for",
                "Koyyalagunta",
                "and",
                "KoyyRestrict",
                "scoring",
                "functions,",
                "but",
                "also",
                "for",
                "the",
                "Harmonic",
                "function.",
                "We",
                "pair",
                "all",
                "relatedness",
                "measures",
                "to",
                "all",
                "scoring",
                "functions,",
                "creating",
                "16",
                "agents",
                "in",
                "total,",
                "and",
                "generate",
                "clues",
                "for",
                "n",
                "=",
                "2",
                "and",
                "3",
                "targeted",
                "blue",
                "words",
                "using",
                "all",
                "of",
                "them.",
                "Differently",
                "from",
                "#REF",
                ",",
                "we",
                "consider",
                "all",
                "of",
                "our",
                "vocabulary",
                "words",
                "as",
                "possible",
                "clue",
                "words.",
                "For",
                "each",
                "possible",
                "clue",
                "word,",
                "the",
                "best",
                "target",
                "words",
                "in",
                "the",
                "set",
                "I",
                "n",
                "are",
                "the",
                "n",
                "closest",
                "words",
                "to",
                "the",
                "clue",
                "word,",
                "so",
                "scoring",
                "a",
                "possible",
                "clue",
                "is",
                "computationally",
                "inexpensive."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Following #TARGET_REF , we use λ = 0.5 for Koyyalagunta and KoyyRestrict scoring functions, but also for the Harmonic function. We pair all relatedness measures to all scoring functions, creating 16 agents in total, and generate clues for n = 2 and 3 targeted blue words using all of them. Differently from #REF , we consider all of our vocabulary words as possible clue words. For each possible clue word, the best target words in the set I n are the n closest words to the clue word, so scoring a possible clue is computationally inexpensive.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"we consider all of our vocabulary words as possible clue words.\"], \"BACK\": [\"Following #TARGET_REF , we use \\u03bb = 0.5 for Koyyalagunta and KoyyRestrict scoring functions, but also for the Harmonic function. We pair all relatedness measures to all scoring functions, creating 16 agents in total, and generate clues for n = 2 and 3 targeted blue words using all of them.\", \"the best target words in the set I n are the n closest words to the clue word, so scoring a possible clue is computationally inexpensive.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "task",
                "of",
                "fact",
                "extraction",
                "and",
                "verification",
                "aims",
                "to",
                "extract",
                "evidence",
                "and",
                "verify",
                "a",
                "given",
                "claim.",
                "Previous",
                "efforts",
                "focus",
                "on",
                "dealing",
                "with",
                "text",
                "format",
                "evidence",
                "from",
                "unstructured",
                "documents",
                "#REF",
                "or",
                "evidence",
                "from",
                "a",
                "single",
                "given",
                "table",
                "#REF",
                ".",
                "Recently,",
                "#TARGET_REF",
                "propose",
                "a",
                "new",
                "realistic",
                "setting,",
                "FEVEROUS,",
                "i.e.,",
                "fact",
                "extraction",
                "and",
                "verification",
                "over",
                "unstructured",
                "and",
                "structured",
                "information.",
                "In",
                "FEVEROUS,",
                "models",
                "should",
                "not",
                "only",
                "extract",
                "evidence",
                "sentences/table",
                "cells",
                "from",
                "millions",
                "of",
                "passages,",
                "but",
                "also",
                "combine",
                "the",
                "evidence",
                "in",
                "different",
                "formats",
                "to",
                "verify",
                "a",
                "given",
                "claim."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The task of fact extraction and verification aims to extract evidence and verify a given claim. Previous efforts focus on dealing with text format evidence from unstructured documents #REF or evidence from a single given table #REF . Recently, #TARGET_REF propose a new realistic setting, FEVEROUS, i.e., fact extraction and verification over unstructured and structured information. In FEVEROUS, models should not only extract evidence sentences/table cells from millions of passages, but also combine the evidence in different formats to verify a given claim.",
        "output": "{\"INFO\": [\"#TARGET_REF propose a new realistic setting, FEVEROUS, i.e., fact extraction and verification over unstructured and structured information. In FEVEROUS, models should not only extract evidence sentences/table cells from millions of passages, but also combine the evidence in different formats to verify a given claim.\"], \"PERCEPT\": [], \"BACK\": [\"Previous efforts focus on dealing with text format evidence from unstructured documents #REF or evidence from a single given table #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Other",
                "architectural",
                "improvements",
                "highlighted",
                "with",
                "the",
                "introduction",
                "of",
                "the",
                "ALBERT",
                "model",
                "#REF",
                "such",
                "as",
                "the",
                "factorization",
                "of",
                "the",
                "attention",
                "matrix",
                "or",
                "parameter",
                "sharing.",
                "Indeed,",
                "the",
                "most",
                "time-consuming",
                "and",
                "memory-intensive",
                "operations",
                "concerns",
                "the",
                "forward",
                "propagation",
                "and",
                "attention",
                "computation",
                "operations.",
                "The",
                "self-attention",
                "layer",
                "of",
                "BERT",
                "pretrained",
                "models",
                "grows",
                "quadratically",
                "in",
                "respect",
                "to",
                "the",
                "input",
                "sequence",
                "length.",
                "One",
                "common",
                "approach",
                "to",
                "this",
                "issue",
                "consists",
                "of",
                "approximating",
                "the",
                "dot-product",
                "attention",
                "for",
                "example",
                "by",
                "using",
                "hashing",
                "techniques",
                "#TARGET_REF",
                "to",
                "accelerate",
                "the",
                "training",
                "and",
                "inference",
                "phases",
                "when",
                "long",
                "sequence",
                "lengths",
                "are",
                "used.",
                "However",
                "these",
                "solutions",
                "have",
                "demonstrated",
                "they",
                "suffer",
                "from",
                "important",
                "computational",
                "overheads",
                "for",
                "tasks",
                "with",
                "smaller",
                "lengths,",
                "such",
                "as",
                "question-answering."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Other architectural improvements highlighted with the introduction of the ALBERT model #REF such as the factorization of the attention matrix or parameter sharing. Indeed, the most time-consuming and memory-intensive operations concerns the forward propagation and attention computation operations. The self-attention layer of BERT pretrained models grows quadratically in respect to the input sequence length. One common approach to this issue consists of approximating the dot-product attention for example by using hashing techniques #TARGET_REF to accelerate the training and inference phases when long sequence lengths are used. However these solutions have demonstrated they suffer from important computational overheads for tasks with smaller lengths, such as question-answering.",
        "output": "{\"INFO\": [\"hashing techniques #TARGET_REF\"], \"PERCEPT\": [\"One common approach to this issue consists of approximating the dot-product attention for example by using\", \"to accelerate the training and inference phases when long sequence lengths are used.\"], \"BACK\": [\"the most time-consuming and memory-intensive operations concerns the forward propagation and attention computation operations.\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "departure",
                "point",
                "for",
                "this",
                "work",
                "has",
                "been",
                "the",
                "notion",
                "of",
                "an",
                "implicit",
                "argument",
                "of",
                "a",
                "noun,",
                "that",
                "is,",
                "nouns",
                "such",
                "as",
                "''brother''",
                "or",
                "''price''",
                "that",
                "are",
                "incomplete",
                "on",
                "their",
                "own,",
                "and",
                "require",
                "an",
                "argument",
                "to",
                "be",
                "complete.",
                "In",
                "linguistics,",
                "these",
                "are",
                "referred",
                "to",
                "as",
                "relational",
                "nouns",
                "#TARGET_REF",
                ".",
                "In",
                "contrast,",
                "nouns",
                "like",
                "''plant'',",
                "or",
                "''sofa''",
                "are",
                "called",
                "sortal",
                "and",
                "are",
                "conceived",
                "as",
                "''complete'',",
                "their",
                "denotation",
                "need",
                "not",
                "rely",
                "on",
                "the",
                "relation",
                "to",
                "other",
                "nouns,",
                "and",
                "can",
                "be",
                "fully",
                "determined."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Our departure point for this work has been the notion of an implicit argument of a noun, that is, nouns such as ''brother'' or ''price'' that are incomplete on their own, and require an argument to be complete. In linguistics, these are referred to as relational nouns #TARGET_REF . In contrast, nouns like ''plant'', or ''sofa'' are called sortal and are conceived as ''complete'', their denotation need not rely on the relation to other nouns, and can be fully determined.",
        "output": "{\"INFO\": [\"In linguistics, these are referred to as relational nouns #TARGET_REF .\"], \"PERCEPT\": [\"Our departure point for this work has been the notion of an implicit argument of a noun, that is, nouns such as ''brother'' or ''price'' that are incomplete on their own, and require an argument to be complete.\"], \"BACK\": [\"nouns like ''plant'', or ''sofa'' are called sortal and are conceived as ''complete'', their denotation need not rely on the relation to other nouns, and can be fully determined.\"]}"
    },
    {
        "gold": {
            "text": [
                "Pre-training.",
                "We",
                "test",
                "two",
                "model",
                "types,",
                "drawing",
                "from",
                "#TARGET_REF",
                ",",
                "to",
                "determine",
                "if",
                "pre-training",
                "effects",
                "curriculums",
                "learning."
            ],
            "context": [
                0,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Pre-training. We test two model types, drawing from #TARGET_REF , to determine if pre-training effects curriculums learning.",
        "output": "{\"INFO\": [\"model types,\"], \"PERCEPT\": [\"We test two\", \"drawing from #TARGET_REF , to determine if pre-training effects curriculums learning.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Contrast",
                "set:",
                "the",
                "evaluation",
                "set",
                "by",
                "#TARGET_REF",
                "that",
                "is",
                "created",
                "based",
                "on",
                "the",
                "official",
                "Quoref",
                "test",
                "set.",
                "For",
                "creating",
                "this",
                "evaluation",
                "set,",
                "the",
                "authors",
                "manually",
                "performed",
                "small",
                "but",
                "meaningful",
                "perturbations",
                "to",
                "the",
                "test",
                "examples",
                "in",
                "a",
                "way",
                "that",
                "it",
                "changes",
                "the",
                "gold",
                "label.",
                "This",
                "dataset",
                "is",
                "constructed",
                "to",
                "evaluate",
                "whether",
                "models",
                "decision",
                "boundaries",
                "align",
                "to",
                "true",
                "decision",
                "boundaries",
                "when",
                "they",
                "are",
                "measured",
                "around",
                "the",
                "same",
                "point."
            ],
            "context": [
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Contrast set: the evaluation set by #TARGET_REF that is created based on the official Quoref test set. For creating this evaluation set, the authors manually performed small but meaningful perturbations to the test examples in a way that it changes the gold label. This dataset is constructed to evaluate whether models decision boundaries align to true decision boundaries when they are measured around the same point.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"the evaluation set by #TARGET_REF that is created based on the official Quoref test set.\"]}"
    },
    {
        "gold": {
            "text": [
                "4.",
                "For",
                "French,",
                "we",
                "use",
                "the",
                "French",
                "TimeBank",
                "as",
                "it",
                "is",
                "the",
                "ISO-TimeML",
                "annotated",
                "reference",
                "corpus",
                "for",
                "event",
                "annotation",
                "tasks",
                "#TARGET_REF",
                ".",
                "The",
                "corpus",
                "consists",
                "of",
                "16,208",
                "tokens",
                "and",
                "2,100",
                "event",
                "mentions."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "4. For French, we use the French TimeBank as it is the ISO-TimeML annotated reference corpus for event annotation tasks #TARGET_REF . The corpus consists of 16,208 tokens and 2,100 event mentions.",
        "output": "{\"INFO\": [\"the French TimeBank\", \"the ISO-TimeML annotated reference corpus for event annotation tasks #TARGET_REF . The corpus consists of 16,208 tokens and 2,100 event mentions.\"], \"PERCEPT\": [\"For French, we use\", \"as it is\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "First,",
                "each",
                "target-side",
                "sentence",
                "from",
                "the",
                "parallel",
                "corpus",
                "is",
                "supertagged",
                "by",
                "assigning",
                "the",
                "best",
                "sequence",
                "of",
                "CCG",
                "supertags",
                "to",
                "its",
                "words.",
                "•",
                "Next,",
                "phrase",
                "pairs",
                "are",
                "extracted",
                "from",
                "the",
                "parallel",
                "corpus",
                "according",
                "to",
                "the",
                "PBSMT",
                "phrase",
                "extraction",
                "method",
                "#TARGET_REF",
                ".",
                "•",
                "Then,",
                "each",
                "phrase",
                "pair",
                "is",
                "assigned",
                "a",
                "CCG",
                "category",
                "that",
                "results",
                "from",
                "combining",
                "the",
                "supertags",
                "of",
                "the",
                "words",
                "of",
                "the",
                "target-side",
                "phrase",
                "using",
                "CCG",
                "combinatory",
                "operators.",
                "In",
                "case",
                "phrase",
                "parsing",
                "fails",
                "to",
                "find",
                "a",
                "single",
                "CCG",
                "category",
                "for",
                "the",
                "phrase,",
                "a",
                "general",
                "X",
                "label",
                "is",
                "assigned",
                "to",
                "the",
                "phrase.",
                "•",
                "Finally,",
                "hierarchical",
                "rules",
                "are",
                "extracted",
                "from",
                "sentencepairs",
                "according",
                "to",
                "the",
                "same",
                "basic",
                "HPB",
                "SMT",
                "rule",
                "extraction",
                "method",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• First, each target-side sentence from the parallel corpus is supertagged by assigning the best sequence of CCG supertags to its words. • Next, phrase pairs are extracted from the parallel corpus according to the PBSMT phrase extraction method #TARGET_REF . • Then, each phrase pair is assigned a CCG category that results from combining the supertags of the words of the target-side phrase using CCG combinatory operators. In case phrase parsing fails to find a single CCG category for the phrase, a general X label is assigned to the phrase. • Finally, hierarchical rules are extracted from sentencepairs according to the same basic HPB SMT rule extraction method #REF .",
        "output": "{\"INFO\": [\"the PBSMT phrase extraction method #TARGET_REF .\"], \"PERCEPT\": [\"phrase pairs are extracted from the parallel corpus according to\"], \"BACK\": [\"each target-side sentence from the parallel corpus is supertagged by assigning the best sequence of CCG supertags to its words.\"]}"
    },
    {
        "gold": {
            "text": [
                "Accurate",
                "enough",
                "parse",
                "selection",
                "for",
                "practical",
                "applications",
                "will",
                "require",
                "a",
                "more",
                "lexic.",
                "alised",
                "system.",
                "#REF",
                "parser",
                "is",
                "an",
                "extension",
                "of",
                "the",
                "history-based",
                "parsing",
                "approach",
                "devel",
                "oped",
                "at",
                "IBM",
                "(e.g.",
                "#TARGET_REF",
                "in",
                "which",
                "rules",
                "are",
                "conditioned",
                "on",
                "lexical",
                "and",
                "other",
                "(essentially",
                "arbitrary)",
                "information",
                "available",
                "in",
                "the",
                "parse",
                "history.",
                "In",
                "future",
                "work,",
                "we",
                "intend",
                "to",
                "explore",
                "a",
                "more",
                "restricted",
                "and",
                "semantically-driven",
                "version",
                "of",
                "this",
                "approach",
                "in",
                "which,",
                "firstly,",
                "probabilities",
                "are",
                "associated",
                "with",
                "different",
                "subcategorisation",
                "possibilities,",
                "and",
                "secondly,",
                "alternative",
                "predicate",
                "argument",
                "structures",
                "derived",
                "from",
                "the",
                "grammar",
                "are",
                "ranked",
                "probabilistically.",
                "However,",
                "the",
                "mas",
                "sively",
                "increased",
                "coverage",
                "obtained",
                "here",
                "by",
                "relaxing",
                "subcategorisation",
                "constraints",
                "underlines",
                "the",
                "need",
                "to",
                "acquire",
                "accurate",
                "and",
                "complet�",
                "subcategorisation",
                "frames",
                "in",
                "a",
                "corpus-driven",
                "fas",
                "hion,",
                "before",
                "such",
                "constraints",
                "can",
                "be",
                "exploited",
                "robustly",
                "and",
                "effectively",
                "with",
                "free",
                "text."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Accurate enough parse selection for practical applications will require a more lexic. alised system. #REF parser is an extension of the history-based parsing approach devel oped at IBM (e.g. #TARGET_REF in which rules are conditioned on lexical and other (essentially arbitrary) information available in the parse history. In future work, we intend to explore a more restricted and semantically-driven version of this approach in which, firstly, probabilities are associated with different subcategorisation possibilities, and secondly, alternative predicate argument structures derived from the grammar are ranked probabilistically. However, the mas sively increased coverage obtained here by relaxing subcategorisation constraints underlines the need to acquire accurate and complet� subcategorisation frames in a corpus-driven fas hion, before such constraints can be exploited robustly and effectively with free text.",
        "output": "{\"INFO\": [\"in which rules are conditioned on lexical and other (essentially arbitrary) information available in the parse history.\"], \"PERCEPT\": [\"parser is an extension of the history-based parsing approach devel oped at IBM\"], \"BACK\": [\"#TARGET_REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Model",
                "stacking",
                "is",
                "an",
                "efficient",
                "ensemble",
                "method",
                "to",
                "improve",
                "model",
                "accuracy.",
                "The",
                "main",
                "procedure",
                "of",
                "stacking",
                "trained",
                "models",
                "in",
                "our",
                "method",
                "including",
                "five",
                "steps.",
                "First,",
                "we",
                "use",
                "heterogeneous",
                "PLMs",
                "including",
                "BERT,",
                "RoBERTa,",
                "ALBERT,",
                "and",
                "ERNIE",
                "as",
                "base",
                "models.",
                "Second,",
                "we",
                "generate",
                "multiple",
                "hyperparameter",
                "sets",
                "by",
                "setting",
                "different",
                "values",
                "of",
                "dropout,",
                "selecting",
                "different",
                "numbers",
                "of",
                "last",
                "hidden",
                "layers,",
                "and",
                "using",
                "different",
                "loss",
                "functions.",
                "Since",
                "our",
                "purpose",
                "here",
                "is",
                "not",
                "only",
                "to",
                "find",
                "the",
                "best",
                "hyperparameter",
                "sets",
                "but",
                "also",
                "to",
                "collect",
                "diverse",
                "sets",
                "with",
                "reasonable",
                "performances,",
                "we",
                "keep",
                "all",
                "the",
                "training",
                "results",
                "from",
                "different",
                "sets.",
                "Third,",
                "we",
                "perform",
                "7fold",
                "cross-validation",
                "during",
                "the",
                "whole",
                "training",
                "process",
                "to",
                "avoid",
                "overfitting",
                "or",
                "selection",
                "bias.",
                "Fourth,",
                "we",
                "adopt",
                "several",
                "training",
                "strategies",
                "including",
                "using",
                "pseudo-labelling",
                "#TARGET_REF",
                "and",
                "data",
                "augmentation",
                "to",
                "further",
                "improve",
                "the",
                "diversity",
                "of",
                "trained",
                "models."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Model stacking is an efficient ensemble method to improve model accuracy. The main procedure of stacking trained models in our method including five steps. First, we use heterogeneous PLMs including BERT, RoBERTa, ALBERT, and ERNIE as base models. Second, we generate multiple hyperparameter sets by setting different values of dropout, selecting different numbers of last hidden layers, and using different loss functions. Since our purpose here is not only to find the best hyperparameter sets but also to collect diverse sets with reasonable performances, we keep all the training results from different sets. Third, we perform 7fold cross-validation during the whole training process to avoid overfitting or selection bias. Fourth, we adopt several training strategies including using pseudo-labelling #TARGET_REF and data augmentation to further improve the diversity of trained models.",
        "output": "{\"INFO\": [\"pseudo-labelling #TARGET_REF\"], \"PERCEPT\": [\"The main procedure of stacking trained models in our method including five steps.\", \"we adopt several training strategies including using\", \"to further improve the diversity of trained models.\"], \"BACK\": [\"Model stacking is an efficient ensemble method to improve model accuracy.\", \"and data augmentation\"]}"
    },
    {
        "gold": {
            "text": [
                "From",
                "our",
                "source",
                "data",
                "we",
                "can",
                "extract",
                "parallel",
                "sentences",
                "for",
                "43",
                "languages.",
                "For",
                "12",
                "of",
                "these",
                "languages",
                "we",
                "have",
                "over",
                "10,000",
                "sentences",
                "available",
                "for",
                "projection",
                "as",
                "per",
                "table",
                "4.",
                "We",
                "removed",
                "some",
                "of",
                "these",
                "languages",
                "for",
                "having",
                "fewer",
                "than",
                "950",
                "lines,",
                "resulting",
                "in",
                "a",
                "total",
                "of",
                "32",
                "languages",
                "5",
                "including",
                "the",
                "annotated",
                "English",
                "and",
                "Finnish",
                "data.",
                "We",
                "have",
                "made",
                "all",
                "32",
                "datasets",
                "available",
                "on",
                "GitHub",
                "plus",
                "the",
                "raw",
                "data",
                "for",
                "all",
                "43",
                "languages",
                "including",
                "the",
                "11",
                "datasets",
                "that",
                "had",
                "fewer",
                "than",
                "950",
                "lines.",
                "#TARGET_REF",
                "Table",
                "4:",
                "Languages",
                "(ISO",
                "code)",
                "with",
                "over",
                "10k",
                "parallel",
                "sentences",
                "with",
                "our",
                "annotated",
                "English",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "From our source data we can extract parallel sentences for 43 languages. For 12 of these languages we have over 10,000 sentences available for projection as per table 4. We removed some of these languages for having fewer than 950 lines, resulting in a total of 32 languages 5 including the annotated English and Finnish data. We have made all 32 datasets available on GitHub plus the raw data for all 43 languages including the 11 datasets that had fewer than 950 lines. #TARGET_REF Table 4: Languages (ISO code) with over 10k parallel sentences with our annotated English data.",
        "output": "{\"INFO\": [\"#TARGET_REF Table 4: Languages (ISO code) with over 10k parallel sentences with our annotated English data.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "section,",
                "we",
                "discuss",
                "individual",
                "modules",
                "for",
                "operationalizing",
                "the",
                "PSL",
                "rules.",
                "For",
                "each",
                "module,",
                "we",
                "fine-tune",
                "the",
                "pretrained",
                "uncased",
                "BERT-base",
                "#TARGET_REF",
                ".",
                "We",
                "use",
                "the",
                "Transformers",
                "library",
                "v3.3.0",
                "#REF",
                "for",
                "high",
                "reproducibility",
                "and",
                "low",
                "development",
                "costs.",
                "But",
                "any",
                "other",
                "models",
                "could",
                "be",
                "used",
                "instead.",
                "Each",
                "dataset",
                "used",
                "is",
                "randomly",
                "split",
                "with",
                "a",
                "ratio",
                "of",
                "9:1",
                "for",
                "training",
                "and",
                "test.",
                "Cross-entropy",
                "and",
                "Adam",
                "are",
                "used",
                "for",
                "optimization.",
                "To",
                "address",
                "the",
                "imbalance",
                "of",
                "classes",
                "and",
                "datasets,",
                "the",
                "loss",
                "for",
                "each",
                "training",
                "instance",
                "is",
                "scaled",
                "by",
                "a",
                "weight",
                "inversely",
                "proportional",
                "to",
                "the",
                "number",
                "of",
                "its",
                "class",
                "and",
                "dataset."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this section, we discuss individual modules for operationalizing the PSL rules. For each module, we fine-tune the pretrained uncased BERT-base #TARGET_REF . We use the Transformers library v3.3.0 #REF for high reproducibility and low development costs. But any other models could be used instead. Each dataset used is randomly split with a ratio of 9:1 for training and test. Cross-entropy and Adam are used for optimization. To address the imbalance of classes and datasets, the loss for each training instance is scaled by a weight inversely proportional to the number of its class and dataset.",
        "output": "{\"INFO\": [\"the pretrained uncased BERT-base #TARGET_REF .\"], \"PERCEPT\": [\"For each module, we fine-tune\"], \"BACK\": [\"In this section, we discuss individual modules for operationalizing the PSL rules.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "final",
                "dataset",
                "contained",
                "17,520",
                "unique",
                "emotion-annotated",
                "subtitles",
                "as",
                "shown",
                "in",
                "table",
                "3.",
                "In",
                "addition",
                "there",
                "are",
                "some",
                "6.5k",
                "subtitles",
                "annotated",
                "as",
                "neutral.",
                "The",
                "label",
                "distribution",
                "can",
                "be",
                "seen",
                "in",
                "table",
                "3",
                "The",
                "emotion",
                "labels",
                "are",
                "surprisingly",
                "balanced",
                "with",
                "the",
                "exception",
                "of",
                "anger",
                "and",
                "anticipation,",
                "which",
                "are",
                "more",
                "common",
                "than",
                "the",
                "other",
                "labels.",
                "In",
                "comparison",
                "with",
                "one",
                "of",
                "the",
                "most",
                "well-known",
                "emotion",
                "datasets",
                "using",
                "the",
                "same",
                "annotation",
                "scheme,",
                "the",
                "NRC",
                "emotion",
                "lexicon",
                "(EmoLex)",
                "#TARGET_REF",
                ",",
                "the",
                "distribution",
                "differs",
                "somewhat.",
                "Although",
                "anger",
                "is",
                "a",
                "large",
                "category",
                "in",
                "both",
                "datasets,",
                "fear",
                "is",
                "average",
                "in",
                "our",
                "dataset,",
                "but",
                "the",
                "largest",
                "category",
                "in",
                "EmoLex.",
                "It",
                "is",
                "hard",
                "to",
                "speculate",
                "why",
                "this",
                "is,",
                "but",
                "one",
                "possible",
                "reason",
                "is",
                "the",
                "different",
                "source",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The final dataset contained 17,520 unique emotion-annotated subtitles as shown in table 3. In addition there are some 6.5k subtitles annotated as neutral. The label distribution can be seen in table 3 The emotion labels are surprisingly balanced with the exception of anger and anticipation, which are more common than the other labels. In comparison with one of the most well-known emotion datasets using the same annotation scheme, the NRC emotion lexicon (EmoLex) #TARGET_REF , the distribution differs somewhat. Although anger is a large category in both datasets, fear is average in our dataset, but the largest category in EmoLex. It is hard to speculate why this is, but one possible reason is the different source data.",
        "output": "{\"INFO\": [\"emotion datasets\", \"the NRC emotion lexicon (EmoLex) #TARGET_REF ,\"], \"PERCEPT\": [\"In comparison with one of the most well-known\", \"using the same annotation scheme,\", \"the distribution differs somewhat. Although anger is a large category in both datasets, fear is average in our dataset, but the largest category in EmoLex. It is hard to speculate why this is, but one possible reason is the different source data.\"], \"BACK\": [\"The emotion labels are surprisingly balanced with the exception of anger and anticipation,\"]}"
    },
    {
        "gold": {
            "text": [
                "Passage",
                "retrieval",
                "for",
                "open-domain",
                "QA",
                "For",
                "opendomain",
                "QA,",
                "a",
                "passage",
                "retriever",
                "is",
                "an",
                "important",
                "component",
                "to",
                "identify",
                "relevant",
                "passages",
                "for",
                "answer",
                "extraction.",
                "Traditional",
                "approaches",
                "#REF",
                "implemented",
                "term-based",
                "passage",
                "retrievers",
                "(e.g.",
                "TF-IDF",
                "and",
                "BM25),",
                "which",
                "have",
                "limited",
                "representation",
                "capabilities.",
                "Recently,",
                "researchers",
                "have",
                "utilized",
                "deep",
                "learning",
                "to",
                "improve",
                "traditional",
                "passage",
                "retrievers,",
                "including",
                "document",
                "expansions",
                "#TARGET_REF",
                ",",
                "question",
                "expansions",
                "#REF",
                "and",
                "term",
                "weight",
                "estimation",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0
            ]
        },
        "input": "Passage retrieval for open-domain QA For opendomain QA, a passage retriever is an important component to identify relevant passages for answer extraction. Traditional approaches #REF implemented term-based passage retrievers (e.g. TF-IDF and BM25), which have limited representation capabilities. Recently, researchers have utilized deep learning to improve traditional passage retrievers, including document expansions #TARGET_REF , question expansions #REF and term weight estimation #REF .",
        "output": "{\"INFO\": [\"document expansions\"], \"PERCEPT\": [\"Recently, researchers have utilized deep learning to improve traditional passage retrievers,\"], \"BACK\": [\"Passage retrieval for open-domain QA For opendomain QA, a passage retriever is an important component to identify relevant passages for answer extraction.\", \"including\", \"question expansions #REF and term weight estimation\"]}"
    },
    {
        "gold": {
            "text": [
                "Implementation",
                "In",
                "all",
                "experiments",
                "reported",
                "below,",
                "stochastic",
                "gradient",
                "descent",
                "is",
                "performed",
                "using",
                "the",
                "Adam",
                "algorithm",
                "with",
                "default",
                "initial",
                "learning",
                "rate",
                "#TARGET_REF",
                ".",
                "All",
                "experiments",
                "are",
                "implemented",
                "in",
                "PyTorch",
                "with",
                "use",
                "of",
                "opt_einsum",
                "to",
                "compute",
                "the",
                "partition",
                "function",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Implementation In all experiments reported below, stochastic gradient descent is performed using the Adam algorithm with default initial learning rate #TARGET_REF . All experiments are implemented in PyTorch with use of opt_einsum to compute the partition function #REF .",
        "output": "{\"INFO\": [\"stochastic gradient descent is performed using the Adam algorithm with default initial learning rate #TARGET_REF .\"], \"PERCEPT\": [\"Implementation In all experiments reported below,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "typical",
                "neural",
                "NLP",
                "systems,",
                "entities",
                "are",
                "embedded",
                "in",
                "the",
                "same",
                "space",
                "as",
                "other",
                "words",
                "either",
                "in",
                "context-independent",
                "#REF",
                "or",
                "in",
                "context-dependent",
                "ways",
                "#REF",
                ".",
                "Such",
                "approaches",
                "are",
                "powerful:",
                "pre-trained",
                "language",
                "models",
                "implicitly",
                "learn",
                "factual",
                "knowledge",
                "about",
                "those",
                "entities",
                "#REF",
                "and",
                "these",
                "representations",
                "can",
                "be",
                "grounded",
                "in",
                "structured",
                "and",
                "human-curated",
                "knowledge",
                "bases",
                "#REF",
                ".",
                "However,",
                "these",
                "embeddings",
                "do",
                "not",
                "explicitly",
                "maintain",
                "representations",
                "of",
                "this",
                "knowledge,",
                "and",
                "dense",
                "entity",
                "representations",
                "are",
                "not",
                "directly",
                "interpretable.",
                "Knowledge",
                "probing",
                "tasks",
                "can",
                "be",
                "used",
                "to",
                "measure",
                "LMs'",
                "factual",
                "knowledge",
                "#REF",
                ",",
                "but",
                "designing",
                "the",
                "right",
                "probing",
                "task",
                "is",
                "another",
                "hard",
                "problem",
                "#TARGET_REF",
                ",",
                "particularly",
                "if",
                "the",
                "probes",
                "are",
                "parameter-rich",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "In typical neural NLP systems, entities are embedded in the same space as other words either in context-independent #REF or in context-dependent ways #REF . Such approaches are powerful: pre-trained language models implicitly learn factual knowledge about those entities #REF and these representations can be grounded in structured and human-curated knowledge bases #REF . However, these embeddings do not explicitly maintain representations of this knowledge, and dense entity representations are not directly interpretable. Knowledge probing tasks can be used to measure LMs' factual knowledge #REF , but designing the right probing task is another hard problem #TARGET_REF , particularly if the probes are parameter-rich #REF .",
        "output": "{\"INFO\": [\"designing the right probing task is\", \"hard problem #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Knowledge probing tasks can be used to measure LMs' factual knowledge #REF , but\", \"another\", \"particularly if the probes are parameter-rich #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Data",
                "Augmentation",
                "The",
                "third",
                "strategy",
                "aims",
                "to",
                "alleviate",
                "the",
                "issue",
                "of",
                "limited",
                "training",
                "data.",
                "Since",
                "the",
                "cross-encoder",
                "is",
                "more",
                "powerful",
                "in",
                "measuring",
                "the",
                "similarity",
                "between",
                "questions",
                "and",
                "passages,",
                "we",
                "utilize",
                "it",
                "to",
                "annotate",
                "unlabeled",
                "questions",
                "for",
                "data",
                "augmentation.",
                "Specifically,",
                "we",
                "incorporate",
                "a",
                "new",
                "collection",
                "of",
                "unlabeled",
                "questions,",
                "while",
                "reuse",
                "the",
                "passage",
                "collection.",
                "Then,",
                "we",
                "use",
                "the",
                "learned",
                "crossencoder",
                "to",
                "predict",
                "the",
                "passage",
                "labels",
                "for",
                "the",
                "new",
                "questions.",
                "To",
                "ensure",
                "the",
                "quality",
                "of",
                "the",
                "automatically",
                "labeled",
                "data,",
                "we",
                "only",
                "select",
                "the",
                "predicted",
                "positive",
                "and",
                "negative",
                "passages",
                "with",
                "high",
                "confidence",
                "scores",
                "estimated",
                "by",
                "the",
                "cross-encoder.",
                "Finally,",
                "the",
                "automatically",
                "labeled",
                "data",
                "is",
                "used",
                "as",
                "augmented",
                "training",
                "data",
                "to",
                "learn",
                "the",
                "dual",
                "encoder.",
                "Another",
                "view",
                "of",
                "the",
                "data",
                "augmentation",
                "is",
                "knowledge",
                "distillation",
                "#TARGET_REF",
                ",",
                "where",
                "the",
                "cross-encoder",
                "is",
                "the",
                "teacher",
                "and",
                "the",
                "dual-encoder",
                "is",
                "the",
                "student."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Data Augmentation The third strategy aims to alleviate the issue of limited training data. Since the cross-encoder is more powerful in measuring the similarity between questions and passages, we utilize it to annotate unlabeled questions for data augmentation. Specifically, we incorporate a new collection of unlabeled questions, while reuse the passage collection. Then, we use the learned crossencoder to predict the passage labels for the new questions. To ensure the quality of the automatically labeled data, we only select the predicted positive and negative passages with high confidence scores estimated by the cross-encoder. Finally, the automatically labeled data is used as augmented training data to learn the dual encoder. Another view of the data augmentation is knowledge distillation #TARGET_REF , where the cross-encoder is the teacher and the dual-encoder is the student.",
        "output": "{\"INFO\": [\"knowledge distillation #TARGET_REF , where the cross-encoder is the teacher and the dual-encoder is the student.\"], \"PERCEPT\": [\"Another view of the data augmentation is\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "After",
                "obtaining",
                "natural",
                "language",
                "actions,",
                "we",
                "enrich",
                "the",
                "dialogues",
                "as",
                "{(c",
                "t",
                ",",
                "l(x",
                "t",
                "),",
                "x",
                "t",
                ")|1",
                "≤",
                "t",
                "≤",
                "n",
                "d",
                "},",
                "where",
                "l(x",
                "t",
                ")",
                "is",
                "the",
                "natural",
                "language",
                "action",
                "of",
                "utterance",
                "x",
                "t",
                ".",
                "We",
                "could",
                "then",
                "run",
                "conditioned",
                "response",
                "generation",
                "to",
                "train",
                "content",
                "planning",
                "and",
                "language",
                "generation",
                "models",
                "as",
                "Eqn.",
                "1-3.",
                "The",
                "learning",
                "efficiency",
                "can",
                "be",
                "improved",
                "by",
                "the",
                "more",
                "compact",
                "and",
                "noise-free",
                "action",
                "space.",
                "Moreover,",
                "the",
                "natural",
                "language",
                "actions",
                "present",
                "abundant",
                "information",
                "of",
                "correlations",
                "among",
                "actions,",
                "which",
                "allows",
                "for",
                "better",
                "generalization",
                "over",
                "actions",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "After obtaining natural language actions, we enrich the dialogues as {(c t , l(x t ), x t )|1 ≤ t ≤ n d }, where l(x t ) is the natural language action of utterance x t . We could then run conditioned response generation to train content planning and language generation models as Eqn. 1-3. The learning efficiency can be improved by the more compact and noise-free action space. Moreover, the natural language actions present abundant information of correlations among actions, which allows for better generalization over actions #TARGET_REF .",
        "output": "{\"INFO\": [\"the natural language actions present abundant information of correlations among actions, which allows for better generalization over actions #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "2",
                "Encoding",
                "Anchored",
                "DRSs",
                "as",
                "Sequences",
                "#REF",
                ",",
                "#TARGET_REF",
                ",",
                "#REF",
                "encode",
                "syntax",
                "trees",
                "as",
                "token",
                "labels",
                "to",
                "cast",
                "syntactic",
                "parsing",
                "as",
                "a",
                "sequence",
                "labeling",
                "task.",
                "We",
                "apply",
                "a",
                "similar",
                "method",
                "to",
                "DRS",
                "parsing.",
                "We",
                "will",
                "use",
                "a",
                "simplified",
                "example",
                "from",
                "the",
                "Parallel",
                "Meaning",
                "Bank",
                "(PMB,",
                "#REF",
                "for",
                "exposition."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "2 Encoding Anchored DRSs as Sequences #REF , #TARGET_REF , #REF encode syntax trees as token labels to cast syntactic parsing as a sequence labeling task. We apply a similar method to DRS parsing. We will use a simplified example from the Parallel Meaning Bank (PMB, #REF for exposition.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"Encoding Anchored DRSs as Sequences #REF\", \"#REF encode syntax trees as token labels to cast syntactic parsing as a sequence labeling task.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Top-k",
                "attention",
                "also",
                "reduces",
                "memory",
                "consumption",
                "in",
                "Transformer",
                "feed-forward",
                "layers,",
                "by",
                "casting",
                "this",
                "layer",
                "into",
                "the",
                "familiar",
                "query-key-value",
                "framework",
                "using",
                "ReLU",
                "instead",
                "of",
                "the",
                "row-wise",
                "softmax",
                "#REF",
                ".",
                "This",
                "is",
                "specifically",
                "appealing",
                "in",
                "models",
                "such",
                "as",
                "T5",
                "#REF",
                "and",
                "GPT-3",
                "#REF",
                ",",
                "where",
                "for",
                "short",
                "inputs,",
                "the",
                "memory",
                "consumption",
                "is",
                "dominated",
                "by",
                "the",
                "feed-forward",
                "layers,",
                "as",
                "the",
                "number",
                "of",
                "keys,",
                "corresponding",
                "to",
                "the",
                "feedforward",
                "hidden",
                "dimension",
                "size,",
                "is",
                "as",
                "large",
                "as",
                "65K.",
                "Conversely,",
                "methods",
                "that",
                "rely",
                "on",
                "random",
                "feature",
                "approximations",
                "of",
                "attention,",
                "such",
                "as",
                "Performer",
                "#REF",
                "and",
                "RFA",
                "#REF",
                "do",
                "not",
                "admit",
                "an",
                "efficient",
                "approximation",
                "for",
                "the",
                "ReLU",
                "activation",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• Top-k attention also reduces memory consumption in Transformer feed-forward layers, by casting this layer into the familiar query-key-value framework using ReLU instead of the row-wise softmax #REF . This is specifically appealing in models such as T5 #REF and GPT-3 #REF , where for short inputs, the memory consumption is dominated by the feed-forward layers, as the number of keys, corresponding to the feedforward hidden dimension size, is as large as 65K. Conversely, methods that rely on random feature approximations of attention, such as Performer #REF and RFA #REF do not admit an efficient approximation for the ReLU activation #TARGET_REF .",
        "output": "{\"INFO\": [\"methods that rely on random feature approximations of attention,\", \"do not admit an efficient approximation for the ReLU activation #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"such as Performer #REF and RFA #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Words'",
                "semantics",
                "have",
                "a",
                "dynamic",
                "nature",
                "which",
                "depends",
                "on",
                "the",
                "surrounding",
                "context",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "the",
                "majority",
                "of",
                "words",
                "tends",
                "to",
                "be",
                "polysemous",
                "(i.e.",
                "have",
                "multiple",
                "senses).",
                "For",
                "few",
                "examples,",
                "words",
                "such",
                "as",
                "\"cell\",",
                "\"bank\"",
                "and",
                "\"report\"",
                "can",
                "be",
                "mentioned.",
                "Due",
                "to",
                "this",
                "nature",
                "in",
                "natural",
                "language,",
                "it",
                "is",
                "important",
                "to",
                "focus",
                "on",
                "word-in-context",
                "sense",
                "while",
                "extracting",
                "the",
                "meaning",
                "of",
                "a",
                "word",
                "which",
                "appeared",
                "in",
                "a",
                "text",
                "segment.",
                "Also,",
                "this",
                "is",
                "a",
                "critical",
                "requirement",
                "to",
                "many",
                "applications",
                "such",
                "as",
                "question",
                "answering,",
                "document",
                "summarisation,",
                "information",
                "retrieval",
                "and",
                "information",
                "extraction."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Words' semantics have a dynamic nature which depends on the surrounding context #TARGET_REF . Therefore, the majority of words tends to be polysemous (i.e. have multiple senses). For few examples, words such as \"cell\", \"bank\" and \"report\" can be mentioned. Due to this nature in natural language, it is important to focus on word-in-context sense while extracting the meaning of a word which appeared in a text segment. Also, this is a critical requirement to many applications such as question answering, document summarisation, information retrieval and information extraction.",
        "output": "{\"INFO\": [\"Words' semantics have a dynamic nature which depends on the surrounding context #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Therefore, the majority of words tends to be polysemous (i.e. have multiple senses).\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "post-editing",
                "interface",
                "can",
                "be",
                "seen",
                "in",
                "Figure",
                "1",
                "above.",
                "Each",
                "text",
                "was",
                "presented",
                "to",
                "posteditors",
                "in",
                "one",
                "of",
                "two",
                "variant",
                "modalities",
                "-word-level",
                "alignment",
                "links",
                "could",
                "either",
                "be",
                "visualized",
                "or",
                "left",
                "absent.",
                "In",
                "both",
                "variants,",
                "each",
                "source",
                "language",
                "segment",
                "was",
                "presented",
                "along",
                "with",
                "the",
                "corresponding",
                "machine",
                "translated",
                "English",
                "segment,",
                "a",
                "text",
                "field",
                "(initially",
                "populated",
                "with",
                "the",
                "machine",
                "translated",
                "segment)",
                "where",
                "the",
                "post-editor",
                "could",
                "make",
                "changes",
                "was",
                "also",
                "presented.",
                "In",
                "the",
                "first",
                "variant,",
                "the",
                "word-level",
                "alignment",
                "links",
                "produced",
                "by",
                "the",
                "machine",
                "translation",
                "decoder",
                "(Moses",
                "for",
                "Russian-English,",
                "Bing",
                "Translator",
                "for",
                "Spanish-English)",
                "were",
                "graphically",
                "displayed,",
                "linking",
                "source",
                "words",
                "to",
                "their",
                "corresponding",
                "machine",
                "translated",
                "target",
                "words.",
                "In",
                "the",
                "second",
                "variant,",
                "the",
                "word-level",
                "alignment",
                "links",
                "were",
                "omitted",
                "from",
                "the",
                "visualization",
                "interface.",
                "Figure",
                "2:",
                "Percentage",
                "of",
                "segments",
                "judged",
                "to",
                "be",
                "in",
                "each",
                "adequacy",
                "category.",
                "For",
                "each",
                "language",
                "pair,",
                "we",
                "report",
                "percentages",
                "for",
                "raw",
                "(unedited)",
                "machine",
                "translation",
                "output,",
                "as",
                "well",
                "as",
                "output",
                "postedited",
                "by",
                "a",
                "bilingual",
                "post-editor",
                "with",
                "access",
                "to",
                "alignments",
                "and",
                "without",
                "access",
                "to",
                "alignments.",
                "For",
                "Russian-English,",
                "we",
                "additionally",
                "report",
                "percentages",
                "for",
                "output",
                "post-edited",
                "by",
                "a",
                "monolingual",
                "post-editor",
                "#TARGET_REF",
                "with",
                "access",
                "to",
                "alignments."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Our post-editing interface can be seen in Figure 1 above. Each text was presented to posteditors in one of two variant modalities -word-level alignment links could either be visualized or left absent. In both variants, each source language segment was presented along with the corresponding machine translated English segment, a text field (initially populated with the machine translated segment) where the post-editor could make changes was also presented. In the first variant, the word-level alignment links produced by the machine translation decoder (Moses for Russian-English, Bing Translator for Spanish-English) were graphically displayed, linking source words to their corresponding machine translated target words. In the second variant, the word-level alignment links were omitted from the visualization interface. Figure 2: Percentage of segments judged to be in each adequacy category. For each language pair, we report percentages for raw (unedited) machine translation output, as well as output postedited by a bilingual post-editor with access to alignments and without access to alignments. For Russian-English, we additionally report percentages for output post-edited by a monolingual post-editor #TARGET_REF with access to alignments.",
        "output": "{\"INFO\": [\"monolingual post-editor #TARGET_REF with access to alignments.\"], \"PERCEPT\": [], \"BACK\": [\"For Russian-English, we additionally report percentages for output post-edited by a\"]}"
    },
    {
        "gold": {
            "text": [
                "Nevertheless,",
                "it",
                "has",
                "been",
                "shown",
                "by",
                "#TARGET_REF",
                "that",
                "it",
                "is",
                "possible",
                "to",
                "improve",
                "phone",
                "recognition",
                "with",
                "even",
                "small",
                "amounts",
                "(approximately",
                "100",
                "sentences)",
                "of",
                "annotation.",
                "It",
                "may",
                "be",
                "possible",
                "to",
                "improve",
                "phonetic",
                "language",
                "modeling",
                "results",
                "by",
                "performing",
                "this",
                "fine-tuning",
                "in",
                "the",
                "target",
                "language."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Nevertheless, it has been shown by #TARGET_REF that it is possible to improve phone recognition with even small amounts (approximately 100 sentences) of annotation. It may be possible to improve phonetic language modeling results by performing this fine-tuning in the target language.",
        "output": "{\"INFO\": [\"by #TARGET_REF\"], \"PERCEPT\": [\"it has been shown\", \"It may be possible to improve phonetic language modeling results by performing this fine-tuning in the target language.\"], \"BACK\": [\"it is possible to improve phone recognition with even small amounts (approximately 100 sentences) of annotation.\"]}"
    },
    {
        "gold": {
            "text": [
                "deceptively",
                "simple:",
                "For",
                "each",
                "ordered",
                "pair",
                "(n",
                "1",
                ",",
                "n",
                "2",
                ")",
                "of",
                "non-pronominal",
                "base-NP",
                "3",
                "spans",
                "in",
                "an",
                "input",
                "text,",
                "determine",
                "if",
                "there",
                "exists",
                "a",
                "preposition-mediated",
                "relation",
                "between",
                "n",
                "1",
                "and",
                "n",
                "2",
                ",",
                "and",
                "if",
                "there",
                "is",
                "one,",
                "determine",
                "the",
                "preposition",
                "that",
                "best",
                "describes",
                "their",
                "relation.",
                "4",
                "The",
                "output",
                "is",
                "a",
                "list",
                "3",
                "We",
                "follow",
                "the",
                "definition",
                "of",
                "Base-NPs",
                "as",
                "defined",
                "by",
                "#TARGET_REF",
                ":",
                "initial",
                "portions",
                "of",
                "non-recursive",
                "noun-phrases,",
                "including",
                "pre-modifiers",
                "such",
                "as",
                "determiners,",
                "adjectives",
                "and",
                "noun-compounds,",
                "but",
                "not",
                "including",
                "post-modifiers",
                "such",
                "as",
                "prepositional",
                "phrases",
                "and",
                "clauses.",
                "These",
                "are",
                "also",
                "known",
                "in",
                "the",
                "NLP",
                "literature",
                "as",
                "''NP",
                "Chunks''.",
                "4",
                "During",
                "annotation,",
                "we",
                "noticed",
                "that",
                "annotators",
                "often",
                "tried",
                "to",
                "express",
                "set-membership",
                "using",
                "prepositions,",
                "which",
                "resulted",
                "in",
                "awkward",
                "and",
                "unclear",
                "annotations.",
                "To",
                "remedy",
                "this,",
                "we",
                "found",
                "it",
                "effective",
                "to",
                "add",
                "an",
                "explicit",
                "''member-of''",
                "relation",
                "as",
                "an",
                "allowed",
                "annotation",
                "option.",
                "This",
                "significantly",
                "reduced",
                "of",
                "tuples",
                "of",
                "the",
                "form",
                "(n",
                "i",
                ",",
                "prep,",
                "n",
                "j",
                "),",
                "where",
                "n",
                "i",
                "is",
                "called",
                "the",
                "anchor",
                "and",
                "n",
                "j",
                "is",
                "called",
                "the",
                "complement",
                "of",
                "the",
                "relation.",
                "Figure",
                "2",
                "shows",
                "an",
                "example",
                "of",
                "text",
                "where",
                "each",
                "NP",
                "n",
                "1",
                "is",
                "annotated",
                "with",
                "its",
                "(prep,",
                "n",
                "2",
                ")",
                "NP-enrichments."
            ],
            "context": [
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "deceptively simple: For each ordered pair (n 1 , n 2 ) of non-pronominal base-NP 3 spans in an input text, determine if there exists a preposition-mediated relation between n 1 and n 2 , and if there is one, determine the preposition that best describes their relation. 4 The output is a list 3 We follow the definition of Base-NPs as defined by #TARGET_REF : initial portions of non-recursive noun-phrases, including pre-modifiers such as determiners, adjectives and noun-compounds, but not including post-modifiers such as prepositional phrases and clauses. These are also known in the NLP literature as ''NP Chunks''. 4 During annotation, we noticed that annotators often tried to express set-membership using prepositions, which resulted in awkward and unclear annotations. To remedy this, we found it effective to add an explicit ''member-of'' relation as an allowed annotation option. This significantly reduced of tuples of the form (n i , prep, n j ), where n i is called the anchor and n j is called the complement of the relation. Figure 2 shows an example of text where each NP n 1 is annotated with its (prep, n 2 ) NP-enrichments.",
        "output": "{\"INFO\": [\"the definition of Base-NPs as defined by #TARGET_REF : initial portions of non-recursive noun-phrases, including pre-modifiers\", \"not including post-modifiers\"], \"PERCEPT\": [\"We follow\", \"These are also known in the NLP literature as ''NP Chunks''.\"], \"BACK\": [\"deceptively simple:\", \"such as determiners, adjectives and noun-compounds,\", \"such as prepositional phrases and clauses.\"]}"
    },
    {
        "gold": {
            "text": [
                "Wiggins",
                "(",
                "2013)",
                "gives",
                "yet",
                "another",
                "perspective",
                "of",
                "investment",
                "and",
                "MT",
                "implementation",
                "in",
                "Asia",
                "Online",
                "3",
                "business",
                "environment.",
                "Some",
                "of",
                "the",
                "advantages",
                "of",
                "providing",
                "MT-incorporated",
                "solutions",
                "#TARGET_REF",
                "list",
                "are",
                "reduced",
                "translation",
                "costs,",
                "faster",
                "delivery",
                "time,",
                "expansion",
                "of",
                "existing",
                "relationships",
                "with",
                "clients,",
                "broadening",
                "offered",
                "functionality",
                "and",
                "opening",
                "new",
                "market",
                "possibilities."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Wiggins ( 2013) gives yet another perspective of investment and MT implementation in Asia Online 3 business environment. Some of the advantages of providing MT-incorporated solutions #TARGET_REF list are reduced translation costs, faster delivery time, expansion of existing relationships with clients, broadening offered functionality and opening new market possibilities.",
        "output": "{\"INFO\": [\"Some of the advantages of providing MT-incorporated solutions #TARGET_REF list are reduced translation costs, faster delivery time, expansion of existing relationships with clients, broadening offered functionality and opening new market possibilities.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Table",
                "2",
                "shows",
                "the",
                "main",
                "experimental",
                "results.",
                "We",
                "can",
                "see",
                "that",
                "RocketQA",
                "significantly",
                "outperforms",
                "all",
                "the",
                "baselines",
                "on",
                "both",
                "MSMARCO",
                "and",
                "NQ",
                "datasets.",
                "Another",
                "observation",
                "is",
                "that",
                "the",
                "dense",
                "retrievers",
                "are",
                "overall",
                "better",
                "than",
                "the",
                "sparse",
                "retrievers.",
                "Such",
                "a",
                "finding",
                "has",
                "also",
                "been",
                "reported",
                "in",
                "previous",
                "studies",
                "#TARGET_REF",
                ",",
                "which",
                "indicates",
                "the",
                "effectiveness",
                "of",
                "the",
                "dense",
                "retrieval",
                "approach."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Table 2 shows the main experimental results. We can see that RocketQA significantly outperforms all the baselines on both MSMARCO and NQ datasets. Another observation is that the dense retrievers are overall better than the sparse retrievers. Such a finding has also been reported in previous studies #TARGET_REF , which indicates the effectiveness of the dense retrieval approach.",
        "output": "{\"INFO\": [\"previous studies #TARGET_REF , which indicates the effectiveness of the dense retrieval approach.\"], \"PERCEPT\": [], \"BACK\": [\"Another observation is that the dense retrievers are overall better than the sparse retrievers. Such a finding has also been reported in\"]}"
    },
    {
        "gold": {
            "text": [
                "Benchmarks",
                "for",
                "fact",
                "verification",
                "on",
                "structured",
                "evidence",
                "are",
                "built",
                "on",
                "tables",
                "collected",
                "from",
                "Wikipedia",
                "#REF",
                "or",
                "scientific",
                "articles",
                "#REF",
                ".",
                "Many",
                "previous",
                "works",
                "search",
                "latent",
                "programs",
                "as",
                "an",
                "intermediary",
                "to",
                "reason",
                "over",
                "the",
                "given",
                "table.",
                "They",
                "directly",
                "encode",
                "programs",
                "#REF",
                "or",
                "construct",
                "heterogeneous",
                "graphs",
                "#TARGET_REF",
                "with",
                "the",
                "claim,",
                "the",
                "table",
                "and",
                "the",
                "programs.",
                "Another",
                "way",
                "is",
                "to",
                "linearize",
                "the",
                "input",
                "table",
                "and",
                "perform",
                "table",
                "pre-training",
                "#REF",
                "and",
                "add",
                "additional",
                "table-aware",
                "embeddings",
                "#REF",
                "to",
                "enhance",
                "the",
                "table",
                "encoding.",
                "However,",
                "in",
                "these",
                "datasets,",
                "the",
                "evidence",
                "is",
                "only",
                "one",
                "given",
                "table,",
                "and",
                "models",
                "are",
                "not",
                "requested",
                "to",
                "find",
                "out",
                "the",
                "evidence",
                "cells",
                "explicitly."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Benchmarks for fact verification on structured evidence are built on tables collected from Wikipedia #REF or scientific articles #REF . Many previous works search latent programs as an intermediary to reason over the given table. They directly encode programs #REF or construct heterogeneous graphs #TARGET_REF with the claim, the table and the programs. Another way is to linearize the input table and perform table pre-training #REF and add additional table-aware embeddings #REF to enhance the table encoding. However, in these datasets, the evidence is only one given table, and models are not requested to find out the evidence cells explicitly.",
        "output": "{\"INFO\": [\"construct heterogeneous graphs #TARGET_REF with the claim, the table and the programs.\"], \"PERCEPT\": [\"They\"], \"BACK\": [\"Many previous works search latent programs as an intermediary to reason over the given table.\", \"directly encode programs #REF or\"]}"
    },
    {
        "gold": {
            "text": [
                "5.",
                "For",
                "Hindi,",
                "we",
                "use",
                "the",
                "gold-standard",
                "corpus",
                "of",
                "#TARGET_REF",
                ",",
                "which",
                "consists",
                "of",
                "810",
                "event",
                "annotated",
                "news",
                "articles",
                "based",
                "on",
                "modified",
                "TimeML",
                "rules.",
                "The",
                "dataset",
                "has",
                "242,201",
                "tokens",
                "and",
                "20,190",
                "event",
                "mentions."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "5. For Hindi, we use the gold-standard corpus of #TARGET_REF , which consists of 810 event annotated news articles based on modified TimeML rules. The dataset has 242,201 tokens and 20,190 event mentions.",
        "output": "{\"INFO\": [\"#TARGET_REF , which consists of 810 event annotated news articles based on modified TimeML rules. The dataset has 242,201 tokens and 20,190 event mentions.\"], \"PERCEPT\": [\"For Hindi, we use the gold-standard corpus of\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "MOST",
                "FREQUENT",
                "baseline",
                "chooses",
                "the",
                "most",
                "frequently",
                "observed",
                "entity",
                "for",
                "a",
                "given",
                "mention",
                "as",
                "a",
                "prediction,",
                "based",
                "on",
                "a",
                "prior",
                "probability",
                "p",
                "prior",
                "computed",
                "from",
                "link",
                "counts",
                "on",
                "Wikipedia.",
                "All",
                "baselines",
                "except",
                "MOST",
                "FREQUENT",
                "combine",
                "the",
                "classifier",
                "output",
                "and",
                "the",
                "prior",
                "probability",
                "to",
                "make",
                "a",
                "prediction:",
                "arg",
                "max",
                "c",
                "p",
                "prior",
                "(c)",
                "+",
                "p",
                "classifier",
                "(c)",
                ".",
                "10",
                "data.",
                "Our",
                "approach",
                "outperforms",
                "all",
                "baselines,",
                "indicating",
                "that",
                "our",
                "entity",
                "representations",
                "include",
                "useful",
                "information",
                "about",
                "entities",
                "out-of-the-box.",
                "Such",
                "a",
                "performance",
                "gap",
                "is",
                "expected",
                "since",
                "our",
                "entity",
                "representations",
                "can",
                "directly",
                "encode",
                "some",
                "factual",
                "knowledge",
                "from",
                "Wikipedia.",
                "However,",
                "these",
                "results",
                "also",
                "imply",
                "that",
                "pre-trained",
                "LMs",
                "do",
                "not",
                "have",
                "enough",
                "factual",
                "information",
                "out-of-the-box,",
                "they",
                "may",
                "rely",
                "on",
                "in-domain",
                "fine-tuning",
                "to",
                "achieve",
                "high",
                "performance",
                "in",
                "the",
                "target",
                "domain,",
                "and",
                "often",
                "fail",
                "to",
                "generalize",
                "to",
                "new",
                "settings.",
                "Note",
                "that",
                "while",
                "these",
                "accuracies",
                "are",
                "significantly",
                "below",
                "the",
                "supervised",
                "state-of-the-art",
                "(95%),",
                "they",
                "are",
                "competitive",
                "with",
                "the",
                "\"zero-shot\"",
                "entity",
                "results",
                "from",
                "recent",
                "past",
                "work",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The MOST FREQUENT baseline chooses the most frequently observed entity for a given mention as a prediction, based on a prior probability p prior computed from link counts on Wikipedia. All baselines except MOST FREQUENT combine the classifier output and the prior probability to make a prediction: arg max c p prior (c) + p classifier (c) . 10 data. Our approach outperforms all baselines, indicating that our entity representations include useful information about entities out-of-the-box. Such a performance gap is expected since our entity representations can directly encode some factual knowledge from Wikipedia. However, these results also imply that pre-trained LMs do not have enough factual information out-of-the-box, they may rely on in-domain fine-tuning to achieve high performance in the target domain, and often fail to generalize to new settings. Note that while these accuracies are significantly below the supervised state-of-the-art (95%), they are competitive with the \"zero-shot\" entity results from recent past work #TARGET_REF .",
        "output": "{\"INFO\": [\"recent past work #TARGET_REF .\"], \"PERCEPT\": [\"while these accuracies are significantly below the supervised state-of-the-art (95%), they are competitive with the \\\"zero-shot\\\" entity results from\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Goal",
                "oriented",
                "Dialogue.",
                "Sub-tasks",
                "within",
                "the",
                "overall",
                "task",
                "of",
                "goal",
                "oriented",
                "dialogue,",
                "such",
                "as",
                "dialogue",
                "state",
                "management",
                "#REF",
                "and",
                "response",
                "generation",
                "#REF",
                "have",
                "used",
                "RL",
                "to",
                "boost",
                "performance.",
                "As",
                "noted",
                "by",
                "#REF",
                ",",
                "the",
                "negotiation",
                "tasks",
                "of",
                "(Yarats",
                "and",
                "#TARGET_REF",
                ",",
                "where",
                "two",
                "agents",
                "are",
                "trying",
                "to",
                "convince",
                "each",
                "other",
                "to",
                "perform",
                "certain",
                "actions,",
                "are",
                "related",
                "to",
                "the",
                "tasks",
                "in",
                "LIGHT-Quests.",
                "These",
                "works",
                "all",
                "lack",
                "environment",
                "grounding."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Goal oriented Dialogue. Sub-tasks within the overall task of goal oriented dialogue, such as dialogue state management #REF and response generation #REF have used RL to boost performance. As noted by #REF , the negotiation tasks of (Yarats and #TARGET_REF , where two agents are trying to convince each other to perform certain actions, are related to the tasks in LIGHT-Quests. These works all lack environment grounding.",
        "output": "{\"INFO\": [\"the negotiation tasks of\", \"#TARGET_REF , where two agents are trying to convince each other to perform certain actions,\"], \"PERCEPT\": [\"As noted by #REF ,\", \"are related to the tasks in LIGHT-Quests. These works all lack environment grounding.\"], \"BACK\": [\"(Yarats and\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "generation",
                "task",
                "adopts",
                "the",
                "traditional",
                "image",
                "captioning",
                "evaluation",
                "metric",
                "using",
                "the",
                "open-source",
                "tool",
                "2",
                "with",
                "a",
                "minor",
                "modification",
                "3",
                "to",
                "suit",
                "with",
                "LN-COCO,",
                "including",
                "BLEU",
                "#REF",
                ",",
                "METEOR",
                "#REF",
                ",",
                "ROUGE-L",
                "#TARGET_REF",
                ",",
                "ROUGE-1-F1(Pont-Tuset",
                "et",
                "al.,",
                "2020),",
                "and",
                "CIDEr-D",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "This generation task adopts the traditional image captioning evaluation metric using the open-source tool 2 with a minor modification 3 to suit with LN-COCO, including BLEU #REF , METEOR #REF , ROUGE-L #TARGET_REF , ROUGE-1-F1(Pont-Tuset et al., 2020), and CIDEr-D #REF .",
        "output": "{\"INFO\": [\"ROUGE-L #TARGET_REF ,\"], \"PERCEPT\": [\"This generation task adopts the traditional image captioning evaluation metric using the open-source tool 2 with a minor modification 3 to suit with LN-COCO,\"], \"BACK\": [\"including BLEU #REF , METEOR #REF ,\", \"ROUGE-1-F1(Pont-Tuset et al., 2020), and CIDEr-D #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Opposed",
                "to",
                "#TARGET_REF",
                "estimates",
                "the",
                "post-editing",
                "costs",
                "of",
                "a",
                "commercial",
                "business",
                "for",
                "instant",
                "communication",
                "messaging",
                "translation.",
                "Interestingly,",
                "his",
                "cost",
                "estimations",
                "cover",
                "corpus",
                "management",
                "and",
                "acquisition,",
                "5",
                "to",
                "200",
                "GBP",
                "per",
                "year,",
                "customization",
                "costs,",
                "human",
                "resources",
                "training,",
                "5",
                "to",
                "10",
                "GBP",
                "per",
                "year,",
                "among",
                "others.",
                "He",
                "measures",
                "investment",
                "cost",
                "of",
                "product",
                "licenses",
                "to",
                "100",
                "GBP",
                "per",
                "year.",
                "Overall,",
                "the",
                "total",
                "investment",
                "costs",
                "are",
                "estimated",
                "to",
                "180",
                "GBP",
                "per",
                "year.",
                "The",
                "predicted",
                "ROI",
                "for",
                "the",
                "first",
                "year",
                "after",
                "successful",
                "MT",
                "implementation",
                "equals",
                "to",
                "minus",
                "30000",
                "GBP,",
                "therefore",
                "is",
                "negative",
                "speaking",
                "in",
                "financial",
                "terms.",
                "The",
                "vendor",
                "pricing",
                "models",
                "is",
                "estimated",
                "to",
                "65-85%",
                "of",
                "the",
                "original",
                "pay",
                "per",
                "word.",
                "What",
                "is",
                "intriguing",
                "is",
                "the",
                "fact",
                "benefits",
                "are",
                "not",
                "only",
                "measured",
                "in",
                "money.",
                "#REF",
                ",",
                "as",
                "#REF",
                ",",
                "measures",
                "the",
                "user",
                "satisfaction",
                "rate,",
                "which",
                "in",
                "the",
                "case",
                "of",
                "Lionbridge",
                "2",
                "has",
                "increased",
                "with",
                "30-50%.",
                "The",
                "success",
                "rate",
                "measured",
                "varies",
                "between",
                "5%",
                "and",
                "25%."
            ],
            "context": [
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Opposed to #TARGET_REF estimates the post-editing costs of a commercial business for instant communication messaging translation. Interestingly, his cost estimations cover corpus management and acquisition, 5 to 200 GBP per year, customization costs, human resources training, 5 to 10 GBP per year, among others. He measures investment cost of product licenses to 100 GBP per year. Overall, the total investment costs are estimated to 180 GBP per year. The predicted ROI for the first year after successful MT implementation equals to minus 30000 GBP, therefore is negative speaking in financial terms. The vendor pricing models is estimated to 65-85% of the original pay per word. What is intriguing is the fact benefits are not only measured in money. #REF , as #REF , measures the user satisfaction rate, which in the case of Lionbridge 2 has increased with 30-50%. The success rate measured varies between 5% and 25%.",
        "output": "{\"INFO\": [\"estimates the post-editing costs of a commercial business for instant communication messaging translation.\"], \"PERCEPT\": [\"Interestingly, his cost estimations cover corpus management and acquisition, 5 to 200 GBP per year, customization costs, human resources training, 5 to 10 GBP per year, among others.\"], \"BACK\": [\"He measures investment cost of product licenses to 100 GBP per year.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "get",
                "an",
                "increase",
                "of",
                "5.77%",
                "on",
                "the",
                "FEVEROUS",
                "score",
                "and",
                "7.91%",
                "on",
                "the",
                "accuracy",
                "over",
                "the",
                "previous",
                "best",
                "model",
                "FaBULOUS",
                "#REF",
                "on",
                "the",
                "development",
                "set.",
                "For",
                "the",
                "test",
                "set,",
                "the",
                "increase",
                "is",
                "6.96%",
                "and",
                "7.14%",
                "in",
                "Feverous",
                "score",
                "and",
                "label",
                "accuracy,",
                "respectively.",
                "These",
                "results",
                "suggest",
                "the",
                "effectiveness",
                "of",
                "our",
                "proposed",
                "DCUF",
                "model.",
                "The",
                "evidence",
                "format",
                "of",
                "a",
                "global",
                "evidence",
                "table",
                "is",
                "consistent",
                "to",
                "the",
                "input",
                "of",
                "pre-trained",
                "table",
                "models.",
                "Thus,",
                "DCUF",
                "can",
                "make",
                "better",
                "use",
                "of",
                "the",
                "internal",
                "ability",
                "of",
                "pre-trained",
                "models",
                "than",
                "previous",
                "works",
                "which",
                "concatenate",
                "linearized",
                "tables",
                "or",
                "max-pool",
                "lots",
                "of",
                "claim-table",
                "pair",
                "encoding",
                "#TARGET_REF",
                ".",
                "Moreover,",
                "DCUF",
                "also",
                "performs",
                "better",
                "than",
                "another",
                "well-performing",
                "model,",
                "CARE",
                "#REF",
                ".",
                "DCUF",
                "converts",
                "cells",
                "to",
                "meaningful",
                "sentences",
                "that",
                "are",
                "similar",
                "to",
                "the",
                "inputs",
                "of",
                "PLMs",
                "pre-training",
                "stage,",
                "which",
                "makes",
                "better",
                "use",
                "of",
                "the",
                "PLMs",
                "ability."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We get an increase of 5.77% on the FEVEROUS score and 7.91% on the accuracy over the previous best model FaBULOUS #REF on the development set. For the test set, the increase is 6.96% and 7.14% in Feverous score and label accuracy, respectively. These results suggest the effectiveness of our proposed DCUF model. The evidence format of a global evidence table is consistent to the input of pre-trained table models. Thus, DCUF can make better use of the internal ability of pre-trained models than previous works which concatenate linearized tables or max-pool lots of claim-table pair encoding #TARGET_REF . Moreover, DCUF also performs better than another well-performing model, CARE #REF . DCUF converts cells to meaningful sentences that are similar to the inputs of PLMs pre-training stage, which makes better use of the PLMs ability.",
        "output": "{\"INFO\": [\"previous works which concatenate linearized tables or max-pool lots of claim-table pair encoding #TARGET_REF .\"], \"PERCEPT\": [\"DCUF can make better use of the internal ability of pre-trained models than\"], \"BACK\": [\"The evidence format of a global evidence table is consistent to the input of pre-trained table models.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "note",
                "that",
                "as",
                "we",
                "targeted",
                "at",
                "the",
                "one-to-many",
                "generation",
                "problem,",
                "we",
                "excluded",
                "those",
                "baseline",
                "methods",
                "mentioned",
                "in",
                "the",
                "related",
                "work",
                "that",
                "cannot",
                "produce",
                "multiple",
                "outputs,",
                "e.g.,",
                "#REF",
                ",",
                "#REF",
                ",",
                "#TARGET_REF",
                ".",
                "Different",
                "from",
                "aforementioned",
                "methods,",
                "our",
                "MoKGE",
                "can",
                "seek",
                "diverse",
                "reasoning",
                "on",
                "KG",
                "to",
                "encourage",
                "various",
                "generation",
                "outputs",
                "without",
                "any",
                "additional",
                "conditions."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We note that as we targeted at the one-to-many generation problem, we excluded those baseline methods mentioned in the related work that cannot produce multiple outputs, e.g., #REF , #REF , #TARGET_REF . Different from aforementioned methods, our MoKGE can seek diverse reasoning on KG to encourage various generation outputs without any additional conditions.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"We note that as we targeted at the one-to-many generation problem, we excluded those baseline methods mentioned in the related work that cannot produce multiple outputs,\", \"Different from aforementioned methods, our MoKGE can seek diverse reasoning on KG to encourage various generation outputs without any additional conditions.\"], \"BACK\": [\"e.g., #REF , #REF ,\"]}"
    },
    {
        "gold": {
            "text": [
                "Therefore,",
                "we",
                "additionally",
                "use",
                "two",
                "distantly",
                "labeled",
                "entity",
                "typing",
                "datasets",
                "derived",
                "from",
                "Wikipedia.",
                "We",
                "leverage",
                "past",
                "work",
                "in",
                "using",
                "types",
                "derived",
                "from",
                "Wikipedia",
                "categories",
                "#TARGET_REF",
                ",",
                "which",
                "contain",
                "type",
                "information",
                "and",
                "are",
                "widely",
                "annotated",
                "across",
                "Wikipedia",
                "articles.",
                "We",
                "select",
                "the",
                "appropriate",
                "dataset",
                "for",
                "each",
                "setting",
                "depending",
                "on",
                "task-specific",
                "requirements",
                "(see",
                "Section",
                "6).",
                "For",
                "all",
                "datasets,",
                "we",
                "compute",
                "entity",
                "typing",
                "macro",
                "F1",
                "using",
                "development",
                "examples",
                "(1k)",
                "to",
                "check",
                "model",
                "convergence."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Therefore, we additionally use two distantly labeled entity typing datasets derived from Wikipedia. We leverage past work in using types derived from Wikipedia categories #TARGET_REF , which contain type information and are widely annotated across Wikipedia articles. We select the appropriate dataset for each setting depending on task-specific requirements (see Section 6). For all datasets, we compute entity typing macro F1 using development examples (1k) to check model convergence.",
        "output": "{\"INFO\": [\"Wikipedia categories #TARGET_REF , which contain type information and are widely annotated across Wikipedia articles.\"], \"PERCEPT\": [\"We leverage past work in using types derived from\"], \"BACK\": [\"we additionally use two distantly labeled entity typing datasets derived from Wikipedia.\", \"We select the appropriate dataset for each setting depending on task-specific requirements (see Section 6).\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "connection",
                "of",
                "all",
                "this",
                "to",
                "ideograms",
                "had",
                "been",
                "noted",
                "by",
                "Richards,",
                "who",
                "was",
                "much",
                "preoccupied",
                "by",
                "Chinese,",
                "and",
                "who",
                "developed",
                "English",
                "through",
                "pictures",
                "#TARGET_REF",
                ",",
                "a",
                "highly",
                "successful",
                "language",
                "teaching",
                "tool.",
                "MMB",
                "came",
                "to",
                "Chinese",
                "through",
                "Michael",
                "Halliday,",
                "then",
                "a",
                "Cambridge",
                "University",
                "lecturer",
                "in",
                "Chinese,",
                "and",
                "began",
                "to",
                "use",
                "stick-pictures",
                "as",
                "representations",
                "of",
                "situations",
                "but",
                "which",
                "could",
                "also",
                "provide",
                "a",
                "plausible",
                "referential",
                "underpinning",
                "for",
                "language:",
                "something",
                "universal,",
                "and",
                "outside",
                "the",
                "world",
                "of",
                "the",
                "language",
                "signs",
                "themselves,",
                "yet",
                "which",
                "did",
                "not",
                "fall",
                "back",
                "on",
                "the",
                "naive",
                "referentialism",
                "of",
                "those",
                "who",
                "said",
                "that",
                "the",
                "meanings",
                "of",
                "words",
                "were",
                "things",
                "or",
                "inexpressible",
                "concepts."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The connection of all this to ideograms had been noted by Richards, who was much preoccupied by Chinese, and who developed English through pictures #TARGET_REF , a highly successful language teaching tool. MMB came to Chinese through Michael Halliday, then a Cambridge University lecturer in Chinese, and began to use stick-pictures as representations of situations but which could also provide a plausible referential underpinning for language: something universal, and outside the world of the language signs themselves, yet which did not fall back on the naive referentialism of those who said that the meanings of words were things or inexpressible concepts.",
        "output": "{\"INFO\": [\"English through pictures #TARGET_REF , a highly successful language teaching tool.\"], \"PERCEPT\": [\"The connection of all this to ideograms had been noted by Richards, who was much preoccupied by Chinese, and who developed\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Proximity-based",
                "features",
                "Traditional",
                "retrieval",
                "models",
                "assume",
                "terms",
                "are",
                "independent",
                "and",
                "ignore",
                "their",
                "relationships,",
                "but",
                "the",
                "proximity",
                "among",
                "query",
                "terms",
                "often",
                "serves",
                "as",
                "an",
                "important",
                "relevance",
                "signal.",
                "Thus,",
                "we",
                "include",
                "features",
                "that",
                "directly",
                "capture",
                "the",
                "proximity",
                "of",
                "query",
                "terms,",
                "such",
                "as",
                "the",
                "counts",
                "of",
                "ordered",
                "and",
                "unordered",
                "co-occurrence",
                "of",
                "bigrams",
                "within",
                "different",
                "window",
                "sizes.",
                "We",
                "compute",
                "the",
                "scores",
                "of",
                "proximity-based",
                "retrieval",
                "functions,",
                "such",
                "as",
                "SDM",
                "#REF",
                "and",
                "BM25-TP",
                "#TARGET_REF",
                ",",
                "as",
                "our",
                "features."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2
            ]
        },
        "input": "Proximity-based features Traditional retrieval models assume terms are independent and ignore their relationships, but the proximity among query terms often serves as an important relevance signal. Thus, we include features that directly capture the proximity of query terms, such as the counts of ordered and unordered co-occurrence of bigrams within different window sizes. We compute the scores of proximity-based retrieval functions, such as SDM #REF and BM25-TP #TARGET_REF , as our features.",
        "output": "{\"INFO\": [\"BM25-TP #TARGET_REF ,\"], \"PERCEPT\": [\"We compute the scores of proximity-based retrieval functions, such as\", \"as our features.\"], \"BACK\": [\"SDM #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "recently",
                "popular",
                "approach",
                "in",
                "Named-Entity",
                "Recognition",
                "tasks",
                "has",
                "been",
                "to",
                "use",
                "Conditional",
                "Random",
                "Fields",
                "(CRF)",
                "with",
                "BERT-based",
                "models.",
                "Inspired",
                "by",
                "the",
                "CRF-based",
                "approaches",
                "#TARGET_REF",
                ",",
                "we",
                "use",
                "BERT-based",
                "models",
                "with",
                "a",
                "single",
                "BiLSTM",
                "layer",
                "and",
                "a",
                "CRF",
                "layer.",
                "During",
                "training,",
                "the",
                "CRF",
                "loss",
                "is",
                "used",
                "and",
                "during",
                "prediction,",
                "Viterbi",
                "Decoding",
                "is",
                "performed.",
                "Though",
                "CRF",
                "is",
                "generally",
                "used",
                "for",
                "word-level",
                "classification,",
                "we",
                "do",
                "not",
                "mask",
                "inner",
                "and",
                "end",
                "tokens",
                "for",
                "a",
                "word",
                "as",
                "it",
                "degrades",
                "dev",
                "set",
                "performance",
                "for",
                "our",
                "systems.",
                "Hence,",
                "all",
                "the",
                "tokens",
                "of",
                "a",
                "word",
                "are",
                "considered",
                "for",
                "classification."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A recently popular approach in Named-Entity Recognition tasks has been to use Conditional Random Fields (CRF) with BERT-based models. Inspired by the CRF-based approaches #TARGET_REF , we use BERT-based models with a single BiLSTM layer and a CRF layer. During training, the CRF loss is used and during prediction, Viterbi Decoding is performed. Though CRF is generally used for word-level classification, we do not mask inner and end tokens for a word as it degrades dev set performance for our systems. Hence, all the tokens of a word are considered for classification.",
        "output": "{\"INFO\": [\"the CRF-based approaches #TARGET_REF ,\"], \"PERCEPT\": [\"Inspired by\", \"we use BERT-based models with a single BiLSTM layer and a CRF layer.\"], \"BACK\": [\"A recently popular approach in Named-Entity Recognition tasks has been to use Conditional Random Fields (CRF) with BERT-based models.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "order",
                "to",
                "assess",
                "the",
                "contribution",
                "of",
                "punctuation",
                "to",
                "the",
                "selection",
                "of",
                "the",
                "correct",
                "analysis,",
                "w�",
                "applied",
                "the",
                "same",
                "trained",
                "version",
                "of",
                "the",
                "integrated",
                "grammar",
                "to",
                "the",
                "106",
                "sentences",
                "from",
                "the",
                "test",
                "set",
                "which",
                "contain",
                "internal",
                "punctuation,",
                "both",
                "with",
                "and",
                "without",
                "the",
                "punctuation",
                "marks",
                "in",
                "the",
                "input.",
                "A",
                "comparison",
                "of",
                "the",
                "GEIG",
                "evaluation",
                "metrics",
                "for",
                "this",
                "set",
                "of",
                "sentences",
                "punctuated",
                "and",
                "unpunctuated",
                "gives",
                "a",
                "measure",
                "of",
                "the",
                "contribution",
                "of",
                "punctuation",
                "to",
                "parse",
                "selection",
                "on",
                "this",
                "data.",
                "(The",
                "results",
                "for",
                "the",
                "unpunctuated",
                "set",
                "were",
                "computed",
                "against",
                "a",
                "version",
                "of",
                "the",
                "Susanne",
                "tree",
                "bank",
                "from",
                "which",
                "punctuation",
                "had",
                "also",
                "been",
                "�",
                "emoved.)",
                "As",
                "table",
                "3",
                "shows,",
                "recall",
                "declines",
                "by",
                "10%,",
                "precision",
                "by",
                "5%",
                "and",
                "there",
                "are",
                "an",
                "average",
                "of",
                "1.27",
                "more",
                "crossing",
                "brackets",
                "per",
                "sentence.",
                "6",
                "Conclusions",
                "#TARGET_REF",
                "and",
                "#REF",
                "showed",
                "that",
                "the",
                "LR",
                "model,",
                "combined",
                "with",
                "a",
                "gram",
                "mar",
                "exploiting",
                "subcategorisation",
                "constraints,",
                "could",
                "achieve",
                "good",
                "parse",
                "selection",
                "accuracy",
                "bu�",
                "at",
                "the",
                "expense",
                "of",
                "poor",
                "coverage",
                "of",
                "free",
                "text.",
                "The",
                "results",
                "reported",
                "here",
                "suggest",
                "that",
                "improved",
                "coverage",
                "of",
                "heterogeneous",
                "text",
                "can",
                "be",
                "achieved",
                "by",
                "exploiting",
                "textual",
                "and",
                "grammatical",
                "con",
                "straints",
                "on",
                "PoS",
                "and",
                "punctuation",
                "sequences.",
                "The",
                "experiments",
                "show",
                "that",
                "grammatical",
                "coverage",
                "can",
                "be",
                "greatly",
                "increased",
                "by",
                "relaxing",
                "subcategorisation",
                "constraints,",
                "and",
                "that",
                "text",
                "grammatical",
                "or",
                "punctuation-cued",
                "constraints",
                "can",
                "reduce",
                "ambiguity",
                "and",
                "increase",
                "coverage",
                "during",
                "parsing."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In order to assess the contribution of punctuation to the selection of the correct analysis, w� applied the same trained version of the integrated grammar to the 106 sentences from the test set which contain internal punctuation, both with and without the punctuation marks in the input. A comparison of the GEIG evaluation metrics for this set of sentences punctuated and unpunctuated gives a measure of the contribution of punctuation to parse selection on this data. (The results for the unpunctuated set were computed against a version of the Susanne tree bank from which punctuation had also been � emoved.) As table 3 shows, recall declines by 10%, precision by 5% and there are an average of 1.27 more crossing brackets per sentence. 6 Conclusions #TARGET_REF and #REF showed that the LR model, combined with a gram mar exploiting subcategorisation constraints, could achieve good parse selection accuracy bu� at the expense of poor coverage of free text. The results reported here suggest that improved coverage of heterogeneous text can be achieved by exploiting textual and grammatical con straints on PoS and punctuation sequences. The experiments show that grammatical coverage can be greatly increased by relaxing subcategorisation constraints, and that text grammatical or punctuation-cued constraints can reduce ambiguity and increase coverage during parsing.",
        "output": "{\"INFO\": [\"#TARGET_REF\", \"showed that the LR model, combined with a gram mar exploiting subcategorisation constraints, could achieve good parse selection accuracy bu\\ufffd at the expense of poor coverage of free text. The results reported here suggest that improved coverage of heterogeneous text can be achieved by exploiting textual and grammatical con straints on PoS and punctuation sequences. The experiments show that grammatical coverage can be greatly increased by relaxing subcategorisation constraints, and that text grammatical or punctuation-cued constraints can reduce ambiguity and increase coverage during parsing.\"], \"PERCEPT\": [], \"BACK\": [\"and #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "Yamamoto",
                "and",
                "Church's",
                "work,",
                "they",
                "demonstrate",
                "how",
                "interesting",
                "multiword",
                "phrases",
                "can",
                "be",
                "discovered,",
                "by",
                "interesting",
                "they",
                "mean",
                "phrases",
                "that",
                "may",
                "be",
                "beneficial",
                "for",
                "information",
                "retrieval",
                "or",
                "computational",
                "lexicography",
                "as",
                "determined",
                "by",
                "Mutual",
                "Information",
                "(MI)",
                "or",
                "Residual",
                "Inverse",
                "Document",
                "Frequency",
                "(RIDF)",
                "#TARGET_REF",
                "scores."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In Yamamoto and Church's work, they demonstrate how interesting multiword phrases can be discovered, by interesting they mean phrases that may be beneficial for information retrieval or computational lexicography as determined by Mutual Information (MI) or Residual Inverse Document Frequency (RIDF) #TARGET_REF scores.",
        "output": "{\"INFO\": [\"Residual Inverse Document Frequency (RIDF) #TARGET_REF scores.\"], \"PERCEPT\": [\"by interesting they mean phrases that may be beneficial for information retrieval or computational lexicography as determined by\"], \"BACK\": [\"In Yamamoto and Church's work, they demonstrate how interesting multiword phrases can be discovered,\", \"Mutual Information (MI) or\"]}"
    },
    {
        "gold": {
            "text": [
                "From",
                "the",
                "point",
                "of",
                "view",
                "of",
                "communication",
                "study,",
                "most",
                "of",
                "the",
                "research",
                "on",
                "public",
                "apologies",
                "is",
                "focused",
                "on",
                "apology",
                "as",
                "a",
                "speech",
                "act",
                "(e.g.",
                "#REF",
                ".",
                "The",
                "studies",
                "are",
                "based",
                "on",
                "two",
                "perspectives.",
                "The",
                "first",
                "is",
                "from",
                "the",
                "point",
                "of",
                "view",
                "of",
                "the",
                "offended",
                "party",
                "#REF",
                "and",
                "the",
                "second",
                "sees",
                "apology",
                "from",
                "the",
                "point",
                "of",
                "view",
                "of",
                "the",
                "offender",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "From the point of view of communication study, most of the research on public apologies is focused on apology as a speech act (e.g. #REF . The studies are based on two perspectives. The first is from the point of view of the offended party #REF and the second sees apology from the point of view of the offender #TARGET_REF .",
        "output": "{\"INFO\": [\"apology from the point of view of the offender #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"most of the research on public apologies is focused on apology as a speech act\", \"The studies are based on two perspectives. The first is from the point of view of the offended party #REF and the second sees\"]}"
    },
    {
        "gold": {
            "text": [
                "Self-training",
                "#TARGET_REF",
                ")",
                "uses",
                "a",
                "source-to-target",
                "model",
                "to",
                "generate",
                "synthetic",
                "pairs",
                "from",
                "source-side",
                "monolingual",
                "data",
                "to",
                "augment",
                "the",
                "original",
                "parallel",
                "corpus.",
                "We",
                "combined",
                "2M",
                "Chinese",
                "monolingual",
                "data",
                "with",
                "2M",
                "Chinese",
                "sentences",
                "randomly",
                "sampled",
                "from",
                "the",
                "CWMT",
                "parallel",
                "corpus,",
                "yielding",
                "a",
                "total",
                "of",
                "4M",
                "monolingual",
                "for",
                "forward",
                "translation."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Self-training #TARGET_REF ) uses a source-to-target model to generate synthetic pairs from source-side monolingual data to augment the original parallel corpus. We combined 2M Chinese monolingual data with 2M Chinese sentences randomly sampled from the CWMT parallel corpus, yielding a total of 4M monolingual for forward translation.",
        "output": "{\"INFO\": [\"Self-training #TARGET_REF ) uses a source-to-target model to generate synthetic pairs from source-side monolingual data to augment the original parallel corpus.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "What",
                "MMB",
                "sought",
                "was",
                "a",
                "compromise",
                "system",
                "of",
                "meaning",
                "representation",
                "for",
                "MT:",
                "one",
                "that",
                "was",
                "fundamental",
                "to",
                "the",
                "process",
                "of",
                "translation,",
                "but",
                "did",
                "not",
                "constitute",
                "a",
                "detailed",
                "representation",
                "of",
                "all",
                "the",
                "relevant",
                "knowledge",
                "of",
                "the",
                "world.",
                "She",
                "believed",
                "there",
                "was",
                "a",
                "level",
                "of",
                "representation,",
                "linguistic",
                "if",
                "you",
                "will,",
                "probably",
                "vague",
                "as",
                "well,",
                "but",
                "which",
                "was",
                "sufficient",
                "for",
                "MT.",
                "In",
                "that",
                "sense,",
                "she",
                "totally",
                "denied",
                "the",
                "assumption",
                "behind",
                "Bar-Hillel's",
                "critique",
                "of",
                "#TARGET_REF",
                "-which",
                "was",
                "taken",
                "up",
                "by",
                "some",
                "artificial",
                "intelligence",
                "researchers",
                "afterwards",
                "(although",
                "not,",
                "of",
                "course,",
                "the",
                "same",
                "ones",
                "as",
                "referred",
                "to",
                "in",
                "the",
                "last",
                "paragraph)",
                "-that",
                "MT",
                "and",
                "language",
                "understanding",
                "in",
                "general",
                "did",
                "require",
                "the",
                "explicit",
                "representation",
                "of",
                "all",
                "world",
                "knowledge.",
                "This",
                "position",
                "of",
                "hers",
                "cannot",
                "be",
                "separated",
                "from",
                "her",
                "quasi-idealist",
                "belief",
                "(see",
                "further",
                "below)",
                "that",
                "world",
                "knowledge",
                "cannot",
                "be",
                "represented",
                "independently",
                "of",
                "some",
                "language,",
                "and",
                "hence",
                "that",
                "any",
                "true",
                "distinction",
                "between",
                "meaning",
                "representation",
                "and",
                "the",
                "representation",
                "of",
                "world",
                "knowledge",
                "is,",
                "ultimately,",
                "misconceived",
                "(see",
                "her",
                "discussion",
                "of",
                "Whorf",
                "#REF",
                ").",
                "The",
                "only",
                "dispute",
                "can",
                "be",
                "about",
                "the",
                "'level'",
                "or",
                "'grain'",
                "of",
                "representation",
                "that",
                "particular",
                "acts",
                "of",
                "translation",
                "require."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "What MMB sought was a compromise system of meaning representation for MT: one that was fundamental to the process of translation, but did not constitute a detailed representation of all the relevant knowledge of the world. She believed there was a level of representation, linguistic if you will, probably vague as well, but which was sufficient for MT. In that sense, she totally denied the assumption behind Bar-Hillel's critique of #TARGET_REF -which was taken up by some artificial intelligence researchers afterwards (although not, of course, the same ones as referred to in the last paragraph) -that MT and language understanding in general did require the explicit representation of all world knowledge. This position of hers cannot be separated from her quasi-idealist belief (see further below) that world knowledge cannot be represented independently of some language, and hence that any true distinction between meaning representation and the representation of world knowledge is, ultimately, misconceived (see her discussion of Whorf #REF ). The only dispute can be about the 'level' or 'grain' of representation that particular acts of translation require.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"she totally denied the assumption behind Bar-Hillel's critique of #TARGET_REF\", \"-that MT and language understanding in general did require the explicit representation of all world knowledge.\"]}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "straightforward",
                "operation",
                "is",
                "to",
                "sum",
                "the",
                "embeddings",
                "(technique",
                "used",
                "in",
                "#TARGET_REF",
                ")",
                "of",
                "the",
                "previous",
                "lemma",
                "with",
                "the",
                "embedding",
                "of",
                "the",
                "previous",
                "factors,",
                "as",
                "described",
                "in",
                "equation",
                "7."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Another straightforward operation is to sum the embeddings (technique used in #TARGET_REF ) of the previous lemma with the embedding of the previous factors, as described in equation 7.",
        "output": "{\"INFO\": [\"(technique used in #TARGET_REF )\"], \"PERCEPT\": [\"Another straightforward operation is to sum the embeddings\", \"of the previous lemma with the embedding of the previous factors,\"], \"BACK\": [\"as described in equation 7.\"]}"
    },
    {
        "gold": {
            "text": [
                "Structural",
                "ambiguity",
                "is",
                "resolved",
                "by",
                "the",
                "cost-based",
                "ambiguity",
                "resolution",
                "method",
                "#REF",
                "].",
                "The",
                "cost-based",
                "ambiguity",
                "resolution",
                "takes",
                "into",
                "account",
                "various",
                "psycholinguistic",
                "studies",
                "such",
                "as",
                "#TARGET_REF",
                "and",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                3
            ]
        },
        "input": "Structural ambiguity is resolved by the cost-based ambiguity resolution method #REF ]. The cost-based ambiguity resolution takes into account various psycholinguistic studies such as #TARGET_REF and #REF .",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"Structural ambiguity is resolved by the cost-based ambiguity resolution method #REF ]. The cost-based ambiguity resolution takes into account various psycholinguistic studies such as\", \"and #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "paper",
                "reports",
                "on",
                "a",
                "project",
                "whose",
                "aims",
                "are",
                "to",
                "investigate",
                "the",
                "usability",
                "of",
                "raw",
                "machine",
                "translated",
                "technical",
                "support",
                "documentation",
                "for",
                "a",
                "commercial",
                "online",
                "service.",
                "It",
                "builds",
                "on",
                "previous",
                "work",
                "which",
                "investigates",
                "the",
                "use",
                "of",
                "eye",
                "tracking",
                "as",
                "a",
                "machine",
                "translation",
                "evaluation",
                "mechanism",
                "#TARGET_REF",
                ",",
                "which",
                "focused",
                "on",
                "the",
                "readability",
                "and",
                "comprehension",
                "of",
                "machine-translated",
                "technical",
                "support",
                "documentation",
                "#REF",
                ",",
                "and",
                "on",
                "the",
                "impact",
                "of",
                "controlled",
                "authoring",
                "on",
                "the",
                "readability",
                "of",
                "MT",
                "output",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "This paper reports on a project whose aims are to investigate the usability of raw machine translated technical support documentation for a commercial online service. It builds on previous work which investigates the use of eye tracking as a machine translation evaluation mechanism #TARGET_REF , which focused on the readability and comprehension of machine-translated technical support documentation #REF , and on the impact of controlled authoring on the readability of MT output #REF .",
        "output": "{\"INFO\": [\"the use of eye tracking as a machine translation evaluation mechanism #TARGET_REF , which focused on the readability and comprehension of machine-translated technical support documentation #REF , and on the impact of controlled authoring on the readability of MT output #REF .\"], \"PERCEPT\": [], \"BACK\": [\"This paper reports on a project whose aims are to investigate the usability of raw machine translated technical support documentation for a commercial online service. It builds on previous work which investigates\"]}"
    },
    {
        "gold": {
            "text": [
                "Say",
                "that",
                "the",
                "agent",
                "plays",
                "in",
                "the",
                "blue",
                "team,",
                "i.e.",
                "we",
                "want",
                "to",
                "generate",
                "clues",
                "associated",
                "to",
                "the",
                "blue",
                "words,",
                "based",
                "on",
                "the",
                "distance",
                "functions",
                "above.",
                "The",
                "functions",
                "of",
                "#TARGET_REF",
                "(see",
                "(",
                "1))",
                "determined",
                "the",
                "score",
                "of",
                "a",
                "possible",
                "reference",
                "based",
                "on",
                "relatedness",
                "of",
                "the",
                "clue",
                "word",
                "to",
                "the",
                "least",
                "related",
                "blue",
                "word",
                "targeted.",
                "The",
                "shortcoming",
                "of",
                "this,",
                "however,",
                "is",
                "that",
                "in",
                "addition",
                "to",
                "blue",
                "(good)",
                "words",
                "that",
                "are",
                "similar",
                "to",
                "the",
                "clue",
                "word,",
                "there",
                "may",
                "be",
                "bad",
                "words",
                "of",
                "a",
                "different",
                "color",
                "that",
                "are",
                "only",
                "very",
                "slightly",
                "less",
                "similar",
                "to",
                "the",
                "clue.",
                "We",
                "can",
                "assume",
                "that",
                "in",
                "this",
                "case,",
                "agents",
                "are",
                "less",
                "likely",
                "to",
                "choose",
                "the",
                "targeted",
                "words,",
                "or",
                "in",
                "general,",
                "the",
                "smaller",
                "the",
                "difference",
                "between",
                "the",
                "distances",
                "of",
                "two",
                "words",
                "from",
                "the",
                "clue",
                "according",
                "to",
                "our",
                "distance",
                "function,",
                "the",
                "more",
                "likely",
                "the",
                "human",
                "player",
                "will",
                "perceive",
                "the",
                "order",
                "of",
                "the",
                "two",
                "words",
                "reversed."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Say that the agent plays in the blue team, i.e. we want to generate clues associated to the blue words, based on the distance functions above. The functions of #TARGET_REF (see ( 1)) determined the score of a possible reference based on relatedness of the clue word to the least related blue word targeted. The shortcoming of this, however, is that in addition to blue (good) words that are similar to the clue word, there may be bad words of a different color that are only very slightly less similar to the clue. We can assume that in this case, agents are less likely to choose the targeted words, or in general, the smaller the difference between the distances of two words from the clue according to our distance function, the more likely the human player will perceive the order of the two words reversed.",
        "output": "{\"INFO\": [\"The functions of #TARGET_REF\", \"determined the score of a possible reference based on relatedness of the clue word to the least related blue word targeted.\"], \"PERCEPT\": [], \"BACK\": [\"Say that the agent plays in the blue team, i.e. we want to generate clues associated to the blue words, based on the distance functions above.\", \"(see ( 1))\"]}"
    },
    {
        "gold": {
            "text": [
                "UFET",
                "This",
                "ultra-fine",
                "entity",
                "typing",
                "dataset",
                "is",
                "created",
                "by",
                "#TARGET_REF",
                ".",
                "This",
                "dataset",
                "consists",
                "of",
                "6k",
                "manually",
                "annotated",
                "examples.",
                "The",
                "entity",
                "mention",
                "spans",
                "could",
                "be",
                "named",
                "entities,",
                "nominal",
                "expressions,",
                "and",
                "pronouns",
                "while",
                "Wiki-based",
                "datasets",
                "mostly",
                "provide",
                "named",
                "entity",
                "mention",
                "spans.",
                "We",
                "use",
                "5.5k",
                "examples",
                "for",
                "training",
                "and",
                "500",
                "examples",
                "for",
                "validation.",
                "Note",
                "that",
                "because",
                "our",
                "goal",
                "in",
                "this",
                "work",
                "is",
                "downstream",
                "task",
                "performance,",
                "we",
                "deviate",
                "from",
                "the",
                "standard",
                "train/dev/test",
                "splits",
                "of",
                "2k/2k/2k",
                "in",
                "favor",
                "of",
                "higher",
                "performance."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "UFET This ultra-fine entity typing dataset is created by #TARGET_REF . This dataset consists of 6k manually annotated examples. The entity mention spans could be named entities, nominal expressions, and pronouns while Wiki-based datasets mostly provide named entity mention spans. We use 5.5k examples for training and 500 examples for validation. Note that because our goal in this work is downstream task performance, we deviate from the standard train/dev/test splits of 2k/2k/2k in favor of higher performance.",
        "output": "{\"INFO\": [\"UFET This ultra-fine entity typing dataset is created by #TARGET_REF . This dataset consists of 6k manually annotated examples. The entity mention spans could be named entities, nominal expressions, and pronouns while Wiki-based datasets mostly provide named entity mention spans.\"], \"PERCEPT\": [\"We use 5.5k examples for training and 500 examples for validation.\", \"our goal in this work is downstream task performance, we deviate from the standard train/dev/test splits of 2k/2k/2k in favor of higher performance.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Eq.",
                "6",
                "implies",
                "that",
                "the",
                "abstractive",
                "model",
                "g",
                "should",
                "be",
                "able",
                "to",
                "assign",
                "higher",
                "estimated",
                "probability",
                "to",
                "the",
                "better",
                "candidate",
                "summary",
                "during",
                "inference.",
                "However,",
                "this",
                "intuition",
                "is",
                "not",
                "directly",
                "captured",
                "in",
                "the",
                "standard",
                "MLE",
                "objective",
                "used",
                "in",
                "training",
                "-a",
                "model",
                "obtaining",
                "zero",
                "MLE",
                "loss",
                "would",
                "assign",
                "zero",
                "probability",
                "to",
                "any",
                "candidate",
                "summary",
                "different",
                "from",
                "the",
                "reference.",
                "This",
                "is",
                "obviously",
                "improper",
                "for",
                "any",
                "task",
                "where",
                "multiple",
                "reasonable",
                "generations",
                "may",
                "exist",
                "#TARGET_REF",
                ",",
                "and",
                "also",
                "does",
                "not",
                "say",
                "anything",
                "about",
                "the",
                "ordering",
                "of",
                "two",
                "imperfect",
                "references.",
                "We",
                "therefore",
                "advocate",
                "for",
                "making",
                "the",
                "alternative",
                "assumption",
                "that",
                "the",
                "probability",
                "of",
                "one",
                "candidate",
                "should",
                "be",
                "well-correlated",
                "with",
                "its",
                "quality",
                "as",
                "evaluated",
                "by",
                "an",
                "automatic",
                "metric",
                "M",
                ".",
                "Since",
                "it",
                "is",
                "intractable",
                "to",
                "enumerate",
                "all",
                "the",
                "possible",
                "candidate",
                "outputs,",
                "we",
                "only",
                "require",
                "our",
                "model",
                "to",
                "be",
                "able",
                "to",
                "accurately",
                "predict",
                "the",
                "ranking",
                "order",
                "of",
                "a",
                "set",
                "of",
                "the",
                "most",
                "probable",
                "candidate",
                "summaries",
                "Ŝ,",
                "which",
                "are",
                "its",
                "own",
                "beam",
                "search",
                "results.",
                "In",
                "order",
                "to",
                "achieve",
                "this",
                "objective,",
                "we",
                "slightly",
                "modify",
                "the",
                "conditions",
                "of",
                "Eq.",
                "5,",
                "maintaining",
                "the",
                "general",
                "functional",
                "form,",
                "but",
                "instead",
                "specifying",
                "the",
                "marginal",
                "probability",
                "of",
                "the",
                "non-reference",
                "candidates",
                "S",
                "to",
                "be",
                "β,",
                "and",
                "encouraging",
                "coordination",
                "of",
                "probabilities",
                "and",
                "qualities",
                "among",
                "non-reference",
                "candidates",
                "as",
                "follows:"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Eq. 6 implies that the abstractive model g should be able to assign higher estimated probability to the better candidate summary during inference. However, this intuition is not directly captured in the standard MLE objective used in training -a model obtaining zero MLE loss would assign zero probability to any candidate summary different from the reference. This is obviously improper for any task where multiple reasonable generations may exist #TARGET_REF , and also does not say anything about the ordering of two imperfect references. We therefore advocate for making the alternative assumption that the probability of one candidate should be well-correlated with its quality as evaluated by an automatic metric M . Since it is intractable to enumerate all the possible candidate outputs, we only require our model to be able to accurately predict the ranking order of a set of the most probable candidate summaries Ŝ, which are its own beam search results. In order to achieve this objective, we slightly modify the conditions of Eq. 5, maintaining the general functional form, but instead specifying the marginal probability of the non-reference candidates S to be β, and encouraging coordination of probabilities and qualities among non-reference candidates as follows:",
        "output": "{\"INFO\": [\"any task where multiple reasonable generations may exist #TARGET_REF ,\"], \"PERCEPT\": [\"This is obviously improper for\", \"and also does not say anything about the ordering of two imperfect references. We\", \"advocate for making the alternative assumption that the probability of one candidate should be well-correlated with its quality as evaluated by an automatic metric M .\"], \"BACK\": [\"Eq. 6 implies that the abstractive model g should be able to assign higher estimated probability to the better candidate summary during inference. However, this intuition is not directly captured in the standard MLE objective used in training -a model obtaining zero MLE loss would assign zero probability to any candidate summary different from the reference.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "Portuguese",
                "language,",
                "most",
                "of",
                "the",
                "works",
                "follow",
                "the",
                "trend",
                "of",
                "supervised",
                "approaches.",
                "de",
                "Pelle",
                "and",
                "Moreira",
                "(2017)",
                "created",
                "a",
                "dataset",
                "consist",
                "of",
                "1,",
                "250",
                "offensive",
                "comments",
                "and",
                "developed",
                "a",
                "baseline",
                "method",
                "based",
                "on",
                "n-gram",
                "features",
                "to",
                "classify",
                "offensive",
                "comments",
                "in",
                "their",
                "dataset.",
                "#TARGET_REF",
                "created",
                "a",
                "hate",
                "speech",
                "dataset",
                "composed",
                "of",
                "5,",
                "668",
                "tweets",
                "and",
                "developed",
                "a",
                "baseline",
                "classification",
                "using",
                "pre-trained",
                "word",
                "embeddings",
                "and",
                "LSTM",
                "in",
                "their",
                "dataset.",
                "Coutinho",
                "and",
                "Malheiros",
                "(2020)",
                "trained",
                "a",
                "logistic",
                "regression",
                "using",
                "superficial",
                "features",
                "for",
                "sentiment",
                "analysis.",
                "Then,",
                "they",
                "evaluated",
                "that",
                "model",
                "into",
                "a",
                "homophobia",
                "corpus",
                "to",
                "detect",
                "homophobic",
                "posts."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For the Portuguese language, most of the works follow the trend of supervised approaches. de Pelle and Moreira (2017) created a dataset consist of 1, 250 offensive comments and developed a baseline method based on n-gram features to classify offensive comments in their dataset. #TARGET_REF created a hate speech dataset composed of 5, 668 tweets and developed a baseline classification using pre-trained word embeddings and LSTM in their dataset. Coutinho and Malheiros (2020) trained a logistic regression using superficial features for sentiment analysis. Then, they evaluated that model into a homophobia corpus to detect homophobic posts.",
        "output": "{\"INFO\": [\"#TARGET_REF created a hate speech dataset composed of 5, 668 tweets and developed a baseline classification using pre-trained word embeddings and LSTM in their dataset.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Logical",
                "mechanisms",
                "have",
                "not",
                "been",
                "actively",
                "studied",
                "in",
                "argumentative",
                "relation",
                "classification.",
                "Models",
                "based",
                "on",
                "hand-crafted",
                "features",
                "have",
                "used",
                "relatively",
                "simple",
                "lexical",
                "features,",
                "such",
                "as",
                "n-grams,",
                "discourse",
                "markers,",
                "and",
                "sentiment",
                "agreement",
                "and",
                "word",
                "overlap",
                "between",
                "two",
                "statements",
                "#TARGET_REF",
                ".",
                "Recently,",
                "neural",
                "models",
                "have",
                "become",
                "dominant",
                "approaches",
                "#REF",
                ".",
                "Despite",
                "their",
                "high",
                "accuracy",
                "and",
                "finding",
                "of",
                "some",
                "word-level",
                "interactions",
                "between",
                "statements",
                "#REF",
                ",",
                "they",
                "provide",
                "quite",
                "limited",
                "insight",
                "into",
                "governing",
                "mechanisms",
                "in",
                "argumentative",
                "relations.",
                "Indeed,",
                "more",
                "and",
                "more",
                "evidence",
                "suggests",
                "that",
                "supervised",
                "models",
                "learn",
                "to",
                "overly",
                "rely",
                "on",
                "superficial",
                "cues,",
                "such",
                "as",
                "discourse",
                "markers",
                "#REF",
                ",",
                "negating",
                "words",
                "#REF",
                ",",
                "and",
                "sentiment",
                "#REF",
                "behind",
                "the",
                "scenes.",
                "We",
                "instead",
                "use",
                "an",
                "interpretable",
                "method",
                "based",
                "on",
                "PSL",
                "to",
                "examine",
                "logical",
                "mechanisms",
                "(",
                "§7)",
                "and",
                "then",
                "show",
                "evidence",
                "that",
                "these",
                "mechanisms",
                "can",
                "inform",
                "supervised",
                "models",
                "in",
                "intuitive",
                "ways",
                "(",
                "§8)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Logical mechanisms have not been actively studied in argumentative relation classification. Models based on hand-crafted features have used relatively simple lexical features, such as n-grams, discourse markers, and sentiment agreement and word overlap between two statements #TARGET_REF . Recently, neural models have become dominant approaches #REF . Despite their high accuracy and finding of some word-level interactions between statements #REF , they provide quite limited insight into governing mechanisms in argumentative relations. Indeed, more and more evidence suggests that supervised models learn to overly rely on superficial cues, such as discourse markers #REF , negating words #REF , and sentiment #REF behind the scenes. We instead use an interpretable method based on PSL to examine logical mechanisms ( §7) and then show evidence that these mechanisms can inform supervised models in intuitive ways ( §8).",
        "output": "{\"INFO\": [\"word overlap between two statements #TARGET_REF .\"], \"PERCEPT\": [\"Models based on hand-crafted features have used relatively simple lexical features, such as\"], \"BACK\": [\"n-grams, discourse markers, and sentiment agreement and\"]}"
    },
    {
        "gold": {
            "text": [
                "Results.",
                "For",
                "the",
                "SVM,",
                "the",
                "3-1",
                "pretraining",
                "without",
                "data",
                "augmentation",
                "resulted",
                "in",
                "the",
                "highest",
                "dev",
                "set",
                "accuracy",
                "(32.03%),",
                "though",
                "accuracy",
                "was",
                "only",
                "slightly",
                "better",
                "than",
                "for",
                "direct",
                "single-trial",
                "training",
                "(31.93%).",
                "For",
                "the",
                "Transformer,",
                "the",
                "3-1",
                "pretraining",
                "scheme",
                "with",
                "250k",
                "data",
                "augmentation",
                "obtained",
                "the",
                "highest",
                "single-trial",
                "decoding",
                "accuracy",
                "(39.41%)",
                "on",
                "the",
                "dev",
                "set.",
                "Indeed,",
                "Wilcoxon",
                "signed-rank",
                "test",
                "#TARGET_REF",
                "confirmed",
                "that",
                "the",
                "best",
                "dev",
                "set",
                "Transformer",
                "performed",
                "significantly",
                "better",
                "on",
                "the",
                "test",
                "set",
                "after",
                "3-1",
                "pretraining",
                "than",
                "after",
                "direct",
                "single-trial",
                "training",
                "(p",
                "&lt,",
                "0.01)."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Results. For the SVM, the 3-1 pretraining without data augmentation resulted in the highest dev set accuracy (32.03%), though accuracy was only slightly better than for direct single-trial training (31.93%). For the Transformer, the 3-1 pretraining scheme with 250k data augmentation obtained the highest single-trial decoding accuracy (39.41%) on the dev set. Indeed, Wilcoxon signed-rank test #TARGET_REF confirmed that the best dev set Transformer performed significantly better on the test set after 3-1 pretraining than after direct single-trial training (p &lt, 0.01).",
        "output": "{\"INFO\": [\"Wilcoxon signed-rank test\"], \"PERCEPT\": [\"confirmed that the best dev set Transformer performed significantly better on the test set after 3-1 pretraining than after direct single-trial training (p &lt, 0.01).\"], \"BACK\": [\"For the SVM, the 3-1 pretraining without data augmentation resulted in the highest dev set accuracy (32.03%), though accuracy was only slightly better than for direct single-trial training (31.93%). For the Transformer, the 3-1 pretraining scheme with 250k data augmentation obtained the highest single-trial decoding accuracy (39.41%) on the dev set.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Random",
                "named",
                "entity:",
                "the",
                "majority",
                "of",
                "answers",
                "in",
                "Quoref",
                "are",
                "person",
                "names.",
                "To",
                "evaluate",
                "this",
                "artifact,",
                "we",
                "randomly",
                "select",
                "a",
                "PERSON",
                "named",
                "entity",
                "from",
                "the",
                "context",
                "as",
                "the",
                "answer.",
                "3",
                "•",
                "Wh-word",
                "#REF",
                ":",
                "to",
                "recognize",
                "the",
                "QA",
                "pairs",
                "that",
                "can",
                "be",
                "answered",
                "by",
                "only",
                "using",
                "the",
                "interrogative",
                "adverbs",
                "from",
                "the",
                "question,",
                "we",
                "train",
                "a",
                "model",
                "on",
                "a",
                "variation",
                "of",
                "the",
                "training",
                "dataset",
                "in",
                "which",
                "questions",
                "only",
                "contain",
                "interrogative",
                "adverbs.",
                "•",
                "Empty",
                "question",
                "#TARGET_REF",
                ":",
                "to",
                "recognize",
                "QA",
                "pairs",
                "that",
                "are",
                "answerable",
                "without",
                "considering",
                "the",
                "question,",
                "4",
                "we",
                "train",
                "a",
                "QA",
                "model",
                "only",
                "on",
                "the",
                "contexts",
                "and",
                "without",
                "questions.",
                "•",
                "Semantic",
                "overlap",
                "#REF",
                ":",
                "for",
                "this",
                "artifact,",
                "we",
                "report",
                "the",
                "ratio",
                "of",
                "the",
                "QA",
                "pairs",
                "whose",
                "answers",
                "lie",
                "in",
                "the",
                "sentence",
                "of",
                "the",
                "context",
                "that",
                "has",
                "the",
                "highest",
                "semantic",
                "similarity",
                "to",
                "the",
                "question.",
                "We",
                "use",
                "sentence-BERT",
                "#REF",
                "to",
                "find",
                "the",
                "most",
                "similar",
                "sentence.",
                "•",
                "Short",
                "distance",
                "reasoning:",
                "for",
                "this",
                "bias,",
                "we",
                "train",
                "a",
                "model",
                "only",
                "using",
                "the",
                "sentence",
                "of",
                "the",
                "context",
                "that",
                "is",
                "the",
                "most",
                "similar",
                "to",
                "the",
                "question,",
                "instead",
                "of",
                "the",
                "whole",
                "context.",
                "We",
                "exclude",
                "the",
                "question-answer",
                "pairs",
                "in",
                "which",
                "the",
                "most",
                "similar",
                "sentence",
                "does",
                "not",
                "contain",
                "the",
                "answer.",
                "This",
                "model",
                "will",
                "not",
                "learn",
                "to",
                "perform",
                "coreference",
                "reasoning",
                "when",
                "the",
                "related",
                "coreferring",
                "pairs",
                "are",
                "not",
                "in",
                "the",
                "same",
                "sentence."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Random named entity: the majority of answers in Quoref are person names. To evaluate this artifact, we randomly select a PERSON named entity from the context as the answer. 3 • Wh-word #REF : to recognize the QA pairs that can be answered by only using the interrogative adverbs from the question, we train a model on a variation of the training dataset in which questions only contain interrogative adverbs. • Empty question #TARGET_REF : to recognize QA pairs that are answerable without considering the question, 4 we train a QA model only on the contexts and without questions. • Semantic overlap #REF : for this artifact, we report the ratio of the QA pairs whose answers lie in the sentence of the context that has the highest semantic similarity to the question. We use sentence-BERT #REF to find the most similar sentence. • Short distance reasoning: for this bias, we train a model only using the sentence of the context that is the most similar to the question, instead of the whole context. We exclude the question-answer pairs in which the most similar sentence does not contain the answer. This model will not learn to perform coreference reasoning when the related coreferring pairs are not in the same sentence.",
        "output": "{\"INFO\": [\"Empty question #TARGET_REF : to recognize QA pairs that are answerable without considering the question,\"], \"PERCEPT\": [\"we train a QA model only on the contexts and without questions.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Crosslingual",
                "Since",
                "there",
                "were",
                "no",
                "training",
                "data",
                "available",
                "for",
                "cross-lingual",
                "datasets,",
                "we",
                "followed",
                "a",
                "zero-shot",
                "approach",
                "for",
                "them.",
                "Multilingual",
                "and",
                "cross-lingual",
                "transformer",
                "models",
                "like",
                "multilingual",
                "BERT",
                "and",
                "XLM-R",
                "show",
                "strong",
                "cross-lingual",
                "transfer",
                "learning",
                "performance.",
                "They",
                "can",
                "be",
                "trained",
                "on",
                "one",
                "language,",
                "typically",
                "a",
                "resource-rich",
                "language",
                "and",
                "can",
                "be",
                "used",
                "to",
                "perform",
                "inference",
                "on",
                "another",
                "language.",
                "The",
                "cross-lingual",
                "nature",
                "of",
                "the",
                "transformer",
                "models",
                "has",
                "provided",
                "the",
                "ability",
                "to",
                "do",
                "this",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "we",
                "used",
                "the",
                "models",
                "trained",
                "on",
                "the",
                "English-English",
                "dataset",
                "to",
                "get",
                "predictions",
                "for",
                "cross-lingual",
                "datasets."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Crosslingual Since there were no training data available for cross-lingual datasets, we followed a zero-shot approach for them. Multilingual and cross-lingual transformer models like multilingual BERT and XLM-R show strong cross-lingual transfer learning performance. They can be trained on one language, typically a resource-rich language and can be used to perform inference on another language. The cross-lingual nature of the transformer models has provided the ability to do this #TARGET_REF . Therefore, we used the models trained on the English-English dataset to get predictions for cross-lingual datasets.",
        "output": "{\"INFO\": [\"The cross-lingual nature of the transformer models has provided the ability to do this #TARGET_REF .\"], \"PERCEPT\": [\"Therefore, we used the models trained on the English-English dataset to get predictions for cross-lingual datasets.\"], \"BACK\": [\"cross-lingual transformer models\", \"show strong cross-lingual transfer learning performance. They can be trained on one language, typically a resource-rich language and can be used to perform inference on another language.\"]}"
    },
    {
        "gold": {
            "text": [
                "Different",
                "from",
                "the",
                "above",
                "term-based",
                "approaches,",
                "dense",
                "passage",
                "retrieval",
                "has",
                "been",
                "proposed",
                "to",
                "represent",
                "both",
                "questions",
                "and",
                "documents",
                "as",
                "dense",
                "vectors",
                "(i.e.,",
                "embeddings),",
                "typically",
                "in",
                "a",
                "dual-encoder",
                "architecture",
                "(as",
                "shown",
                "in",
                "Figure",
                "1a).",
                "Existing",
                "approaches",
                "can",
                "be",
                "divided",
                "into",
                "two",
                "categories:",
                "(1)",
                "self-supervised",
                "pre-training",
                "for",
                "retrieval",
                "#TARGET_REF",
                "and",
                "(2)",
                "fine-tuning",
                "pre-trained",
                "language",
                "models",
                "on",
                "labeled",
                "data.",
                "Our",
                "work",
                "follows",
                "the",
                "second",
                "class",
                "of",
                "approaches,",
                "which",
                "show",
                "better",
                "performance",
                "with",
                "less",
                "cost.",
                "Although",
                "the",
                "dual-encoder",
                "architecture",
                "enables",
                "the",
                "appealing",
                "paradigm",
                "of",
                "dense",
                "retrieval,",
                "it",
                "is",
                "difficult",
                "to",
                "effectively",
                "train",
                "a",
                "retriever",
                "with",
                "such",
                "an",
                "architecture.",
                "As",
                "discussed",
                "in",
                "Section",
                "1,",
                "it",
                "suffers",
                "from",
                "a",
                "number",
                "of",
                "challenges,",
                "including",
                "the",
                "training",
                "and",
                "inference",
                "discrepancy,",
                "a",
                "large",
                "number",
                "of",
                "unlabeled",
                "positives",
                "and",
                "limited",
                "training",
                "data.",
                "Several",
                "recent",
                "studies",
                "#REF",
                "tried",
                "to",
                "address",
                "the",
                "first",
                "challenge",
                "by",
                "designing",
                "complicated",
                "sampling",
                "mechanism",
                "to",
                "generate",
                "hard",
                "negatives.",
                "However,",
                "it",
                "still",
                "suffers",
                "from",
                "the",
                "issue",
                "of",
                "false",
                "negatives.",
                "The",
                "later",
                "two",
                "challenges",
                "have",
                "seldom",
                "been",
                "considered",
                "for",
                "open-domain",
                "QA."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Different from the above term-based approaches, dense passage retrieval has been proposed to represent both questions and documents as dense vectors (i.e., embeddings), typically in a dual-encoder architecture (as shown in Figure 1a). Existing approaches can be divided into two categories: (1) self-supervised pre-training for retrieval #TARGET_REF and (2) fine-tuning pre-trained language models on labeled data. Our work follows the second class of approaches, which show better performance with less cost. Although the dual-encoder architecture enables the appealing paradigm of dense retrieval, it is difficult to effectively train a retriever with such an architecture. As discussed in Section 1, it suffers from a number of challenges, including the training and inference discrepancy, a large number of unlabeled positives and limited training data. Several recent studies #REF tried to address the first challenge by designing complicated sampling mechanism to generate hard negatives. However, it still suffers from the issue of false negatives. The later two challenges have seldom been considered for open-domain QA.",
        "output": "{\"INFO\": [\"self-supervised pre-training for retrieval #TARGET_REF\"], \"PERCEPT\": [\"Existing approaches can be divided into two categories:\"], \"BACK\": [\"and\", \"fine-tuning pre-trained language models on labeled data.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "observe",
                "the",
                "effect",
                "of",
                "disentanglement",
                "in",
                "homotopy",
                "#TARGET_REF",
                "Additionally,",
                "to",
                "highlight",
                "the",
                "role",
                "of",
                "generative",
                "factor",
                "in",
                "generation,",
                "we",
                "conduct",
                "a",
                "dimensionwise",
                "homotopy,",
                "transitioning",
                "from",
                "the",
                "first",
                "to",
                "the",
                "last",
                "sentence",
                "by",
                "interpolating",
                "between",
                "the",
                "dimensions",
                "one-by-one.",
                "This",
                "is",
                "implemented",
                "as",
                "follows:",
                "(i)",
                "using",
                "prior",
                "distribution",
                "7",
                "we",
                "sample",
                "two",
                "latent",
                "codes",
                "denoted",
                "by",
                "z",
                "1",
                "=",
                "(z",
                "1,1",
                ",",
                "z",
                "1,2",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                "),",
                "z",
                "2",
                "=",
                "(z",
                "2,1",
                ",",
                "z",
                "2,2",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,n",
                "),",
                "(ii)",
                "for",
                "i-th",
                "dimension,",
                "using",
                "z",
                "1,i",
                "=",
                "(z",
                "2,1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,i−1",
                ",",
                "z",
                "1,i",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                ")",
                "as",
                "the",
                "start,",
                "we",
                "interpolate",
                "along",
                "the",
                "i-th",
                "dimension",
                "towards",
                "z",
                "2,i",
                "=",
                "(z",
                "2,1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,i",
                ",",
                "z",
                "1,i+1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                ").",
                "Table",
                "6",
                "illustrates",
                "this",
                "for",
                "a",
                "3D",
                "latent",
                "code",
                "example."
            ],
            "context": [
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "To observe the effect of disentanglement in homotopy #TARGET_REF Additionally, to highlight the role of generative factor in generation, we conduct a dimensionwise homotopy, transitioning from the first to the last sentence by interpolating between the dimensions one-by-one. This is implemented as follows: (i) using prior distribution 7 we sample two latent codes denoted by z 1 = (z 1,1 , z 1,2 , . . . , z 1,n ), z 2 = (z 2,1 , z 2,2 , . . . , z 2,n ), (ii) for i-th dimension, using z 1,i = (z 2,1 , . . . , z 2,i−1 , z 1,i , . . . , z 1,n ) as the start, we interpolate along the i-th dimension towards z 2,i = (z 2,1 , . . . , z 2,i , z 1,i+1 , . . . , z 1,n ). Table 6 illustrates this for a 3D latent code example.",
        "output": "{\"INFO\": [\"the effect of disentanglement in homotopy #TARGET_REF\"], \"PERCEPT\": [\"To observe\", \"to highlight the role of generative factor in generation, we conduct a dimensionwise homotopy, transitioning from the first to the last sentence by interpolating between the dimensions one-by-one.\"], \"BACK\": [\"This is implemented as follows: (i) using prior distribution 7 we sample two latent codes denoted by z 1 = (z 1,1 , z 1,2 , . . . , z 1,n ), z 2 = (z 2,1 , z 2,2 , . . . , z 2,n ), (ii) for i-th dimension, using z 1,i = (z 2,1 , . . . , z 2,i\\u22121 , z 1,i , . . . , z 1,n ) as the start, we interpolate along the i-th dimension towards z 2,i = (z 2,1 , . . . , z 2,i , z 1,i+1 , . . . , z 1,n ). Table 6 illustrates this for a 3D latent code example.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "modeled",
                "that",
                "problem",
                "as",
                "a",
                "heterogeneous",
                "network.",
                "The",
                "structure",
                "of",
                "our",
                "graph",
                "was",
                "inspired",
                "by",
                "#TARGET_REF",
                ".",
                "These",
                "authors",
                "modeled",
                "the",
                "tasks",
                "of",
                "helpfulness",
                "prediction",
                "and",
                "paraphrase",
                "identification",
                "as",
                "a",
                "heterogeneous",
                "network,",
                "respectively.",
                "For",
                "that,",
                "they",
                "defined",
                "an",
                "undirected",
                "unweighted",
                "graph",
                "with",
                "two",
                "node",
                "types:",
                "sentence",
                "and",
                "token.",
                "However,",
                "we",
                "have",
                "created",
                "a",
                "weighted",
                "graph",
                "based",
                "on",
                "pre-trained",
                "word",
                "embeddings.",
                "The",
                "weight",
                "between",
                "sentence",
                "and",
                "token",
                "nodes",
                "is",
                "the",
                "average",
                "of",
                "the",
                "embedding",
                "values",
                "for",
                "that",
                "token.",
                "Figure",
                "1",
                "depicts",
                "an",
                "example",
                "of",
                "a",
                "sentence",
                "modeled",
                "as",
                "a",
                "graph.",
                "From",
                "this",
                "figure,",
                "we",
                "may",
                "see",
                "two",
                "node",
                "types:",
                "token",
                "and",
                "sentence,",
                "and",
                "an",
                "undirected",
                "and",
                "weighted",
                "edges",
                "between",
                "the",
                "sentence",
                "and",
                "tokens",
                "nodes.",
                "To",
                "extract",
                "features",
                "from",
                "the",
                "graph",
                "structure,",
                "we",
                "used",
                "a",
                "regularization",
                "algorithm",
                "that",
                "propagates",
                "labels",
                "from",
                "a",
                "small",
                "set",
                "of",
                "labeled",
                "nodes",
                "to",
                "the",
                "entire",
                "graph.E(t)",
                "E(t)",
                "E(t)",
                "E(t)",
                "E(t)",
                "E(t)We",
                "evaluated",
                "the",
                "approach",
                "using",
                "the",
                "ToLD-Br",
                "corpus",
                "#REF",
                ".",
                "It",
                "has",
                "twenty-one",
                "thousand",
                "annotated",
                "tweets",
                "as",
                "either",
                "toxic",
                "or",
                "non-toxic",
                "language.",
                "Also,",
                "we",
                "compared",
                "our",
                "strategy",
                "with",
                "different",
                "graph-based",
                "methods",
                "and",
                "with",
                "transformerbased",
                "methods.",
                "Our",
                "method",
                "outperformed",
                "all",
                "graph-based",
                "approaches",
                "and",
                "achieved",
                "competitive",
                "results",
                "compared",
                "to",
                "transformer-based",
                "methods,",
                "using",
                "only",
                "10%",
                "of",
                "labeled",
                "nodes."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We modeled that problem as a heterogeneous network. The structure of our graph was inspired by #TARGET_REF . These authors modeled the tasks of helpfulness prediction and paraphrase identification as a heterogeneous network, respectively. For that, they defined an undirected unweighted graph with two node types: sentence and token. However, we have created a weighted graph based on pre-trained word embeddings. The weight between sentence and token nodes is the average of the embedding values for that token. Figure 1 depicts an example of a sentence modeled as a graph. From this figure, we may see two node types: token and sentence, and an undirected and weighted edges between the sentence and tokens nodes. To extract features from the graph structure, we used a regularization algorithm that propagates labels from a small set of labeled nodes to the entire graph.E(t) E(t) E(t) E(t) E(t) E(t)We evaluated the approach using the ToLD-Br corpus #REF . It has twenty-one thousand annotated tweets as either toxic or non-toxic language. Also, we compared our strategy with different graph-based methods and with transformerbased methods. Our method outperformed all graph-based approaches and achieved competitive results compared to transformer-based methods, using only 10% of labeled nodes.",
        "output": "{\"INFO\": [\"These authors modeled the tasks of helpfulness prediction and paraphrase identification as a heterogeneous network, respectively. For that, they defined an undirected unweighted graph with two node types: sentence and token.\"], \"PERCEPT\": [\"The structure of our graph was inspired by #TARGET_REF .\", \"we have created a weighted graph based on pre-trained word embeddings.\", \"Also, we compared our strategy with different graph-based methods and with transformerbased methods. Our method outperformed all graph-based approaches and achieved competitive results compared to transformer-based methods, using only 10% of labeled nodes.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Transformer",
                "architecture",
                "#REF",
                "has",
                "been",
                "successful",
                "in",
                "a",
                "wide",
                "range",
                "of",
                "natural",
                "language",
                "processing",
                "tasks,",
                "including",
                "machine",
                "translation",
                "#REF",
                ",",
                "language",
                "modeling",
                "#REF",
                ",",
                "question-answering",
                "#REF",
                ",",
                "and",
                "many",
                "more.",
                "Transformers",
                "pre-trained",
                "on",
                "large",
                "amounts",
                "of",
                "text",
                "with",
                "a",
                "language",
                "modeling",
                "(LM)",
                "objective,",
                "have",
                "become",
                "the",
                "standard",
                "in",
                "NLP,",
                "exhibiting",
                "surprising",
                "amounts",
                "of",
                "linguistic",
                "and",
                "world",
                "knowledge",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The Transformer architecture #REF has been successful in a wide range of natural language processing tasks, including machine translation #REF , language modeling #REF , question-answering #REF , and many more. Transformers pre-trained on large amounts of text with a language modeling (LM) objective, have become the standard in NLP, exhibiting surprising amounts of linguistic and world knowledge #TARGET_REF .",
        "output": "{\"INFO\": [\"Transformers pre-trained on large amounts of text with a language modeling (LM) objective, have become the standard in NLP, exhibiting surprising amounts of linguistic and world knowledge #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"The Transformer architecture #REF has been successful in a wide range of natural language processing tasks, including machine translation #REF , language modeling #REF , question-answering #REF , and many more.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "paper",
                "examines",
                "the",
                "question",
                "of",
                "differences",
                "between",
                "a",
                "traditional",
                "interlingua",
                "approach",
                "and",
                "a",
                "transferbased",
                "approach",
                "that",
                "uses",
                "cross-linguistic",
                "semantic",
                "features",
                "to",
                "generalize",
                "its",
                "transfer",
                "lexicon",
                "entries,",
                "and",
                "concludes",
                "that",
                "the",
                "two",
                "approaches",
                "share",
                "a",
                "common",
                "interest",
                "in",
                "lexical",
                "classifications",
                "that",
                "can",
                "be",
                "distinguished",
                "by",
                "cross-linguistic",
                "semantic",
                "features.",
                "The",
                "paper",
                "goes",
                "on",
                "to",
                "discuss",
                "current",
                "approaches",
                "to",
                "English",
                "classification,",
                "Levin",
                "classes",
                "#REF",
                "and",
                "WordNet",
                "#TARGET_REF",
                ".",
                "We",
                "present",
                "a",
                "refinement",
                "of",
                "Levin",
                "classes",
                "-Intersective",
                "Classes",
                "-that",
                "shows",
                "interesting",
                "correlations",
                "to",
                "WordNet",
                "and",
                "that",
                "makes",
                "more",
                "explicit",
                "the",
                "semantic",
                "components",
                "that",
                "serve",
                "to",
                "distinguish",
                "different",
                "classes."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "This paper examines the question of differences between a traditional interlingua approach and a transferbased approach that uses cross-linguistic semantic features to generalize its transfer lexicon entries, and concludes that the two approaches share a common interest in lexical classifications that can be distinguished by cross-linguistic semantic features. The paper goes on to discuss current approaches to English classification, Levin classes #REF and WordNet #TARGET_REF . We present a refinement of Levin classes -Intersective Classes -that shows interesting correlations to WordNet and that makes more explicit the semantic components that serve to distinguish different classes.",
        "output": "{\"INFO\": [\"WordNet #TARGET_REF\"], \"PERCEPT\": [\"The paper goes on to discuss current approaches to English classification,\", \"We present a refinement of Levin classes\", \"-that shows interesting correlations to WordNet\"], \"BACK\": [\"Levin classes #REF and\", \"-Intersective Classes\"]}"
    },
    {
        "gold": {
            "text": [
                "the",
                "candidate",
                "summaries.",
                "In",
                "other",
                "words,",
                "we",
                "give",
                "the",
                "abstractive",
                "model",
                "a",
                "dual",
                "role:",
                "as",
                "a",
                "generation",
                "model,",
                "it",
                "generates",
                "the",
                "output",
                "summaries",
                "in",
                "an",
                "autoregressive",
                "way,",
                "as",
                "an",
                "evaluation",
                "model,",
                "it",
                "can",
                "be",
                "used",
                "to",
                "score",
                "the",
                "quality",
                "of",
                "candidate",
                "summaries",
                "by",
                "estimating",
                "a",
                "probability",
                "distribution",
                "over",
                "candidate",
                "outputs.",
                "The",
                "generation",
                "model",
                "is",
                "trained",
                "using",
                "the",
                "standard",
                "MLE",
                "loss,",
                "but",
                "to",
                "train",
                "the",
                "evaluation",
                "model",
                "we",
                "introduce",
                "a",
                "contrastive",
                "loss",
                "#TARGET_REF",
                "defined",
                "over",
                "different",
                "candidate",
                "summaries",
                "generated",
                "by",
                "pre-trained",
                "abstractive",
                "models",
                "(Fig.",
                "1),",
                "following",
                "previous",
                "work",
                "on",
                "ranking-based",
                "or",
                "contrastive",
                "learning",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "the candidate summaries. In other words, we give the abstractive model a dual role: as a generation model, it generates the output summaries in an autoregressive way, as an evaluation model, it can be used to score the quality of candidate summaries by estimating a probability distribution over candidate outputs. The generation model is trained using the standard MLE loss, but to train the evaluation model we introduce a contrastive loss #TARGET_REF defined over different candidate summaries generated by pre-trained abstractive models (Fig. 1), following previous work on ranking-based or contrastive learning #REF .",
        "output": "{\"INFO\": [\"contrastive loss #TARGET_REF defined over different candidate summaries generated by pre-trained abstractive models\"], \"PERCEPT\": [\"but to train the evaluation model we introduce a\", \"following previous work on ranking-based or contrastive learning #REF .\"], \"BACK\": [\"The generation model is trained using the standard MLE loss,\", \"(Fig. 1),\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Sampled",
                "Curriculums.",
                "Inspired",
                "by",
                "#TARGET_REF",
                ",",
                "Graves",
                "et",
                "al.",
                "(",
                "2017),",
                "we",
                "explore",
                "an",
                "alternate",
                "method",
                "of",
                "creating",
                "curriculums",
                "by",
                "simply",
                "oversampling",
                "the",
                "same",
                "rare",
                "quests",
                "found",
                "in",
                "the",
                "tails",
                "of",
                "the",
                "distributions."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "• Sampled Curriculums. Inspired by #TARGET_REF , Graves et al. ( 2017), we explore an alternate method of creating curriculums by simply oversampling the same rare quests found in the tails of the distributions.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"Inspired by #TARGET_REF ,\", \"we explore an alternate method of creating curriculums by simply oversampling the same rare quests found in the tails of the distributions.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "baseline",
                "system",
                "built",
                "for",
                "the",
                "task",
                "is",
                "a",
                "simple",
                "PBSMT",
                "system",
                "trained",
                "only",
                "on",
                "the",
                "'in-domain'",
                "training",
                "data",
                "released",
                "as",
                "a",
                "part",
                "of",
                "the",
                "evaluation",
                "campaign.",
                "This",
                "training",
                "data",
                "comprised",
                "of",
                "both",
                "parallel",
                "and",
                "monolingual",
                "data",
                "from",
                "the",
                "TED",
                "1",
                "http://iwslt2011.org",
                "Talks:",
                "2",
                "a",
                "collection",
                "of",
                "public",
                "speeches",
                "on",
                "a",
                "variety",
                "of",
                "topics.",
                "Out-of-domain",
                "data",
                "in",
                "the",
                "form",
                "of",
                "a",
                "parallel",
                "Multi-UN",
                "corpus",
                "3",
                "was",
                "also",
                "available",
                "to",
                "enrich",
                "the",
                "models",
                "trained",
                "on",
                "in-domain",
                "data.",
                "For",
                "domain-adaptation",
                "we",
                "enhanced",
                "the",
                "language",
                "models",
                "built",
                "on",
                "the",
                "TED",
                "corpus",
                "data",
                "with",
                "selected",
                "data",
                "from",
                "the",
                "UN",
                "corpus.",
                "Mixture",
                "adaptation",
                "#TARGET_REF",
                "techniques",
                "were",
                "used",
                "to",
                "combine",
                "models",
                "from",
                "multiple",
                "sources",
                "weighted",
                "according",
                "to",
                "their",
                "fit",
                "with",
                "respect",
                "to",
                "the",
                "development",
                "set.",
                "The",
                "adapted",
                "language",
                "models",
                "provided",
                "an",
                "improvement",
                "of",
                "about",
                "5.16",
                "absolute",
                "(21.99%",
                "relative)",
                "BLEU",
                "points",
                "for",
                "Ar-En",
                "and",
                "1.25",
                "absolute",
                "(11.76%",
                "relative)",
                "BLEU",
                "points",
                "for",
                "Zh-En",
                "language",
                "pairs",
                "over",
                "the",
                "unadapted",
                "baseline."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The baseline system built for the task is a simple PBSMT system trained only on the 'in-domain' training data released as a part of the evaluation campaign. This training data comprised of both parallel and monolingual data from the TED 1 http://iwslt2011.org Talks: 2 a collection of public speeches on a variety of topics. Out-of-domain data in the form of a parallel Multi-UN corpus 3 was also available to enrich the models trained on in-domain data. For domain-adaptation we enhanced the language models built on the TED corpus data with selected data from the UN corpus. Mixture adaptation #TARGET_REF techniques were used to combine models from multiple sources weighted according to their fit with respect to the development set. The adapted language models provided an improvement of about 5.16 absolute (21.99% relative) BLEU points for Ar-En and 1.25 absolute (11.76% relative) BLEU points for Zh-En language pairs over the unadapted baseline.",
        "output": "{\"INFO\": [\"Mixture adaptation #TARGET_REF techniques\"], \"PERCEPT\": [\"For domain-adaptation we enhanced the language models built on the TED corpus data with selected data from the UN corpus.\", \"were used to combine models from multiple sources weighted according to their fit with respect to the development set.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "A",
                "three-fold",
                "analysis",
                "of",
                "the",
                "selected",
                "keywords",
                "was",
                "done.",
                "The",
                "semantics",
                "of",
                "the",
                "words",
                "was",
                "studied",
                "by",
                "using",
                "WordNet.",
                "In",
                "dialogue",
                "acts",
                "such",
                "as",
                "apologizing,",
                "thanking,",
                "or",
                "expressing",
                "sympathy,",
                "affective",
                "language",
                "is",
                "often",
                "employed",
                "to",
                "represent",
                "and",
                "convey",
                "psychological",
                "attitudes",
                "#REF",
                ".",
                "Also,",
                "there",
                "is",
                "what",
                "is",
                "called",
                "a",
                "'heartfelt",
                "apology'",
                "as",
                "against",
                "'routine",
                "apology",
                "#TARGET_REF",
                ").",
                "Hence,",
                "it",
                "was",
                "decided",
                "to",
                "further",
                "explore",
                "the",
                "sentiments",
                "and",
                "emotions",
                "associated",
                "with",
                "the",
                "keywords.",
                "The",
                "sentiments",
                "were",
                "studied",
                "using",
                "SentiWordNet",
                "and",
                "the",
                "emotion",
                "labels",
                "were",
                "determined",
                "through",
                "WordNet-Affect.",
                "The",
                "analysis",
                "and",
                "conclusions",
                "thus",
                "drawn",
                "are",
                "presented",
                "below."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A three-fold analysis of the selected keywords was done. The semantics of the words was studied by using WordNet. In dialogue acts such as apologizing, thanking, or expressing sympathy, affective language is often employed to represent and convey psychological attitudes #REF . Also, there is what is called a 'heartfelt apology' as against 'routine apology #TARGET_REF ). Hence, it was decided to further explore the sentiments and emotions associated with the keywords. The sentiments were studied using SentiWordNet and the emotion labels were determined through WordNet-Affect. The analysis and conclusions thus drawn are presented below.",
        "output": "{\"INFO\": [\"'routine apology #TARGET_REF\"], \"PERCEPT\": [\"there is what is called a 'heartfelt apology' as against\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Pre-trained",
                "language",
                "models",
                "are",
                "increasingly",
                "applied",
                "in",
                "ways",
                "that",
                "are",
                "agnostic",
                "to",
                "targeted",
                "downstream",
                "tasks",
                "#REF",
                ".",
                "This",
                "usage",
                "has",
                "led",
                "to",
                "a",
                "proliferation",
                "of",
                "large",
                "language",
                "models",
                "trained",
                "on",
                "enormous",
                "amounts",
                "of",
                "data.",
                "For",
                "example,",
                "the",
                "recent",
                "Megatron-Turing",
                "NLG",
                "530B",
                "model",
                "was",
                "trained",
                "on",
                "the",
                "Pile,",
                "which",
                "includes",
                "800GB+",
                "of",
                "text",
                "#REF",
                ",",
                "and",
                "other",
                "large",
                "language",
                "models",
                "utilize",
                "large",
                "portions",
                "of",
                "the",
                "200TB+",
                "common",
                "crawl",
                "data.",
                "1",
                "These",
                "large",
                "data",
                "sets",
                "include",
                "impressive",
                "amounts",
                "of",
                "text,",
                "but",
                "all",
                "languages",
                "are",
                "not",
                "represented",
                "equally",
                "(or",
                "at",
                "all)",
                "in",
                "that",
                "text.",
                "The",
                "reality",
                "is",
                "that",
                "only",
                "a",
                "negligible",
                "fraction",
                "of",
                "the",
                "7000+",
                "currently",
                "spoken",
                "languages",
                "#TARGET_REF",
                "have",
                "sufficient",
                "text",
                "corpora",
                "to",
                "train",
                "state-of-theart",
                "language",
                "models.",
                "This",
                "data",
                "scarcity",
                "results",
                "in",
                "systematic",
                "inequalities",
                "in",
                "the",
                "performance",
                "of",
                "NLP",
                "tasks",
                "across",
                "the",
                "world's",
                "languages",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Pre-trained language models are increasingly applied in ways that are agnostic to targeted downstream tasks #REF . This usage has led to a proliferation of large language models trained on enormous amounts of data. For example, the recent Megatron-Turing NLG 530B model was trained on the Pile, which includes 800GB+ of text #REF , and other large language models utilize large portions of the 200TB+ common crawl data. 1 These large data sets include impressive amounts of text, but all languages are not represented equally (or at all) in that text. The reality is that only a negligible fraction of the 7000+ currently spoken languages #TARGET_REF have sufficient text corpora to train state-of-theart language models. This data scarcity results in systematic inequalities in the performance of NLP tasks across the world's languages #REF .",
        "output": "{\"INFO\": [\"the 7000+ currently spoken languages #TARGET_REF\"], \"PERCEPT\": [\"The reality is that only a negligible fraction of\", \"have sufficient text corpora to train state-of-theart language models. This data scarcity results in systematic inequalities in the performance of NLP tasks across the world's languages #REF .\"], \"BACK\": [\"1 These large data sets include impressive amounts of text, but all languages are not represented equally (or at all) in that text.\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "future",
                "work,",
                "we",
                "would",
                "be",
                "looking",
                "to",
                "improve",
                "our",
                "results",
                "more",
                "with",
                "new",
                "strategies.",
                "We",
                "would",
                "like",
                "to",
                "experiment",
                "with",
                "whether",
                "adding",
                "languagespecific",
                "processing",
                "and",
                "resources",
                "would",
                "improve",
                "the",
                "results.",
                "We",
                "are",
                "keen",
                "to",
                "add",
                "different",
                "neural",
                "network",
                "architectures",
                "like",
                "Siamese",
                "transformer",
                "networks",
                "#REF",
                "that",
                "perform",
                "well",
                "in",
                "sentence",
                "pair",
                "classification",
                "tasks",
                "#TARGET_REF",
                "to",
                "the",
                "TransWiC",
                "framework.",
                "Furthermore,",
                "we",
                "are",
                "hoping",
                "to",
                "work",
                "in",
                "a",
                "multi-task",
                "environment",
                "and",
                "experiment",
                "whether",
                "transfer",
                "learning",
                "from",
                "a",
                "similar",
                "task",
                "like",
                "semantic",
                "textual",
                "similarity",
                "#REF",
                "would",
                "improve",
                "the",
                "results",
                "for",
                "this",
                "task."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "As future work, we would be looking to improve our results more with new strategies. We would like to experiment with whether adding languagespecific processing and resources would improve the results. We are keen to add different neural network architectures like Siamese transformer networks #REF that perform well in sentence pair classification tasks #TARGET_REF to the TransWiC framework. Furthermore, we are hoping to work in a multi-task environment and experiment whether transfer learning from a similar task like semantic textual similarity #REF would improve the results for this task.",
        "output": "{\"INFO\": [\"sentence pair classification tasks\"], \"PERCEPT\": [\"We are keen to add different neural network architectures like Siamese transformer networks #REF that perform well in\", \"to the TransWiC framework.\"], \"BACK\": [\"We would like to experiment with whether adding languagespecific processing and resources would improve the results.\"]}"
    },
    {
        "gold": {
            "text": [
                "Specifically,",
                "we",
                "use",
                "a",
                "retrieval-based",
                "ranker",
                "model",
                "that",
                "checks",
                "for",
                "similarity",
                "of",
                "#REF",
                "embeddings.",
                "Our",
                "choice",
                "of",
                "model",
                "is",
                "influenced",
                "by",
                "#TARGET_REF",
                "who",
                "report",
                "stateof-the-art",
                "retrieval",
                "performance",
                "for",
                "locations",
                "in",
                "LIGHT",
                "using",
                "this",
                "model.",
                "The",
                "overall",
                "ranker",
                "model",
                "first",
                "trains",
                "a",
                "randomly",
                "initialized",
                "StarSpace",
                "embedding",
                "model",
                "that",
                "is",
                "designed",
                "to",
                "correlate",
                "characters",
                "with",
                "the",
                "locations",
                "they",
                "are",
                "found",
                "in.",
                "It",
                "learns",
                "a",
                "single",
                "bag-of-words",
                "embedding",
                "that",
                "takes",
                "into",
                "account",
                "all",
                "the",
                "individual",
                "words",
                "contained",
                "within",
                "the",
                "input-encoding",
                "character",
                "and",
                "location",
                "information",
                "as",
                "well",
                "as",
                "the",
                "previously",
                "mentioned",
                "negative",
                "Quest",
                "Generation.",
                "The",
                "quest",
                "is",
                "now",
                "generated",
                "using",
                "the",
                "existing",
                "character",
                "and",
                "location",
                "information.",
                "The",
                "generation-based",
                "models",
                "used",
                "in",
                "this",
                "pipeline",
                "are",
                "trained",
                "to",
                "return",
                "the",
                "most",
                "likely",
                "output",
                "sequence",
                "given",
                "an",
                "input",
                "sequence.",
                "Given",
                "a",
                "target",
                "sequence",
                "Y",
                "=",
                "{y",
                "1",
                ",",
                "...,",
                "y",
                "M",
                "}",
                "and",
                "some",
                "input",
                "context",
                "vector",
                "via",
                "the",
                "encoders",
                "X.",
                "These",
                "models",
                "use",
                "autoregressive",
                "decoding",
                "techniques",
                "that",
                "factor",
                "the",
                "distribution",
                "over",
                "the",
                "target",
                "sequence",
                "into",
                "a",
                "chain",
                "of",
                "conditional",
                "probabilities",
                "with",
                "a",
                "causal",
                "left",
                "to",
                "right",
                "structure",
                "as",
                "P",
                "(Y",
                "|X,",
                "θ)",
                "=",
                "M",
                "+1",
                "i=1",
                "p(y",
                "i",
                "|y",
                "0:i−1",
                ",",
                "X,",
                "θ)",
                "where",
                "θ",
                "represents",
                "the",
                "current",
                "network",
                "parameters.",
                "At",
                "test",
                "time,",
                "a",
                "special",
                "start-of-sequence",
                "token",
                "is",
                "provided",
                "to",
                "the",
                "model",
                "which",
                "then",
                "proceeds",
                "to",
                "decode",
                "the",
                "rest",
                "of",
                "the",
                "output",
                "sequence",
                "using",
                "beam",
                "search."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Specifically, we use a retrieval-based ranker model that checks for similarity of #REF embeddings. Our choice of model is influenced by #TARGET_REF who report stateof-the-art retrieval performance for locations in LIGHT using this model. The overall ranker model first trains a randomly initialized StarSpace embedding model that is designed to correlate characters with the locations they are found in. It learns a single bag-of-words embedding that takes into account all the individual words contained within the input-encoding character and location information as well as the previously mentioned negative Quest Generation. The quest is now generated using the existing character and location information. The generation-based models used in this pipeline are trained to return the most likely output sequence given an input sequence. Given a target sequence Y = {y 1 , ..., y M } and some input context vector via the encoders X. These models use autoregressive decoding techniques that factor the distribution over the target sequence into a chain of conditional probabilities with a causal left to right structure as P (Y |X, θ) = M +1 i=1 p(y i |y 0:i−1 , X, θ) where θ represents the current network parameters. At test time, a special start-of-sequence token is provided to the model which then proceeds to decode the rest of the output sequence using beam search.",
        "output": "{\"INFO\": [\"Our choice of model is influenced by #TARGET_REF who report stateof-the-art retrieval performance for locations in LIGHT using this model.\"], \"PERCEPT\": [], \"BACK\": [\"Specifically, we use a retrieval-based ranker model that checks for similarity of #REF embeddings.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "training",
                "of",
                "Transformer+CTC,",
                "we",
                "applied",
                "joint",
                "CTC",
                "training",
                "to",
                "improve",
                "performance",
                "#REF",
                ".",
                "For",
                "CTC-based",
                "decoding,",
                "we",
                "used",
                "the",
                "greedy",
                "search",
                "algorithm.",
                "For",
                "Transformer",
                "decoding,",
                "we",
                "used",
                "the",
                "beam",
                "search",
                "algorithm",
                "and",
                "tuned",
                "search",
                "parameters",
                "using",
                "the",
                "development",
                "set.",
                "For",
                "the",
                "Transformer+CTC",
                "model,",
                "we",
                "applied",
                "Transformer/CTC",
                "joint",
                "decoding",
                "#TARGET_REF",
                ".",
                "and",
                "tuned",
                "the",
                "weights",
                "of",
                "the",
                "objective",
                "using",
                "the",
                "development",
                "set.",
                "Note",
                "that",
                "the",
                "language",
                "model",
                "shallow",
                "fusion",
                "#REF",
                "is",
                "not",
                "applied",
                "since",
                "we",
                "could",
                "not",
                "find",
                "effectiveness",
                "in",
                "our",
                "preliminary",
                "experiment."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For the training of Transformer+CTC, we applied joint CTC training to improve performance #REF . For CTC-based decoding, we used the greedy search algorithm. For Transformer decoding, we used the beam search algorithm and tuned search parameters using the development set. For the Transformer+CTC model, we applied Transformer/CTC joint decoding #TARGET_REF . and tuned the weights of the objective using the development set. Note that the language model shallow fusion #REF is not applied since we could not find effectiveness in our preliminary experiment.",
        "output": "{\"INFO\": [\"Transformer/CTC joint decoding\"], \"PERCEPT\": [\"we applied\"], \"BACK\": [\"For the Transformer+CTC model,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "use",
                "of",
                "synthetic",
                "datasets",
                "is",
                "the",
                "common",
                "practice",
                "for",
                "evaluating",
                "disentanglement",
                "in",
                "image",
                "domain",
                "#TARGET_REF",
                ".",
                "Generative",
                "simplistic",
                "datasets",
                "in",
                "image",
                "domain",
                "define",
                "independent",
                "generative",
                "factors",
                "(e.g.",
                "shape,",
                "color)",
                "behind",
                "the",
                "data",
                "generation.",
                "However,",
                "a",
                "comparable",
                "resource",
                "is",
                "missing",
                "in",
                "text",
                "domain.",
                "We",
                "develop",
                "two",
                "synthetic",
                "generative",
                "datasets",
                "with",
                "varying",
                "degrees",
                "of",
                "difficulty",
                "to",
                "analyse",
                "and",
                "measure",
                "disentanglement:",
                "The",
                "YNOC",
                "dataset",
                "(",
                "§3.1)",
                "which",
                "has",
                "only",
                "three",
                "structures",
                "and",
                "generative",
                "factors",
                "appearing",
                "in",
                "every",
                "sentence,",
                "and",
                "the",
                "POS",
                "dataset",
                "(",
                "§3.2)",
                "which",
                "has",
                "more",
                "structures",
                "while",
                "some",
                "generative",
                "factors",
                "are",
                "not",
                "guaranteed",
                "to",
                "appear",
                "in",
                "every",
                "sentence.",
                "The",
                "YNOC",
                "dataset",
                "offers",
                "a",
                "simpler",
                "setting",
                "for",
                "disentanglement.",
                "The",
                "templates",
                "were",
                "then",
                "converted",
                "into",
                "real",
                "sentences",
                "using",
                "10",
                "years,",
                "40",
                "names,",
                "20",
                "occupations,",
                "and",
                "30",
                "cities.",
                "This",
                "amounted",
                "to",
                "a",
                "total",
                "of",
                "720K",
                "sentences,",
                "split",
                "as",
                "(60%,20%,20%)",
                "into",
                "training,",
                "validation,",
                "and",
                "test",
                "sets."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The use of synthetic datasets is the common practice for evaluating disentanglement in image domain #TARGET_REF . Generative simplistic datasets in image domain define independent generative factors (e.g. shape, color) behind the data generation. However, a comparable resource is missing in text domain. We develop two synthetic generative datasets with varying degrees of difficulty to analyse and measure disentanglement: The YNOC dataset ( §3.1) which has only three structures and generative factors appearing in every sentence, and the POS dataset ( §3.2) which has more structures while some generative factors are not guaranteed to appear in every sentence. The YNOC dataset offers a simpler setting for disentanglement. The templates were then converted into real sentences using 10 years, 40 names, 20 occupations, and 30 cities. This amounted to a total of 720K sentences, split as (60%,20%,20%) into training, validation, and test sets.",
        "output": "{\"INFO\": [\"The use of synthetic datasets is the common practice for evaluating disentanglement in image domain #TARGET_REF .\"], \"PERCEPT\": [\"We develop two synthetic generative datasets with varying degrees of difficulty to analyse and measure disentanglement:\"], \"BACK\": [\"The YNOC dataset ( \\u00a73.1)\", \"the POS dataset ( \\u00a73.2)\"]}"
    },
    {
        "gold": {
            "text": [
                "(b)",
                "One-to-one",
                "model",
                "with",
                "a",
                "conditional",
                "chain",
                "mapping.\"",
                "!\"#",
                "#",
                "\"",
                "#\"#",
                "#",
                "$",
                "#",
                "\"",
                "$",
                "\"#",
                "!!",
                "\"",
                "!\"!",
                "#",
                "\"",
                "#\"!",
                "#",
                "\"",
                "!\"#",
                "#",
                "\"",
                "#\"#",
                "#",
                "$",
                "#",
                "\"",
                "$",
                "\"",
                "\"!",
                "#",
                "\"",
                "$",
                "!",
                "\"#",
                "!",
                "!\"+##',*",
                "!\"#$%#&amp,'#(-(.()*",
                "!",
                "\"",
                "#",
                "\"",
                "#",
                "$",
                "#",
                "\"(c)",
                "One-to-one",
                "model",
                "with",
                "a",
                "single",
                "sequence.",
                "data,",
                "including",
                "spoken",
                "dialogue",
                "systems",
                "#REF",
                ".",
                "This",
                "study",
                "aims",
                "to",
                "endow",
                "existing",
                "E2E",
                "ASR",
                "models",
                "with",
                "the",
                "ability",
                "to",
                "produce",
                "such",
                "linguistic",
                "annotations.",
                "Prior",
                "work",
                "explored",
                "using",
                "E2E",
                "ASR",
                "systems",
                "to",
                "predict",
                "multiple",
                "kinds",
                "of",
                "labels.",
                "Fig.",
                "1",
                "shows",
                "a",
                "diagram",
                "of",
                "these",
                "systems.",
                "These",
                "approaches",
                "use",
                "one",
                "of",
                "the",
                "following",
                "models:",
                "a",
                "one-to-many",
                "(O2M)",
                "model",
                "#REF",
                ",",
                "a",
                "one-to-one",
                "(O2O)",
                "model",
                "with",
                "a",
                "conditional",
                "chain",
                "mapping",
                "#REF",
                ",",
                "or",
                "an",
                "O2O",
                "model",
                "with",
                "a",
                "single",
                "sequence",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "(b) One-to-one model with a conditional chain mapping.\" !\"# # \" #\"# # $ # \" $ \"# !! \" !\"! # \" #\"! # \" !\"# # \" #\"# # $ # \" $ \" \"! # \" $ ! \"# ! !\"+##',* !\"#$%#&amp,'#(-(.()* ! \" # \" # $ # \"(c) One-to-one model with a single sequence. data, including spoken dialogue systems #REF . This study aims to endow existing E2E ASR models with the ability to produce such linguistic annotations. Prior work explored using E2E ASR systems to predict multiple kinds of labels. Fig. 1 shows a diagram of these systems. These approaches use one of the following models: a one-to-many (O2M) model #REF , a one-to-one (O2O) model with a conditional chain mapping #REF , or an O2O model with a single sequence #TARGET_REF .",
        "output": "{\"INFO\": [\"an O2O model with a single sequence #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Prior work explored using E2E ASR systems to predict multiple kinds of labels. Fig. 1 shows a diagram of these systems. These approaches use one of the following models: a one-to-many (O2M) model #REF , a one-to-one (O2O) model with a conditional chain mapping #REF , or\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "simple",
                "yet",
                "effective",
                "method",
                "for",
                "improving",
                "translation",
                "quality",
                "on",
                "the",
                "downstream",
                "task",
                "is",
                "fine-tuning",
                "with",
                "domain",
                "data,which",
                "is",
                "known",
                "as",
                "domain",
                "adaption",
                "#TARGET_REF",
                ".",
                "We",
                "train",
                "for",
                "another",
                "2",
                "epochs",
                "on",
                "the",
                "BSTC",
                "dataset",
                "with",
                "pretrained",
                "model.",
                "Furthermore,",
                "we",
                "obverse",
                "that",
                "finetuning",
                "on",
                "limited",
                "spoken",
                "corpus",
                "lead",
                "to",
                "overfit",
                "quickly,",
                "as",
                "evidenced",
                "by",
                "the",
                "significant",
                "improvement",
                "on",
                "the",
                "BSTC",
                "development",
                "set",
                "while",
                "degrades",
                "rapidly",
                "on",
                "the",
                "CWMT",
                "development",
                "set."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "A simple yet effective method for improving translation quality on the downstream task is fine-tuning with domain data,which is known as domain adaption #TARGET_REF . We train for another 2 epochs on the BSTC dataset with pretrained model. Furthermore, we obverse that finetuning on limited spoken corpus lead to overfit quickly, as evidenced by the significant improvement on the BSTC development set while degrades rapidly on the CWMT development set.",
        "output": "{\"INFO\": [\"domain adaption #TARGET_REF .\"], \"PERCEPT\": [\"A simple yet effective method for improving translation quality on the downstream task is fine-tuning with domain data,which is known as\", \"We train for another 2 epochs on the BSTC dataset with pretrained model.\", \"we obverse that finetuning on limited spoken corpus lead to overfit quickly, as evidenced by the significant improvement on the BSTC development set while degrades rapidly on the CWMT development set.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Data",
                "augmentation",
                "Data",
                "augmentation",
                "is",
                "the",
                "technique",
                "used",
                "to",
                "increase",
                "the",
                "amount",
                "of",
                "data",
                "by",
                "adding",
                "slightly",
                "modified",
                "copies",
                "of",
                "already",
                "existing",
                "data",
                "or",
                "newly",
                "created",
                "synthetic",
                "data",
                "from",
                "existing",
                "data.",
                "It",
                "acts",
                "as",
                "a",
                "regularizer",
                "and",
                "helps",
                "reduce",
                "overfitting",
                "when",
                "training",
                "a",
                "machine",
                "learning",
                "model.",
                "In",
                "this",
                "paper,",
                "data",
                "augmentation",
                "consists",
                "of",
                "two",
                "parts.",
                "We",
                "first",
                "add",
                "the",
                "dataset",
                "released",
                "by",
                "CWI",
                "2018",
                "into",
                "the",
                "training",
                "set.",
                "Besides,",
                "for",
                "subtask",
                "2,",
                "since",
                "its",
                "training",
                "dataset",
                "is",
                "small",
                "which",
                "only",
                "contains",
                "one",
                "thousand",
                "samples,",
                "we",
                "add",
                "the",
                "dataset",
                "of",
                "subtask",
                "1",
                "to",
                "train",
                "the",
                "model",
                "for",
                "subtask",
                "2.",
                "Then,",
                "for",
                "a",
                "given",
                "sentence",
                "in",
                "the",
                "training",
                "set,",
                "we",
                "perform",
                "the",
                "operations",
                "containing",
                "synonym",
                "replacement,",
                "random",
                "insertion,",
                "random",
                "swap,",
                "and",
                "random",
                "deletion",
                "introduced",
                "by",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Data augmentation Data augmentation is the technique used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model. In this paper, data augmentation consists of two parts. We first add the dataset released by CWI 2018 into the training set. Besides, for subtask 2, since its training dataset is small which only contains one thousand samples, we add the dataset of subtask 1 to train the model for subtask 2. Then, for a given sentence in the training set, we perform the operations containing synonym replacement, random insertion, random swap, and random deletion introduced by #TARGET_REF .",
        "output": "{\"INFO\": [\"synonym replacement, random insertion, random swap, and random deletion introduced by #TARGET_REF .\"], \"PERCEPT\": [\"for a given sentence in the training set, we perform the operations containing\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Ping",
                "and",
                "Chi",
                "(2022)",
                "(AN(L)P)",
                "participated",
                "in",
                "the",
                "Entity",
                "Extraction",
                "only.",
                "They",
                "finetuned",
                "a",
                "BERTlarge",
                "model",
                "#TARGET_REF",
                "for",
                "each",
                "domain.",
                "For",
                "cs.ai",
                "domain,",
                "they",
                "used",
                "data",
                "from",
                "cs.ai",
                "only,",
                "whereas,",
                "for",
                "the",
                "other",
                "domain,",
                "they",
                "augmented",
                "the",
                "in-domain",
                "data",
                "with",
                "the",
                "data",
                "from",
                "cs.ai."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Ping and Chi (2022) (AN(L)P) participated in the Entity Extraction only. They finetuned a BERTlarge model #TARGET_REF for each domain. For cs.ai domain, they used data from cs.ai only, whereas, for the other domain, they augmented the in-domain data with the data from cs.ai.",
        "output": "{\"INFO\": [\"BERTlarge model #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"They finetuned a\", \"for each domain. For cs.ai domain, they used data from cs.ai only, whereas, for the other domain, they augmented the in-domain data with the data from cs.ai.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "meet",
                "these",
                "constraints,",
                "compact",
                "models",
                "represent",
                "one",
                "of",
                "the",
                "most",
                "promising",
                "solutions.",
                "As",
                "far",
                "as",
                "we",
                "know,",
                "they",
                "have",
                "only",
                "been",
                "evaluated",
                "on",
                "the",
                "comprehension",
                "tasks",
                "covered",
                "by",
                "GLUE",
                "#REF",
                "and",
                "the",
                "question-answering",
                "task",
                "with",
                "the",
                "SQuAD",
                "corpus",
                "#REF",
                "with",
                "abundant",
                "data,",
                "in",
                "English.",
                "The",
                "improvements",
                "resulting",
                "from",
                "the",
                "algorithmic",
                "optimizations",
                "of",
                "the",
                "models,",
                "although",
                "significant,",
                "raise",
                "questions",
                "about",
                "their",
                "effectiveness",
                "on",
                "lower-scale",
                "learning",
                "problems",
                "on",
                "poorly",
                "endowed",
                "languages.",
                "The",
                "works",
                "of",
                "#TARGET_REF",
                "and",
                "#REF",
                "have",
                "furthermore",
                "shown",
                "degraded",
                "performance",
                "in",
                "these",
                "conditions.",
                "These",
                "two",
                "reflections",
                "are",
                "at",
                "the",
                "origin",
                "of",
                "a",
                "double",
                "question",
                "which",
                "our",
                "contribution",
                "attempts",
                "to",
                "answer.",
                "On",
                "the",
                "one",
                "hand,",
                "what",
                "is",
                "the",
                "behavior",
                "of",
                "a",
                "Transformer-based",
                "model",
                "in",
                "the",
                "context",
                "of",
                "a",
                "question-answering",
                "task",
                "in",
                "French,",
                "a",
                "task",
                "that",
                "is",
                "poorly",
                "endowed",
                "in",
                "this",
                "language?",
                "On",
                "the",
                "other",
                "hand,",
                "what",
                "are",
                "the",
                "impacts",
                "of",
                "algorithmic",
                "improvements",
                "of",
                "these",
                "same",
                "models",
                "in",
                "this",
                "context?"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To meet these constraints, compact models represent one of the most promising solutions. As far as we know, they have only been evaluated on the comprehension tasks covered by GLUE #REF and the question-answering task with the SQuAD corpus #REF with abundant data, in English. The improvements resulting from the algorithmic optimizations of the models, although significant, raise questions about their effectiveness on lower-scale learning problems on poorly endowed languages. The works of #TARGET_REF and #REF have furthermore shown degraded performance in these conditions. These two reflections are at the origin of a double question which our contribution attempts to answer. On the one hand, what is the behavior of a Transformer-based model in the context of a question-answering task in French, a task that is poorly endowed in this language? On the other hand, what are the impacts of algorithmic improvements of these same models in this context?",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"To meet these constraints, compact models represent one of the most promising solutions. As far as we know,\", \"The improvements resulting from the algorithmic optimizations of the models, although significant, raise questions about their effectiveness on lower-scale learning problems on poorly endowed languages.\", \"These two reflections are at the origin of a double question which our contribution attempts to answer.\"], \"BACK\": [\"they have only been evaluated on the comprehension tasks covered by GLUE #REF and the question-answering task with the SQuAD corpus #REF with abundant data, in English.\", \"The works of\", \"and #REF have furthermore shown degraded performance in these conditions.\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "two",
                "general",
                "approaches",
                "to",
                "tackle",
                "such",
                "artifacts:",
                "(1)",
                "adversarial",
                "filtering",
                "of",
                "biased",
                "examples,",
                "i.e.,",
                "examples",
                "that",
                "contain",
                "artifacts,",
                "and",
                "(2)",
                "debiasing",
                "methods.",
                "In",
                "the",
                "first",
                "approach,",
                "potentially",
                "biased",
                "examples",
                "are",
                "discarded",
                "from",
                "the",
                "dataset,",
                "either",
                "after",
                "the",
                "dataset",
                "creation",
                "#TARGET_REF",
                ",",
                "or",
                "while",
                "creating",
                "the",
                "dataset",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                2,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "There are two general approaches to tackle such artifacts: (1) adversarial filtering of biased examples, i.e., examples that contain artifacts, and (2) debiasing methods. In the first approach, potentially biased examples are discarded from the dataset, either after the dataset creation #TARGET_REF , or while creating the dataset #REF .",
        "output": "{\"INFO\": [\"the dataset creation\"], \"PERCEPT\": [\"In the first approach, potentially biased examples are discarded from the dataset,\", \"after\"], \"BACK\": [\"There are two general approaches to tackle such artifacts: (1) adversarial filtering of biased examples, i.e., examples that contain artifacts, and (2) debiasing methods.\", \"either\", \", or while creating the dataset #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "thing",
                "marking",
                "the",
                "difference",
                "between",
                "the",
                "two",
                "words.",
                "The",
                "alternative",
                "model",
                "is",
                "called",
                "Item",
                "&amp,",
                "Process",
                "(IP).",
                "In",
                "this",
                "model,",
                "word",
                "formation",
                "rules",
                "are",
                "processes",
                "applying",
                "to",
                "a",
                "base.",
                "In",
                "(1a),",
                "the",
                "process",
                "adds",
                "un",
                "to",
                "the",
                "left",
                "of",
                "the",
                "stem",
                "clear.",
                "In",
                "(2a),",
                "the",
                "process",
                "changes",
                "the",
                "stem",
                "vowel",
                "of",
                "sing.",
                "In",
                "IP",
                "there",
                "are",
                "no",
                "morphemes",
                "but",
                "only",
                "lexemes",
                "and",
                "processes.",
                "In",
                "modern",
                "morphological",
                "theories",
                "both",
                "are",
                "represented,",
                "e.g.",
                "#REF",
                "for",
                "IA",
                "and",
                "#REF",
                "for",
                "IP.",
                "An",
                "important",
                "difference",
                "for",
                "our",
                "purposes",
                "is",
                "that",
                "in",
                "IA",
                "we",
                "have",
                "a",
                "tree",
                "structure",
                "whereas",
                "in",
                "IP",
                "we",
                "have",
                "a",
                "derivation",
                "history.",
                "A",
                "tree",
                "structure",
                "represents",
                "the",
                "relationship",
                "between",
                "morphemes,",
                "e.g.",
                "(3).",
                "A",
                "derivation",
                "history",
                "lists",
                "the",
                "different",
                "stages",
                "rules",
                "applying,",
                "e.g.",
                "(",
                "4).",
                "It",
                "should",
                "be",
                "noted",
                "that",
                "there",
                "are",
                "many",
                "variants",
                "of",
                "IA",
                "and",
                "IP.",
                "The",
                "reason",
                "we",
                "are",
                "interested",
                "in",
                "word",
                "formation",
                "rules",
                "is",
                "their",
                "productivity.",
                "Productivity",
                "is",
                "a",
                "difficult",
                "and",
                "controversial",
                "concept,",
                "cf.",
                "#REF",
                ".",
                "Basically,",
                "a",
                "productive",
                "word",
                "formation",
                "rule",
                "can",
                "be",
                "used",
                "to",
                "produce",
                "new",
                "lexical",
                "items.",
                "When",
                "a",
                "speaker",
                "has",
                "a",
                "productive",
                "word",
                "formation",
                "rule",
                "at",
                "her",
                "disposal,",
                "she",
                "can",
                "use",
                "a",
                "word",
                "not",
                "in",
                "her",
                "mental",
                "lexicon",
                "and",
                "be",
                "understood",
                "as",
                "far",
                "as",
                "other",
                "speakers",
                "have",
                "the",
                "same",
                "word",
                "formation",
                "rule",
                "available.",
                "The",
                "productivity",
                "of",
                "word",
                "formation",
                "makes",
                "it",
                "impossible",
                "to",
                "cover",
                "the",
                "entire",
                "lexicon",
                "in",
                "a",
                "finite",
                "list."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "thing marking the difference between the two words. The alternative model is called Item &amp, Process (IP). In this model, word formation rules are processes applying to a base. In (1a), the process adds un to the left of the stem clear. In (2a), the process changes the stem vowel of sing. In IP there are no morphemes but only lexemes and processes. In modern morphological theories both are represented, e.g. #REF for IA and #REF for IP. An important difference for our purposes is that in IA we have a tree structure whereas in IP we have a derivation history. A tree structure represents the relationship between morphemes, e.g. (3). A derivation history lists the different stages rules applying, e.g. ( 4). It should be noted that there are many variants of IA and IP. The reason we are interested in word formation rules is their productivity. Productivity is a difficult and controversial concept, cf. #REF . Basically, a productive word formation rule can be used to produce new lexical items. When a speaker has a productive word formation rule at her disposal, she can use a word not in her mental lexicon and be understood as far as other speakers have the same word formation rule available. The productivity of word formation makes it impossible to cover the entire lexicon in a finite list.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Dagan",
                "and",
                "Church",
                "developed,",
                "Termight,",
                "a",
                "tool",
                "that",
                "was",
                "meant",
                "assist",
                "professional",
                "translators",
                "and",
                "terminologists",
                "develop",
                "bilingual",
                "term",
                "lists",
                "and",
                "technical",
                "terminology",
                "in",
                "particular",
                "#TARGET_REF",
                ".",
                "Like",
                "Kupiec's",
                "work,",
                "they",
                "also",
                "presume",
                "the",
                "availability",
                "of",
                "POS-tagging",
                "and",
                "work",
                "with",
                "noun",
                "phrases",
                "extracted",
                "from",
                "sentence-aligned",
                "corpora.",
                "A",
                "distinctive",
                "feature",
                "of",
                "their",
                "approach",
                "is",
                "using",
                "word-level",
                "alignments",
                "to",
                "score",
                "translations,",
                "this",
                "enables",
                "identification",
                "of",
                "correct",
                "translations",
                "even",
                "with",
                "the",
                "correct",
                "source",
                "term",
                "/",
                "target",
                "term",
                "correspondence",
                "is",
                "observed",
                "once",
                "or",
                "twice",
                "in",
                "the",
                "bilingual",
                "data.",
                "(This",
                "scenario,",
                "when",
                "term",
                "frequency",
                "is",
                "small,",
                "makes",
                "translation",
                "using",
                "contingency",
                "table",
                "methods",
                "such",
                "as",
                "Dice",
                "coefficients",
                "problematic.)",
                "They",
                "report",
                "finding",
                "a",
                "correct",
                "translation",
                "at",
                "rank",
                "1",
                "40%",
                "of",
                "the",
                "time",
                "and",
                "at",
                "rank",
                "2",
                "an",
                "additional",
                "7%",
                "of",
                "the",
                "time",
                "for",
                "a",
                "list",
                "of",
                "192",
                "English/German",
                "technical",
                "terms."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Dagan and Church developed, Termight, a tool that was meant assist professional translators and terminologists develop bilingual term lists and technical terminology in particular #TARGET_REF . Like Kupiec's work, they also presume the availability of POS-tagging and work with noun phrases extracted from sentence-aligned corpora. A distinctive feature of their approach is using word-level alignments to score translations, this enables identification of correct translations even with the correct source term / target term correspondence is observed once or twice in the bilingual data. (This scenario, when term frequency is small, makes translation using contingency table methods such as Dice coefficients problematic.) They report finding a correct translation at rank 1 40% of the time and at rank 2 an additional 7% of the time for a list of 192 English/German technical terms.",
        "output": "{\"INFO\": [\"Dagan and Church developed, Termight, a tool that was meant assist professional translators and terminologists develop bilingual term lists and technical terminology\"], \"PERCEPT\": [\"A distinctive feature of their approach is using word-level alignments to score translations, this enables identification of correct translations even with the correct source term / target term correspondence is observed once or twice in the bilingual data. (This scenario, when term frequency is small, makes translation using contingency table methods such as Dice coefficients problematic.) They report finding a correct translation at rank 1 40% of the time and at rank 2 an additional 7% of the time for a list of 192 English/German technical terms.\"], \"BACK\": [\"Like Kupiec's work, they also presume the availability of POS-tagging and work with noun phrases extracted from sentence-aligned corpora.\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "model",
                "achieved",
                "the",
                "highest",
                "score",
                "for",
                "subtask",
                "1b",
                "(i.e.,",
                "adverse",
                "effect",
                "span",
                "detection)",
                "with",
                "an",
                "F",
                "1",
                "-score",
                "of",
                "51%,",
                "arguing",
                "that",
                "MTL",
                "can",
                "enhance",
                "adverse",
                "effect",
                "extraction",
                "from",
                "social",
                "media",
                "posts.",
                "In",
                "terms",
                "of",
                "future",
                "work,",
                "adversarial",
                "training",
                "#TARGET_REF",
                "will",
                "be",
                "considered",
                "to",
                "improve",
                "the",
                "robustness",
                "of",
                "our",
                "approach."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Our model achieved the highest score for subtask 1b (i.e., adverse effect span detection) with an F 1 -score of 51%, arguing that MTL can enhance adverse effect extraction from social media posts. In terms of future work, adversarial training #TARGET_REF will be considered to improve the robustness of our approach.",
        "output": "{\"INFO\": [\"adversarial training #TARGET_REF\"], \"PERCEPT\": [\"arguing that MTL can enhance adverse effect extraction from social media posts.\", \"will be considered to improve the robustness of our approach.\"], \"BACK\": [\"Our model achieved the highest score for subtask 1b (i.e., adverse effect span detection) with an F 1 -score of 51%,\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "study",
                "is",
                "also",
                "related",
                "to",
                "attribution",
                "approaches,",
                "which",
                "aims",
                "to",
                "find",
                "features",
                "or",
                "regions",
                "of",
                "input",
                "that",
                "are",
                "important",
                "for",
                "tasks.",
                "Different",
                "types",
                "of",
                "techniques,",
                "including",
                "gradient-based",
                "#REF",
                ",",
                "are",
                "applied",
                "for",
                "reinforcement",
                "learning",
                "#REF",
                ",",
                "computer",
                "vision",
                "#REF",
                ",",
                "and",
                "text",
                "classification",
                "#TARGET_REF",
                ".",
                "While",
                "these",
                "works",
                "focus",
                "on",
                "interpreting",
                "model",
                "behaviors,",
                "we",
                "aim",
                "to",
                "find",
                "salient",
                "words",
                "beyond",
                "input",
                "and",
                "utilize",
                "them",
                "as",
                "action",
                "representations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Our study is also related to attribution approaches, which aims to find features or regions of input that are important for tasks. Different types of techniques, including gradient-based #REF , are applied for reinforcement learning #REF , computer vision #REF , and text classification #TARGET_REF . While these works focus on interpreting model behaviors, we aim to find salient words beyond input and utilize them as action representations.",
        "output": "{\"INFO\": [\"and text classification #TARGET_REF .\"], \"PERCEPT\": [\"Different types of techniques, including gradient-based #REF , are applied for\", \"While these works focus on interpreting model behaviors, we aim to find salient words beyond input and utilize them as action representations.\"], \"BACK\": [\"Our study is also related to attribution approaches, which aims to find features or regions of input that are important for tasks.\", \"reinforcement learning #REF , computer vision #REF ,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "key",
                "insight",
                "of",
                "this",
                "paper",
                "is",
                "that",
                "entities",
                "that",
                "share",
                "many",
                "attributes",
                "are",
                "often",
                "similar.",
                "This",
                "is",
                "an",
                "extension",
                "of",
                "the",
                "distributional",
                "hypothesis,",
                "#TARGET_REF",
                ",",
                "which",
                "states",
                "that",
                "words",
                "with",
                "similar",
                "semantic",
                "meanings",
                "tend",
                "to",
                "appear",
                "in",
                "similar",
                "contexts,",
                "and",
                "builds",
                "on",
                "work",
                "that",
                "use",
                "referential",
                "attributes",
                "to",
                "estimate",
                "semantic",
                "relatedness",
                "#REF",
                ".",
                "For",
                "the",
                "attribute-aware",
                "embeddings,",
                "we",
                "argue",
                "that",
                "a",
                "good",
                "representation",
                "for",
                "an",
                "entity",
                "can",
                "be",
                "inferred",
                "from",
                "its",
                "most",
                "common",
                "attributes,",
                "which",
                "we",
                "may",
                "have",
                "access",
                "to",
                "from",
                "an",
                "external",
                "source",
                "of",
                "knowledge.",
                "In",
                "Figure",
                "1,",
                "we",
                "want",
                "to",
                "classify",
                "two",
                "candidate",
                "relations",
                "given",
                "the",
                "other",
                "known",
                "relations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The key insight of this paper is that entities that share many attributes are often similar. This is an extension of the distributional hypothesis, #TARGET_REF , which states that words with similar semantic meanings tend to appear in similar contexts, and builds on work that use referential attributes to estimate semantic relatedness #REF . For the attribute-aware embeddings, we argue that a good representation for an entity can be inferred from its most common attributes, which we may have access to from an external source of knowledge. In Figure 1, we want to classify two candidate relations given the other known relations.",
        "output": "{\"INFO\": [\"the distributional hypothesis, #TARGET_REF , which states that words with similar semantic meanings tend to appear in similar contexts,\"], \"PERCEPT\": [], \"BACK\": [\"and builds on work that use referential attributes to estimate semantic relatedness #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "uses",
                "a",
                "joint",
                "transformer",
                "architecture",
                "that",
                "encodes",
                "sequences",
                "of",
                "phonemes",
                "and",
                "sequences",
                "of",
                "text",
                "simultaneously.",
                "However,",
                "this",
                "joint",
                "model",
                "is",
                "utilized",
                "to",
                "learn",
                "representations",
                "that",
                "are",
                "more",
                "robust",
                "to",
                "transcription",
                "errors.",
                "The",
                "architecture",
                "still",
                "requires",
                "text",
                "inputs",
                "(from",
                "ASR",
                "transcriptions)",
                "and",
                "generates",
                "outputs",
                "in",
                "both",
                "text",
                "and",
                "phoneme",
                "representations.",
                "In",
                "contrast,",
                "our",
                "approach",
                "allows",
                "for",
                "text",
                "input,",
                "audio",
                "input,",
                "or",
                "text",
                "plus",
                "audio",
                "input",
                "to",
                "language",
                "models.",
                "Similarly,",
                "in",
                "#REF",
                "and",
                "#TARGET_REF",
                "investigate",
                "the",
                "potential",
                "of",
                "phoneme-based",
                "or",
                "phoneme",
                "aware",
                "representations",
                "and",
                "models,",
                "showing",
                "gains",
                "in",
                "performance,",
                "language",
                "transfer,",
                "and",
                "flexibility",
                "across",
                "written",
                "scripts.",
                "These",
                "works",
                "conduct",
                "training",
                "on",
                "text-based",
                "data",
                "only,",
                "using",
                "Epitran",
                "to",
                "convert",
                "to",
                "phonemes.",
                "#REF",
                "transforms",
                "unlabeled",
                "text",
                "(i.e.,",
                "not",
                "aligned",
                "with",
                "corresponding",
                "audio",
                "files)",
                "into",
                "phonemes",
                "in",
                "a",
                "scheme",
                "to",
                "train",
                "speech",
                "recognition",
                "models",
                "without",
                "any",
                "labeled",
                "data.",
                "This",
                "scheme",
                "involves",
                "a",
                "generator",
                "model",
                "trained",
                "jointly",
                "with",
                "a",
                "discriminator",
                "model.",
                "The",
                "generator",
                "model",
                "converts",
                "audio,",
                "segmented",
                "into",
                "phonetic",
                "units",
                "into",
                "predicted",
                "phonemes,",
                "and",
                "the",
                "discriminator",
                "model",
                "attempts",
                "to",
                "discriminate",
                "between",
                "these",
                "predicted",
                "phonemes",
                "and",
                "the",
                "phonemes",
                "transliterated",
                "from",
                "unlabeled",
                "text.",
                "Although",
                "both",
                "text",
                "and",
                "audio",
                "are",
                "utilized",
                "in",
                "this",
                "work,",
                "they",
                "are",
                "not",
                "input",
                "to",
                "the",
                "same",
                "model",
                "and",
                "the",
                "primary",
                "output",
                "of",
                "the",
                "training",
                "scheme",
                "is",
                "a",
                "model",
                "that",
                "creates",
                "good",
                "phonetic",
                "speech",
                "representations",
                "from",
                "input",
                "audio."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "uses a joint transformer architecture that encodes sequences of phonemes and sequences of text simultaneously. However, this joint model is utilized to learn representations that are more robust to transcription errors. The architecture still requires text inputs (from ASR transcriptions) and generates outputs in both text and phoneme representations. In contrast, our approach allows for text input, audio input, or text plus audio input to language models. Similarly, in #REF and #TARGET_REF investigate the potential of phoneme-based or phoneme aware representations and models, showing gains in performance, language transfer, and flexibility across written scripts. These works conduct training on text-based data only, using Epitran to convert to phonemes. #REF transforms unlabeled text (i.e., not aligned with corresponding audio files) into phonemes in a scheme to train speech recognition models without any labeled data. This scheme involves a generator model trained jointly with a discriminator model. The generator model converts audio, segmented into phonetic units into predicted phonemes, and the discriminator model attempts to discriminate between these predicted phonemes and the phonemes transliterated from unlabeled text. Although both text and audio are utilized in this work, they are not input to the same model and the primary output of the training scheme is a model that creates good phonetic speech representations from input audio.",
        "output": "{\"INFO\": [\"#TARGET_REF investigate the potential of phoneme-based or phoneme aware representations and models, showing gains in performance, language transfer, and flexibility across written scripts.\"], \"PERCEPT\": [], \"BACK\": [\"#REF and\", \"These works conduct training on text-based data only, using Epitran to convert to phonemes.\"]}"
    },
    {
        "gold": {
            "text": [
                "Various",
                "studies",
                "attempted",
                "to",
                "generate",
                "multiple",
                "different",
                "definitions",
                "for",
                "polysemous",
                "words.",
                "#REF",
                "tackled",
                "this",
                "problem",
                "by",
                "computing",
                "the",
                "AdaGram",
                "vectors",
                "#REF",
                "of",
                "input",
                "words,",
                "which",
                "are",
                "capable",
                "of",
                "learning",
                "different",
                "representations",
                "at",
                "desired",
                "semantic",
                "resolutions.",
                "However,",
                "generating",
                "different",
                "definitions",
                "based",
                "on",
                "contexts,",
                "i.e.,",
                "example",
                "sentences,",
                "became",
                "the",
                "mainstream",
                "method",
                "#REF",
                ").",
                "Among",
                "them,",
                "some",
                "studies",
                "used",
                "pre-trained",
                "language",
                "models",
                "to",
                "obtain",
                "contextualized",
                "embeddings.",
                "#REF",
                "initialized",
                "encoders",
                "with",
                "BERT",
                "#TARGET_REF",
                "and",
                "employed",
                "variational",
                "inference",
                "for",
                "estimation",
                "and",
                "leveraged",
                "contextualized",
                "word",
                "embeddings",
                "for",
                "improved",
                "performance.",
                "#REF",
                "employed",
                "a",
                "novel",
                "spanbased",
                "encoding",
                "scheme",
                "to",
                "fine-tune",
                "a",
                "pre-trained",
                "English",
                "encoder-decoder",
                "system",
                "to",
                "generate",
                "definitions.",
                "#REF",
                "leveraged",
                "the",
                "T5",
                "#REF",
                "model",
                "for",
                "this",
                "task",
                "and",
                "introduced",
                "a",
                "re-ranking",
                "mechanism",
                "to",
                "model",
                "specificity",
                "in",
                "definitions."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Various studies attempted to generate multiple different definitions for polysemous words. #REF tackled this problem by computing the AdaGram vectors #REF of input words, which are capable of learning different representations at desired semantic resolutions. However, generating different definitions based on contexts, i.e., example sentences, became the mainstream method #REF ). Among them, some studies used pre-trained language models to obtain contextualized embeddings. #REF initialized encoders with BERT #TARGET_REF and employed variational inference for estimation and leveraged contextualized word embeddings for improved performance. #REF employed a novel spanbased encoding scheme to fine-tune a pre-trained English encoder-decoder system to generate definitions. #REF leveraged the T5 #REF model for this task and introduced a re-ranking mechanism to model specificity in definitions.",
        "output": "{\"INFO\": [\"encoders with BERT #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"generating different definitions based on contexts, i.e., example sentences, became the mainstream method #REF ). Among them, some studies used pre-trained language models to obtain contextualized embeddings. #REF initialized\", \"employed variational inference for estimation and leveraged contextualized word embeddings for improved performance.\"]}"
    },
    {
        "gold": {
            "text": [
                "They",
                "found",
                "that",
                "the",
                "behavior",
                "of",
                "human",
                "players",
                "is",
                "best",
                "modeled",
                "on",
                "the",
                "probabilities",
                "of",
                "bigrams,",
                "which",
                "is",
                "in",
                "line",
                "with",
                "the",
                "results",
                "of",
                "(Spence",
                "and",
                "Owens,",
                "1990)",
                "(although",
                "the",
                "latter",
                "calculated",
                "cooccurrences",
                "with",
                "much",
                "larger",
                "window",
                "size).",
                "#TARGET_REF",
                "were",
                "the",
                "first",
                "to",
                "build",
                "agents",
                "designed",
                "explicitly",
                "to",
                "play",
                "the",
                "game.",
                "As",
                "a",
                "background",
                "to",
                "their",
                "relatedness",
                "measure,",
                "they",
                "used",
                "•",
                "CBOW,",
                "Skip-gram",
                "and",
                "GloVe",
                "word",
                "embeddings",
                "(in",
                "multiple",
                "configurations),"
            ],
            "context": [
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "They found that the behavior of human players is best modeled on the probabilities of bigrams, which is in line with the results of (Spence and Owens, 1990) (although the latter calculated cooccurrences with much larger window size). #TARGET_REF were the first to build agents designed explicitly to play the game. As a background to their relatedness measure, they used • CBOW, Skip-gram and GloVe word embeddings (in multiple configurations),",
        "output": "{\"INFO\": [\"#TARGET_REF were the first to build agents designed explicitly to play the game.\", \"they used \\u2022 CBOW, Skip-gram and GloVe word embeddings (in multiple configurations),\"], \"PERCEPT\": [\"As a background to their relatedness measure,\"], \"BACK\": [\"behavior of human players is best modeled on the probabilities of bigrams,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "SCE",
                "loss,",
                "which",
                "is",
                "often",
                "used",
                "to",
                "train",
                "a",
                "sequence-to-sequence",
                "(Seq2Seq)",
                "model",
                "#REF",
                ",",
                "is",
                "expressed",
                "as",
                "𝐿",
                "𝑆𝐶𝐸",
                "=",
                "−𝑙𝑜𝑔{𝑠𝑜𝑓𝑡𝑚𝑎𝑥",
                "𝑐",
                "}",
                ",",
                "where𝑠𝑜𝑓𝑡𝑚𝑎𝑥",
                "𝑐",
                "=",
                "𝑒",
                "𝑑",
                "𝑐",
                "∑",
                "𝑒",
                "𝑑",
                "𝑘",
                "|𝑉|",
                "𝑘.",
                "Therein,",
                "𝑉",
                "represents",
                "the",
                "lexicon,",
                "𝑑",
                "𝑘",
                "denotes",
                "the",
                "𝑘-th",
                "element",
                "of",
                "the",
                "output",
                "𝑑",
                "∈",
                "ℝ",
                "|𝑉|",
                ".",
                "#TARGET_REF",
                "defined",
                "Inverse",
                "Token",
                "Frequency",
                "(ITF)",
                "loss",
                "as",
                "shown",
                "below."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3
            ]
        },
        "input": "The SCE loss, which is often used to train a sequence-to-sequence (Seq2Seq) model #REF , is expressed as 𝐿 𝑆𝐶𝐸 = −𝑙𝑜𝑔{𝑠𝑜𝑓𝑡𝑚𝑎𝑥 𝑐 } , where𝑠𝑜𝑓𝑡𝑚𝑎𝑥 𝑐 = 𝑒 𝑑 𝑐 ∑ 𝑒 𝑑 𝑘 |𝑉| 𝑘. Therein, 𝑉 represents the lexicon, 𝑑 𝑘 denotes the 𝑘-th element of the output 𝑑 ∈ ℝ |𝑉| . #TARGET_REF defined Inverse Token Frequency (ITF) loss as shown below.",
        "output": "{\"INFO\": [\"#TARGET_REF defined Inverse Token Frequency (ITF) loss\"], \"PERCEPT\": [], \"BACK\": [\"as shown below.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "model",
                "training,",
                "we",
                "used",
                "Adam",
                "with",
                "batch",
                "size",
                "of",
                "60,",
                "learning",
                "rate",
                "of",
                "3e-5,",
                "L2",
                "weight",
                "decay",
                "of",
                "0.01,",
                "learning",
                "rate",
                "warm",
                "up",
                "over",
                "the",
                "first",
                "10,000",
                "steps,",
                "and",
                "linear",
                "decay",
                "of",
                "learning",
                "rate.",
                "Our",
                "models",
                "were",
                "trained",
                "by",
                "one",
                "Tesla",
                "V100",
                "GPU",
                "card",
                "with",
                "32GB",
                "memory,",
                "and",
                "implemented",
                "on",
                "PyTorch",
                "with",
                "the",
                "Huggingface's",
                "Transformer",
                "#TARGET_REF",
                ".",
                "All",
                "Transformer-based",
                "methods",
                "were",
                "trained",
                "with",
                "30",
                "epochs,",
                "taken",
                "about",
                "4-5",
                "hours",
                "on",
                "the",
                "ComVE",
                "dataset",
                "and",
                "7-9",
                "hours",
                "on",
                "the",
                "α-NLG",
                "dataset."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "For model training, we used Adam with batch size of 60, learning rate of 3e-5, L2 weight decay of 0.01, learning rate warm up over the first 10,000 steps, and linear decay of learning rate. Our models were trained by one Tesla V100 GPU card with 32GB memory, and implemented on PyTorch with the Huggingface's Transformer #TARGET_REF . All Transformer-based methods were trained with 30 epochs, taken about 4-5 hours on the ComVE dataset and 7-9 hours on the α-NLG dataset.",
        "output": "{\"INFO\": [\"Huggingface's Transformer #TARGET_REF .\"], \"PERCEPT\": [\"Our models were trained by one Tesla V100 GPU card with 32GB memory, and implemented on PyTorch with the\"], \"BACK\": [\"All Transformer-based methods were trained with 30 epochs, taken about 4-5 hours on the ComVE dataset and 7-9 hours on the \\u03b1-NLG dataset.\"]}"
    },
    {
        "gold": {
            "text": [
                "to",
                "form",
                "reasoning",
                "chains",
                "that",
                "support",
                "the",
                "correct",
                "answer",
                "(see",
                "Figure",
                "1).",
                "As",
                "such,",
                "multi-hop",
                "inference",
                "represents",
                "a",
                "crucial",
                "step",
                "towards",
                "explainability",
                "in",
                "complex",
                "question",
                "answering,",
                "as",
                "the",
                "set",
                "of",
                "supporting",
                "facts",
                "can",
                "be",
                "interpreted",
                "as",
                "an",
                "explanation",
                "for",
                "the",
                "underlying",
                "inference",
                "process",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "to form reasoning chains that support the correct answer (see Figure 1). As such, multi-hop inference represents a crucial step towards explainability in complex question answering, as the set of supporting facts can be interpreted as an explanation for the underlying inference process #TARGET_REF .",
        "output": "{\"INFO\": [\"the underlying inference process #TARGET_REF .\"], \"PERCEPT\": [\"multi-hop inference represents a crucial step towards explainability in complex question answering, as the set of supporting facts can be interpreted as an explanation for\"], \"BACK\": [\"to form reasoning chains that support the correct answer (see Figure 1).\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "baseline",
                "is",
                "the",
                "mBERT",
                "model",
                "#TARGET_REF",
                ",",
                "which",
                "is",
                "pre-trained",
                "using",
                "pretext",
                "tasks",
                "like",
                "Masked",
                "Language",
                "Modelling",
                "and",
                "Next",
                "Sentence",
                "Prediction",
                "on",
                "a",
                "multilingual",
                "text",
                "corpus",
                "that",
                "includes",
                "our",
                "target",
                "languages,",
                "Hindi",
                "and",
                "Tamil.",
                "The",
                "default",
                "output",
                "head",
                "of",
                "mBERT",
                "is",
                "replaced",
                "with",
                "the",
                "head",
                "for",
                "the",
                "question-answering",
                "task.",
                "This",
                "is",
                "done",
                "by",
                "adding",
                "separate",
                "output",
                "heads",
                "for",
                "classifying",
                "the",
                "start",
                "and",
                "end",
                "positions",
                "as",
                "shown",
                "in",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Our baseline is the mBERT model #TARGET_REF , which is pre-trained using pretext tasks like Masked Language Modelling and Next Sentence Prediction on a multilingual text corpus that includes our target languages, Hindi and Tamil. The default output head of mBERT is replaced with the head for the question-answering task. This is done by adding separate output heads for classifying the start and end positions as shown in #REF .",
        "output": "{\"INFO\": [\"the mBERT model #TARGET_REF ,\", \"mBERT\"], \"PERCEPT\": [\"Our baseline is\", \"which is pre-trained using pretext tasks like Masked Language Modelling and Next Sentence Prediction on a multilingual text corpus that includes our target languages, Hindi and Tamil. The default output head of\", \"is replaced with the head for the question-answering task. This is done by adding separate output heads for classifying the start and end positions as shown in #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Although",
                "the",
                "canonical",
                "way",
                "to",
                "represent",
                "words",
                "is",
                "to",
                "assign",
                "them",
                "to",
                "vectors,",
                "if",
                "the",
                "goal",
                "is",
                "to",
                "model",
                "connections",
                "between",
                "words,",
                "a",
                "graph",
                "structure",
                "is",
                "at",
                "least",
                "as",
                "suitable.",
                "When",
                "each",
                "word",
                "is",
                "represented",
                "by",
                "a",
                "vector,",
                "the",
                "similarity",
                "between",
                "them",
                "is",
                "most",
                "often",
                "calculated",
                "as",
                "the",
                "cosine",
                "of",
                "the",
                "angle",
                "of",
                "the",
                "two",
                "vectors.",
                "In",
                "the",
                "case",
                "of",
                "graph",
                "representations,",
                "all",
                "words",
                "in",
                "the",
                "dictionary",
                "correspond",
                "to",
                "the",
                "vertices",
                "of",
                "a",
                "large",
                "graph,",
                "and",
                "the",
                "distance",
                "between",
                "them",
                "can",
                "be",
                "defined",
                "in",
                "many",
                "ways",
                "depending",
                "on",
                "the",
                "graph.",
                "One",
                "option",
                "is",
                "the",
                "length",
                "or",
                "weight",
                "of",
                "the",
                "shortest",
                "path",
                "between",
                "the",
                "two",
                "vertices.",
                "Knowledge",
                "graphs",
                "#TARGET_REF",
                "were",
                "already",
                "used",
                "to",
                "model",
                "word",
                "connections",
                "in",
                "previous",
                "Codenames",
                "agents,",
                "but",
                "other",
                "types",
                "of",
                "language",
                "graphs",
                "also",
                "exist,",
                "which",
                "could",
                "be",
                "utilized",
                "for",
                "this",
                "task",
                "as",
                "well."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Although the canonical way to represent words is to assign them to vectors, if the goal is to model connections between words, a graph structure is at least as suitable. When each word is represented by a vector, the similarity between them is most often calculated as the cosine of the angle of the two vectors. In the case of graph representations, all words in the dictionary correspond to the vertices of a large graph, and the distance between them can be defined in many ways depending on the graph. One option is the length or weight of the shortest path between the two vertices. Knowledge graphs #TARGET_REF were already used to model word connections in previous Codenames agents, but other types of language graphs also exist, which could be utilized for this task as well.",
        "output": "{\"INFO\": [\"Knowledge graphs #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"were already used to model word connections in previous Codenames agents, but other types of language graphs also exist, which could be utilized for this task as well.\"]}"
    },
    {
        "gold": {
            "text": [
                "based",
                "on",
                "tweets.",
                "Similarly,",
                "many",
                "of",
                "the",
                "non-multilabel",
                "classification",
                "papers",
                "use",
                "Twitter",
                "data.",
                "Twitter",
                "is",
                "a",
                "good",
                "base",
                "for",
                "emotion",
                "classification",
                "as",
                "tweets",
                "are",
                "limited",
                "in",
                "length",
                "and",
                "generally",
                "stand-alone,",
                "i.e.",
                "the",
                "reader",
                "or",
                "annotator",
                "does",
                "not",
                "need",
                "to",
                "guess",
                "the",
                "context",
                "in",
                "the",
                "majority",
                "of",
                "cases.",
                "Furthermore,",
                "hashtags",
                "and",
                "emojis",
                "are",
                "common,",
                "which",
                "further",
                "makes",
                "the",
                "emotion",
                "recognition",
                "easier",
                "for",
                "both",
                "human",
                "annotators",
                "and",
                "emotion",
                "detection",
                "and",
                "sentiment",
                "analysis",
                "models.",
                "Reddit",
                "data,",
                "as",
                "used",
                "by",
                "#REF",
                ",",
                "and",
                "movie",
                "subtitles",
                "used",
                "by",
                "this",
                "paper,",
                "are",
                "slightly",
                "more",
                "problematic",
                "as",
                "they",
                "are",
                "not",
                "\"selfcontained\".",
                "Reddit",
                "comments",
                "are",
                "typically",
                "longer",
                "than",
                "one",
                "line",
                "and",
                "therefore",
                "provide",
                "some",
                "context",
                "for",
                "annotators",
                "to",
                "go",
                "by,",
                "but",
                "often",
                "lacks",
                "the",
                "hashtags",
                "and",
                "emojis",
                "of",
                "twitter",
                "and",
                "can",
                "be",
                "quite",
                "context-dependent",
                "as",
                "Reddit",
                "comments",
                "are",
                "by",
                "definition",
                "reactions",
                "to",
                "a",
                "post",
                "or",
                "another",
                "comment.",
                "Movie",
                "subtitles",
                "annotated",
                "out",
                "of",
                "sequence",
                "have",
                "virtually",
                "no",
                "context",
                "to",
                "aid",
                "the",
                "annotator",
                "and",
                "are",
                "supposed",
                "to",
                "be",
                "accompanied",
                "by",
                "visual",
                "cues",
                "as",
                "well.",
                "However,",
                "annotating",
                "with",
                "context",
                "can",
                "reduce",
                "the",
                "accuracy",
                "of",
                "one's",
                "model",
                "by",
                "doubly",
                "weighting",
                "surrounding",
                "units",
                "of",
                "granularity",
                "(roughly",
                "'sentences'",
                "in",
                "our",
                "case)",
                "#TARGET_REF",
                ".",
                "On",
                "the",
                "other",
                "hand,",
                "contextual",
                "annotations",
                "are",
                "less",
                "frustrating",
                "for",
                "the",
                "annotator",
                "and",
                "therefore,",
                "would",
                "likely",
                "provide",
                "more",
                "annotations",
                "in",
                "the",
                "same",
                "amount",
                "of",
                "time",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "based on tweets. Similarly, many of the non-multilabel classification papers use Twitter data. Twitter is a good base for emotion classification as tweets are limited in length and generally stand-alone, i.e. the reader or annotator does not need to guess the context in the majority of cases. Furthermore, hashtags and emojis are common, which further makes the emotion recognition easier for both human annotators and emotion detection and sentiment analysis models. Reddit data, as used by #REF , and movie subtitles used by this paper, are slightly more problematic as they are not \"selfcontained\". Reddit comments are typically longer than one line and therefore provide some context for annotators to go by, but often lacks the hashtags and emojis of twitter and can be quite context-dependent as Reddit comments are by definition reactions to a post or another comment. Movie subtitles annotated out of sequence have virtually no context to aid the annotator and are supposed to be accompanied by visual cues as well. However, annotating with context can reduce the accuracy of one's model by doubly weighting surrounding units of granularity (roughly 'sentences' in our case) #TARGET_REF . On the other hand, contextual annotations are less frustrating for the annotator and therefore, would likely provide more annotations in the same amount of time #REF .",
        "output": "{\"INFO\": [\"annotating with context can reduce the accuracy of one's model by doubly weighting surrounding units of granularity\", \"#TARGET_REF .\"], \"PERCEPT\": [\"(roughly 'sentences' in our case)\"], \"BACK\": [\"On the other hand, contextual annotations are less frustrating for the annotator and therefore, would likely provide more annotations in the same amount of time #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Following",
                "the",
                "widely",
                "adopted",
                "fact",
                "verification",
                "pipeline",
                "#TARGET_REF",
                ",",
                "we",
                "take",
                "three",
                "steps",
                "to",
                "solve",
                "the",
                "FEVEROUS",
                "task",
                "(i)",
                "retrieving",
                "pages",
                "from",
                "the",
                "Wikipedia",
                "dump,",
                "(ii)",
                "extracting",
                "evidence",
                "from",
                "the",
                "retrieved",
                "pages,",
                "and",
                "(iii)",
                "verifying",
                "the",
                "claim",
                "according",
                "to",
                "extracted",
                "evidence."
            ],
            "context": [
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Following the widely adopted fact verification pipeline #TARGET_REF , we take three steps to solve the FEVEROUS task (i) retrieving pages from the Wikipedia dump, (ii) extracting evidence from the retrieved pages, and (iii) verifying the claim according to extracted evidence.",
        "output": "{\"INFO\": [\"fact verification pipeline #TARGET_REF ,\"], \"PERCEPT\": [\"Following the widely adopted\", \"we take three steps to solve the FEVEROUS task\"], \"BACK\": [\"(i) retrieving pages from the Wikipedia dump, (ii) extracting evidence from the retrieved pages, and (iii) verifying the claim according to extracted evidence.\"]}"
    },
    {
        "gold": {
            "text": [
                "These",
                "co-occurrence",
                "probabilities",
                "are",
                "psycholinguistically",
                "relevant",
                "because",
                "they",
                "feed",
                "into",
                "information-theoretic",
                "measures",
                "of",
                "'thematic",
                "fit'",
                "and",
                "selectional",
                "restriction",
                "#REF",
                "which",
                "are",
                "relevant",
                "in",
                "predicting",
                "human",
                "online",
                "processing",
                "difficulty",
                "(e.g.",
                "#TARGET_REF",
                ",",
                "and",
                "play",
                "a",
                "key",
                "role",
                "in",
                "language",
                "acquisition",
                "#REF",
                ".",
                "Most",
                "prominently,",
                "the",
                "widely-used",
                "pointwise",
                "mutual",
                "information",
                "(PMI)",
                "measure",
                "of",
                "association",
                "strength,",
                "PMI",
                "(w,",
                "c)",
                "=",
                "log",
                "p(w|c)",
                "p(w)",
                "#REF",
                ",",
                "relies",
                "on",
                "these",
                "condi-tional",
                "probabilities",
                "as",
                "an",
                "input.",
                "PMI",
                "makes",
                "appearances",
                "in",
                "models",
                "of",
                "grammar",
                "induction",
                "from",
                "text",
                "(Magerman",
                "and",
                "#REF",
                ",",
                "online",
                "sentence",
                "comprehension",
                "and",
                "production",
                "#REF",
                ",",
                "and",
                "quantitative",
                "theories",
                "of",
                "word",
                "order",
                "variation",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "These co-occurrence probabilities are psycholinguistically relevant because they feed into information-theoretic measures of 'thematic fit' and selectional restriction #REF which are relevant in predicting human online processing difficulty (e.g. #TARGET_REF , and play a key role in language acquisition #REF . Most prominently, the widely-used pointwise mutual information (PMI) measure of association strength, PMI (w, c) = log p(w|c) p(w) #REF , relies on these condi-tional probabilities as an input. PMI makes appearances in models of grammar induction from text (Magerman and #REF , online sentence comprehension and production #REF , and quantitative theories of word order variation #REF .",
        "output": "{\"INFO\": [\"#TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"These co-occurrence probabilities are psycholinguistically relevant because they feed into information-theoretic measures of 'thematic fit' and selectional restriction #REF which are relevant in predicting human online processing difficulty (e.g.\", \"and play a key role in language acquisition #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "What,",
                "then,",
                "is",
                "known",
                "about",
                "BERT,",
                "and",
                "its",
                "syntactic",
                "and",
                "semantic",
                "capabilities?",
                "Of",
                "the",
                "two,",
                "it",
                "is",
                "syntax",
                "that",
                "BERT",
                "is",
                "most",
                "widely",
                "claimed",
                "to",
                "capture",
                "within",
                "its",
                "internal",
                "representations:",
                "#REF",
                "use",
                "structural",
                "probing",
                "to",
                "find",
                "dependency",
                "trees",
                "in",
                "BERT's",
                "vector",
                "geometry,",
                "while",
                "#REF",
                "use",
                "probing",
                "to",
                "find",
                "part",
                "of",
                "speech",
                "tags",
                "and",
                "dependency",
                "arc",
                "labels,",
                "among",
                "other",
                "types",
                "of",
                "syntactic",
                "information.",
                "Analysis",
                "of",
                "BERT's",
                "attention",
                "has",
                "shown",
                "that",
                "certain",
                "heads",
                "attend",
                "to",
                "not",
                "only",
                "relevant",
                "linguistic",
                "units",
                "such",
                "as",
                "determiners",
                "of",
                "nouns",
                "and",
                "coreferent",
                "mentions",
                "#REF",
                ",",
                "but",
                "also",
                "dependency",
                "relations",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                0
            ]
        },
        "input": "What, then, is known about BERT, and its syntactic and semantic capabilities? Of the two, it is syntax that BERT is most widely claimed to capture within its internal representations: #REF use structural probing to find dependency trees in BERT's vector geometry, while #REF use probing to find part of speech tags and dependency arc labels, among other types of syntactic information. Analysis of BERT's attention has shown that certain heads attend to not only relevant linguistic units such as determiners of nouns and coreferent mentions #REF , but also dependency relations #TARGET_REF .",
        "output": "{\"INFO\": [\"Analysis of BERT's attention has shown that certain heads attend to\", \"dependency relations #TARGET_REF\"], \"PERCEPT\": [\"not only relevant linguistic units\", \"but also\"], \"BACK\": [\"BERT is most widely claimed to capture within its internal representations:\", \"such as determiners of nouns and coreferent mentions #REF ,\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "have",
                "chosen",
                "the",
                "CYK-like",
                "algorithm",
                "for",
                "LIG",
                "described",
                "in",
                "#TARGET_REF",
                "as",
                "our",
                "starting",
                "point.",
                "Due",
                "to",
                "the",
                "intrinsic",
                "limitations",
                "of",
                "this",
                "pure",
                "bottom-up",
                "algorithm,",
                "the",
                "grammars",
                "it",
                "can",
                "deal",
                "with",
                "are",
                "restricted",
                "to",
                "those",
                "having",
                "two",
                "elements,",
                "or",
                "one",
                "element",
                "which",
                "must",
                "be",
                "a",
                "terminal,",
                "in",
                "the",
                "right-hand",
                "side",
                "of",
                "each",
                "production.",
                "This",
                "restriction",
                "could",
                "be",
                "considered",
                "as",
                "the",
                "transposition",
                "of",
                "the",
                "Chomsky",
                "normal",
                "form",
                "to",
                "linear",
                "indexed",
                "grammars."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We have chosen the CYK-like algorithm for LIG described in #TARGET_REF as our starting point. Due to the intrinsic limitations of this pure bottom-up algorithm, the grammars it can deal with are restricted to those having two elements, or one element which must be a terminal, in the right-hand side of each production. This restriction could be considered as the transposition of the Chomsky normal form to linear indexed grammars.",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"We have chosen the CYK-like algorithm for LIG described in\", \"as our starting point.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "addition",
                "to",
                "Levin",
                "classes",
                "like",
                "cut",
                "whose",
                "members",
                "have",
                "core",
                "senses",
                "that",
                "are",
                "closely",
                "and",
                "systematically",
                "related",
                "in",
                "the",
                "WordNet",
                "hierarchy,",
                "other",
                "Levin",
                "classes",
                "are",
                "composed",
                "of",
                "verbs",
                "that",
                "exhibit",
                "a",
                "wider",
                "range",
                "of",
                "possible",
                "semantic",
                "components.",
                "The",
                "split",
                "verbs",
                "(blow,",
                "break,",
                "cut,",
                "draw,",
                "hack,",
                "hew,",
                "kick,",
                "knock,",
                "pry,",
                "pull,",
                "push,",
                "rip,",
                "roll,",
                "saw,",
                "shove,",
                "slip,",
                "split,",
                "tear,",
                "tug,",
                "yank)",
                "do",
                "not",
                "obviously",
                "form",
                "a",
                "tight",
                "semantic",
                "class.",
                "Instead,",
                "in",
                "their",
                "use",
                "as",
                "split",
                "verbs,",
                "each",
                "verb",
                "manifests",
                "an",
                "extended",
                "sense",
                "that",
                "can",
                "be",
                "paraphrased",
                "as",
                "\"separate",
                "by",
                "V-ing,\"",
                "where",
                "\"V\"",
                "is",
                "the",
                "basic",
                "meaning",
                "of",
                "that",
                "verb",
                "#TARGET_REF",
                ".",
                "Many",
                "of",
                "the",
                "verbs",
                "(e.g.,",
                "draw,",
                "pull,",
                "push,",
                "shove,",
                "tug,",
                "yank)",
                "that",
                "do",
                "not",
                "have",
                "an",
                "inherent",
                "semantic",
                "component",
                "of",
                "\"separating\"",
                "belong",
                "to",
                "this",
                "class",
                "because",
                "of",
                "the",
                "component",
                "of",
                "force",
                "in",
                "their",
                "meaning.",
                "They",
                "are",
                "interpretable",
                "as",
                "verbs",
                "of",
                "splitting",
                "or",
                "separating",
                "only",
                "in",
                "particular",
                "syntactic",
                "frames.",
                "The",
                "adjunction",
                "of",
                "the",
                "apart",
                "adverb",
                "adds",
                "a",
                "change",
                "of",
                "state",
                "semantic",
                "component",
                "with",
                "respect",
                "to",
                "the",
                "object",
                "which",
                "is",
                "not",
                "present",
                "otherwise."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In addition to Levin classes like cut whose members have core senses that are closely and systematically related in the WordNet hierarchy, other Levin classes are composed of verbs that exhibit a wider range of possible semantic components. The split verbs (blow, break, cut, draw, hack, hew, kick, knock, pry, pull, push, rip, roll, saw, shove, slip, split, tear, tug, yank) do not obviously form a tight semantic class. Instead, in their use as split verbs, each verb manifests an extended sense that can be paraphrased as \"separate by V-ing,\" where \"V\" is the basic meaning of that verb #TARGET_REF . Many of the verbs (e.g., draw, pull, push, shove, tug, yank) that do not have an inherent semantic component of \"separating\" belong to this class because of the component of force in their meaning. They are interpretable as verbs of splitting or separating only in particular syntactic frames. The adjunction of the apart adverb adds a change of state semantic component with respect to the object which is not present otherwise.",
        "output": "{\"INFO\": [\"in their use as split verbs, each verb manifests an extended sense that can be paraphrased as \\\"separate by V-ing,\\\" where \\\"V\\\" is the basic meaning of that verb #TARGET_REF .\"], \"PERCEPT\": [\"The split verbs\", \"do not obviously form a tight semantic class.\"], \"BACK\": [\"(blow, break, cut, draw, hack, hew, kick, knock, pry, pull, push, rip, roll, saw, shove, slip, split, tear, tug, yank)\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "extract",
                "the",
                "features",
                "regarding",
                "the",
                "network",
                "object",
                "classes,",
                "we",
                "applied",
                "a",
                "regularization",
                "method",
                "to",
                "the",
                "graph.",
                "Regularization",
                "is",
                "a",
                "kind",
                "of",
                "semi-supervised",
                "(or",
                "transductive)",
                "classification",
                "method",
                "that",
                "aims",
                "to",
                "find",
                "a",
                "set",
                "of",
                "labels,",
                "minimizing",
                "a",
                "cost",
                "function",
                "and",
                "satisfying",
                "two",
                "conditions:",
                "(i)",
                "the",
                "method",
                "needs",
                "to",
                "be",
                "consistent",
                "with",
                "the",
                "set",
                "of",
                "labels",
                "manually",
                "annotated",
                "and",
                "(ii)",
                "the",
                "method",
                "needs",
                "to",
                "be",
                "consistent",
                "with",
                "the",
                "network",
                "topology,",
                "considering",
                "that",
                "nearest",
                "neighbors",
                "tend",
                "to",
                "have",
                "the",
                "same",
                "labels",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To extract the features regarding the network object classes, we applied a regularization method to the graph. Regularization is a kind of semi-supervised (or transductive) classification method that aims to find a set of labels, minimizing a cost function and satisfying two conditions: (i) the method needs to be consistent with the set of labels manually annotated and (ii) the method needs to be consistent with the network topology, considering that nearest neighbors tend to have the same labels #TARGET_REF .",
        "output": "{\"INFO\": [\"nearest neighbors tend to have the same labels #TARGET_REF .\"], \"PERCEPT\": [\"the method needs to be consistent with the network topology, considering that\"], \"BACK\": [\"Regularization is a kind of semi-supervised\", \"classification method\", \"satisfying two conditions:\", \"the method needs to be consistent with the set of labels manually annotated and\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "work,",
                "we",
                "explore",
                "a",
                "set",
                "of",
                "interpretable",
                "entity",
                "representations",
                "that",
                "are",
                "simultaneously",
                "human",
                "and",
                "machine",
                "readable.",
                "The",
                "key",
                "idea",
                "of",
                "this",
                "approach",
                "is",
                "to",
                "use",
                "fine-grained",
                "entity",
                "typing",
                "models",
                "with",
                "large",
                "type",
                "inventories",
                "#REF",
                ".",
                "Given",
                "an",
                "entity",
                "mention",
                "and",
                "context",
                "words,",
                "our",
                "typing",
                "model",
                "outputs",
                "a",
                "highdimensional",
                "vector",
                "whose",
                "values",
                "are",
                "associated",
                "with",
                "predefined",
                "fine-grained",
                "entity",
                "types.",
                "Each",
                "value",
                "ranges",
                "between",
                "0",
                "and",
                "1,",
                "corresponding",
                "to",
                "the",
                "confidence",
                "of",
                "the",
                "model's",
                "decision",
                "that",
                "the",
                "entity",
                "has",
                "the",
                "property",
                "given",
                "by",
                "the",
                "corresponding",
                "type.",
                "We",
                "use",
                "pre-trained",
                "Transformer-based",
                "entity",
                "typing",
                "models,",
                "trained",
                "either",
                "on",
                "a",
                "supervised",
                "entity",
                "typing",
                "dataset",
                "#TARGET_REF",
                "or",
                "on",
                "a",
                "distantlysupervised",
                "dataset",
                "derived",
                "from",
                "Wikipedia",
                "categories",
                "#REF",
                ".",
                "The",
                "type",
                "vectors",
                "from",
                "these",
                "models,",
                "which",
                "contain",
                "tens",
                "of",
                "thousands",
                "of",
                "types,",
                "are",
                "then",
                "used",
                "as",
                "contextualized",
                "entity",
                "embeddings",
                "in",
                "downstream",
                "tasks."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this work, we explore a set of interpretable entity representations that are simultaneously human and machine readable. The key idea of this approach is to use fine-grained entity typing models with large type inventories #REF . Given an entity mention and context words, our typing model outputs a highdimensional vector whose values are associated with predefined fine-grained entity types. Each value ranges between 0 and 1, corresponding to the confidence of the model's decision that the entity has the property given by the corresponding type. We use pre-trained Transformer-based entity typing models, trained either on a supervised entity typing dataset #TARGET_REF or on a distantlysupervised dataset derived from Wikipedia categories #REF . The type vectors from these models, which contain tens of thousands of types, are then used as contextualized entity embeddings in downstream tasks.",
        "output": "{\"INFO\": [\"trained either on a supervised entity typing dataset #TARGET_REF\"], \"PERCEPT\": [\"We use pre-trained Transformer-based entity typing models,\"], \"BACK\": [\"or on a distantlysupervised dataset derived from Wikipedia categories #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "During",
                "the",
                "fine-tuning",
                "phase,",
                "we",
                "first",
                "apply",
                "finetuning",
                "on",
                "a",
                "small",
                "spoken",
                "corpus.",
                "For",
                "better",
                "domain",
                "adaptation,",
                "we",
                "adopt",
                "mixed",
                "fine-tuning",
                "#REF",
                ",",
                "which",
                "trains",
                "on",
                "a",
                "mixed",
                "dataset",
                "that",
                "includes",
                "a",
                "subsampled",
                "general",
                "corpus",
                "and",
                "an",
                "upsampled",
                "spoken",
                "corpus.",
                "Thirdly,",
                "we",
                "propose",
                "a",
                "method",
                "called",
                "\"in-domain",
                "mixed",
                "fine-tuning\",",
                "which",
                "further",
                "improve",
                "the",
                "BLEU",
                "score",
                "than",
                "mixed",
                "finetuning.",
                "Specifically,",
                "inspired",
                "by",
                "in-domain",
                "data",
                "filtering",
                "#TARGET_REF",
                ",",
                "we",
                "mixed",
                "upsampled",
                "spoken",
                "data",
                "with",
                "selected",
                "in-domain",
                "data",
                "from",
                "general",
                "corpus",
                "rather",
                "than",
                "random",
                "subsampled."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "During the fine-tuning phase, we first apply finetuning on a small spoken corpus. For better domain adaptation, we adopt mixed fine-tuning #REF , which trains on a mixed dataset that includes a subsampled general corpus and an upsampled spoken corpus. Thirdly, we propose a method called \"in-domain mixed fine-tuning\", which further improve the BLEU score than mixed finetuning. Specifically, inspired by in-domain data filtering #TARGET_REF , we mixed upsampled spoken data with selected in-domain data from general corpus rather than random subsampled.",
        "output": "{\"INFO\": [\"in-domain data filtering #TARGET_REF\"], \"PERCEPT\": [\"inspired by\", \"we mixed upsampled spoken data with selected in-domain data from general corpus rather than random subsampled.\"], \"BACK\": [\"we propose a method called \\\"in-domain mixed fine-tuning\\\", which further improve the BLEU score than mixed finetuning.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "all",
                "configurations,",
                "the",
                "performance",
                "in",
                "terms",
                "of",
                "EM",
                "and",
                "F1",
                "on",
                "PIAF",
                "remains",
                "significantly",
                "lower",
                "than",
                "that",
                "obtained",
                "on",
                "FQuAD",
                "since",
                "the",
                "PIAF",
                "corpus",
                "does",
                "not",
                "include",
                "multiple",
                "responses",
                "as",
                "pointed",
                "out",
                "by",
                "d",
                "#TARGET_REF",
                ".",
                "Unsurprisingly,",
                "PIAF",
                "dev",
                "offer",
                "a",
                "more",
                "challenging",
                "evaluation",
                "set,",
                "where",
                "the",
                "answer",
                "extraction",
                "performance",
                "are",
                "lower.",
                "Indeed,",
                "the",
                "corpus",
                "is",
                "more",
                "diversified",
                "with",
                "questions",
                "on",
                "191",
                "different",
                "Wikipedia",
                "articles,",
                "whereas",
                "on",
                "FQuAD",
                "dev",
                "it",
                "only",
                "covers",
                "18."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In all configurations, the performance in terms of EM and F1 on PIAF remains significantly lower than that obtained on FQuAD since the PIAF corpus does not include multiple responses as pointed out by d #TARGET_REF . Unsurprisingly, PIAF dev offer a more challenging evaluation set, where the answer extraction performance are lower. Indeed, the corpus is more diversified with questions on 191 different Wikipedia articles, whereas on FQuAD dev it only covers 18.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"In all configurations, the performance in terms of EM and F1 on PIAF remains significantly lower than that obtained on FQuAD since the PIAF corpus does not include multiple responses as pointed out by d\"]}"
    },
    {
        "gold": {
            "text": [
                "Construction",
                "with",
                "masked",
                "language",
                "model.",
                "We",
                "construct",
                "neighborhood",
                "sentences",
                "from",
                "x",
                "0",
                "by",
                "substituting",
                "at",
                "most",
                "k",
                "tokens.",
                "As",
                "shown",
                "in",
                "Algorithm",
                "1,",
                "the",
                "construction",
                "employs",
                "a",
                "recursive",
                "approach",
                "and",
                "replaces",
                "one",
                "token",
                "at",
                "a",
                "time.",
                "For",
                "each",
                "recursion,",
                "the",
                "algorithm",
                "first",
                "masks",
                "each",
                "token",
                "of",
                "the",
                "input",
                "sentence",
                "(may",
                "be",
                "the",
                "original",
                "x",
                "0",
                "or",
                "the",
                "x",
                "from",
                "last",
                "recursion)",
                "separately",
                "and",
                "predicts",
                "likely",
                "replacements",
                "with",
                "a",
                "masked",
                "language",
                "model",
                "(e.g.,",
                "#TARGET_REF",
                ".",
                "To",
                "ensure",
                "the",
                "naturalness,",
                "we",
                "keep",
                "the",
                "top",
                "20",
                "tokens",
                "for",
                "each",
                "mask",
                "with",
                "the",
                "largest",
                "logit",
                "(subject",
                "to",
                "a",
                "threshold,",
                "Line",
                "9).",
                "Then,",
                "the",
                "algorithm",
                "constructs",
                "neighborhood",
                "sentences",
                "by",
                "replacing",
                "the",
                "mask",
                "with",
                "found",
                "tokens.",
                "We",
                "use",
                "the",
                "notation",
                "x",
                "in",
                "the",
                "following",
                "sections",
                "to",
                "denote",
                "the",
                "constructed",
                "sentences",
                "within",
                "the",
                "neighborhood.",
                "L",
                "←",
                "SortDecreasing(L),",
                "9",
                "lmin",
                "←",
                "max{L",
                "(κ)",
                ",",
                "L",
                "(0)",
                "−",
                "δ},"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Construction with masked language model. We construct neighborhood sentences from x 0 by substituting at most k tokens. As shown in Algorithm 1, the construction employs a recursive approach and replaces one token at a time. For each recursion, the algorithm first masks each token of the input sentence (may be the original x 0 or the x from last recursion) separately and predicts likely replacements with a masked language model (e.g., #TARGET_REF . To ensure the naturalness, we keep the top 20 tokens for each mask with the largest logit (subject to a threshold, Line 9). Then, the algorithm constructs neighborhood sentences by replacing the mask with found tokens. We use the notation x in the following sections to denote the constructed sentences within the neighborhood. L ← SortDecreasing(L), 9 lmin ← max{L (κ) , L (0) − δ},",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"the algorithm first masks each token of the input sentence (may be the original x 0 or the x from last recursion) separately and predicts likely replacements with a masked language model (e.g.,\"]}"
    },
    {
        "gold": {
            "text": [
                "Linguistic",
                "variations.",
                "Another",
                "aspect",
                "comes",
                "from",
                "looking",
                "at",
                "implicit",
                "abuse,",
                "whereby",
                "a",
                "user",
                "may",
                "utilize",
                "novel",
                "slangs",
                "or",
                "conventional",
                "words",
                "in",
                "unconventional",
                "ways,",
                "e.g.,",
                "as",
                "a",
                "racial",
                "slur",
                "or",
                "as",
                "a",
                "name",
                "for",
                "some",
                "specific",
                "demographic",
                "#REF",
                ".",
                "Information",
                "about",
                "how",
                "a",
                "term",
                "is",
                "being",
                "used",
                "by",
                "other",
                "members",
                "of",
                "a",
                "user's",
                "community,",
                "e.g.,",
                "in",
                "abusive",
                "contexts",
                "or",
                "otherwise,",
                "can",
                "help",
                "decipher",
                "linguistic",
                "variations",
                "that",
                "come",
                "up",
                "from",
                "time",
                "to",
                "time.",
                "In",
                "fact,",
                "it",
                "is",
                "usually",
                "the",
                "users",
                "with",
                "strong",
                "ties",
                "who",
                "are",
                "responsible",
                "for",
                "popularizing",
                "language",
                "variations",
                "as",
                "well",
                "as",
                "for",
                "spreading",
                "hate",
                "speech",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "having",
                "user",
                "and",
                "community",
                "information",
                "alongside",
                "linguistic",
                "features",
                "helps",
                "capture",
                "linguistic",
                "variations",
                "and",
                "their",
                "diffusion."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Linguistic variations. Another aspect comes from looking at implicit abuse, whereby a user may utilize novel slangs or conventional words in unconventional ways, e.g., as a racial slur or as a name for some specific demographic #REF . Information about how a term is being used by other members of a user's community, e.g., in abusive contexts or otherwise, can help decipher linguistic variations that come up from time to time. In fact, it is usually the users with strong ties who are responsible for popularizing language variations as well as for spreading hate speech #TARGET_REF . Therefore, having user and community information alongside linguistic features helps capture linguistic variations and their diffusion.",
        "output": "{\"INFO\": [\"spreading hate speech\"], \"PERCEPT\": [\"it is usually the users with strong ties who are responsible for popularizing language variations as well as for\", \"having user and community information alongside linguistic features helps capture linguistic variations and their diffusion.\"], \"BACK\": [\"Linguistic variations. Another aspect comes from looking at implicit abuse, whereby a user may utilize novel slangs or conventional words in unconventional ways,\", \"Information about how a term is being used by other members of a user's community,\", \"can help decipher linguistic variations that come up from time to time.\"]}"
    },
    {
        "gold": {
            "text": [
                "Japanese",
                "and",
                "English",
                "Twitter",
                "conversations",
                "were",
                "extracted",
                "from",
                "Twitter",
                "replies,",
                "adjacent",
                "tweets",
                "as",
                "pairs",
                "of",
                "#REF",
                "to",
                "construct",
                "a",
                "single-turn",
                "dialogue",
                "dataset",
                "of",
                "one",
                "million",
                "dialogue",
                "pairs",
                "for",
                "each",
                "language.",
                "SentencePiece",
                "#TARGET_REF",
                "was",
                "trained",
                "using",
                "a",
                "dataset",
                "with",
                "a",
                "vocabulary",
                "of",
                "32,000",
                "for",
                "both",
                "Japanese",
                "and",
                "English",
                "data.",
                "We",
                "then",
                "used",
                "these",
                "SentencePiece",
                "models",
                "to",
                "tokenize",
                "the",
                "training",
                "set",
                "into",
                "subwords.",
                "Each",
                "of",
                "the",
                "verification",
                "set",
                "and",
                "the",
                "test",
                "set",
                "consists",
                "of",
                "1024",
                "pairs."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Japanese and English Twitter conversations were extracted from Twitter replies, adjacent tweets as pairs of #REF to construct a single-turn dialogue dataset of one million dialogue pairs for each language. SentencePiece #TARGET_REF was trained using a dataset with a vocabulary of 32,000 for both Japanese and English data. We then used these SentencePiece models to tokenize the training set into subwords. Each of the verification set and the test set consists of 1024 pairs.",
        "output": "{\"INFO\": [\"SentencePiece #TARGET_REF\"], \"PERCEPT\": [\"was trained using a dataset with a vocabulary of 32,000 for both Japanese and English data. We then used these SentencePiece models to tokenize the training set into subwords.\"], \"BACK\": [\"Each of the verification set and the test set consists of 1024 pairs.\"]}"
    },
    {
        "gold": {
            "text": [
                "Experimental",
                "details",
                "For",
                "all",
                "models,",
                "we",
                "benchmark",
                "by",
                "running",
                "a",
                "forward",
                "and",
                "backward",
                "pass",
                "over",
                "random",
                "inputs.",
                "Each",
                "measurement",
                "is",
                "an",
                "average",
                "over",
                "3",
                "runs",
                "on",
                "an",
                "Nvidia",
                "A100",
                "GPU",
                "and",
                "is",
                "discarded",
                "if",
                "memory",
                "usage",
                "exceeds",
                "30GiB.",
                "We",
                "use",
                "causal",
                "masking",
                "for",
                "self-attention",
                "layers",
                "to",
                "highlight",
                "the",
                "simplicity",
                "of",
                "our",
                "approach",
                "that",
                "can",
                "seamlessly",
                "handle",
                "arbitrary",
                "attention",
                "masks,",
                "unlike",
                "other",
                "methods",
                "#TARGET_REF",
                ",",
                "where",
                "implementing",
                "causal",
                "masking",
                "requires",
                "customized",
                "CUDA",
                "implementations.",
                "For",
                "Performer,",
                "we",
                "use",
                "256",
                "random",
                "features,",
                "and",
                "the",
                "CUDA",
                "implementation",
                "from",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Experimental details For all models, we benchmark by running a forward and backward pass over random inputs. Each measurement is an average over 3 runs on an Nvidia A100 GPU and is discarded if memory usage exceeds 30GiB. We use causal masking for self-attention layers to highlight the simplicity of our approach that can seamlessly handle arbitrary attention masks, unlike other methods #TARGET_REF , where implementing causal masking requires customized CUDA implementations. For Performer, we use 256 random features, and the CUDA implementation from #REF .",
        "output": "{\"INFO\": [\"implementing causal masking requires customized CUDA implementations.\"], \"PERCEPT\": [\"We use causal masking for self-attention layers to highlight the simplicity of our approach that can seamlessly handle arbitrary attention masks, unlike other methods #TARGET_REF , where\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "While",
                "manual,",
                "human",
                "evaluation",
                "of",
                "machine",
                "translation",
                "(MT)",
                "systems",
                "is",
                "still",
                "the",
                "gold",
                "standard,",
                "automatic",
                "evaluation",
                "metrics",
                "have",
                "long",
                "been",
                "used",
                "for",
                "their",
                "relative",
                "speed",
                "and",
                "inexpensiveness.",
                "Early",
                "automatic",
                "metrics",
                "were",
                "easy",
                "to",
                "implement",
                "and",
                "somewhat",
                "correlated",
                "with",
                "human",
                "judgements,",
                "but",
                "have",
                "clear",
                "limitations:",
                "BLEU",
                "#TARGET_REF",
                "relies",
                "on",
                "n-gram",
                "overlap,",
                "and",
                "is",
                "thus",
                "not",
                "robust",
                "to",
                "differing",
                "word",
                "order",
                "or",
                "choice.",
                "In",
                "contrast,",
                "ME-TEOR",
                "#REF",
                "requires",
                "training,",
                "but",
                "depends",
                "on",
                "token",
                "alignment,",
                "which",
                "is",
                "also",
                "a",
                "fraught",
                "task."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "While manual, human evaluation of machine translation (MT) systems is still the gold standard, automatic evaluation metrics have long been used for their relative speed and inexpensiveness. Early automatic metrics were easy to implement and somewhat correlated with human judgements, but have clear limitations: BLEU #TARGET_REF relies on n-gram overlap, and is thus not robust to differing word order or choice. In contrast, ME-TEOR #REF requires training, but depends on token alignment, which is also a fraught task.",
        "output": "{\"INFO\": [\"BLEU #TARGET_REF relies on n-gram overlap, and is thus not robust to differing word order or choice.\"], \"PERCEPT\": [], \"BACK\": [\"Early automatic metrics were easy to implement and somewhat correlated with human judgements, but have clear limitations:\"]}"
    },
    {
        "gold": {
            "text": [
                "Large",
                "explanations",
                "are",
                "typically",
                "evaluated",
                "on",
                "two",
                "dimensions:",
                "relevance",
                "and",
                "completeness.",
                "Relevance",
                "refers",
                "to",
                "whether",
                "each",
                "fact",
                "in",
                "an",
                "explanation",
                "is",
                "relevant,",
                "topical,",
                "and",
                "required",
                "to",
                "complete",
                "the",
                "chain",
                "of",
                "inference",
                "that",
                "moves",
                "from",
                "question",
                "to",
                "correct",
                "answer.",
                "Conversely,",
                "completeness",
                "evaluates",
                "whether",
                "the",
                "entire",
                "set",
                "of",
                "facts",
                "in",
                "the",
                "explanation,",
                "together,",
                "composes",
                "a",
                "complete",
                "chain",
                "of",
                "inference",
                "from",
                "question",
                "to",
                "answer,",
                "without",
                "significant",
                "gaps.",
                "In",
                "practice,",
                "both",
                "of",
                "these",
                "are",
                "challenging",
                "to",
                "evaluate",
                "automatically",
                "#TARGET_REF",
                ",",
                "given",
                "that",
                "multi-hop",
                "datasets",
                "typically",
                "include",
                "a",
                "single",
                "example",
                "of",
                "a",
                "complete",
                "explanation,",
                "in",
                "large",
                "part",
                "due",
                "to",
                "the",
                "time",
                "and",
                "expense",
                "associated",
                "with",
                "generating",
                "such",
                "annotation.",
                "Underscoring",
                "this",
                "difficulty,",
                "post-competition",
                "manual",
                "analyses",
                "on",
                "participating",
                "systems",
                "in",
                "the",
                "previous",
                "two",
                "iterations",
                "of",
                "this",
                "shared",
                "task",
                "showed",
                "that",
                "models",
                "may",
                "be",
                "performing",
                "up",
                "to",
                "20%",
                "better",
                "at",
                "retrieving",
                "correct",
                "facts",
                "to",
                "build",
                "their",
                "explanation",
                "from,",
                "highlighting",
                "this",
                "significant",
                "methodological",
                "challenge."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Large explanations are typically evaluated on two dimensions: relevance and completeness. Relevance refers to whether each fact in an explanation is relevant, topical, and required to complete the chain of inference that moves from question to correct answer. Conversely, completeness evaluates whether the entire set of facts in the explanation, together, composes a complete chain of inference from question to answer, without significant gaps. In practice, both of these are challenging to evaluate automatically #TARGET_REF , given that multi-hop datasets typically include a single example of a complete explanation, in large part due to the time and expense associated with generating such annotation. Underscoring this difficulty, post-competition manual analyses on participating systems in the previous two iterations of this shared task showed that models may be performing up to 20% better at retrieving correct facts to build their explanation from, highlighting this significant methodological challenge.",
        "output": "{\"INFO\": [\"both of these are challenging to evaluate automatically #TARGET_REF ,\"], \"PERCEPT\": [\"given that multi-hop datasets typically include a single example of a complete explanation, in large part due to the time and expense associated with generating such annotation. Underscoring this difficulty, post-competition manual analyses on participating systems in the previous two iterations of this shared task showed that models may be performing up to 20% better at retrieving correct facts to build their explanation from, highlighting this significant methodological challenge.\"], \"BACK\": [\"Large explanations are typically evaluated on two dimensions: relevance and completeness. Relevance refers to whether each fact in an explanation is relevant, topical, and required to complete the chain of inference that moves from question to correct answer.\", \"completeness evaluates whether the entire set of facts in the explanation, together, composes a complete chain of inference from question to answer, without significant gaps.\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "a",
                "first",
                "step,",
                "we",
                "consider",
                "only",
                "cases",
                "where",
                "at",
                "any",
                "node",
                "during",
                "the",
                "tree",
                "traversal",
                "in",
                "the",
                "BURS,",
                "there",
                "is",
                "only",
                "potentially",
                "one",
                "gNCN",
                "at",
                "a",
                "time:",
                "that",
                "is,",
                "it",
                "is",
                "not",
                "possible",
                "to",
                "embed",
                "or",
                "overlap",
                "these",
                "gNCNs.",
                "In",
                "order",
                "to",
                "explain",
                "this,",
                "consider",
                "first",
                "the",
                "example",
                "below.",
                "The",
                "input",
                "AST",
                "(ignoring",
                "the",
                "annotations",
                "on",
                "the",
                "nodes)",
                "is",
                "in",
                "Figure",
                "7,",
                "pattern",
                "trees,",
                "in",
                "the",
                "form",
                "of",
                "a",
                "TAG",
                "grammar",
                "(with",
                "associated",
                "costs",
                "still",
                "indicated",
                "by",
                "),",
                "are",
                "also",
                "in",
                "Figure",
                "7.",
                "The",
                "algorithm",
                "we",
                "use",
                "for",
                "bottom-up",
                "pattern",
                "matching,",
                "adapted",
                "from",
                "that",
                "of",
                "#TARGET_REF",
                ",",
                "is",
                "in",
                "Figure",
                "8."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "As a first step, we consider only cases where at any node during the tree traversal in the BURS, there is only potentially one gNCN at a time: that is, it is not possible to embed or overlap these gNCNs. In order to explain this, consider first the example below. The input AST (ignoring the annotations on the nodes) is in Figure 7, pattern trees, in the form of a TAG grammar (with associated costs still indicated by ), are also in Figure 7. The algorithm we use for bottom-up pattern matching, adapted from that of #TARGET_REF , is in Figure 8.",
        "output": "{\"INFO\": [\"The algorithm\", \"adapted from that of #TARGET_REF\"], \"PERCEPT\": [\"we use for bottom-up pattern matching,\", \", is in Figure 8.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "research",
                "proposal,",
                "we",
                "focus",
                "on",
                "three",
                "factors",
                "that",
                "can",
                "enhance",
                "the",
                "communication",
                "between",
                "humans",
                "and",
                "assistive",
                "technologies.",
                "The",
                "first",
                "one",
                "is",
                "the",
                "encoding",
                "of",
                "the",
                "referential",
                "complexity",
                "of",
                "the",
                "situated",
                "settings",
                "while",
                "creating",
                "multimodal",
                "embeddings.",
                "As",
                "pointed",
                "out",
                "in",
                "#TARGET_REF",
                ",",
                "pre-trained",
                "models,",
                "that",
                "were",
                "created",
                "by",
                "fusing",
                "the",
                "modalities",
                "without",
                "constraints,",
                "are",
                "expected",
                "to",
                "be",
                "an",
                "out-of-the-box",
                "solution",
                "and",
                "work",
                "well",
                "for",
                "a",
                "variety",
                "of",
                "simpler",
                "tasks.",
                "In",
                "this",
                "research,",
                "we",
                "propose",
                "to",
                "encode",
                "referential",
                "complexity",
                "during",
                "the",
                "training",
                "phase",
                "to",
                "see",
                "whether",
                "the",
                "complexity-sensitive",
                "embeddings",
                "will",
                "improve",
                "the",
                "tasks",
                "of",
                "crossmodal",
                "mapping",
                "and",
                "meaning",
                "recovery.",
                "We",
                "believe",
                "that",
                "this",
                "will",
                "implicitly",
                "direct",
                "the",
                "model",
                "to",
                "focus",
                "on",
                "various",
                "textual",
                "and",
                "visual",
                "forms",
                "of",
                "the",
                "same",
                "concepts."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this research proposal, we focus on three factors that can enhance the communication between humans and assistive technologies. The first one is the encoding of the referential complexity of the situated settings while creating multimodal embeddings. As pointed out in #TARGET_REF , pre-trained models, that were created by fusing the modalities without constraints, are expected to be an out-of-the-box solution and work well for a variety of simpler tasks. In this research, we propose to encode referential complexity during the training phase to see whether the complexity-sensitive embeddings will improve the tasks of crossmodal mapping and meaning recovery. We believe that this will implicitly direct the model to focus on various textual and visual forms of the same concepts.",
        "output": "{\"INFO\": [\"As pointed out in #TARGET_REF , pre-trained models, that were created by fusing the modalities without constraints, are expected to be an out-of-the-box solution and work well for a variety of simpler tasks.\"], \"PERCEPT\": [], \"BACK\": [\"The first one is the encoding of the referential complexity of the situated settings while creating multimodal embeddings.\"]}"
    },
    {
        "gold": {
            "text": [
                "EBMT",
                "proceeds",
                "by",
                "finding",
                "suitable",
                "examples",
                "in",
                "the",
                "database",
                "and",
                "then",
                "'recombining'",
                "them",
                "appropriately.",
                "Key",
                "factors",
                "are",
                "therefore",
                "the",
                "efficient",
                "retrieval",
                "of",
                "texts",
                "from",
                "the",
                "database",
                "which",
                "are",
                "sufficiently",
                "similar",
                "to",
                "the",
                "given",
                "text",
                "(",
                "#TARGET_REF",
                "),",
                "and",
                "the",
                "alignment",
                "of",
                "translation",
                "pairs,",
                "given",
                "a",
                "bilingual",
                "corpus",
                "#REF",
                ")."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "EBMT proceeds by finding suitable examples in the database and then 'recombining' them appropriately. Key factors are therefore the efficient retrieval of texts from the database which are sufficiently similar to the given text ( #TARGET_REF ), and the alignment of translation pairs, given a bilingual corpus #REF ).",
        "output": "{\"INFO\": [\"which are sufficiently similar to the given text ( #TARGET_REF ), and the alignment of translation pairs,\"], \"PERCEPT\": [\"Key factors are therefore the efficient retrieval of texts from the database\"], \"BACK\": [\"given a bilingual corpus #REF ).\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "are",
                "relatively",
                "few",
                "studies",
                "of",
                "the",
                "usability",
                "of",
                "raw",
                "machine",
                "translated",
                "documentation",
                "by",
                "real",
                "end-users.",
                "For",
                "example,",
                "Tomita's",
                "work",
                "#REF",
                "focused",
                "on",
                "the",
                "concept",
                "of",
                "content",
                "comprehension.",
                "#REF",
                "evaluated",
                "the",
                "informativeness,",
                "comprehension,",
                "and",
                "fluency",
                "of",
                "MT",
                "output,",
                "where",
                "participants",
                "had",
                "no",
                "reference",
                "to",
                "the",
                "source",
                "text,",
                "while",
                "#REF",
                "measured",
                "the",
                "concept",
                "of",
                "usefulness.",
                "#TARGET_REF",
                "measure",
                "the",
                "readability",
                "of",
                "MT",
                "output.",
                "While",
                "comprehensibility",
                "and",
                "readability",
                "are",
                "frequently",
                "considered",
                "to",
                "be",
                "components",
                "of",
                "usability,",
                "these",
                "studies",
                "address",
                "only",
                "specific",
                "aspects",
                "of",
                "the",
                "concept",
                "of",
                "usability.",
                "#REF",
                "in",
                "which",
                "real",
                "end",
                "users'",
                "needs",
                "are",
                "evaluated",
                "in",
                "the",
                "context",
                "of",
                "web",
                "usability",
                "comes",
                "closest",
                "to",
                "the",
                "study",
                "presented",
                "here.",
                "However,",
                "Gaspari's",
                "focus",
                "is",
                "on",
                "the",
                "usability",
                "of",
                "online",
                "MT",
                "systems,",
                "as",
                "opposed",
                "to",
                "the",
                "text",
                "they",
                "generate."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "There are relatively few studies of the usability of raw machine translated documentation by real end-users. For example, Tomita's work #REF focused on the concept of content comprehension. #REF evaluated the informativeness, comprehension, and fluency of MT output, where participants had no reference to the source text, while #REF measured the concept of usefulness. #TARGET_REF measure the readability of MT output. While comprehensibility and readability are frequently considered to be components of usability, these studies address only specific aspects of the concept of usability. #REF in which real end users' needs are evaluated in the context of web usability comes closest to the study presented here. However, Gaspari's focus is on the usability of online MT systems, as opposed to the text they generate.",
        "output": "{\"INFO\": [\"#TARGET_REF measure the readability of MT output.\"], \"PERCEPT\": [\"There are relatively few studies of the usability of raw machine translated documentation by real end-users.\", \"While comprehensibility and readability are frequently considered to be components of usability, these studies address only specific aspects of the concept of usability.\"], \"BACK\": [\"#REF evaluated the informativeness, comprehension, and fluency of MT output, where participants had no reference to the source text, while #REF measured the concept of usefulness.\"]}"
    },
    {
        "gold": {
            "text": [
                "Thee",
                "Adjoining",
                "Grammars",
                "(TAG)",
                "#TARGET_REF",
                "and",
                "Linear",
                "Indexed",
                "Grammars",
                "(LIG)",
                "#REF",
                "are",
                "extensions",
                "of",
                "Con",
                "text",
                "Free",
                "Grammars",
                "(CFG).",
                "Thee",
                "adjoining",
                "grammars",
                "use",
                "trees",
                "instead",
                "of",
                "productions",
                "as",
                "primary",
                "representing",
                "structure",
                "and",
                "seems",
                "to",
                "be",
                "adequate",
                "to",
                "describe",
                "syntactic",
                "phenomena",
                "occurring",
                "in",
                "nat",
                "ural",
                "language,",
                "due",
                "to",
                "their",
                "extended",
                "domain",
                "of",
                "locality",
                "and",
                "to",
                "their",
                "ability",
                "for",
                "factoring",
                "recursion",
                "from",
                "the",
                "domain",
                "of",
                "dependencies.",
                "Linear",
                "indexed",
                "grammars",
                "associate",
                "a",
                "stack",
                "of",
                "indices",
                "with",
                "each",
                "non-terminal",
                "symbol,",
                "with",
                "the",
                "restriction",
                "that",
                "the",
                "indices",
                "stack",
                "of",
                "the",
                "head",
                "non-terminal",
                "of",
                "each",
                "pro",
                "duction",
                "(the",
                "fa",
                "ther)",
                "can",
                "be",
                "inherited",
                "by",
                "at",
                "most",
                "one",
                "body",
                "non-terminal",
                "(the",
                "dependent",
                "child)",
                "while",
                "the",
                "other",
                "stacks",
                "must",
                "have",
                "a",
                "bounded",
                "stack",
                "size",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Thee Adjoining Grammars (TAG) #TARGET_REF and Linear Indexed Grammars (LIG) #REF are extensions of Con text Free Grammars (CFG). Thee adjoining grammars use trees instead of productions as primary representing structure and seems to be adequate to describe syntactic phenomena occurring in nat ural language, due to their extended domain of locality and to their ability for factoring recursion from the domain of dependencies. Linear indexed grammars associate a stack of indices with each non-terminal symbol, with the restriction that the indices stack of the head non-terminal of each pro duction (the fa ther) can be inherited by at most one body non-terminal (the dependent child) while the other stacks must have a bounded stack size .",
        "output": "{\"INFO\": [\"Thee Adjoining Grammars (TAG) #TARGET_REF\", \"are extensions of Con text Free Grammars (CFG). Thee adjoining grammars use trees instead of productions as primary representing structure\"], \"PERCEPT\": [\"and seems to be adequate to describe syntactic phenomena occurring in nat ural language,\"], \"BACK\": [\"and Linear Indexed Grammars (LIG) #REF\", \"due to their extended domain of locality and to their ability for factoring recursion from the domain of dependencies.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Symlink",
                "track",
                "at",
                "SemEval-2022",
                "received",
                "4",
                "system",
                "description",
                "paper",
                "submissions",
                "presented",
                "in",
                "Table",
                "2.",
                "Overall,",
                "all",
                "submitted",
                "systems",
                "are",
                "based",
                "on",
                "BERT",
                "architecture",
                "#REF",
                ".",
                "Among",
                "those,",
                "two",
                "out",
                "of",
                "four",
                "systems",
                "use",
                "SciBERT",
                "#REF",
                ",",
                "while",
                "two",
                "remaining",
                "systems",
                "use",
                "other",
                "variants",
                "of",
                "BERT",
                "such",
                "as",
                "original",
                "BERT",
                "#TARGET_REF",
                "and",
                "mBERT",
                "#REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The Symlink track at SemEval-2022 received 4 system description paper submissions presented in Table 2. Overall, all submitted systems are based on BERT architecture #REF . Among those, two out of four systems use SciBERT #REF , while two remaining systems use other variants of BERT such as original BERT #TARGET_REF and mBERT #REF .",
        "output": "{\"INFO\": [\"original BERT #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The Symlink track at SemEval-2022 received 4 system description paper submissions presented in Table 2.\", \"all submitted systems are based on BERT architecture #REF . Among those, two out of four systems use SciBERT #REF , while two remaining systems use other variants of BERT such as\", \"and mBERT #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "the",
                "popularity",
                "of",
                "multi-player",
                "online",
                "games",
                "has",
                "grown,",
                "the",
                "phenomenon",
                "of",
                "in-game",
                "toxic",
                "behavior",
                "has",
                "taken",
                "root",
                "within",
                "them.",
                "Toxic",
                "behavior",
                "is",
                "strongly",
                "present",
                "in",
                "recent",
                "online",
                "games",
                "and",
                "is",
                "problematic",
                "to",
                "the",
                "gaming",
                "industry",
                "#REF",
                ".",
                "For",
                "instance,",
                "74%",
                "of",
                "US",
                "players",
                "of",
                "such",
                "games",
                "report",
                "harassment",
                "with",
                "65%",
                "experiencing",
                "severe",
                "harassment.",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "As the popularity of multi-player online games has grown, the phenomenon of in-game toxic behavior has taken root within them. Toxic behavior is strongly present in recent online games and is problematic to the gaming industry #REF . For instance, 74% of US players of such games report harassment with 65% experiencing severe harassment. #TARGET_REF .",
        "output": "{\"INFO\": [\"74% of US players of such games report harassment with 65% experiencing severe harassment. #TARGET_REF .\"], \"PERCEPT\": [\"Toxic behavior is strongly present in recent online games and is problematic to the gaming industry #REF .\"], \"BACK\": [\"As the popularity of multi-player online games has grown, the phenomenon of in-game toxic behavior has taken root within them.\"]}"
    },
    {
        "gold": {
            "text": [
                "L",
                "PRA",
                "({α",
                "z,n",
                "}",
                "|P|,N",
                "z,n=1",
                ",",
                "M,",
                "P,",
                "V,",
                "W)",
                "(5)Masked",
                "Language",
                "Modeling",
                "(MLM)",
                "We",
                "take",
                "the",
                "same",
                "masking",
                "strategy",
                "(15%",
                "prob.",
                "to",
                "mask)",
                "as",
                "in",
                "BERT",
                "#TARGET_REF",
                "to",
                "randomly",
                "mask",
                "out",
                "the",
                "input",
                "word",
                "tokens.",
                "Here,",
                "MLM",
                "aims",
                "to",
                "predict",
                "the",
                "original",
                "word",
                "index",
                "in",
                "vocabulary",
                "space",
                "for",
                "each",
                "masked",
                "token",
                "based",
                "on",
                "the",
                "whole",
                "image",
                "and",
                "its",
                "surrounding",
                "language",
                "context",
                "via",
                "the",
                "Transformer.",
                "Hence",
                "a",
                "cross-entropy",
                "loss",
                "is",
                "adopted:L",
                "MLM",
                "=",
                "−E",
                "(I,D)∼X",
                "logP",
                "(w",
                "j",
                "|V,",
                "W",
                "\\j",
                ")",
                "(6)Image-Text",
                "Matching",
                "(ITM)",
                "In",
                "ITM,",
                "the",
                "multilayer",
                "Transformer",
                "is",
                "trained",
                "to",
                "distinguish",
                "whether",
                "the",
                "input",
                "image-text",
                "pairs",
                "are",
                "semantically",
                "matched",
                "based",
                "on",
                "the",
                "final",
                "layer",
                "[cls]",
                "token",
                "representation",
                "h",
                "cls",
                ".",
                "To",
                "construct",
                "the",
                "training",
                "samples,",
                "we",
                "randomly",
                "replace",
                "the",
                "text",
                "for",
                "each",
                "image-text",
                "pair",
                "with",
                "another",
                "text",
                "from",
                "dataset",
                "with",
                "a",
                "probability",
                "of",
                "0.5.",
                "Thus,",
                "the",
                "output",
                "label",
                "can",
                "be",
                "defined",
                "as",
                "y",
                "∈",
                "{0,",
                "1}",
                "where",
                "y",
                "=",
                "1",
                "indicates",
                "matched",
                "pair.",
                "The",
                "training",
                "objective",
                "for",
                "the",
                "ITM",
                "task",
                "is",
                "to",
                "minimize",
                "binary",
                "cross-entropy",
                "loss:L",
                "ITM",
                "=",
                "−E",
                "(I,D)∼X",
                "logP",
                "(y|V,",
                "W)",
                "(7)4",
                "Experiments"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "L PRA ({α z,n } |P|,N z,n=1 , M, P, V, W) (5)Masked Language Modeling (MLM) We take the same masking strategy (15% prob. to mask) as in BERT #TARGET_REF to randomly mask out the input word tokens. Here, MLM aims to predict the original word index in vocabulary space for each masked token based on the whole image and its surrounding language context via the Transformer. Hence a cross-entropy loss is adopted:L MLM = −E (I,D)∼X logP (w j |V, W \\j ) (6)Image-Text Matching (ITM) In ITM, the multilayer Transformer is trained to distinguish whether the input image-text pairs are semantically matched based on the final layer [cls] token representation h cls . To construct the training samples, we randomly replace the text for each image-text pair with another text from dataset with a probability of 0.5. Thus, the output label can be defined as y ∈ {0, 1} where y = 1 indicates matched pair. The training objective for the ITM task is to minimize binary cross-entropy loss:L ITM = −E (I,D)∼X logP (y|V, W) (7)4 Experiments",
        "output": "{\"INFO\": [\"the\", \"masking strategy (15% prob. to mask)\", \"BERT #TARGET_REF\"], \"PERCEPT\": [\"We take\", \"same\", \"as in\", \"to randomly mask out the input word tokens.\"], \"BACK\": [\"(5)Masked Language Modeling (MLM)\", \"Here, MLM aims to predict the original word index in vocabulary space for each masked token based on the whole image and its surrounding language context via the Transformer.\"]}"
    },
    {
        "gold": {
            "text": [
                "Kinyarwanda",
                "#TARGET_REF",
                "data",
                "is",
                "used",
                "in",
                "our",
                "experiments",
                "as",
                "a",
                "language",
                "related",
                "to",
                "the",
                "target",
                "language",
                "(swh)",
                "with",
                "existing",
                "text",
                "and",
                "audio",
                "resources",
                "that,",
                "in",
                "some",
                "ways,",
                "surpasses",
                "those",
                "available",
                "in",
                "the",
                "target",
                "language.",
                "Thus,",
                "we",
                "pre-train",
                "some",
                "models",
                "on",
                "kin",
                "data",
                "while",
                "fine-tuning",
                "for",
                "the",
                "downstream",
                "NER",
                "task",
                "using",
                "swh",
                "data."
            ],
            "context": [
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Kinyarwanda #TARGET_REF data is used in our experiments as a language related to the target language (swh) with existing text and audio resources that, in some ways, surpasses those available in the target language. Thus, we pre-train some models on kin data while fine-tuning for the downstream NER task using swh data.",
        "output": "{\"INFO\": [\"Kinyarwanda #TARGET_REF data\"], \"PERCEPT\": [\"is used in our experiments as a language related to the target language (swh) with existing text and audio resources that,\", \"surpasses those available in the target language. Thus, we pre-train some models on kin data while fine-tuning for the downstream NER task using swh data.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Lastly,",
                "we",
                "test",
                "two",
                "recent",
                "models",
                "from",
                "stance",
                "detection",
                "and",
                "dis/agreement",
                "classification.",
                "TGA",
                "Net",
                "#TARGET_REF",
                "takes",
                "a",
                "statement-topic",
                "pair",
                "and",
                "predicts",
                "the",
                "statement's",
                "stance.",
                "It",
                "encodes",
                "the",
                "input",
                "using",
                "BERT",
                "and",
                "weighs",
                "topic",
                "tokens",
                "based",
                "on",
                "similarity",
                "to",
                "other",
                "topics.",
                "In",
                "our",
                "task,",
                "claims",
                "serve",
                "as",
                "''topics''.",
                "We",
                "use",
                "the",
                "published",
                "implementation,",
                "exploring",
                "{50,",
                "100,",
                "150,",
                "200}",
                "for",
                "the",
                "number",
                "of",
                "clusters",
                "and",
                "increasing",
                "the",
                "max",
                "input",
                "size",
                "to",
                "the",
                "BERT",
                "input",
                "size.",
                "Hybrid",
                "Net",
                "#REF",
                "takes",
                "a",
                "quote-response",
                "pair",
                "and",
                "predicts",
                "whether",
                "the",
                "response",
                "agrees",
                "or",
                "disagrees",
                "with",
                "the",
                "quote.",
                "It",
                "encodes",
                "the",
                "input",
                "using",
                "BiLSTM",
                "and",
                "uses",
                "selfand",
                "cross-attention",
                "between",
                "tokens.",
                "In",
                "our",
                "task,",
                "claims",
                "and",
                "statements",
                "serve",
                "as",
                "''quotes''",
                "and",
                "''responses'',",
                "respectively."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Lastly, we test two recent models from stance detection and dis/agreement classification. TGA Net #TARGET_REF takes a statement-topic pair and predicts the statement's stance. It encodes the input using BERT and weighs topic tokens based on similarity to other topics. In our task, claims serve as ''topics''. We use the published implementation, exploring {50, 100, 150, 200} for the number of clusters and increasing the max input size to the BERT input size. Hybrid Net #REF takes a quote-response pair and predicts whether the response agrees or disagrees with the quote. It encodes the input using BiLSTM and uses selfand cross-attention between tokens. In our task, claims and statements serve as ''quotes'' and ''responses'', respectively.",
        "output": "{\"INFO\": [\"TGA Net #TARGET_REF takes a statement-topic pair and predicts the statement's stance. It encodes the input using BERT and weighs topic tokens based on similarity to other topics.\"], \"PERCEPT\": [\"we test two recent models from stance detection and dis/agreement classification.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Bridging",
                "vs.",
                "TNE",
                "Bridging",
                "has",
                "been",
                "extensively",
                "studied",
                "in",
                "the",
                "past",
                "decades,",
                "as",
                "we",
                "discuss",
                "in",
                "§10.",
                "Here,",
                "we",
                "explore",
                "how",
                "many",
                "of",
                "the",
                "relations",
                "we",
                "collected",
                "correspond",
                "to",
                "the",
                "definition",
                "of",
                "bridging.",
                "We",
                "use",
                "the",
                "same",
                "three",
                "documents",
                "from",
                "the",
                "analysis",
                "described",
                "above,",
                "and",
                "follow",
                "the",
                "annotation",
                "scheme",
                "from",
                "ISNotes1.0",
                "#REF",
                "16",
                "to",
                "annotate",
                "them",
                "for",
                "bridging.",
                "We",
                "found",
                "that",
                "15",
                "out",
                "of",
                "the",
                "590",
                "links",
                "(2.5%)",
                "in",
                "these",
                "documents",
                "are",
                "bridging",
                "links",
                "(i.e.,",
                "meet",
                "the",
                "criteria",
                "for",
                "bridging",
                "defined",
                "in",
                "ISNotes).",
                "These",
                "three",
                "documents",
                "contain",
                "104",
                "NPs,",
                "that",
                "is,",
                "the",
                "ratio",
                "of",
                "bridging",
                "links",
                "per",
                "NP",
                "is",
                "0.14.",
                "While",
                "the",
                "ratio",
                "is",
                "small,",
                "it",
                "is",
                "larger",
                "than",
                "the",
                "ratio",
                "in",
                "ISNotes,",
                "which",
                "contains",
                "663",
                "bridging",
                "links",
                "out",
                "of",
                "11K",
                "annotated",
                "NPs",
                "#TARGET_REF",
                ",",
                "that",
                "is,",
                "0.06",
                "bridging",
                "links",
                "per",
                "NP."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Bridging vs. TNE Bridging has been extensively studied in the past decades, as we discuss in §10. Here, we explore how many of the relations we collected correspond to the definition of bridging. We use the same three documents from the analysis described above, and follow the annotation scheme from ISNotes1.0 #REF 16 to annotate them for bridging. We found that 15 out of the 590 links (2.5%) in these documents are bridging links (i.e., meet the criteria for bridging defined in ISNotes). These three documents contain 104 NPs, that is, the ratio of bridging links per NP is 0.14. While the ratio is small, it is larger than the ratio in ISNotes, which contains 663 bridging links out of 11K annotated NPs #TARGET_REF , that is, 0.06 bridging links per NP.",
        "output": "{\"INFO\": [\"which contains 663 bridging links out of 11K annotated NPs #TARGET_REF , that is, 0.06 bridging links per NP.\"], \"PERCEPT\": [\"While the ratio is small, it is larger than the ratio in ISNotes,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "However,",
                "sentence",
                "diversity",
                "is",
                "based",
                "not",
                "only",
                "on",
                "individual",
                "tokens,",
                "but",
                "also",
                "on",
                "the",
                "token",
                "sequence.",
                "We",
                "are",
                "able",
                "to",
                "compute",
                "weights",
                "for",
                "loss",
                "functions",
                "dynamically,",
                "depending",
                "on",
                "the",
                "context,",
                "while",
                "retaining",
                "the",
                "fluency",
                "of",
                "generated",
                "sentences.",
                "We",
                "propose",
                "such",
                "a",
                "loss",
                "function,",
                "Inverse",
                "N-gram",
                "Frequency",
                "(INF)",
                "loss,",
                "which",
                "uses",
                "the",
                "inverse",
                "of",
                "the",
                "frequency",
                "of",
                "the",
                "n-gram",
                "of",
                "the",
                "tokens,",
                "rather",
                "than",
                "the",
                "token",
                "frequency.",
                "We",
                "built",
                "a",
                "neural",
                "dialogue",
                "system",
                "trained",
                "by",
                "INF",
                "loss",
                "using",
                "huge",
                "amounts",
                "of",
                "dialogue",
                "data",
                "extracted",
                "from",
                "Twitter.",
                "After",
                "comparing",
                "models",
                "using",
                "the",
                "SCE",
                "loss,",
                "the",
                "ITF",
                "loss,",
                "and",
                "the",
                "INF",
                "loss,",
                "we",
                "evaluated",
                "their",
                "diversity",
                "and",
                "fluency.",
                "Results",
                "show",
                "that",
                "our",
                "proposed",
                "INF",
                "loss",
                "model",
                "outperformed",
                "the",
                "SCE",
                "loss",
                "and",
                "ITF",
                "loss",
                "models",
                "for",
                "most",
                "automatic",
                "assessment",
                "measures",
                "such",
                "as",
                "DIST-N",
                "#TARGET_REF",
                "and",
                "ROUGE",
                "#REF",
                ".",
                "Our",
                "INF",
                "loss",
                "model",
                "also",
                "achieved",
                "higher",
                "scores",
                "on",
                "our",
                "human",
                "evaluations",
                "of",
                "coherence",
                "and",
                "richness."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "However, sentence diversity is based not only on individual tokens, but also on the token sequence. We are able to compute weights for loss functions dynamically, depending on the context, while retaining the fluency of generated sentences. We propose such a loss function, Inverse N-gram Frequency (INF) loss, which uses the inverse of the frequency of the n-gram of the tokens, rather than the token frequency. We built a neural dialogue system trained by INF loss using huge amounts of dialogue data extracted from Twitter. After comparing models using the SCE loss, the ITF loss, and the INF loss, we evaluated their diversity and fluency. Results show that our proposed INF loss model outperformed the SCE loss and ITF loss models for most automatic assessment measures such as DIST-N #TARGET_REF and ROUGE #REF . Our INF loss model also achieved higher scores on our human evaluations of coherence and richness.",
        "output": "{\"INFO\": [\"DIST-N #TARGET_REF\"], \"PERCEPT\": [\"Results show that our proposed INF loss model outperformed the SCE loss and ITF loss models for most automatic assessment measures such as\"], \"BACK\": [\"After comparing models using the SCE loss, the ITF loss, and the INF loss, we evaluated their diversity and fluency.\", \"and ROUGE #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Google-BERT.",
                "#TARGET_REF",
                "propose",
                "a",
                "framework",
                "composed",
                "of",
                "three",
                "main",
                "steps.",
                "In",
                "the",
                "first",
                "step,",
                "the",
                "model",
                "adopts",
                "a",
                "simple",
                "tf.idf",
                "model",
                "with",
                "cosine",
                "similarity",
                "to",
                "retrieve",
                "the",
                "top-K",
                "relevant",
                "explanation",
                "sentences",
                "(K",
                "=",
                "50)",
                "for",
                "each",
                "question",
                "and",
                "correct",
                "answer",
                "pair.",
                "In",
                "the",
                "second",
                "step,",
                "the",
                "authors",
                "employ",
                "an",
                "autoregressive",
                "model",
                "which",
                "selects",
                "the",
                "most",
                "relevant",
                "facts",
                "in",
                "a",
                "iterative",
                "manner.",
                "Specifically,",
                "the",
                "authors",
                "propose",
                "the",
                "adoption",
                "of",
                "a",
                "BERT-based",
                "model",
                "#REF",
                "that",
                "selects",
                "the",
                "facts",
                "at",
                "iteration",
                "n",
                "given",
                "the",
                "facts",
                "retrieved",
                "in",
                "the",
                "previous",
                "step.",
                "The",
                "model",
                "uses",
                "up",
                "to",
                "4",
                "iterations.",
                "Finally,",
                "the",
                "authors",
                "employ",
                "a",
                "re-ranking",
                "module",
                "to",
                "re-score",
                "the",
                "retrieved",
                "candidate",
                "explanations",
                "computing",
                "the",
                "relevance",
                "between",
                "each",
                "fact",
                "and",
                "the",
                "question-answer",
                "pairs.",
                "The",
                "re-ranking",
                "model",
                "is",
                "implemented",
                "using",
                "a",
                "BERT",
                "model",
                "for",
                "binary",
                "classification.",
                "The",
                "ablation",
                "study",
                "shows",
                "that",
                "the",
                "first",
                "two",
                "steps",
                "allow",
                "achieving",
                "a",
                "performance",
                "of",
                "0.679",
                "NDCG,",
                "that",
                "is",
                "improved",
                "up",
                "to",
                "0.700",
                "NDCG",
                "using",
                "the",
                "re-ranking",
                "model.",
                "Moreover,",
                "the",
                "experiments",
                "show",
                "that",
                "the",
                "best",
                "performance",
                "is",
                "achieved",
                "when",
                "the",
                "re-ranking",
                "model",
                "is",
                "adopted",
                "to",
                "re-score",
                "the",
                "top",
                "K",
                "=",
                "30",
                "facts."
            ],
            "context": [
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Google-BERT. #TARGET_REF propose a framework composed of three main steps. In the first step, the model adopts a simple tf.idf model with cosine similarity to retrieve the top-K relevant explanation sentences (K = 50) for each question and correct answer pair. In the second step, the authors employ an autoregressive model which selects the most relevant facts in a iterative manner. Specifically, the authors propose the adoption of a BERT-based model #REF that selects the facts at iteration n given the facts retrieved in the previous step. The model uses up to 4 iterations. Finally, the authors employ a re-ranking module to re-score the retrieved candidate explanations computing the relevance between each fact and the question-answer pairs. The re-ranking model is implemented using a BERT model for binary classification. The ablation study shows that the first two steps allow achieving a performance of 0.679 NDCG, that is improved up to 0.700 NDCG using the re-ranking model. Moreover, the experiments show that the best performance is achieved when the re-ranking model is adopted to re-score the top K = 30 facts.",
        "output": "{\"INFO\": [\"propose a framework composed of three main steps. In the first step, the model adopts a simple tf.idf model with cosine similarity to retrieve the top-K relevant explanation sentences (K = 50) for each question and correct answer pair. In the second step, the authors employ an autoregressive model which selects the most relevant facts in a iterative manner.\", \"the authors propose the adoption of a BERT-based model #REF that selects the facts at iteration n given the facts retrieved in the previous step. The model uses up to 4 iterations. Finally, the authors employ a re-ranking module to re-score the retrieved candidate explanations computing the relevance between each fact and the question-answer pairs. The re-ranking model is implemented using a BERT model for binary classification.\"], \"PERCEPT\": [\"Specifically,\"], \"BACK\": [\"The ablation study shows that the first two steps allow achieving a performance of 0.679 NDCG, that is improved up to 0.700 NDCG using the re-ranking model.\", \"the experiments show that the best performance is achieved when the re-ranking model is adopted to re-score the top K = 30 facts.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "the",
                "best",
                "of",
                "our",
                "knowledge,",
                "the",
                "first",
                "algorithms",
                "similar",
                "to",
                "Codenames",
                "agents",
                "have",
                "been",
                "created",
                "by",
                "#TARGET_REF",
                "specifically",
                "to",
                "model",
                "human",
                "associations.",
                "In",
                "their",
                "simplified",
                "game,",
                "the",
                "board",
                "always",
                "consists",
                "of",
                "three",
                "nouns,",
                "and",
                "the",
                "agent",
                "gives",
                "a",
                "clue",
                "that",
                "must",
                "be",
                "one",
                "of",
                "three",
                "adjectives,",
                "and",
                "refers",
                "to",
                "exactly",
                "two",
                "of",
                "the",
                "board",
                "words.",
                "Their",
                "clues",
                "were",
                "generated",
                "based",
                "on",
                "the",
                "following",
                "five",
                "similarity",
                "functions:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To the best of our knowledge, the first algorithms similar to Codenames agents have been created by #TARGET_REF specifically to model human associations. In their simplified game, the board always consists of three nouns, and the agent gives a clue that must be one of three adjectives, and refers to exactly two of the board words. Their clues were generated based on the following five similarity functions:",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"To the best of our knowledge, the first algorithms similar to Codenames agents have been created by\", \"specifically to model human associations.\"], \"BACK\": [\"In their simplified game, the board always consists of three nouns, and the agent gives a clue that must be one of three adjectives, and refers to exactly two of the board words.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "Localized",
                "Narratives",
                "dataset",
                "#TARGET_REF",
                ",",
                "the",
                "annotators",
                "describe",
                "the",
                "image",
                "while",
                "drawing",
                "the",
                "traces",
                "of",
                "their",
                "attention",
                "movement,",
                "which",
                "presents",
                "a",
                "spatial",
                "alignment",
                "between",
                "visual",
                "objects",
                "and",
                "caption",
                "tokens",
                "as",
                "well",
                "as",
                "a",
                "temporal",
                "alignment",
                "between",
                "user",
                "intention(by",
                "trace)",
                "and",
                "caption",
                "sentences.",
                "From",
                "Figure",
                "1,",
                "we",
                "see",
                "that",
                "the",
                "caption",
                "tokens,",
                "e.g.",
                "\"person\",",
                "\"horse\",",
                "\"trees\"",
                "can",
                "be",
                "grounded",
                "to",
                "the",
                "visual",
                "objects",
                "spatially,",
                "and",
                "the",
                "order",
                "of",
                "caption",
                "sentences",
                "can",
                "be",
                "arranged",
                "to",
                "align",
                "to",
                "the",
                "order",
                "of",
                "traces",
                "temporally.",
                "Although",
                "it",
                "is",
                "easy",
                "for",
                "humans",
                "to",
                "recognize",
                "which",
                "visual",
                "object",
                "is",
                "indicated",
                "by",
                "the",
                "traces,",
                "it",
                "is",
                "a",
                "challenge",
                "for",
                "the",
                "agent",
                "to",
                "recognize,",
                "emphasize",
                "and",
                "arrange",
                "visual",
                "semantics",
                "solely",
                "based",
                "on",
                "several",
                "tracepoints'",
                "coordinates.",
                "Thereby,",
                "we",
                "mainly",
                "devote",
                "our",
                "effort",
                "to",
                "the",
                "spatial",
                "grounding",
                "and",
                "temporal",
                "controllability",
                "of",
                "image",
                "captioning."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the Localized Narratives dataset #TARGET_REF , the annotators describe the image while drawing the traces of their attention movement, which presents a spatial alignment between visual objects and caption tokens as well as a temporal alignment between user intention(by trace) and caption sentences. From Figure 1, we see that the caption tokens, e.g. \"person\", \"horse\", \"trees\" can be grounded to the visual objects spatially, and the order of caption sentences can be arranged to align to the order of traces temporally. Although it is easy for humans to recognize which visual object is indicated by the traces, it is a challenge for the agent to recognize, emphasize and arrange visual semantics solely based on several tracepoints' coordinates. Thereby, we mainly devote our effort to the spatial grounding and temporal controllability of image captioning.",
        "output": "{\"INFO\": [\"In the Localized Narratives dataset #TARGET_REF , the annotators describe the image while drawing the traces of their attention movement, which presents a spatial alignment between visual objects and caption tokens as well as a temporal alignment between user intention(by trace) and caption sentences.\"], \"PERCEPT\": [\"From Figure 1, we see that the caption tokens,\", \"can be grounded to the visual objects spatially, and the order of caption sentences can be arranged to align to the order of traces temporally.\"], \"BACK\": [\"\\\"person\\\", \\\"horse\\\", \\\"trees\\\"\"]}"
    },
    {
        "gold": {
            "text": [
                "Nonetheless,",
                "the",
                "established",
                "convention",
                "incorporates",
                "a",
                "distancing",
                "from",
                "the",
                "offence.",
                "Also,",
                "writers",
                "use",
                "apologies",
                "when",
                "they",
                "are",
                "apologising",
                "in",
                "a",
                "role",
                "(e.g.",
                "as",
                "the",
                "representative",
                "of",
                "an",
                "organisation).",
                "When",
                "speaking",
                "personally,",
                "they",
                "use",
                "other",
                "forms,",
                "typically",
                "sorry",
                "#TARGET_REF",
                ".",
                "Another",
                "possibility",
                "is",
                "that",
                "use",
                "of",
                "the",
                "noun",
                "form",
                "enables",
                "the",
                "writer",
                "to",
                "avoid",
                "the",
                "personal",
                "pronoun,",
                "creating",
                "a",
                "distance",
                "between",
                "the",
                "writer",
                "and",
                "the",
                "responsibility",
                "for",
                "the",
                "offence",
                "(ibid).",
                "In",
                "our",
                "data,",
                "individuals",
                "have",
                "not",
                "used",
                "this",
                "form",
                "at",
                "all",
                "and",
                "of",
                "the",
                "seven",
                "occurrences",
                "of",
                "the",
                "noun",
                "form,",
                "six",
                "are",
                "by",
                "individuals",
                "as",
                "representative",
                "of",
                "an",
                "organisation.",
                "This",
                "co-relates",
                "to",
                "Harrison's",
                "finding",
                "that",
                "the",
                "word",
                "apology/",
                "apologies",
                "help",
                "the",
                "writers",
                "to",
                "distance",
                "themselves",
                "from",
                "the",
                "instance",
                "or",
                "event."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Nonetheless, the established convention incorporates a distancing from the offence. Also, writers use apologies when they are apologising in a role (e.g. as the representative of an organisation). When speaking personally, they use other forms, typically sorry #TARGET_REF . Another possibility is that use of the noun form enables the writer to avoid the personal pronoun, creating a distance between the writer and the responsibility for the offence (ibid). In our data, individuals have not used this form at all and of the seven occurrences of the noun form, six are by individuals as representative of an organisation. This co-relates to Harrison's finding that the word apology/ apologies help the writers to distance themselves from the instance or event.",
        "output": "{\"INFO\": [\"When speaking personally, they use other forms, typically sorry #TARGET_REF .\"], \"PERCEPT\": [\"writers use apologies when they are apologising in a role\"], \"BACK\": [\"(e.g. as the representative of an organisation).\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "paper",
                "reports",
                "the",
                "submissions",
                "of",
                "the",
                "Am-rita_CEN_NLP",
                "team",
                "for",
                "the",
                "3C",
                "Citation",
                "Context",
                "Classification",
                "shared",
                "task",
                "#REF",
                ".",
                "We",
                "used",
                "deep",
                "learning",
                "and",
                "machine",
                "learning",
                "models",
                "developed",
                "using",
                "Bi-LSTM",
                "and",
                "Random",
                "Forest",
                "algorithms",
                "#TARGET_REF",
                ",",
                "#REF",
                ",",
                "#REF",
                "to",
                "complete",
                "the",
                "subtasks.",
                "They",
                "will",
                "be",
                "elaborated",
                "upon",
                "in",
                "Section",
                "4."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "This paper reports the submissions of the Am-rita_CEN_NLP team for the 3C Citation Context Classification shared task #REF . We used deep learning and machine learning models developed using Bi-LSTM and Random Forest algorithms #TARGET_REF , #REF , #REF to complete the subtasks. They will be elaborated upon in Section 4.",
        "output": "{\"INFO\": [\"Random Forest algorithms\"], \"PERCEPT\": [\"We used deep learning and machine learning models developed using\", \"to complete the subtasks.\"], \"BACK\": [\"the 3C Citation Context Classification shared task #REF .\", \"Bi-LSTM and\", \", #REF , #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "entity",
                "linking",
                "specifically,",
                "typing",
                "has",
                "been",
                "explored",
                "for",
                "cross-domain",
                "entity",
                "linking",
                "#REF",
                ".",
                "Past",
                "work",
                "by",
                "#TARGET_REF",
                "has",
                "also",
                "explored",
                "learning",
                "a",
                "type",
                "system",
                "for",
                "this",
                "task.",
                "Our",
                "approach",
                "to",
                "learning",
                "types",
                "starts",
                "from",
                "a",
                "large",
                "set",
                "and",
                "filters",
                "it",
                "down,",
                "which",
                "is",
                "a",
                "simpler",
                "problem.",
                "A",
                "range",
                "of",
                "approaches",
                "have",
                "also",
                "considered",
                "augmenting",
                "pretrained",
                "models",
                "with",
                "type",
                "information",
                "#REF",
                ",",
                "however,",
                "in",
                "these",
                "models,",
                "the",
                "types",
                "inform",
                "dense",
                "embeddings",
                "which",
                "are",
                "still",
                "uninterpretable."
            ],
            "context": [
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In entity linking specifically, typing has been explored for cross-domain entity linking #REF . Past work by #TARGET_REF has also explored learning a type system for this task. Our approach to learning types starts from a large set and filters it down, which is a simpler problem. A range of approaches have also considered augmenting pretrained models with type information #REF , however, in these models, the types inform dense embeddings which are still uninterpretable.",
        "output": "{\"INFO\": [\"In entity linking\", \"#TARGET_REF has\", \"explored learning a type system\"], \"PERCEPT\": [], \"BACK\": [\"specifically, typing has been explored for cross-domain entity linking #REF . Past work by\", \"also\", \"for this task.\"]}"
    },
    {
        "gold": {
            "text": [
                "Natural",
                "language",
                "generation",
                "(NLG)",
                "is",
                "gaining",
                "increasing",
                "attention",
                "in",
                "the",
                "NLP",
                "community",
                "thanks",
                "to",
                "its",
                "intriguing",
                "complexity",
                "and",
                "central",
                "role",
                "in",
                "many",
                "tasks",
                "and",
                "applications.",
                "Recently,",
                "generative",
                "adversarial",
                "networks",
                "(GANs)",
                "#REF",
                "have",
                "started",
                "to",
                "display",
                "promising",
                "performance",
                "also",
                "in",
                "NLG.",
                "GANs",
                "leverage",
                "a",
                "form",
                "of",
                "adversarial",
                "learning",
                "where",
                "a",
                "generator",
                "incrementally",
                "learns",
                "to",
                "generate",
                "realistic",
                "samples,",
                "while",
                "a",
                "discriminator",
                "simultaneously",
                "learns",
                "to",
                "discriminate",
                "between",
                "real",
                "and",
                "generated",
                "data.",
                "They",
                "had",
                "originally",
                "been",
                "proposed",
                "as",
                "a",
                "generative",
                "approach",
                "for",
                "continuous",
                "data,",
                "such",
                "as",
                "images,",
                "but",
                "have",
                "later",
                "found",
                "application",
                "also",
                "for",
                "discrete",
                "data,",
                "despite",
                "their",
                "well-known",
                "\"non-differentiability",
                "issue\".",
                "In",
                "fact,",
                "several",
                "GANs",
                "have",
                "recently",
                "been",
                "proposed",
                "for",
                "text",
                "generation",
                "#REF",
                "and",
                "have",
                "achieved",
                "encouraging",
                "results",
                "in",
                "comparison",
                "to",
                "comparable",
                "maximum",
                "likelihood",
                "approaches,",
                "in",
                "particular,",
                "RelGAN",
                "#TARGET_REF",
                "has",
                "outperformed",
                "state-of-theart",
                "(SOTA)",
                "results."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Natural language generation (NLG) is gaining increasing attention in the NLP community thanks to its intriguing complexity and central role in many tasks and applications. Recently, generative adversarial networks (GANs) #REF have started to display promising performance also in NLG. GANs leverage a form of adversarial learning where a generator incrementally learns to generate realistic samples, while a discriminator simultaneously learns to discriminate between real and generated data. They had originally been proposed as a generative approach for continuous data, such as images, but have later found application also for discrete data, despite their well-known \"non-differentiability issue\". In fact, several GANs have recently been proposed for text generation #REF and have achieved encouraging results in comparison to comparable maximum likelihood approaches, in particular, RelGAN #TARGET_REF has outperformed state-of-theart (SOTA) results.",
        "output": "{\"INFO\": [\"RelGAN #TARGET_REF has outperformed state-of-theart (SOTA) results.\"], \"PERCEPT\": [\"and have achieved encouraging results in comparison to comparable maximum likelihood approaches, in particular,\"], \"BACK\": [\"several GANs have recently been proposed for text generation #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "chose",
                "to",
                "use",
                "prepositions",
                "as",
                "relation",
                "labels,",
                "despite",
                "this",
                "ambiguity.",
                "This",
                "follows",
                "a",
                "line",
                "of",
                "annotation",
                "work",
                "that",
                "aims",
                "to",
                "express",
                "semantic",
                "relations",
                "using",
                "natural",
                "language",
                "#TARGET_REF",
                ",",
                "as",
                "opposed",
                "to",
                "works",
                "that",
                "used",
                "formal",
                "linguistic",
                "terms,",
                "traditionally",
                "relying",
                "on",
                "expert-defined",
                "taxonomies",
                "of",
                "semantic",
                "roles",
                "and",
                "discourse",
                "relations.",
                "The",
                "aforementioned",
                "works",
                "label",
                "predicateargument",
                "relations",
                "using",
                "restricted",
                "questions.",
                "In",
                "the",
                "same",
                "vein,",
                "we",
                "label",
                "nominal",
                "relations",
                "using",
                "prepositions."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We chose to use prepositions as relation labels, despite this ambiguity. This follows a line of annotation work that aims to express semantic relations using natural language #TARGET_REF , as opposed to works that used formal linguistic terms, traditionally relying on expert-defined taxonomies of semantic roles and discourse relations. The aforementioned works label predicateargument relations using restricted questions. In the same vein, we label nominal relations using prepositions.",
        "output": "{\"INFO\": [\"natural language #TARGET_REF\", \"The aforementioned works label predicateargument relations using restricted questions.\"], \"PERCEPT\": [\"We chose to use prepositions as relation labels, despite this ambiguity. This follows a line of annotation work that aims to express semantic relations using\", \"as opposed to works that used formal linguistic terms, traditionally relying on expert-defined taxonomies of semantic roles and discourse relations.\", \"In the same vein, we label nominal relations using prepositions.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "and",
                "the",
                "WordNet",
                "database",
                "#TARGET_REF",
                "with",
                "a",
                "number",
                "of",
                "different",
                "distance",
                "functions."
            ],
            "context": [
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• and the WordNet database #TARGET_REF with a number of different distance functions.",
        "output": "{\"INFO\": [\"the WordNet database #TARGET_REF with a number of different distance functions.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Recent",
                "work",
                "has",
                "identified",
                "that",
                "consecutive",
                "lay-",
                "ers",
                "of",
                "BERT",
                "have",
                "similar",
                "functionality",
                "#TARGET_REF",
                ".",
                "To",
                "study",
                "this,",
                "we",
                "considered",
                "configurations",
                "where",
                "six",
                "even",
                "and",
                "odd",
                "alternate",
                "layers",
                "are",
                "pruned",
                "and",
                "compare",
                "it",
                "with",
                "other",
                "strategies",
                "of",
                "pruning",
                "50%",
                "layers",
                "of",
                "BERT",
                "(Table",
                "6).",
                "We",
                "observe",
                "that",
                "the",
                "odd",
                "configuration",
                "performs",
                "better",
                "than",
                "the",
                "Top",
                "6",
                "and",
                "Bottom",
                "6",
                "configurations,",
                "indicating",
                "a",
                "preference",
                "to",
                "avoid",
                "pruning",
                "of",
                "consecutive",
                "layers.",
                "Effect",
                "of",
                "Fine-Tuning.",
                "Recent",
                "studies",
                "#REF",
                "have",
                "reported",
                "that",
                "when",
                "fine-tuning",
                "BERT",
                "for",
                "specific",
                "tasks,",
                "the",
                "top",
                "layers",
                "change",
                "much",
                "more",
                "than",
                "the",
                "lower",
                "layers.",
                "We",
                "now",
                "evaluate",
                "this",
                "for",
                "fine-tuning",
                "after",
                "pruning."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Recent work has identified that consecutive lay- ers of BERT have similar functionality #TARGET_REF . To study this, we considered configurations where six even and odd alternate layers are pruned and compare it with other strategies of pruning 50% layers of BERT (Table 6). We observe that the odd configuration performs better than the Top 6 and Bottom 6 configurations, indicating a preference to avoid pruning of consecutive layers. Effect of Fine-Tuning. Recent studies #REF have reported that when fine-tuning BERT for specific tasks, the top layers change much more than the lower layers. We now evaluate this for fine-tuning after pruning.",
        "output": "{\"INFO\": [\"Recent work has identified that consecutive lay- ers of BERT have similar functionality #TARGET_REF .\"], \"PERCEPT\": [\"To study this, we considered configurations where six even and odd alternate layers are pruned and compare it with other strategies of pruning 50% layers of BERT\"], \"BACK\": [\"(Table 6).\"]}"
    },
    {
        "gold": {
            "text": [
                "Though",
                "the",
                "importance",
                "of",
                "categorizing",
                "scientific",
                "literature",
                "according",
                "to",
                "context",
                "is",
                "apparent,",
                "the",
                "reported",
                "amount",
                "of",
                "research",
                "that",
                "has",
                "been",
                "carried",
                "out",
                "is",
                "insufficient.",
                "Along",
                "with",
                "a",
                "classification",
                "model,",
                "#REF",
                "also",
                "proposed",
                "an",
                "annotation",
                "scheme",
                "for",
                "the",
                "categorization",
                "of",
                "the",
                "citations.",
                "12",
                "classes",
                "were",
                "considered",
                "for",
                "annotation.",
                "From",
                "116",
                "articles,",
                "2829",
                "citation",
                "samples",
                "were",
                "gathered.",
                "These",
                "were",
                "used",
                "to",
                "train",
                "the",
                "machine",
                "learning",
                "model.",
                "113K",
                "algorithms",
                "were",
                "used",
                "for",
                "classification",
                "with",
                "hand-engineered",
                "features.",
                "One",
                "of",
                "such",
                "features",
                "was",
                "cue",
                "phrases.",
                "Features",
                "such",
                "as",
                "patternbased",
                "features,",
                "topic-based",
                "features,",
                "and",
                "prototypical",
                "argument",
                "features",
                "were",
                "used",
                "by",
                "D.",
                "#REF",
                "to",
                "separate",
                "the",
                "documents",
                "into",
                "its",
                "6",
                "corresponding",
                "classes.",
                "The",
                "RandomForest",
                "algorithm",
                "was",
                "used",
                "for",
                "classification.",
                "#REF",
                "also",
                "utilised",
                "Glove,",
                "ELMO",
                "word",
                "embedding",
                "features,",
                "and",
                "Bi-LSTM",
                "with",
                "attention",
                "models",
                "to",
                "aid",
                "in",
                "the",
                "classification",
                "of",
                "the",
                "citations.",
                "#TARGET_REF",
                "organized",
                "the",
                "first",
                "shared",
                "task",
                "on",
                "citation",
                "classification",
                "in",
                "2020,",
                "where",
                "different",
                "teams",
                "came",
                "up",
                "with",
                "different",
                "approaches",
                "to",
                "solve",
                "3c",
                "classification",
                "problem."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Though the importance of categorizing scientific literature according to context is apparent, the reported amount of research that has been carried out is insufficient. Along with a classification model, #REF also proposed an annotation scheme for the categorization of the citations. 12 classes were considered for annotation. From 116 articles, 2829 citation samples were gathered. These were used to train the machine learning model. 113K algorithms were used for classification with hand-engineered features. One of such features was cue phrases. Features such as patternbased features, topic-based features, and prototypical argument features were used by D. #REF to separate the documents into its 6 corresponding classes. The RandomForest algorithm was used for classification. #REF also utilised Glove, ELMO word embedding features, and Bi-LSTM with attention models to aid in the classification of the citations. #TARGET_REF organized the first shared task on citation classification in 2020, where different teams came up with different approaches to solve 3c classification problem.",
        "output": "{\"INFO\": [\"#TARGET_REF organized the first shared task on citation classification in 2020, where different teams came up with different approaches to solve 3c classification problem.\"], \"PERCEPT\": [], \"BACK\": [\"Though the importance of categorizing scientific literature according to context is apparent, the reported amount of research that has been carried out is insufficient. Along with a classification model, #REF also proposed an annotation scheme for the categorization of the citations.\"]}"
    },
    {
        "gold": {
            "text": [
                "Earlier,",
                "it",
                "was",
                "stated",
                "that",
                "the",
                "design",
                "of",
                "the",
                "system",
                "was",
                "in",
                "response",
                "to",
                "perceived",
                "weaknesses",
                "in",
                "the",
                "classical",
                "approaches",
                "to",
                "MT.",
                "It",
                "should",
                "now",
                "be",
                "clear",
                "that",
                "the",
                "approach",
                "will",
                "avoid",
                "structurepreserving",
                "translation",
                "as",
                "a",
                "first",
                "choice,",
                "since",
                "the",
                "translation",
                "process",
                "involves",
                "no",
                "analysis",
                "of",
                "syntactic",
                "structure",
                "as",
                "such,",
                "the",
                "stratificational",
                "approach",
                "to",
                "linguistic",
                "description",
                "is",
                "likewise",
                "absent,",
                "and",
                "the",
                "predominantly",
                "bottom-up",
                "compositional",
                "theory-driven",
                "translation",
                "algorithm",
                "is",
                "replaced",
                "by",
                "a",
                "more",
                "global",
                "data-driven",
                "process,",
                "finally,",
                "the",
                "use",
                "of",
                "examples",
                "rather",
                "than",
                "rules",
                "and",
                "lexicons",
                "derived",
                "from",
                "linguists'",
                "introspection",
                "mean",
                "that",
                "the",
                "system",
                "will",
                "produce",
                "more",
                "natural",
                "output",
                "(especially",
                "where",
                "source",
                "and",
                "target",
                "are",
                "structurally",
                "dissimilar:",
                "so-called",
                "metaphors",
                "and",
                "idioms),",
                "will",
                "be",
                "more",
                "robust,",
                "easier",
                "to",
                "extend",
                "and",
                "to",
                "debug",
                "(",
                "#TARGET_REF",
                ")."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Earlier, it was stated that the design of the system was in response to perceived weaknesses in the classical approaches to MT. It should now be clear that the approach will avoid structurepreserving translation as a first choice, since the translation process involves no analysis of syntactic structure as such, the stratificational approach to linguistic description is likewise absent, and the predominantly bottom-up compositional theory-driven translation algorithm is replaced by a more global data-driven process, finally, the use of examples rather than rules and lexicons derived from linguists' introspection mean that the system will produce more natural output (especially where source and target are structurally dissimilar: so-called metaphors and idioms), will be more robust, easier to extend and to debug ( #TARGET_REF ).",
        "output": "{\"INFO\": [\"the use of examples rather than rules and lexicons derived from linguists' introspection mean that the system will produce more natural output (especially where source and target are structurally dissimilar: so-called metaphors and idioms), will be more robust, easier to extend and to debug ( #TARGET_REF ).\"], \"PERCEPT\": [\"It should now be clear that the approach will avoid structurepreserving translation as a first choice, since the translation process involves no analysis of syntactic structure as such, the stratificational approach to linguistic description is likewise absent, and the predominantly bottom-up compositional theory-driven translation algorithm is replaced by a more global data-driven process,\"], \"BACK\": [\"it was stated that the design of the system was in response to perceived weaknesses in the classical approaches to MT.\"]}"
    },
    {
        "gold": {
            "text": [
                "Existing",
                "diversity-promoting",
                "methods",
                "only",
                "varied",
                "the",
                "language",
                "styles",
                "and",
                "failed",
                "to",
                "perform",
                "different",
                "knowledge",
                "reasoning",
                "to",
                "generate",
                "diverse",
                "contents",
                "#TARGET_REF",
                ".",
                "Here,",
                "incorporating",
                "commonsense",
                "KG",
                "is",
                "essential",
                "for",
                "the",
                "generative",
                "reasoning",
                "(GR)",
                "tasks",
                "because",
                "the",
                "KG",
                "cannot",
                "only",
                "augment",
                "the",
                "limited",
                "information",
                "in",
                "the",
                "input",
                "text,",
                "but",
                "also",
                "provide",
                "a",
                "rich",
                "searching",
                "space",
                "for",
                "knowledge",
                "reasoning.",
                "Therefore,",
                "we",
                "propose",
                "to",
                "employ",
                "commonsense",
                "KG",
                "to",
                "play",
                "the",
                "central",
                "role",
                "of",
                "performing",
                "diverse",
                "knowledge",
                "reasoning,",
                "then",
                "use",
                "different",
                "sets",
                "of",
                "selected",
                "concepts",
                "to",
                "produce",
                "diverse",
                "outputs."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Existing diversity-promoting methods only varied the language styles and failed to perform different knowledge reasoning to generate diverse contents #TARGET_REF . Here, incorporating commonsense KG is essential for the generative reasoning (GR) tasks because the KG cannot only augment the limited information in the input text, but also provide a rich searching space for knowledge reasoning. Therefore, we propose to employ commonsense KG to play the central role of performing diverse knowledge reasoning, then use different sets of selected concepts to produce diverse outputs.",
        "output": "{\"INFO\": [\"generate diverse contents #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Existing diversity-promoting methods only varied the language styles and failed to perform different knowledge reasoning to\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "choice",
                "of",
                "languages",
                "used",
                "for",
                "translation",
                "and",
                "transliteration",
                "is",
                "critical.",
                "#REF",
                "showed",
                "that",
                "languages",
                "under",
                "the",
                "same",
                "family",
                "have",
                "similar",
                "representations",
                "in",
                "multilingual",
                "models.",
                "Hence,",
                "we",
                "put",
                "together",
                "translations",
                "and",
                "transliterations",
                "from",
                "related",
                "languages",
                "within",
                "the",
                "same",
                "language",
                "family",
                "to",
                "achieve",
                "better",
                "performance.",
                "This",
                "will",
                "also",
                "help",
                "with",
                "better",
                "use",
                "of",
                "the",
                "vo-cabulary",
                "corpora",
                "from",
                "the",
                "low-resource",
                "languages.",
                "We",
                "also",
                "study",
                "the",
                "impact",
                "of",
                "translation",
                "and",
                "transliteration",
                "on",
                "languages",
                "outside",
                "the",
                "family",
                "of",
                "the",
                "target",
                "language.",
                "Since",
                "the",
                "cross-family",
                "language",
                "transfer",
                "degraded",
                "the",
                "QA",
                "performance,",
                "we",
                "introduce",
                "a",
                "contrastive",
                "loss",
                "#TARGET_REF",
                "between",
                "the",
                "translated",
                "pairs",
                "to",
                "help",
                "retain",
                "or",
                "improve",
                "the",
                "original",
                "performance",
                "by",
                "encouraging",
                "the",
                "embeddings",
                "from",
                "all",
                "languages",
                "to",
                "be",
                "similar",
                "regardless",
                "of",
                "the",
                "family",
                "group.",
                "Thus,",
                "the",
                "contributions",
                "of",
                "the",
                "paper",
                "are",
                "three-fold:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The choice of languages used for translation and transliteration is critical. #REF showed that languages under the same family have similar representations in multilingual models. Hence, we put together translations and transliterations from related languages within the same language family to achieve better performance. This will also help with better use of the vo-cabulary corpora from the low-resource languages. We also study the impact of translation and transliteration on languages outside the family of the target language. Since the cross-family language transfer degraded the QA performance, we introduce a contrastive loss #TARGET_REF between the translated pairs to help retain or improve the original performance by encouraging the embeddings from all languages to be similar regardless of the family group. Thus, the contributions of the paper are three-fold:",
        "output": "{\"INFO\": [\"we introduce a contrastive loss #TARGET_REF between the translated pairs to help retain or improve the original performance by encouraging the embeddings from all languages to be similar regardless of the family group.\"], \"PERCEPT\": [\"Since the cross-family language transfer degraded the QA performance,\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "More",
                "recently,",
                "#REF",
                "run",
                "a",
                "large-scale",
                "comparison",
                "of",
                "MT",
                "metrics,",
                "including",
                "BERTScore",
                "using",
                "a",
                "large",
                "dataset",
                "of",
                "translations",
                "with",
                "human",
                "judgments,",
                "they",
                "find",
                "that",
                "BERTScore's",
                "performance",
                "is",
                "middle-of-the-road,",
                "though",
                "better",
                "than",
                "BLEU,",
                "and",
                "recommend",
                "COMET",
                "#TARGET_REF",
                "for",
                "general",
                "use."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                2,
                2,
                2
            ]
        },
        "input": "More recently, #REF run a large-scale comparison of MT metrics, including BERTScore using a large dataset of translations with human judgments, they find that BERTScore's performance is middle-of-the-road, though better than BLEU, and recommend COMET #TARGET_REF for general use.",
        "output": "{\"INFO\": [\"COMET #TARGET_REF\"], \"PERCEPT\": [\"More recently, #REF run a large-scale comparison of MT metrics,\", \"they find that BERTScore's performance is middle-of-the-road,\", \"and recommend\", \"for general use.\"], \"BACK\": [\"including BERTScore using a large dataset of translations with human judgments,\", \"though better than BLEU,\"]}"
    },
    {
        "gold": {
            "text": [
                "Long",
                "Range",
                "Arena",
                "#REF",
                ")",
                "is",
                "a",
                "recently",
                "established",
                "benchmark",
                "for",
                "evaluating",
                "the",
                "ability",
                "of",
                "Transformer",
                "variants",
                "to",
                "handle",
                "long",
                "sequences.",
                "It",
                "comprises",
                "of",
                "multiple",
                "text",
                "classification",
                "tasks",
                "with",
                "inputs",
                "containing",
                "thousands",
                "of",
                "tokens",
                "(Table",
                "1).",
                "In",
                "ListOps",
                "#REF",
                ",",
                "given",
                "a",
                "sequence",
                "of",
                "operations",
                "on",
                "single-digit",
                "integers,",
                "the",
                "model",
                "predicts",
                "a",
                "single-digit",
                "solution",
                "modeled",
                "as",
                "10-way",
                "classification.",
                "IMDb",
                "movie",
                "reviews",
                "#TARGET_REF",
                "is",
                "a",
                "character-level",
                "binary",
                "sentiment",
                "classification",
                "task.",
                "Lastly,",
                "in",
                "the",
                "ACL",
                "Anthology",
                "Network",
                "(AAN)",
                "#REF",
                "task,",
                "a",
                "character-level",
                "model",
                "classifies",
                "if",
                "there",
                "is",
                "a",
                "citation",
                "between",
                "a",
                "pair",
                "of",
                "papers."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Long Range Arena #REF ) is a recently established benchmark for evaluating the ability of Transformer variants to handle long sequences. It comprises of multiple text classification tasks with inputs containing thousands of tokens (Table 1). In ListOps #REF , given a sequence of operations on single-digit integers, the model predicts a single-digit solution modeled as 10-way classification. IMDb movie reviews #TARGET_REF is a character-level binary sentiment classification task. Lastly, in the ACL Anthology Network (AAN) #REF task, a character-level model classifies if there is a citation between a pair of papers.",
        "output": "{\"INFO\": [\"IMDb movie reviews #TARGET_REF is a character-level binary sentiment classification task.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "word",
                "embeddings",
                "extracted",
                "from",
                "the",
                "first",
                "layer",
                "of",
                "the",
                "GPT2",
                "language",
                "model",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• word embeddings extracted from the first layer of the GPT2 language model #TARGET_REF .",
        "output": "{\"INFO\": [\"GPT2 language model #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"word embeddings extracted from the first layer of the\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "combine",
                "the",
                "benefits",
                "of",
                "the",
                "message-passing",
                "paradigm",
                "with",
                "the",
                "benefits",
                "of",
                "the",
                "parameterized",
                "approach",
                "to",
                "build",
                "a",
                "more",
                "efficient,",
                "but",
                "easily",
                "extensible",
                "system,",
                "called",
                "PRINCITRAN.",
                "1",
                "Our",
                "work",
                "extends",
                "that",
                "of",
                "#REF",
                "and",
                "#TARGET_REF",
                "in",
                "that",
                "it",
                "provides",
                "a",
                "parameterization",
                "mechanism",
                "along",
                "the",
                "lines",
                "of",
                "Dorr",
                "(1993b)",
                "that",
                "allows",
                "the",
                "system",
                "to",
                "be",
                "ported",
                "to",
                "languages",
                "other",
                "than",
                "English.",
                "We",
                "focus",
                "particularly",
                "on",
                "the",
                "problem",
                "of",
                "processing",
                "head-final",
                "languages",
                "such",
                "as",
                "Korean.",
                "The",
                "algorithm",
                "has",
                "been",
                "implemented",
                "in",
                "C++",
                "and",
                "successfully",
                "tested",
                "on",
                "well-known,",
                "translationally",
                "divergent",
                "sentences."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We combine the benefits of the message-passing paradigm with the benefits of the parameterized approach to build a more efficient, but easily extensible system, called PRINCITRAN. 1 Our work extends that of #REF and #TARGET_REF in that it provides a parameterization mechanism along the lines of Dorr (1993b) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final languages such as Korean. The algorithm has been implemented in C++ and successfully tested on well-known, translationally divergent sentences.",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"We combine the benefits of the message-passing paradigm with the benefits of the parameterized approach to build a more efficient, but easily extensible system, called PRINCITRAN.\", \"Our work extends that of\", \"in that it provides a parameterization mechanism along the lines of Dorr (1993b) that allows the system to be ported to languages other than English. We focus particularly on the problem of processing head-final languages such as Korean.\"], \"BACK\": [\"#REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "our",
                "knowledge",
                "these",
                "are",
                "the",
                "first",
                "experiments",
                "which",
                "objectively",
                "demonstrate",
                "the",
                "utility",
                "of",
                "punctuation",
                "for",
                "resolving",
                "syntactic",
                "ambiguity",
                "and",
                "improving",
                "parser",
                "coverage.",
                "They",
                "extend",
                "work",
                "by",
                "#REF",
                "and",
                "#TARGET_REF",
                "by",
                "applying",
                "a",
                "wide-coverage",
                "text",
                "grammar",
                "to",
                "substantial",
                "quantities",
                "of",
                "naturally-punctuated",
                "text",
                "and",
                "by",
                "quantifying",
                "the",
                "contribution",
                "of",
                "punctuation",
                "to",
                "ambiguity",
                "resolution",
                "in",
                "a",
                "well-defined",
                "probabilistic",
                "parse",
                "selection",
                "model."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To our knowledge these are the first experiments which objectively demonstrate the utility of punctuation for resolving syntactic ambiguity and improving parser coverage. They extend work by #REF and #TARGET_REF by applying a wide-coverage text grammar to substantial quantities of naturally-punctuated text and by quantifying the contribution of punctuation to ambiguity resolution in a well-defined probabilistic parse selection model.",
        "output": "{\"INFO\": [\"#TARGET_REF by applying a wide-coverage text grammar to substantial quantities of naturally-punctuated text and by quantifying the contribution of punctuation to ambiguity resolution in a well-defined probabilistic parse selection model.\"], \"PERCEPT\": [\"To our knowledge these are the first experiments which objectively demonstrate the utility of punctuation for resolving syntactic ambiguity and improving parser coverage.\"], \"BACK\": [\"They extend work by #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "DeKo",
                "is",
                "implemented",
                "as",
                "a",
                "series",
                "of",
                "finite-state",
                "transducers,",
                "using",
                "the",
                "FST-suite",
                "provided",
                "by",
                "AT&amp,T",
                "#TARGET_REF",
                ".",
                "A",
                "more",
                "detailed",
                "description",
                "of",
                "the",
                "architecture",
                "is",
                "given",
                "in",
                "#REF",
                "and",
                "examples",
                "for",
                "the",
                "rule",
                "format",
                "are",
                "provided",
                "in",
                "#REF",
                ".",
                "We",
                "need",
                "to",
                "model",
                "three",
                "types",
                "of",
                "rules:"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "DeKo is implemented as a series of finite-state transducers, using the FST-suite provided by AT&amp,T #TARGET_REF . A more detailed description of the architecture is given in #REF and examples for the rule format are provided in #REF . We need to model three types of rules:",
        "output": "{\"INFO\": [\"FST-suite provided by AT&amp,T #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"DeKo is implemented as a series of finite-state transducers, using the\"]}"
    },
    {
        "gold": {
            "text": [
                "With",
                "the",
                "same",
                "parameters",
                "as",
                "for",
                "English,",
                "we",
                "used",
                "language-specific",
                "BERT",
                "models",
                "from",
                "Huggingface",
                "transformers",
                "#TARGET_REF",
                "for",
                "the",
                "Arabic,",
                "Chinese,",
                "Dutch,",
                "Finnish,",
                "German",
                "and",
                "Turkish",
                "datasets",
                "with",
                "5-fold",
                "cross-validation.",
                "The",
                "annotated",
                "Finnish",
                "dataset",
                "achieves",
                "an",
                "f1",
                "score",
                "of",
                "0.51.",
                "The",
                "projected",
                "annotations",
                "achieve",
                "slightly",
                "worse",
                "f1",
                "scores",
                "than",
                "the",
                "annotated",
                "dataset",
                "at",
                "0.45",
                "for",
                "Finnish",
                "(see",
                "table",
                "9).",
                "The",
                "other",
                "datasets",
                "achieve",
                "similar",
                "f1",
                "scores,",
                "with",
                "the",
                "Germanic",
                "languages",
                "of",
                "German",
                "and",
                "Dutch",
                "achieving",
                "almost",
                "as",
                "high",
                "scores",
                "as",
                "the",
                "original",
                "English",
                "dataset.",
                "This",
                "is",
                "likely",
                "a",
                "reflection",
                "of",
                "typological,",
                "cultural,",
                "and",
                "linguistic",
                "similarities",
                "between",
                "the",
                "languages",
                "making",
                "the",
                "translation",
                "to",
                "begin",
                "with",
                "more",
                "similar",
                "to",
                "the",
                "original",
                "and",
                "therefore",
                "minimizing",
                "information",
                "loss."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "With the same parameters as for English, we used language-specific BERT models from Huggingface transformers #TARGET_REF for the Arabic, Chinese, Dutch, Finnish, German and Turkish datasets with 5-fold cross-validation. The annotated Finnish dataset achieves an f1 score of 0.51. The projected annotations achieve slightly worse f1 scores than the annotated dataset at 0.45 for Finnish (see table 9). The other datasets achieve similar f1 scores, with the Germanic languages of German and Dutch achieving almost as high scores as the original English dataset. This is likely a reflection of typological, cultural, and linguistic similarities between the languages making the translation to begin with more similar to the original and therefore minimizing information loss.",
        "output": "{\"INFO\": [\"Huggingface transformers #TARGET_REF\"], \"PERCEPT\": [\"With the same parameters as for English, we used language-specific BERT models from\", \"for the Arabic, Chinese, Dutch, Finnish, German and Turkish datasets with 5-fold cross-validation.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "pre-trained",
                "BERT-large",
                "uncased",
                "(24-layer,",
                "1024-hidden,",
                "16-heads,",
                "340M",
                "parameters,",
                "whole",
                "word",
                "masking)",
                "#REF",
                "for",
                "our",
                "mention",
                "and",
                "context",
                "encoder.",
                "All",
                "BERT",
                "hyperparameters",
                "are",
                "unchanged.",
                "The",
                "entity",
                "embedding",
                "matrix",
                "contains",
                "10M",
                "(UFET",
                "type",
                "set)",
                "or",
                "60M",
                "(Wiki",
                "type",
                "set)",
                "parameters.",
                "We",
                "train",
                "our",
                "models",
                "with",
                "batch",
                "size",
                "32",
                "(8",
                "×",
                "4",
                "gradient",
                "accumulation",
                "steps)",
                "using",
                "one",
                "NVIDIA",
                "V100",
                "GPU",
                "for",
                "a",
                "week.",
                "We",
                "use",
                "the",
                "AdamW",
                "optimizer",
                "#REF",
                "with",
                "learning",
                "rate",
                "2e-5",
                "for",
                "BERT",
                "parameters",
                "and",
                "learning",
                "rate",
                "1e-3",
                "for",
                "the",
                "type",
                "embedding",
                "matrix.",
                "We",
                "use",
                "Hugging-Face's",
                "Transformers",
                "library",
                "#TARGET_REF",
                "Table",
                "2:",
                "\"Out-of-the-box\"",
                "accuracy",
                "on",
                "the",
                "CAP",
                "development",
                "set.",
                "We",
                "compare",
                "performance",
                "of",
                "BERT-base,",
                "BERT-large,",
                "and",
                "the",
                "mention",
                "and",
                "context",
                "representation",
                "of",
                "the",
                "embedding",
                "model",
                "with",
                "ours,",
                "using",
                "just",
                "cosine",
                "similarity",
                "and",
                "no",
                "classifier."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We use pre-trained BERT-large uncased (24-layer, 1024-hidden, 16-heads, 340M parameters, whole word masking) #REF for our mention and context encoder. All BERT hyperparameters are unchanged. The entity embedding matrix contains 10M (UFET type set) or 60M (Wiki type set) parameters. We train our models with batch size 32 (8 × 4 gradient accumulation steps) using one NVIDIA V100 GPU for a week. We use the AdamW optimizer #REF with learning rate 2e-5 for BERT parameters and learning rate 1e-3 for the type embedding matrix. We use Hugging-Face's Transformers library #TARGET_REF Table 2: \"Out-of-the-box\" accuracy on the CAP development set. We compare performance of BERT-base, BERT-large, and the mention and context representation of the embedding model with ours, using just cosine similarity and no classifier.",
        "output": "{\"INFO\": [\"Hugging-Face's Transformers library #TARGET_REF\"], \"PERCEPT\": [\"We use\", \"We compare performance of BERT-base, BERT-large, and the mention and context representation of the embedding model with ours, using just cosine similarity and no classifier.\"], \"BACK\": [\"Table 2: \\\"Out-of-the-box\\\" accuracy on the CAP development set.\"]}"
    },
    {
        "gold": {
            "text": [
                "DeKo",
                "(for",
                "Derivation",
                "and",
                "Komposition,",
                "funded",
                "by",
                "the",
                "state",
                "of",
                "Baden-Württemberg",
                "from",
                "Jan",
                "2000",
                "-June",
                "2001)",
                "is",
                "designed",
                "as",
                "a",
                "German",
                "word",
                "formation",
                "component",
                "in",
                "a",
                "larger",
                "computational",
                "linguistic",
                "application.",
                "13",
                "It",
                "was",
                "done",
                "on",
                "a",
                "much",
                "smaller",
                "scale",
                "than",
                "Word",
                "Manager",
                "and",
                "is",
                "not",
                "used",
                "in",
                "any",
                "commercial",
                "products.",
                "In",
                "this",
                "tutorial",
                "we",
                "focus",
                "on",
                "some",
                "basic",
                "design",
                "features",
                "-especially",
                "where",
                "they",
                "differ",
                "from",
                "Word",
                "Manager's",
                "features.",
                "More",
                "details",
                "can",
                "be",
                "found",
                "in",
                "#TARGET_REF",
                "and",
                "at",
                "http://www.ims.uni-stuttgart.de/projekte/DeKo/.",
                "Here",
                "we",
                "want",
                "to",
                "concentrate",
                "on",
                "the",
                "corpus-based",
                "acquisition",
                "of",
                "data,",
                "the",
                "item-and-arrangement",
                "design,",
                "analysis",
                "and",
                "structure,",
                "and",
                "the",
                "interaction",
                "between",
                "DeKo",
                "and",
                "the",
                "lexicon.",
                "Although",
                "the",
                "DeKo",
                "project",
                "proper",
                "is",
                "finished,",
                "work",
                "is",
                "still",
                "being",
                "done",
                "to",
                "improve",
                "the",
                "program",
                "and",
                "especially",
                "to",
                "extend",
                "the",
                "lexicon."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "DeKo (for Derivation and Komposition, funded by the state of Baden-Württemberg from Jan 2000 -June 2001) is designed as a German word formation component in a larger computational linguistic application. 13 It was done on a much smaller scale than Word Manager and is not used in any commercial products. In this tutorial we focus on some basic design features -especially where they differ from Word Manager's features. More details can be found in #TARGET_REF and at http://www.ims.uni-stuttgart.de/projekte/DeKo/. Here we want to concentrate on the corpus-based acquisition of data, the item-and-arrangement design, analysis and structure, and the interaction between DeKo and the lexicon. Although the DeKo project proper is finished, work is still being done to improve the program and especially to extend the lexicon.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"More details can be found in #TARGET_REF\"], \"BACK\": [\"and at http://www.ims.uni-stuttgart.de/projekte/DeKo/.\"]}"
    },
    {
        "gold": {
            "text": [
                "Totale",
                "toolkit",
                "#REF",
                "was",
                "used",
                "to",
                "POS",
                "tag",
                "#TARGET_REF",
                "and",
                "lemmatize",
                "#REF",
                "words",
                "in",
                "the",
                "bilingual",
                "word",
                "list,",
                "POS",
                "tagger",
                "was",
                "also",
                "used",
                "in",
                "automatic",
                "paradigm",
                "classifying,",
                "see",
                "chapter",
                "3.3.1",
                "for",
                "further",
                "description."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Totale toolkit #REF was used to POS tag #TARGET_REF and lemmatize #REF words in the bilingual word list, POS tagger was also used in automatic paradigm classifying, see chapter 3.3.1 for further description.",
        "output": "{\"INFO\": [\"POS tag #TARGET_REF\"], \"PERCEPT\": [\"Totale toolkit #REF was used to\"], \"BACK\": [\"and lemmatize #REF words in the bilingual word list, POS tagger was also used in automatic paradigm classifying, see chapter 3.3.1 for further description.\"]}"
    },
    {
        "gold": {
            "text": [
                "Returning",
                "to",
                "the",
                "different",
                "approaches",
                "of",
                "handling",
                "Arabic",
                "text.",
                "As",
                "discussed",
                "in",
                "the",
                "previous",
                "sections",
                "letter",
                "normalization",
                "and",
                "transliteration",
                "are",
                "examples",
                "of",
                "the",
                "simplification",
                "approach.",
                "For",
                "example,",
                "letter",
                "normalization",
                "is",
                "commonly",
                "applied",
                "to",
                "reduce",
                "the",
                "noise",
                "and",
                "sparsity",
                "in",
                "the",
                "data",
                "#TARGET_REF",
                ".",
                "For",
                "transliteration,",
                "Ameur",
                "et",
                "al.",
                "(",
                "2017)",
                "applied",
                "a",
                "bidirectional",
                "attention-based",
                "encoder-decoder",
                "model",
                "for",
                "the",
                "task",
                "of",
                "machine",
                "transliteration",
                "between",
                "Arabic",
                "and",
                "English."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Returning to the different approaches of handling Arabic text. As discussed in the previous sections letter normalization and transliteration are examples of the simplification approach. For example, letter normalization is commonly applied to reduce the noise and sparsity in the data #TARGET_REF . For transliteration, Ameur et al. ( 2017) applied a bidirectional attention-based encoder-decoder model for the task of machine transliteration between Arabic and English.",
        "output": "{\"INFO\": [\"data #TARGET_REF\"], \"PERCEPT\": [\"For example, letter normalization is commonly applied to reduce the noise and sparsity in the\"], \"BACK\": [\"Returning to the different approaches of handling Arabic text.\", \"letter normalization and transliteration are examples of the simplification approach.\"]}"
    },
    {
        "gold": {
            "text": [
                "#REF",
                ".",
                "Further,",
                "the",
                "LIGHT",
                "dataset",
                "is",
                "crowdsourced",
                "and",
                "contains",
                "data",
                "biases",
                "that",
                "can",
                "be",
                "attributed",
                "to",
                "the",
                "crowdworkers",
                "tasked",
                "with",
                "creating",
                "the",
                "data.",
                "Dinan",
                "et",
                "al.",
                "(",
                "2020)",
                "provides",
                "an",
                "in",
                "depth",
                "discussion",
                "regarding",
                "the",
                "inherent",
                "dataset",
                "biases,",
                "such",
                "as",
                "gender",
                "bias",
                "in",
                "the",
                "distribution",
                "of",
                "characters,",
                "in",
                "LIGHT",
                "and",
                "techniques",
                "to",
                "mitigate",
                "them-we",
                "follow",
                "these",
                "methods",
                "to",
                "reduce",
                "their",
                "effects",
                "on",
                "both",
                "the",
                "environment",
                "generation",
                "and",
                "agent",
                "training",
                "procedures.",
                "The",
                "LIGHT",
                "environment",
                "further",
                "allows",
                "us",
                "to",
                "factorize",
                "the",
                "overall",
                "action",
                "space",
                "A",
                "into",
                "A",
                "as",
                "the",
                "set",
                "of",
                "possible",
                "textual",
                "actions",
                "or",
                "commands",
                "(e.g.",
                "get",
                "sword,",
                "steal",
                "coins",
                "from",
                "merchant),",
                "and",
                "U",
                "as",
                "the",
                "set",
                "of",
                "possible",
                "dialogues",
                "that",
                "can",
                "be",
                "uttered",
                "by",
                "an",
                "agent,",
                "thus",
                "making",
                "it",
                "a",
                "factored",
                "POMDP",
                "#TARGET_REF",
                ".",
                "This",
                "in",
                "turn",
                "means",
                "that,",
                "for",
                "a",
                "given",
                "quest",
                "q,",
                "each",
                "expert",
                "human",
                "demonstration",
                "D(q)",
                "=",
                "α",
                "*",
                "0",
                ",",
                "α",
                "*",
                "1",
                "...α",
                "*",
                "n",
                "can",
                "be",
                "factorized",
                "into",
                "two",
                "sub-sequences",
                "of",
                "expert",
                "demonstrations",
                "of",
                "actions",
                "and",
                "dialogue",
                "D",
                "A",
                "(q)",
                "=",
                "a",
                "*",
                "0",
                ",",
                "a",
                "*",
                "1",
                ",",
                "...a",
                "*",
                "n",
                "and",
                "D",
                "U",
                "(q)",
                "=",
                "u",
                "*",
                "0",
                ",",
                "u",
                "*",
                "1",
                ",",
                "...u",
                "*",
                "m",
                "respectively.",
                "The",
                "factorized",
                "action",
                "spaces",
                "A",
                "and",
                "U",
                "are",
                "constructed",
                "by",
                "enumerating",
                "all",
                "possible",
                "actions/dialogue",
                "utterances",
                "in",
                "the",
                "all",
                "human",
                "demonstrations",
                "in",
                "LIGHT-quests."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "#REF . Further, the LIGHT dataset is crowdsourced and contains data biases that can be attributed to the crowdworkers tasked with creating the data. Dinan et al. ( 2020) provides an in depth discussion regarding the inherent dataset biases, such as gender bias in the distribution of characters, in LIGHT and techniques to mitigate them-we follow these methods to reduce their effects on both the environment generation and agent training procedures. The LIGHT environment further allows us to factorize the overall action space A into A as the set of possible textual actions or commands (e.g. get sword, steal coins from merchant), and U as the set of possible dialogues that can be uttered by an agent, thus making it a factored POMDP #TARGET_REF . This in turn means that, for a given quest q, each expert human demonstration D(q) = α * 0 , α * 1 ...α * n can be factorized into two sub-sequences of expert demonstrations of actions and dialogue D A (q) = a * 0 , a * 1 , ...a * n and D U (q) = u * 0 , u * 1 , ...u * m respectively. The factorized action spaces A and U are constructed by enumerating all possible actions/dialogue utterances in the all human demonstrations in LIGHT-quests.",
        "output": "{\"INFO\": [\"POMDP #TARGET_REF\"], \"PERCEPT\": [\"This in turn means that,\"], \"BACK\": [\"The LIGHT environment further allows us to factorize the overall action space A into A as the set of possible textual actions or commands\", \"and U as the set of possible dialogues that can be uttered by an agent, thus making it a factored\", \"for a given quest q, each expert human demonstration D(q) = \\u03b1 * 0 , \\u03b1 * 1 ...\\u03b1 * n can be factorized into two sub-sequences of expert demonstrations of actions and dialogue D A (q) = a * 0 , a * 1 , ...a * n and D U (q) = u * 0 , u * 1 , ...u * m respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "BLEU",
                "Previous",
                "definition",
                "generation",
                "studies",
                "#REF",
                "used",
                "the",
                "BLEU",
                "#TARGET_REF",
                "score",
                "to",
                "measure",
                "the",
                "closeness",
                "of",
                "generated",
                "results",
                "to",
                "the",
                "standard",
                "answers,",
                "and",
                "to",
                "evaluate",
                "the",
                "accuracy",
                "of",
                "results.",
                "Since",
                "the",
                "English",
                "test",
                "set",
                "is",
                "manually",
                "annotated,",
                "we",
                "calculate",
                "the",
                "BLEU",
                "score",
                "of",
                "both",
                "complex",
                "and",
                "simple",
                "definitions,",
                "respectively."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "BLEU Previous definition generation studies #REF used the BLEU #TARGET_REF score to measure the closeness of generated results to the standard answers, and to evaluate the accuracy of results. Since the English test set is manually annotated, we calculate the BLEU score of both complex and simple definitions, respectively.",
        "output": "{\"INFO\": [\"the BLEU #TARGET_REF score\"], \"PERCEPT\": [\"Since the English test set is manually annotated, we calculate the BLEU score of both complex and simple definitions, respectively.\"], \"BACK\": [\"Previous definition generation studies #REF used\", \"to measure the closeness of generated results to the standard answers, and to evaluate the accuracy of results.\"]}"
    },
    {
        "gold": {
            "text": [
                "with",
                "additional",
                "pre-training",
                "on",
                "adversarial",
                "tasks.",
                "It",
                "also",
                "introduced",
                "a",
                "Language",
                "Arbitration",
                "Framework",
                "(LAF),",
                "which",
                "consolidated",
                "the",
                "embedding",
                "representations",
                "across",
                "languages",
                "using",
                "properties",
                "of",
                "translation.",
                "Crosslingual",
                "manifold",
                "mixup",
                "(X-Mixup)",
                "#REF",
                "achieved",
                "better",
                "cross-lingual",
                "transfer",
                "by",
                "calibrating",
                "the",
                "representation",
                "discrepancy,",
                "which",
                "resulted",
                "in",
                "a",
                "compromised",
                "representation",
                "for",
                "target",
                "languages.",
                "It",
                "was",
                "shown",
                "that",
                "the",
                "multilingual",
                "pretraining",
                "process",
                "can",
                "be",
                "improved",
                "by",
                "implementing",
                "X-Mixup",
                "on",
                "parallel",
                "data.",
                "Contrastive",
                "Language-Image",
                "pre-training",
                "(CLIP)",
                "#TARGET_REF",
                "introduced",
                "an",
                "efficient",
                "way",
                "to",
                "learn",
                "scalable",
                "image",
                "representations",
                "with",
                "natural",
                "language",
                "supervision.",
                "Drawing",
                "inspiration",
                "from",
                "ConVIRT",
                "#REF",
                ",",
                "CLIP",
                "used",
                "a",
                "contrastive",
                "objective",
                "that",
                "maximizes",
                "the",
                "cosine",
                "similarity",
                "of",
                "the",
                "correct",
                "pairs",
                "of",
                "images",
                "and",
                "text,",
                "while",
                "minimizing",
                "the",
                "same",
                "for",
                "incorrect",
                "pairs.",
                "Building",
                "upon",
                "the",
                "work",
                "of",
                "#REF",
                ",",
                "we",
                "show",
                "that",
                "translations",
                "of",
                "a",
                "small-scale",
                "dataset",
                "into",
                "cross-family",
                "languages",
                "could",
                "degrade",
                "the",
                "QA",
                "performance.",
                "To",
                "overcome",
                "this",
                "problem,",
                "we",
                "propose",
                "multilingual",
                "contrastive",
                "training",
                "to",
                "encourage",
                "cross-lingual",
                "invariance.",
                "Our",
                "approach",
                "is",
                "relatively",
                "simpler",
                "compared",
                "to",
                "adversarial",
                "training",
                "and",
                "LAF",
                "used",
                "in",
                "#REF",
                ".",
                "Though",
                "the",
                "proposed",
                "contrastive",
                "loss",
                "has",
                "a",
                "similar",
                "objective",
                "to",
                "the",
                "pretraining",
                "loss",
                "in",
                "#REF",
                ",",
                "there",
                "are",
                "subtle",
                "differences",
                "because",
                "we",
                "use",
                "it",
                "in",
                "multi-task",
                "learning",
                "setup",
                "along",
                "with",
                "the",
                "original",
                "task",
                "loss",
                "for",
                "finetuning."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "with additional pre-training on adversarial tasks. It also introduced a Language Arbitration Framework (LAF), which consolidated the embedding representations across languages using properties of translation. Crosslingual manifold mixup (X-Mixup) #REF achieved better cross-lingual transfer by calibrating the representation discrepancy, which resulted in a compromised representation for target languages. It was shown that the multilingual pretraining process can be improved by implementing X-Mixup on parallel data. Contrastive Language-Image pre-training (CLIP) #TARGET_REF introduced an efficient way to learn scalable image representations with natural language supervision. Drawing inspiration from ConVIRT #REF , CLIP used a contrastive objective that maximizes the cosine similarity of the correct pairs of images and text, while minimizing the same for incorrect pairs. Building upon the work of #REF , we show that translations of a small-scale dataset into cross-family languages could degrade the QA performance. To overcome this problem, we propose multilingual contrastive training to encourage cross-lingual invariance. Our approach is relatively simpler compared to adversarial training and LAF used in #REF . Though the proposed contrastive loss has a similar objective to the pretraining loss in #REF , there are subtle differences because we use it in multi-task learning setup along with the original task loss for finetuning.",
        "output": "{\"INFO\": [\"Contrastive Language-Image pre-training (CLIP) #TARGET_REF\", \"learn scalable image representations with natural language supervision.\", \"CLIP used a contrastive objective that maximizes the cosine similarity of the correct pairs of images and text, while minimizing the same for incorrect pairs.\"], \"PERCEPT\": [\"introduced an efficient way to\", \"Drawing inspiration from ConVIRT #REF\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "goal",
                "of",
                "SDG",
                "task",
                "is",
                "to",
                "generate",
                "simple",
                "definitions",
                "for",
                "languages",
                "that",
                "lack",
                "learner's",
                "dictionary.",
                "For",
                "example,",
                "Chinese",
                "as",
                "Second",
                "Language",
                "(CSL)",
                "learners",
                "do",
                "not",
                "have",
                "suitable",
                "dictionaries.",
                "As",
                "#TARGET_REF",
                "pointed",
                "out,",
                "since",
                "the",
                "difficulty",
                "of",
                "definitions",
                "is",
                "not",
                "considered,",
                "the",
                "existing",
                "dictionary",
                "cannot",
                "meet",
                "CSL",
                "learner's",
                "needs."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The goal of SDG task is to generate simple definitions for languages that lack learner's dictionary. For example, Chinese as Second Language (CSL) learners do not have suitable dictionaries. As #TARGET_REF pointed out, since the difficulty of definitions is not considered, the existing dictionary cannot meet CSL learner's needs.",
        "output": "{\"INFO\": [\"As #TARGET_REF pointed out, since the difficulty of definitions is not considered, the existing dictionary cannot meet CSL learner's needs.\"], \"PERCEPT\": [], \"BACK\": [\"The goal of SDG task is to generate simple definitions for languages that lack learner's dictionary. For example, Chinese as Second Language (CSL) learners do not have suitable dictionaries.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "section,",
                "we",
                "benchmark",
                "top-k",
                "attention",
                "in",
                "terms",
                "of",
                "time",
                "and",
                "memory,",
                "and",
                "compare",
                "it",
                "to",
                "vanilla",
                "attention,",
                "query-chunking",
                "without",
                "the",
                "top-k",
                "operation,",
                "and",
                "to",
                "Performer",
                "#TARGET_REF",
                ",",
                "as",
                "a",
                "representative",
                "of",
                "state-of-the-art",
                "linear",
                "attention",
                "variants.",
                "We",
                "separately",
                "benchmark",
                "(a)",
                "a",
                "single",
                "self-attention",
                "layer",
                "over",
                "long",
                "sequences,",
                "(b)",
                "a",
                "single",
                "feed-forward",
                "layer",
                "with",
                "a",
                "large",
                "feedforward",
                "dimension,",
                "and",
                "(c)",
                "a",
                "12-layer",
                "Transformer",
                "decoder",
                "with",
                "same",
                "architecture",
                "as",
                "BERT-base",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this section, we benchmark top-k attention in terms of time and memory, and compare it to vanilla attention, query-chunking without the top-k operation, and to Performer #TARGET_REF , as a representative of state-of-the-art linear attention variants. We separately benchmark (a) a single self-attention layer over long sequences, (b) a single feed-forward layer with a large feedforward dimension, and (c) a 12-layer Transformer decoder with same architecture as BERT-base #REF .",
        "output": "{\"INFO\": [\"Performer #TARGET_REF ,\"], \"PERCEPT\": [\"we benchmark top-k attention in terms of time and memory, and compare it to vanilla attention, query-chunking without the top-k operation, and to\", \"as a representative of state-of-the-art linear attention variants.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "training",
                "data",
                "include",
                "two",
                "public",
                "datasets:",
                "MNLI",
                "#TARGET_REF"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1
            ]
        },
        "input": "Our training data include two public datasets: MNLI #TARGET_REF",
        "output": "{\"INFO\": [\"MNLI #TARGET_REF\"], \"PERCEPT\": [\"Our training data include two public datasets:\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "gender-laden",
                "words:",
                "(1,",
                "2)",
                "Gender-Coded",
                "Word",
                "Prevalence:",
                "#REF",
                "define",
                "masculine-and-feminine-themed",
                "words",
                "from",
                "an",
                "experiment",
                "on",
                "job",
                "ads",
                "that",
                "discouraged",
                "female",
                "applicants.",
                "(3)",
                "Superlative",
                "Prevalence",
                "#REF",
                "assess",
                "the",
                "relative",
                "frequency",
                "of",
                "positive",
                "and",
                "negative",
                "superlatives",
                "used",
                "to",
                "describe",
                "male",
                "versus",
                "female",
                "job",
                "candidates",
                "in",
                "recommendation",
                "letters.",
                "We",
                "use",
                "an",
                "established",
                "set",
                "of",
                "superlative",
                "words",
                "#REF",
                ".",
                "(4)",
                "Gender-Laden",
                "Scoring:",
                "#TARGET_REF",
                "analyse",
                "32",
                "properties",
                "related",
                "to",
                "a",
                "set",
                "of",
                "norms",
                "to",
                "score",
                "2,311",
                "words",
                "based",
                "on",
                "their",
                "\"gender-ladenness\".",
                "(5)",
                "Connotation",
                "Frames:",
                "Sap",
                "et",
                "al.",
                "(",
                "2017)",
                "define",
                "linguistic",
                "markers",
                "of",
                "power",
                "and",
                "agency",
                "associated",
                "with",
                "female",
                "versus",
                "male",
                "characters",
                "in",
                "modern",
                "films.",
                "(6)",
                "NRC",
                "VAD",
                "Lexicon:",
                "Mohammad",
                "(2018)",
                "presents",
                "a",
                "lexicon",
                "of",
                "words",
                "coded",
                "by",
                "valence,",
                "arousal,",
                "and",
                "dominance",
                "whose",
                "interpretation",
                "may",
                "interact",
                "with",
                "gender.",
                "5",
                "Dimensionality",
                "Reduction",
                "We",
                "employ",
                "principal",
                "component",
                "analysis",
                "(PCA)",
                "on",
                "the",
                "six",
                "bias",
                "measures",
                "on",
                "real-world",
                "job",
                "ads",
                "to",
                "collapse",
                "them",
                "into",
                "interpretable",
                "components.",
                "We",
                "then",
                "replicate",
                "the",
                "PCA",
                "on",
                "synthetic",
                "job",
                "ads",
                "(zero-shot)",
                "and",
                "project",
                "all",
                "data",
                "points",
                "onto",
                "the",
                "first",
                "two",
                "principal",
                "components",
                "of",
                "real",
                "job",
                "ads",
                "and",
                "vice",
                "versa."
            ],
            "context": [
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "gender-laden words: (1, 2) Gender-Coded Word Prevalence: #REF define masculine-and-feminine-themed words from an experiment on job ads that discouraged female applicants. (3) Superlative Prevalence #REF assess the relative frequency of positive and negative superlatives used to describe male versus female job candidates in recommendation letters. We use an established set of superlative words #REF . (4) Gender-Laden Scoring: #TARGET_REF analyse 32 properties related to a set of norms to score 2,311 words based on their \"gender-ladenness\". (5) Connotation Frames: Sap et al. ( 2017) define linguistic markers of power and agency associated with female versus male characters in modern films. (6) NRC VAD Lexicon: Mohammad (2018) presents a lexicon of words coded by valence, arousal, and dominance whose interpretation may interact with gender. 5 Dimensionality Reduction We employ principal component analysis (PCA) on the six bias measures on real-world job ads to collapse them into interpretable components. We then replicate the PCA on synthetic job ads (zero-shot) and project all data points onto the first two principal components of real job ads and vice versa.",
        "output": "{\"INFO\": [\"(4) Gender-Laden Scoring: #TARGET_REF analyse 32 properties related to a set of norms to score 2,311 words based on their \\\"gender-ladenness\\\".\"], \"PERCEPT\": [\"gender-laden words:\", \"We employ principal component analysis (PCA) on the six bias measures on real-world job ads to collapse them into interpretable components.\"], \"BACK\": [\"(1, 2) Gender-Coded Word Prevalence:\", \"(3) Superlative Prevalence\", \"(5) Connotation Frames:\", \"(6) NRC VAD Lexicon:\"]}"
    },
    {
        "gold": {
            "text": [
                "At",
                "the",
                "answer",
                "level",
                "the",
                "top",
                "candidate",
                "sentences",
                "(up",
                "to",
                "10)",
                "returned",
                "by",
                "our",
                "system",
                "were",
                "compared",
                "against",
                "the",
                "review",
                "snippets",
                "as",
                "the",
                "gold",
                "standard.",
                "The",
                "review",
                "snippets",
                "were",
                "top",
                "review",
                "sentences",
                "returned",
                "by",
                "the",
                "system",
                "used",
                "by",
                "#TARGET_REF",
                "#REF",
                "Average",
                "ROUGE",
                "scores",
                "are",
                "reported",
                "in",
                "Table",
                "2.",
                "Both",
                "systems",
                "aim",
                "at",
                "providing",
                "the",
                "best",
                "candidate",
                "sentences.",
                "Looking",
                "at",
                "the",
                "precision",
                "scores,",
                "it",
                "is",
                "clear",
                "that",
                "our",
                "system",
                "performance",
                "is",
                "good",
                "in",
                "terms",
                "of",
                "returning",
                "relevant",
                "sentences,",
                "similar",
                "in",
                "content",
                "to",
                "the",
                "gold",
                "standard.",
                "The",
                "sim",
                "method",
                "still",
                "is",
                "the",
                "best",
                "performing",
                "method.",
                "We",
                "say",
                "this",
                "because,",
                "ROUGE-L",
                "looks",
                "for",
                "the",
                "longest",
                "common",
                "sub",
                "se-",
                "Looking",
                "at",
                "the",
                "similarity",
                "scores,",
                "it",
                "is",
                "clear",
                "that",
                "the",
                "candidate",
                "sentences",
                "returned",
                "by",
                "our",
                "system",
                "is",
                "almost",
                "exactly",
                "similar",
                "to",
                "the",
                "sentences",
                "returned",
                "by",
                "#REF",
                ".",
                "Once",
                "again",
                "our",
                "system",
                "is",
                "able",
                "to",
                "perform",
                "on",
                "par",
                "with",
                "a",
                "more",
                "complicated",
                "system."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "At the answer level the top candidate sentences (up to 10) returned by our system were compared against the review snippets as the gold standard. The review snippets were top review sentences returned by the system used by #TARGET_REF #REF Average ROUGE scores are reported in Table 2. Both systems aim at providing the best candidate sentences. Looking at the precision scores, it is clear that our system performance is good in terms of returning relevant sentences, similar in content to the gold standard. The sim method still is the best performing method. We say this because, ROUGE-L looks for the longest common sub se- Looking at the similarity scores, it is clear that the candidate sentences returned by our system is almost exactly similar to the sentences returned by #REF . Once again our system is able to perform on par with a more complicated system.",
        "output": "{\"INFO\": [\"the system used by #TARGET_REF\"], \"PERCEPT\": [\"At the answer level the top candidate sentences (up to 10) returned by our system were compared against the review snippets as the gold standard.\", \"Both systems aim at providing the best candidate sentences. Looking at the precision scores, it is clear that our system performance is good in terms of returning relevant sentences, similar in content to the gold standard.\"], \"BACK\": [\"The review snippets were top review sentences returned by\", \"#REF Average ROUGE scores are reported in Table 2.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "oddest",
                "feature",
                "of",
                "MMB's",
                "breath-group",
                "work,",
                "stretching",
                "as",
                "it",
                "did",
                "over",
                "many",
                "years",
                "was",
                "that",
                "it",
                "referred",
                "constantly",
                "to",
                "breathing,",
                "but",
                "nothing",
                "ever",
                "rested",
                "on",
                "that:",
                "partitions",
                "were",
                "always",
                "inserted",
                "into",
                "text",
                "intuitively",
                "in",
                "a",
                "way",
                "that,",
                "to",
                "me",
                "at",
                "least,",
                "corresponded",
                "more",
                "naturally",
                "to",
                "the",
                "criteria",
                "just",
                "listed",
                "#TARGET_REF",
                ".",
                "Finally,",
                "of",
                "course,",
                "it",
                "would",
                "be",
                "overbold",
                "to",
                "assert",
                "that",
                "there",
                "will",
                "never",
                "be",
                "applications",
                "of",
                "Greek",
                "rhetorical",
                "figures",
                "to",
                "the",
                "computer",
                "understanding",
                "of",
                "natural",
                "language,",
                "but",
                "none",
                "have",
                "as",
                "yet",
                "emerged,",
                "except",
                "their",
                "explicit",
                "and",
                "obvious",
                "use",
                "as",
                "forms",
                "of",
                "expression."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The oddest feature of MMB's breath-group work, stretching as it did over many years was that it referred constantly to breathing, but nothing ever rested on that: partitions were always inserted into text intuitively in a way that, to me at least, corresponded more naturally to the criteria just listed #TARGET_REF . Finally, of course, it would be overbold to assert that there will never be applications of Greek rhetorical figures to the computer understanding of natural language, but none have as yet emerged, except their explicit and obvious use as forms of expression.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"partitions were always inserted into text intuitively in a way that, to me at least, corresponded more naturally to the criteria just listed\"], \"BACK\": [\"The oddest feature of MMB's breath-group work, stretching as it did over many years was that it referred constantly to breathing, but nothing ever rested on that:\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "DeKo",
                "rules",
                "can",
                "only",
                "work",
                "if",
                "they",
                "can",
                "refer",
                "to",
                "detailed",
                "information",
                "on",
                "lexical",
                "items",
                "-therefore",
                "the",
                "DeKo",
                "team",
                "and",
                "other",
                "researchers",
                "at",
                "the",
                "IMS",
                "in",
                "Stuttgart",
                "developed",
                "a",
                "highly",
                "flexible",
                "lexicon",
                "concept",
                "where",
                "different",
                "kinds",
                "of",
                "information",
                "are",
                "stored",
                "together",
                "with",
                "morphological",
                "elements",
                "(see",
                "#TARGET_REF",
                "for",
                "more",
                "details).",
                "At",
                "the",
                "moment",
                "the",
                "relevant",
                "information",
                "is",
                "still",
                "being",
                "collected",
                "and",
                "encoded",
                "into",
                "the",
                "IMSLex.",
                "Therefore,",
                "the",
                "DeKo",
                "rules",
                "as",
                "they",
                "stand",
                "now",
                "are",
                "much",
                "less",
                "specific",
                "than",
                "they",
                "should",
                "be."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The DeKo rules can only work if they can refer to detailed information on lexical items -therefore the DeKo team and other researchers at the IMS in Stuttgart developed a highly flexible lexicon concept where different kinds of information are stored together with morphological elements (see #TARGET_REF for more details). At the moment the relevant information is still being collected and encoded into the IMSLex. Therefore, the DeKo rules as they stand now are much less specific than they should be.",
        "output": "{\"INFO\": [\"The DeKo rules can only work if they can refer to detailed information on lexical items -therefore the DeKo team and other researchers at the IMS in Stuttgart developed a highly flexible lexicon concept where different kinds of information are stored together with morphological elements\", \"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"(see\", \"for more details).\", \"the DeKo rules as they stand now are much less specific than they should be.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper,",
                "we",
                "introduce",
                "our",
                "system",
                "for",
                "the",
                "lexical",
                "complexity",
                "prediction",
                "task",
                "of",
                "the",
                "SemEval-2021",
                "#REF",
                ".",
                "We",
                "fulfill",
                "this",
                "task",
                "by",
                "leveraging",
                "multiple",
                "pre-trained",
                "language",
                "models",
                "(PLM)",
                "with",
                "different",
                "training",
                "strategies.",
                "There",
                "are",
                "two",
                "main",
                "steps",
                "for",
                "our",
                "system:",
                "(i)",
                "fine-tuning",
                "numbers",
                "of",
                "heterogeneous",
                "PLMs,",
                "including",
                "BERT",
                "#REF",
                ",",
                "ALBERT",
                "#TARGET_REF",
                ",",
                "RoBERTa",
                "#REF",
                "and",
                "ERNIE",
                "#REF",
                ",",
                "with",
                "various",
                "hyperparameters",
                "and",
                "training",
                "strategies,",
                "obtaining",
                "diverse",
                "models,",
                "(ii)",
                "applying",
                "an",
                "effective",
                "stacking",
                "mechanism",
                "on",
                "top",
                "of",
                "these",
                "PLMs",
                "to",
                "predict",
                "the",
                "final",
                "complexity",
                "scores."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "In this paper, we introduce our system for the lexical complexity prediction task of the SemEval-2021 #REF . We fulfill this task by leveraging multiple pre-trained language models (PLM) with different training strategies. There are two main steps for our system: (i) fine-tuning numbers of heterogeneous PLMs, including BERT #REF , ALBERT #TARGET_REF , RoBERTa #REF and ERNIE #REF , with various hyperparameters and training strategies, obtaining diverse models, (ii) applying an effective stacking mechanism on top of these PLMs to predict the final complexity scores.",
        "output": "{\"INFO\": [\"ALBERT #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"We fulfill this task by leveraging multiple pre-trained language models (PLM) with different training strategies. There are two main steps for our system: (i) fine-tuning numbers of heterogeneous PLMs, including BERT #REF ,\", \"RoBERTa #REF and ERNIE #REF\", \"with various hyperparameters and training strategies, obtaining diverse models, (ii) applying an effective stacking mechanism on top of these PLMs to predict the final complexity scores.\"]}"
    },
    {
        "gold": {
            "text": [
                "firstly",
                "utilizes",
                "off-the-shelf",
                "detectors",
                "to",
                "parse",
                "images",
                "into",
                "a",
                "set",
                "of",
                "object",
                "tokens,",
                "and",
                "then",
                "builds",
                "a",
                "multi-layer",
                "Transformer",
                "to",
                "learn",
                "visual",
                "and",
                "language",
                "embeddings",
                "jointly.",
                "In",
                "order",
                "to",
                "facilitate",
                "the",
                "multi-modal",
                "learning,",
                "those",
                "networks",
                "are",
                "typically",
                "trained",
                "via",
                "a",
                "set",
                "of",
                "carefully",
                "designed",
                "BERT-like",
                "objectives",
                "(e.g.",
                "Image-Text",
                "Matching).",
                "Despite",
                "its",
                "promising",
                "performance,",
                "the",
                "two-step",
                "strategy",
                "suffers",
                "from",
                "several",
                "limitations:",
                "1)",
                "limited",
                "visual",
                "object",
                "concepts",
                "as",
                "the",
                "external",
                "detectors",
                "are",
                "trained",
                "on",
                "a",
                "predefined",
                "set",
                "of",
                "object",
                "categories,",
                "2)",
                "lack",
                "of",
                "context",
                "cues",
                "outside",
                "of",
                "the",
                "object",
                "regions,",
                "which",
                "are",
                "crucial",
                "for",
                "complex",
                "reasoning",
                "tasks,",
                "3)",
                "sub-optimal",
                "visual",
                "representation",
                "due",
                "to",
                "stage-wise",
                "training,",
                "and",
                "4)",
                "computational",
                "inefficiency",
                "caused",
                "by",
                "additional",
                "detection",
                "modules.",
                "To",
                "overcome",
                "those",
                "limitations,",
                "recent",
                "works",
                "attempt",
                "to",
                "learn",
                "a",
                "joint",
                "visual-linguistic",
                "representations",
                "in",
                "an",
                "end-to-end",
                "manner",
                "#TARGET_REF",
                ".",
                "These",
                "methods",
                "directly",
                "take",
                "dense",
                "visual",
                "features",
                "from",
                "image",
                "grids",
                "as",
                "inputs",
                "to",
                "a",
                "multi-modal",
                "Transformer",
                "network,",
                "and",
                "hence",
                "do",
                "not",
                "rely",
                "on",
                "external",
                "object",
                "detectors",
                "in",
                "both",
                "pretraining",
                "and",
                "finetuning",
                "stages.",
                "Such",
                "model",
                "design",
                "significantly",
                "simplifies",
                "overall",
                "network",
                "architecture",
                "and",
                "allows",
                "deeper",
                "integration",
                "between",
                "visual",
                "and",
                "language",
                "features.",
                "However,",
                "using",
                "grid-level",
                "features",
                "makes",
                "it",
                "difficult",
                "to",
                "capture",
                "object-level",
                "visual",
                "concepts,",
                "which",
                "often",
                "results",
                "in",
                "less",
                "expressive",
                "multi-modal",
                "representations",
                "and",
                "inferior",
                "performances",
                "in",
                "downstream",
                "tasks."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                3,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "firstly utilizes off-the-shelf detectors to parse images into a set of object tokens, and then builds a multi-layer Transformer to learn visual and language embeddings jointly. In order to facilitate the multi-modal learning, those networks are typically trained via a set of carefully designed BERT-like objectives (e.g. Image-Text Matching). Despite its promising performance, the two-step strategy suffers from several limitations: 1) limited visual object concepts as the external detectors are trained on a predefined set of object categories, 2) lack of context cues outside of the object regions, which are crucial for complex reasoning tasks, 3) sub-optimal visual representation due to stage-wise training, and 4) computational inefficiency caused by additional detection modules. To overcome those limitations, recent works attempt to learn a joint visual-linguistic representations in an end-to-end manner #TARGET_REF . These methods directly take dense visual features from image grids as inputs to a multi-modal Transformer network, and hence do not rely on external object detectors in both pretraining and finetuning stages. Such model design significantly simplifies overall network architecture and allows deeper integration between visual and language features. However, using grid-level features makes it difficult to capture object-level visual concepts, which often results in less expressive multi-modal representations and inferior performances in downstream tasks.",
        "output": "{\"INFO\": [\"recent works attempt to learn a joint visual-linguistic representations in an end-to-end manner #TARGET_REF\", \"These methods directly take dense visual features from image grids as inputs to a multi-modal Transformer network, and hence do not rely on external object detectors in both pretraining and finetuning stages.\"], \"PERCEPT\": [\"To overcome those limitations,\", \"Such model design significantly simplifies overall network architecture and allows deeper integration between visual and language features. However, using grid-level features makes it difficult to capture object-level visual concepts, which often results in less expressive multi-modal representations and inferior performances in downstream tasks.\"], \"BACK\": [\"limited visual object concepts\", \"lack of context cues outside of the object regions,\", \"sub-optimal visual representation\", \"and\", \"computational inefficiency\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "compare",
                "the",
                "output",
                "of",
                "Epitran",
                "and",
                "Allosaurus",
                "on",
                "the",
                "ALFFA",
                "dataset.",
                "Following",
                "the",
                "practice",
                "of",
                "#REF",
                ",",
                "we",
                "used",
                "the",
                "editdistance",
                "10",
                "library",
                "to",
                "calculate",
                "the",
                "Phone",
                "Error",
                "Rate",
                "(PER).",
                "Having",
                "no",
                "ground",
                "truth",
                "phone",
                "annotations,",
                "we",
                "instead",
                "take",
                "Epitran's",
                "outputs",
                "as",
                "\"ground",
                "truth\"",
                "for",
                "comparison.",
                "The",
                "mean",
                "PER",
                "between",
                "the",
                "outputs",
                "is",
                "23.7%.",
                "This",
                "result",
                "is",
                "consistent",
                "with",
                "#TARGET_REF",
                ",",
                "which",
                "finds",
                "PERs",
                "as",
                "high",
                "as",
                "72.8%",
                "when",
                "testing",
                "on",
                "on",
                "the",
                "Bukusu",
                "(bxk),",
                "Saamia",
                "(lsm)",
                "and",
                "East",
                "Tusom",
                "languages",
                "(an",
                "endangered",
                "subdialect",
                "of",
                "the",
                "Tungkhulic",
                "language",
                "family).",
                "However,",
                "by",
                "training",
                "the",
                "phone",
                "recognizer",
                "on",
                "even",
                "minimal",
                "amounts",
                "of",
                "data",
                "in",
                "these",
                "languages,",
                "PERs",
                "were",
                "improved",
                "significantly."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We compare the output of Epitran and Allosaurus on the ALFFA dataset. Following the practice of #REF , we used the editdistance 10 library to calculate the Phone Error Rate (PER). Having no ground truth phone annotations, we instead take Epitran's outputs as \"ground truth\" for comparison. The mean PER between the outputs is 23.7%. This result is consistent with #TARGET_REF , which finds PERs as high as 72.8% when testing on on the Bukusu (bxk), Saamia (lsm) and East Tusom languages (an endangered subdialect of the Tungkhulic language family). However, by training the phone recognizer on even minimal amounts of data in these languages, PERs were improved significantly.",
        "output": "{\"INFO\": [\"which finds PERs as high as 72.8% when testing on on the Bukusu (bxk), Saamia (lsm) and East Tusom languages\"], \"PERCEPT\": [\"The mean PER between the outputs is 23.7%. This result is consistent with #TARGET_REF ,\", \"by training the phone recognizer on even minimal amounts of data in these languages, PERs were improved significantly.\"], \"BACK\": [\"(an endangered subdialect of the Tungkhulic language family).\"]}"
    },
    {
        "gold": {
            "text": [
                "Moreover,",
                "these",
                "LLMs",
                "are",
                "known",
                "to",
                "have",
                "flaws.",
                "BERT",
                "in",
                "particular",
                "has",
                "been",
                "shown",
                "to",
                "be,",
                "in",
                "certain",
                "scenarios,",
                "insensitive",
                "to",
                "negation",
                "#REF",
                "and",
                "word",
                "order",
                "#REF",
                ".",
                "BERT",
                "also",
                "has",
                "inexact",
                "representations",
                "of",
                "numbers",
                "#REF",
                "and",
                "fails",
                "to",
                "be",
                "robust",
                "to",
                "named",
                "entities",
                "#TARGET_REF",
                ".",
                "All",
                "of",
                "these",
                "phenomena",
                "could",
                "result",
                "in",
                "poor-quality",
                "scores",
                "from",
                "BERTScore.",
                "However,",
                "it",
                "is",
                "difficult",
                "to",
                "say",
                "for",
                "certain",
                "how",
                "these",
                "issues",
                "might",
                "manifest",
                "in",
                "BERTScore,",
                "as",
                "it",
                "employs",
                "BERT",
                "in",
                "an",
                "unsupervised",
                "scenario",
                "distinct",
                "from",
                "that",
                "of",
                "these",
                "analyses."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Moreover, these LLMs are known to have flaws. BERT in particular has been shown to be, in certain scenarios, insensitive to negation #REF and word order #REF . BERT also has inexact representations of numbers #REF and fails to be robust to named entities #TARGET_REF . All of these phenomena could result in poor-quality scores from BERTScore. However, it is difficult to say for certain how these issues might manifest in BERTScore, as it employs BERT in an unsupervised scenario distinct from that of these analyses.",
        "output": "{\"INFO\": [\"BERT\", \"fails to be robust to named entities #TARGET_REF .\"], \"PERCEPT\": [\"All of these phenomena could result in poor-quality scores from BERTScore.\", \"it is difficult to say for certain how these issues might manifest in BERTScore,\"], \"BACK\": [\"these LLMs are known to have flaws.\", \"has inexact representations of numbers #REF and\", \"as it employs BERT in an unsupervised scenario\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "wh-word,",
                "empty",
                "question,",
                "and",
                "short",
                "distance",
                "reasoning,",
                "we",
                "use",
                "the",
                "TASE",
                "model",
                "#TARGET_REF",
                "We",
                "also",
                "investigate",
                "whether",
                "these",
                "biases",
                "have",
                "similar",
                "ratios",
                "in",
                "a",
                "coreference",
                "resolution",
                "dataset.",
                "We",
                "use",
                "the",
                "CoNLL-2012",
                "coreference",
                "resolution",
                "dataset",
                "#REF",
                "and",
                "convert",
                "it",
                "to",
                "a",
                "reading",
                "comprehension",
                "format,",
                "i.e.,",
                "CoNLL",
                "bart",
                "in",
                "Section",
                "5.",
                "5",
                "This",
                "data",
                "contains",
                "question-answer",
                "pairs",
                "in",
                "which",
                "the",
                "question",
                "is",
                "created",
                "based",
                "on",
                "a",
                "coreferring",
                "expression",
                "in",
                "CoNLL-2012,",
                "and",
                "the",
                "answer",
                "is",
                "its",
                "closest",
                "antecedent.",
                "We",
                "split",
                "this",
                "data",
                "into",
                "training",
                "and",
                "test",
                "sets",
                "and",
                "train",
                "bias",
                "models",
                "on",
                "the",
                "training",
                "split.",
                "The",
                "CoNLL",
                "bart",
                "column",
                "in",
                "Table",
                "1",
                "shows",
                "the",
                "bias",
                "proportions",
                "on",
                "this",
                "data."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For wh-word, empty question, and short distance reasoning, we use the TASE model #TARGET_REF We also investigate whether these biases have similar ratios in a coreference resolution dataset. We use the CoNLL-2012 coreference resolution dataset #REF and convert it to a reading comprehension format, i.e., CoNLL bart in Section 5. 5 This data contains question-answer pairs in which the question is created based on a coreferring expression in CoNLL-2012, and the answer is its closest antecedent. We split this data into training and test sets and train bias models on the training split. The CoNLL bart column in Table 1 shows the bias proportions on this data.",
        "output": "{\"INFO\": [\"the TASE model #TARGET_REF\"], \"PERCEPT\": [\"For wh-word, empty question, and short distance reasoning, we use\", \"We also investigate whether these biases have similar ratios in a coreference resolution dataset.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Neural",
                "Machine",
                "Translation",
                "(NMT)",
                "approach",
                "has",
                "been",
                "further",
                "developed",
                "in",
                "the",
                "last",
                "years",
                "#REF",
                ".",
                "In",
                "contrast",
                "to",
                "the",
                "traditional",
                "phrased-based",
                "statistical",
                "machine",
                "translation",
                "#REF",
                "that",
                "represents",
                "and",
                "translates",
                "the",
                "input",
                "sentence",
                "with",
                "a",
                "set",
                "of",
                "phrases,",
                "NMT",
                "uses",
                "the",
                "sequence",
                "to",
                "sequence",
                "learning",
                "architecture",
                "and",
                "the",
                "whole",
                "input",
                "sentence",
                "is",
                "considered",
                "as",
                "one",
                "unit",
                "for",
                "translation",
                "#TARGET_REF",
                ".",
                "Recently,",
                "NMT",
                "is",
                "gaining",
                "more",
                "and",
                "more",
                "interest",
                "and",
                "showing",
                "better",
                "accuracy",
                "than",
                "phrase-based",
                "system",
                "translating",
                "several",
                "language",
                "pairs.",
                "In",
                "spite",
                "of",
                "these",
                "recent",
                "improvements,",
                "the",
                "NMT",
                "systems",
                "still",
                "have",
                "some",
                "restrictions",
                "and",
                "difficulties",
                "to",
                "translate.",
                "One",
                "of",
                "them",
                "is",
                "the",
                "high",
                "computational",
                "of",
                "the",
                "softmax",
                "function",
                "which",
                "requires",
                "to",
                "normalize",
                "all",
                "the",
                "output",
                "vocabulary",
                "size."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Neural Machine Translation (NMT) approach has been further developed in the last years #REF . In contrast to the traditional phrased-based statistical machine translation #REF that represents and translates the input sentence with a set of phrases, NMT uses the sequence to sequence learning architecture and the whole input sentence is considered as one unit for translation #TARGET_REF . Recently, NMT is gaining more and more interest and showing better accuracy than phrase-based system translating several language pairs. In spite of these recent improvements, the NMT systems still have some restrictions and difficulties to translate. One of them is the high computational of the softmax function which requires to normalize all the output vocabulary size.",
        "output": "{\"INFO\": [\"NMT uses the sequence to sequence learning architecture and the whole input sentence is considered as one unit for translation #TARGET_REF\"], \"PERCEPT\": [\"In contrast to the traditional phrased-based statistical machine translation #REF\"], \"BACK\": [\"Neural Machine Translation (NMT) approach has been further developed in the last years #REF .\", \"that represents and translates the input sentence with a set of phrases,\"]}"
    },
    {
        "gold": {
            "text": [
                "First,",
                "we",
                "compare",
                "the",
                "performance",
                "of",
                "UNI-FIEDQA",
                "#TARGET_REF",
                "before",
                "and",
                "after",
                "replacing",
                "its",
                "feed-forward",
                "layers",
                "with",
                "our",
                "implementation",
                "of",
                "top-k",
                "attention",
                "and",
                "directly",
                "performing",
                "inference",
                "on",
                "12",
                "different",
                "question",
                "answering",
                "(QA)",
                "datasets",
                "without",
                "any",
                "training.",
                "UNIFIEDQA",
                "is",
                "a",
                "T5-based",
                "#REF",
                "model",
                "with",
                "11B",
                "parameters",
                "#REF",
                ",",
                "fine-tuned",
                "on",
                "a",
                "weighted",
                "mixture",
                "of",
                "QA",
                "datasets.",
                "The",
                "12",
                "datasets",
                "include",
                "diverse",
                "domains,",
                "such",
                "as",
                "science",
                "questions,",
                "factoid",
                "questions",
                "over",
                "Wikipedia,",
                "commonsense",
                "questions,",
                "etc.",
                "Details",
                "regarding",
                "the",
                "datasets",
                "and",
                "metrics",
                "can",
                "be",
                "found",
                "in",
                "§A.2."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "First, we compare the performance of UNI-FIEDQA #TARGET_REF before and after replacing its feed-forward layers with our implementation of top-k attention and directly performing inference on 12 different question answering (QA) datasets without any training. UNIFIEDQA is a T5-based #REF model with 11B parameters #REF , fine-tuned on a weighted mixture of QA datasets. The 12 datasets include diverse domains, such as science questions, factoid questions over Wikipedia, commonsense questions, etc. Details regarding the datasets and metrics can be found in §A.2.",
        "output": "{\"INFO\": [\"UNI-FIEDQA #TARGET_REF\", \"UNIFIEDQA is a T5-based #REF model with 11B parameters #REF , fine-tuned on a weighted mixture of QA datasets.\"], \"PERCEPT\": [\"we compare the performance of\", \"before and after replacing its feed-forward layers with our implementation of top-k attention and directly performing inference on 12 different question answering (QA) datasets without any training.\"], \"BACK\": [\"The 12 datasets include diverse domains, such as science questions, factoid questions over Wikipedia, commonsense questions, etc.\"]}"
    },
    {
        "gold": {
            "text": [
                "Table",
                "5:",
                "The",
                "experimental",
                "results",
                "of",
                "passage",
                "reading",
                "on",
                "NQ",
                "dataset.",
                "In",
                "this",
                "paper,",
                "we",
                "focus",
                "on",
                "extractive",
                "reader,",
                "while",
                "the",
                "recent",
                "generative",
                "readers",
                "#TARGET_REF",
                "can",
                "also",
                "be",
                "applied",
                "here",
                "and",
                "may",
                "lead",
                "to",
                "better",
                "results."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Table 5: The experimental results of passage reading on NQ dataset. In this paper, we focus on extractive reader, while the recent generative readers #TARGET_REF can also be applied here and may lead to better results.",
        "output": "{\"INFO\": [\"the recent generative readers #TARGET_REF\"], \"PERCEPT\": [\"In this paper, we focus on extractive reader, while\", \"can also be applied here and may lead to better results.\"], \"BACK\": [\"Table 5: The experimental results of passage reading on NQ dataset.\"]}"
    },
    {
        "gold": {
            "text": [
                "we",
                "opted",
                "for",
                "the",
                "second",
                "option",
                "and",
                "joined",
                "together",
                "all",
                "the",
                "suffixes",
                "attached",
                "to",
                "a",
                "particular",
                "lemma",
                "in",
                "one",
                "separate",
                "token.",
                "Thus,",
                "on",
                "splitting",
                "a",
                "word,",
                "we",
                "generated,",
                "at",
                "most,",
                "three",
                "tokens",
                "(prefixes,",
                "lemma",
                "and",
                "suffixes).",
                "Moses",
                "was",
                "trained",
                "and",
                "optimized",
                "on",
                "segmented",
                "text.",
                "Note",
                "that",
                "when",
                "using",
                "segmented",
                "text",
                "for",
                "training,",
                "the",
                "output",
                "of",
                "the",
                "system",
                "is",
                "also",
                "segmented",
                "text.",
                "Real",
                "words",
                "are",
                "not",
                "available",
                "to",
                "the",
                "statistical",
                "decoder.",
                "This",
                "means",
                "that",
                "a",
                "generation",
                "postprocess",
                "(unsegmentation",
                "step)",
                "is",
                "needed",
                "to",
                "obtain",
                "real",
                "word",
                "forms.",
                "We",
                "incorporated",
                "a",
                "second",
                "language",
                "model",
                "(LM)",
                "based",
                "on",
                "real",
                "word",
                "forms",
                "to",
                "be",
                "used",
                "after",
                "the",
                "morphological",
                "postprocess.",
                "We",
                "implemented",
                "the",
                "word",
                "form-based",
                "LM",
                "by",
                "using",
                "an",
                "n-best",
                "list,",
                "as",
                "was",
                "done",
                "in",
                "#REF",
                ".",
                "We",
                "first",
                "asked",
                "Moses",
                "to",
                "generate",
                "a",
                "translation",
                "candidate",
                "ranking",
                "based",
                "on",
                "the",
                "segmented",
                "training",
                "explained",
                "above.",
                "Next,",
                "these",
                "candidates",
                "were",
                "postprocessed.",
                "We",
                "then",
                "recalculated",
                "the",
                "total",
                "cost",
                "of",
                "each",
                "candidate",
                "by",
                "including",
                "the",
                "cost",
                "assigned",
                "by",
                "the",
                "new",
                "word",
                "form-based",
                "LM",
                "in",
                "the",
                "models",
                "used",
                "during",
                "decoding.",
                "Finally,",
                "the",
                "candidate",
                "list",
                "was",
                "re-ranked",
                "according",
                "to",
                "this",
                "new",
                "total",
                "cost.",
                "This",
                "somehow",
                "revises",
                "the",
                "candidate",
                "list",
                "to",
                "promote",
                "the",
                "ones",
                "that",
                "are",
                "more",
                "likely",
                "to",
                "be",
                "real",
                "word-form",
                "sequences.",
                "The",
                "weight",
                "for",
                "the",
                "word",
                "formbased",
                "LM",
                "was",
                "optimized",
                "at",
                "Minimum",
                "Error",
                "Rate",
                "Training",
                "#TARGET_REF",
                "together",
                "with",
                "the",
                "weights",
                "for",
                "the",
                "rest",
                "of",
                "the",
                "models."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "we opted for the second option and joined together all the suffixes attached to a particular lemma in one separate token. Thus, on splitting a word, we generated, at most, three tokens (prefixes, lemma and suffixes). Moses was trained and optimized on segmented text. Note that when using segmented text for training, the output of the system is also segmented text. Real words are not available to the statistical decoder. This means that a generation postprocess (unsegmentation step) is needed to obtain real word forms. We incorporated a second language model (LM) based on real word forms to be used after the morphological postprocess. We implemented the word form-based LM by using an n-best list, as was done in #REF . We first asked Moses to generate a translation candidate ranking based on the segmented training explained above. Next, these candidates were postprocessed. We then recalculated the total cost of each candidate by including the cost assigned by the new word form-based LM in the models used during decoding. Finally, the candidate list was re-ranked according to this new total cost. This somehow revises the candidate list to promote the ones that are more likely to be real word-form sequences. The weight for the word formbased LM was optimized at Minimum Error Rate Training #TARGET_REF together with the weights for the rest of the models.",
        "output": "{\"INFO\": [\"Minimum Error Rate Training #TARGET_REF\"], \"PERCEPT\": [\"The weight for the word formbased LM was optimized at\"], \"BACK\": [\"together with the weights for the rest of the models.\"]}"
    },
    {
        "gold": {
            "text": [
                "Recent",
                "advances",
                "in",
                "the",
                "field",
                "of",
                "Natural",
                "Language",
                "Processing",
                "(NLP)",
                "have",
                "been",
                "made",
                "with",
                "the",
                "development",
                "of",
                "transfer",
                "learning",
                "and",
                "the",
                "availability",
                "of",
                "pre-trained",
                "language",
                "models",
                "based",
                "on",
                "Transformer",
                "architectures",
                "#REF",
                ",",
                "such",
                "as",
                "BERT",
                "#TARGET_REF",
                ".",
                "As",
                "they",
                "provide",
                "contextualized",
                "semantic",
                "representation",
                "they",
                "contribute",
                "both",
                "to",
                "advance",
                "the",
                "state-of-the-art",
                "on",
                "several",
                "NLP",
                "tasks",
                "and",
                "also",
                "to",
                "evolve",
                "training",
                "practices",
                "through",
                "the",
                "use",
                "of",
                "fine-tuning."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Recent advances in the field of Natural Language Processing (NLP) have been made with the development of transfer learning and the availability of pre-trained language models based on Transformer architectures #REF , such as BERT #TARGET_REF . As they provide contextualized semantic representation they contribute both to advance the state-of-the-art on several NLP tasks and also to evolve training practices through the use of fine-tuning.",
        "output": "{\"INFO\": [\"BERT #TARGET_REF .\"], \"PERCEPT\": [\"Recent advances in the field of Natural Language Processing (NLP) have been made with the development of transfer learning and the availability of pre-trained language models based on Transformer architectures #REF , such as\", \"As they provide contextualized semantic representation they contribute both to advance the state-of-the-art on several NLP tasks and also to evolve training practices through the use of fine-tuning.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "evaluate",
                "our",
                "experiments",
                "on",
                "the",
                "English",
                "to",
                "French",
                "Spoken",
                "Language",
                "Translation",
                "task",
                "from",
                "IWSLT",
                "2015",
                "evaluation",
                "campaign",
                "3",
                ".",
                "A",
                "data",
                "selection",
                "method",
                "#TARGET_REF",
                "consisting",
                "on",
                "scoring",
                "the",
                "sentences",
                "according",
                "to",
                "a",
                "in-domain",
                "language",
                "model",
                "has",
                "been",
                "applied.",
                "We",
                "have",
                "used",
                "as",
                "available",
                "parallel",
                "corpora",
                "(news-commentary,",
                "united-nations,",
                "europarl,",
                "wikipedia,",
                "and",
                "two",
                "crawled",
                "corpora)",
                "and",
                "Technology",
                "Entertainment",
                "Design",
                "(TED",
                "4",
                ")",
                "corpus",
                "as",
                "in-domain",
                "corpus.",
                "The",
                "data",
                "selection",
                "allows",
                "us",
                "to",
                "train",
                "the",
                "models",
                "in",
                "a",
                "faster",
                "way",
                "taking",
                "into",
                "account",
                "the",
                "sentences",
                "which",
                "contain",
                "relevant",
                "information",
                "of",
                "the",
                "domain",
                "and",
                "avoids",
                "noisy",
                "data.",
                "We",
                "also",
                "did",
                "a",
                "preprocessing",
                "to",
                "convert",
                "html",
                "entities",
                "and",
                "filter",
                "out",
                "the",
                "sentences",
                "with",
                "more",
                "than",
                "50",
                "words",
                "for",
                "both",
                "source",
                "and",
                "target",
                "languages.",
                "We",
                "finally",
                "end",
                "up",
                "with",
                "a",
                "selected",
                "corpus",
                "of",
                "2M",
                "sentences",
                "(50.5",
                "millions",
                "of",
                "words),",
                "leading",
                "to",
                "147K",
                "unique",
                "tokens",
                "for",
                "English",
                "side",
                "and",
                "266K",
                "unique",
                "tokens",
                "for",
                "French",
                "side."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We evaluate our experiments on the English to French Spoken Language Translation task from IWSLT 2015 evaluation campaign 3 . A data selection method #TARGET_REF consisting on scoring the sentences according to a in-domain language model has been applied. We have used as available parallel corpora (news-commentary, united-nations, europarl, wikipedia, and two crawled corpora) and Technology Entertainment Design (TED 4 ) corpus as in-domain corpus. The data selection allows us to train the models in a faster way taking into account the sentences which contain relevant information of the domain and avoids noisy data. We also did a preprocessing to convert html entities and filter out the sentences with more than 50 words for both source and target languages. We finally end up with a selected corpus of 2M sentences (50.5 millions of words), leading to 147K unique tokens for English side and 266K unique tokens for French side.",
        "output": "{\"INFO\": [\"A data selection method #TARGET_REF consisting on scoring the sentences according to a in-domain language model\"], \"PERCEPT\": [\"We evaluate our experiments on the English to French Spoken Language Translation task from IWSLT 2015 evaluation campaign 3 .\", \"We have used as available parallel corpora (news-commentary, united-nations, europarl, wikipedia, and two crawled corpora) and Technology Entertainment Design (TED 4 ) corpus as in-domain corpus. The data selection allows us to train the models in a faster way taking into account the sentences which contain relevant information of the domain and avoids noisy data. We also did a preprocessing to convert html entities and filter out the sentences with more than 50 words for both source and target languages. We finally end up with a selected corpus of 2M sentences (50.5 millions of words), leading to 147K unique tokens for English side and 266K unique tokens for French side.\"], \"BACK\": [\"has been applied.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "second",
                "problem",
                "of",
                "coverage",
                "can",
                "be",
                "paraphrased",
                "as",
                "\"Are",
                "there",
                "any",
                "examples",
                "in",
                "the",
                "database",
                "which",
                "match",
                "this",
                "input",
                "at",
                "all?\",",
                "and",
                "is",
                "the",
                "basic",
                "problem",
                "with",
                "EBMT",
                "in",
                "that,",
                "in",
                "the",
                "extreme,",
                "EBMT",
                "ignores",
                "the",
                "relevance",
                "of",
                "linguistic",
                "generalities.",
                "It",
                "can",
                "be",
                "overcome",
                "by",
                "making",
                "the",
                "source",
                "text",
                "and",
                "target",
                "text",
                "composition",
                "process",
                "'recombinant'",
                "(",
                "#REF",
                ").",
                "This",
                "recombination",
                "of",
                "partially",
                "matching",
                "examples",
                "is",
                "significantly",
                "different",
                "from",
                "the",
                "corresponding",
                "technique",
                "of",
                "target",
                "text",
                "generation",
                "in",
                "standard",
                "MT",
                "systems,",
                "which",
                "is",
                "essentially",
                "rule-driven",
                "'direct",
                "replacement'",
                "(cf.",
                "#REF",
                ",",
                "pp.",
                "200f)",
                "of",
                "an",
                "abstract",
                "representation",
                "with",
                "the",
                "corresponding",
                "text,",
                "based",
                "on",
                "pre-determined",
                "choices",
                "(cf.",
                "#TARGET_REF",
                ",",
                "pp.137f).",
                "In",
                "recombination",
                "of",
                "examples,",
                "it",
                "is",
                "necessary",
                "to",
                "locate",
                "the",
                "partially",
                "matched",
                "examples",
                "in",
                "a",
                "broader",
                "rhetorical",
                "structure:",
                "in",
                "order",
                "to",
                "accomplish",
                "this",
                "the",
                "representations",
                "and",
                "the",
                "contextual",
                "relation",
                "definitions",
                "of",
                "the",
                "examples,",
                "and",
                "the",
                "global",
                "intentional",
                "model",
                "all",
                "play",
                "their",
                "part.",
                "It",
                "is",
                "important",
                "to",
                "ascertain",
                "the",
                "grammatical,",
                "pragmatic",
                "and",
                "stylistic",
                "legality",
                "of",
                "recombining",
                "examples",
                "and",
                "to",
                "maintain",
                "textual",
                "cohesion.",
                "In",
                "some",
                "(extreme)",
                "cases,",
                "the",
                "system",
                "may",
                "require",
                "the",
                "user",
                "to",
                "rephrase",
                "the",
                "input",
                "so",
                "as",
                "to",
                "match",
                "more",
                "closely",
                "the",
                "expected",
                "input."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The second problem of coverage can be paraphrased as \"Are there any examples in the database which match this input at all?\", and is the basic problem with EBMT in that, in the extreme, EBMT ignores the relevance of linguistic generalities. It can be overcome by making the source text and target text composition process 'recombinant' ( #REF ). This recombination of partially matching examples is significantly different from the corresponding technique of target text generation in standard MT systems, which is essentially rule-driven 'direct replacement' (cf. #REF , pp. 200f) of an abstract representation with the corresponding text, based on pre-determined choices (cf. #TARGET_REF , pp.137f). In recombination of examples, it is necessary to locate the partially matched examples in a broader rhetorical structure: in order to accomplish this the representations and the contextual relation definitions of the examples, and the global intentional model all play their part. It is important to ascertain the grammatical, pragmatic and stylistic legality of recombining examples and to maintain textual cohesion. In some (extreme) cases, the system may require the user to rephrase the input so as to match more closely the expected input.",
        "output": "{\"INFO\": [\"pre-determined choices\", \"#TARGET_REF ,\"], \"PERCEPT\": [\"the corresponding technique of target text generation in standard MT systems, which is essentially rule-driven 'direct replacement'\", \"of an abstract representation with the corresponding text, based on\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "is",
                "suited",
                "for",
                "emotion",
                "projection,",
                "we",
                "projected",
                "the",
                "English",
                "annotations",
                "onto",
                "our",
                "Finnish",
                "unannotated",
                "data",
                "using",
                "OPUS",
                "tools",
                "#TARGET_REF",
                ".",
                "We",
                "chose",
                "Finnish",
                "as",
                "our",
                "main",
                "test",
                "language",
                "as",
                "we",
                "also",
                "have",
                "some",
                "annotated",
                "data",
                "for",
                "it",
                "to",
                "use",
                "as",
                "a",
                "test",
                "set.",
                "The",
                "manually",
                "annotated",
                "Finnish",
                "data",
                "consists",
                "of",
                "nearly",
                "20k",
                "individual",
                "annotations",
                "and",
                "almost",
                "15k",
                "unique",
                "annotated",
                "sentences",
                "plus",
                "an",
                "additional",
                "7,536",
                "sentences",
                "annotated",
                "as",
                "neutral",
                "6",
                ".",
                "The",
                "criteria",
                "for",
                "the",
                "inclusion",
                "of",
                "an",
                "annotation",
                "was",
                "the",
                "same",
                "as",
                "for",
                "English.",
                "The",
                "distribution",
                "of",
                "the",
                "number",
                "of",
                "labels",
                "and",
                "the",
                "labels",
                "themselves",
                "are",
                "quite",
                "similar",
                "to",
                "that",
                "of",
                "the",
                "English",
                "data.",
                "Relatively",
                "speaking",
                "there",
                "is",
                "a",
                "little",
                "less",
                "anticipation",
                "in",
                "the",
                "Finnish",
                "data,",
                "but",
                "anger",
                "is",
                "the",
                "biggest",
                "category",
                "in",
                "both",
                "languages.",
                "We",
                "used",
                "the",
                "11,128",
                "Finnish",
                "sentences",
                "for",
                "which",
                "directly",
                "parallel",
                "sentences",
                "existed",
                "and",
                "projected",
                "the",
                "English",
                "annotations",
                "on",
                "them",
                "using",
                "the",
                "unique",
                "alignment",
                "IDs",
                "for",
                "both",
                "languages",
                "as",
                "guide.",
                "Some",
                "of",
                "those",
                "parallel",
                "sentences",
                "were",
                "part",
                "of",
                "our",
                "already",
                "annotated",
                "data",
                "and",
                "were",
                "discarded",
                "as",
                "training",
                "data.",
                "This",
                "served",
                "as",
                "a",
                "useful",
                "point",
                "of",
                "comparison.",
                "The",
                "average",
                "annotation",
                "correlation",
                "using",
                "Cohen's",
                "kappa",
                "is",
                "0.44",
                "(although",
                "accuracy",
                "by",
                "percentage",
                "is",
                "over",
                "90%),",
                "and",
                "highest",
                "for",
                "joy",
                "at",
                "0.65,",
                "showing",
                "that",
                "annotation",
                "projection",
                "differs",
                "from",
                "human",
                "annotation",
                "to",
                "a",
                "similar",
                "degree",
                "as",
                "human",
                "annotations",
                "differ",
                "from",
                "each",
                "other."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "is suited for emotion projection, we projected the English annotations onto our Finnish unannotated data using OPUS tools #TARGET_REF . We chose Finnish as our main test language as we also have some annotated data for it to use as a test set. The manually annotated Finnish data consists of nearly 20k individual annotations and almost 15k unique annotated sentences plus an additional 7,536 sentences annotated as neutral 6 . The criteria for the inclusion of an annotation was the same as for English. The distribution of the number of labels and the labels themselves are quite similar to that of the English data. Relatively speaking there is a little less anticipation in the Finnish data, but anger is the biggest category in both languages. We used the 11,128 Finnish sentences for which directly parallel sentences existed and projected the English annotations on them using the unique alignment IDs for both languages as guide. Some of those parallel sentences were part of our already annotated data and were discarded as training data. This served as a useful point of comparison. The average annotation correlation using Cohen's kappa is 0.44 (although accuracy by percentage is over 90%), and highest for joy at 0.65, showing that annotation projection differs from human annotation to a similar degree as human annotations differ from each other.",
        "output": "{\"INFO\": [\"OPUS tools #TARGET_REF .\"], \"PERCEPT\": [\"is suited for emotion projection, we projected the English annotations onto our Finnish unannotated data using\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "layer",
                "to",
                "extract",
                "Arabic",
                "NEs.",
                "They",
                "used",
                "two",
                "attention",
                "units,",
                "the",
                "embedding",
                "attention",
                "layer,",
                "and",
                "the",
                "self-attention",
                "unit.",
                "They",
                "achieved",
                "an",
                "F1",
                "score",
                "of",
                "91.31",
                "to",
                "achieve",
                "a",
                "new",
                "stateof-the-art",
                "on",
                "a",
                "large",
                "dataset",
                "proposed",
                "for",
                "evaluation",
                "in",
                "the",
                "same",
                "work.",
                "At",
                "the",
                "same",
                "time,",
                "#REF",
                "used",
                "character",
                "Convolutional",
                "Neural",
                "Networks",
                "(CNN)",
                "as",
                "a",
                "replacement",
                "for",
                "characterlevel",
                "bidirectional",
                "Long",
                "Short-Term",
                "Memory",
                "(LSTM)",
                "in",
                "Arabic",
                "NER.",
                "Their",
                "proposed",
                "system",
                "was",
                "able",
                "to",
                "outperform",
                "the",
                "state-of-art",
                "systems,",
                "including",
                "character-level",
                "Bi-LSTM",
                "on",
                "various",
                "standard",
                "Arabic",
                "NER",
                "corpora.",
                "#REF",
                "proposed",
                "AraBERTv0.1",
                "which",
                "involves",
                "pretraining",
                "the",
                "BERT",
                "transformer",
                "model",
                "for",
                "the",
                "Arabic",
                "language.",
                "They",
                "compared",
                "AraBERTv0.1",
                "and",
                "the",
                "Bi-LSTM-CRF",
                "model",
                "on",
                "ANERCorp,",
                "the",
                "former",
                "achieved",
                "84.2",
                "F1",
                "scores",
                "whereas",
                "the",
                "later",
                "achieved",
                "81.7.",
                "Most",
                "recently,",
                "#TARGET_REF",
                "proposed",
                "a",
                "transfer",
                "learning",
                "approach",
                "for",
                "Arabic",
                "NER",
                "with",
                "Deep",
                "Neural",
                "Networks",
                "where",
                "they",
                "showed",
                "that",
                "their",
                "model",
                "outperformed",
                "significantly",
                "the",
                "Bi-LSTM-CRF",
                "model.",
                "We",
                "have",
                "not",
                "considered",
                "this",
                "approach",
                "here",
                "because",
                "our",
                "aim",
                "is",
                "not",
                "to",
                "create",
                "a",
                "new",
                "state",
                "of",
                "the",
                "art",
                "model",
                "but",
                "to",
                "show",
                "the",
                "effectiveness",
                "of",
                "incorporating",
                "language",
                "specific",
                "characteristics",
                "in",
                "the",
                "form",
                "of",
                "embeddings."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "layer to extract Arabic NEs. They used two attention units, the embedding attention layer, and the self-attention unit. They achieved an F1 score of 91.31 to achieve a new stateof-the-art on a large dataset proposed for evaluation in the same work. At the same time, #REF used character Convolutional Neural Networks (CNN) as a replacement for characterlevel bidirectional Long Short-Term Memory (LSTM) in Arabic NER. Their proposed system was able to outperform the state-of-art systems, including character-level Bi-LSTM on various standard Arabic NER corpora. #REF proposed AraBERTv0.1 which involves pretraining the BERT transformer model for the Arabic language. They compared AraBERTv0.1 and the Bi-LSTM-CRF model on ANERCorp, the former achieved 84.2 F1 scores whereas the later achieved 81.7. Most recently, #TARGET_REF proposed a transfer learning approach for Arabic NER with Deep Neural Networks where they showed that their model outperformed significantly the Bi-LSTM-CRF model. We have not considered this approach here because our aim is not to create a new state of the art model but to show the effectiveness of incorporating language specific characteristics in the form of embeddings.",
        "output": "{\"INFO\": [\"#TARGET_REF proposed a transfer learning approach for Arabic NER with Deep Neural Networks where they showed that their model outperformed significantly the Bi-LSTM-CRF model.\"], \"PERCEPT\": [\"We have not considered this approach here because our aim is not to create a new state of the art model but to show the effectiveness of incorporating language specific characteristics in the form of embeddings.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "require",
                "aligned",
                "parallel",
                "text",
                "to",
                "fuel",
                "our",
                "methods",
                "and",
                "we",
                "relied",
                "on",
                "the",
                "Europarl",
                "corpus",
                "#TARGET_REF",
                "which",
                "is",
                "comprised",
                "of",
                "EU",
                "parliamentary",
                "oration",
                "that",
                "has",
                "been",
                "manually",
                "translated",
                "into",
                "other",
                "EU",
                "languages.",
                "There",
                "is",
                "approximately",
                "160",
                "MB",
                "of",
                "text",
                "(about",
                "24",
                "million",
                "words)",
                "per",
                "language."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "We require aligned parallel text to fuel our methods and we relied on the Europarl corpus #TARGET_REF which is comprised of EU parliamentary oration that has been manually translated into other EU languages. There is approximately 160 MB of text (about 24 million words) per language.",
        "output": "{\"INFO\": [\"the Europarl corpus #TARGET_REF which is comprised of EU parliamentary oration that has been manually translated into other EU languages. There is approximately 160 MB of text (about 24 million words) per language.\"], \"PERCEPT\": [\"we relied on\"], \"BACK\": [\"We require aligned parallel text to fuel our methods and\"]}"
    },
    {
        "gold": {
            "text": [
                "capture",
                "the",
                "relevant",
                "traits,",
                "such",
                "as",
                "age",
                "in",
                "the",
                "case",
                "of",
                "cyber-bullying",
                "and",
                "gender",
                "in",
                "the",
                "case",
                "of",
                "sexism.",
                "In",
                "user",
                "embeddings",
                "and",
                "social",
                "graph",
                "based",
                "methods,",
                "the",
                "profiles",
                "are",
                "instead",
                "generated",
                "by",
                "neural",
                "network",
                "architectures",
                "to",
                "capture",
                "the",
                "linguistic",
                "behavior",
                "or",
                "community",
                "traits",
                "of",
                "users.",
                "That",
                "said,",
                "across",
                "all",
                "three",
                "categories,",
                "the",
                "profiles",
                "essentially",
                "provide",
                "a",
                "wider",
                "context",
                "to",
                "the",
                "comment",
                "being",
                "classified",
                "for",
                "abuse.",
                "For",
                "example,",
                "having",
                "the",
                "gender",
                "of",
                "the",
                "user",
                "who",
                "produces",
                "a",
                "comment",
                "such",
                "as",
                "\"Had",
                "an",
                "accident,",
                "women",
                "can't",
                "drive",
                "it",
                "seems!\"",
                "can",
                "help",
                "to",
                "classify",
                "the",
                "comment",
                "as",
                "sexist",
                "or",
                "not",
                "by",
                "differentiating",
                "benign",
                "self-deprecating",
                "humor",
                "from",
                "intent",
                "to",
                "degrade.",
                "The",
                "context",
                "that",
                "the",
                "profiles",
                "encode",
                "increases",
                "as",
                "we",
                "go",
                "from",
                "social",
                "feature",
                "engineering",
                "based",
                "methods",
                "to",
                "user",
                "embeddings",
                "based",
                "methods",
                "and",
                "further",
                "to",
                "social",
                "graph",
                "based",
                "methods.",
                "This",
                "is",
                "also",
                "evident",
                "from",
                "the",
                "magnitude",
                "of",
                "gains",
                "that",
                "the",
                "profiles",
                "provide",
                "on",
                "top",
                "of",
                "linguistic",
                "features.",
                "For",
                "example,",
                "the",
                "gender",
                "feature",
                "only",
                "increases",
                "the",
                "F",
                "1",
                "from",
                "73.89%",
                "to",
                "73.93%",
                "over",
                "character",
                "n-gram",
                "counts",
                "on",
                "the",
                "dataset",
                "by",
                "#REF",
                ",",
                "while",
                "the",
                "social",
                "graph",
                "based",
                "method",
                "of",
                "#TARGET_REF",
                "increases",
                "the",
                "F",
                "1",
                "to",
                "above",
                "80%.",
                "The",
                "example",
                "aside,",
                "it",
                "makes",
                "intuitive",
                "sense",
                "that",
                "profiles",
                "from",
                "social",
                "graph",
                "based",
                "methods",
                "encode",
                "the",
                "most",
                "amount",
                "of",
                "context,",
                "since",
                "these",
                "profiles",
                "are",
                "able",
                "to",
                "capture",
                "the",
                "various",
                "phenomena",
                "that",
                "occur",
                "in",
                "social",
                "networks,",
                "the",
                "most",
                "prominent",
                "ones",
                "of",
                "which",
                "are:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "capture the relevant traits, such as age in the case of cyber-bullying and gender in the case of sexism. In user embeddings and social graph based methods, the profiles are instead generated by neural network architectures to capture the linguistic behavior or community traits of users. That said, across all three categories, the profiles essentially provide a wider context to the comment being classified for abuse. For example, having the gender of the user who produces a comment such as \"Had an accident, women can't drive it seems!\" can help to classify the comment as sexist or not by differentiating benign self-deprecating humor from intent to degrade. The context that the profiles encode increases as we go from social feature engineering based methods to user embeddings based methods and further to social graph based methods. This is also evident from the magnitude of gains that the profiles provide on top of linguistic features. For example, the gender feature only increases the F 1 from 73.89% to 73.93% over character n-gram counts on the dataset by #REF , while the social graph based method of #TARGET_REF increases the F 1 to above 80%. The example aside, it makes intuitive sense that profiles from social graph based methods encode the most amount of context, since these profiles are able to capture the various phenomena that occur in social networks, the most prominent ones of which are:",
        "output": "{\"INFO\": [\"the social graph based method of #TARGET_REF\"], \"PERCEPT\": [\"increases the F 1 to above 80%.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "pretrained",
                "BERT",
                "2",
                "#REF",
                "for",
                "the",
                "mention",
                "and",
                "context",
                "encoder.",
                "This",
                "BERT-based",
                "encoder",
                "accepts",
                "as",
                "input",
                "a",
                "token",
                "sequence",
                "formatted",
                "asx",
                "=",
                "[CLS]",
                "m",
                "[SEP]",
                "s",
                "[SEP],where",
                "the",
                "mention",
                "m",
                "and",
                "context",
                "s",
                "are",
                "chunked",
                "into",
                "WordPiece",
                "tokens",
                "#TARGET_REF",
                ".",
                "We",
                "encode",
                "the",
                "whole",
                "sequence",
                "using",
                "BERT",
                "and",
                "use",
                "the",
                "hidden",
                "vector",
                "at",
                "the",
                "[CLS]",
                "token",
                "as",
                "the",
                "mention",
                "and",
                "context",
                "representation:h",
                "[CLS]",
                "=",
                "BERTENCODER(x).Type",
                "Embeddings",
                "This",
                "output",
                "layer",
                "is",
                "a",
                "single",
                "linear",
                "layer",
                "whose",
                "parameter",
                "matrix",
                "can",
                "be",
                "viewed",
                "as",
                "a",
                "matrix",
                "of",
                "type",
                "embeddings",
                "E",
                "∈",
                "R",
                "|T",
                "|×d",
                ",",
                "where",
                "d",
                "is",
                "the",
                "dimension",
                "of",
                "the",
                "mention",
                "and",
                "context",
                "representation",
                "h",
                "#REF",
                ".",
                "We",
                "obtain",
                "the",
                "output",
                "probabilities",
                "t",
                "by",
                "multiplying",
                "E",
                "by",
                "h",
                "[CLS]",
                ",",
                "followed",
                "by",
                "an",
                "element-wise",
                "sigmoid",
                "function:t",
                "=",
                "σ",
                "(E",
                "•",
                "h",
                "[CLS]).",
                "3",
                "Similar",
                "to",
                "previous",
                "work",
                "#REF",
                ",",
                "we",
                "assume",
                "independence",
                "between",
                "all",
                "entity",
                "type",
                "in",
                "T",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We use pretrained BERT 2 #REF for the mention and context encoder. This BERT-based encoder accepts as input a token sequence formatted asx = [CLS] m [SEP] s [SEP],where the mention m and context s are chunked into WordPiece tokens #TARGET_REF . We encode the whole sequence using BERT and use the hidden vector at the [CLS] token as the mention and context representation:h [CLS] = BERTENCODER(x).Type Embeddings This output layer is a single linear layer whose parameter matrix can be viewed as a matrix of type embeddings E ∈ R |T |×d , where d is the dimension of the mention and context representation h #REF . We obtain the output probabilities t by multiplying E by h [CLS] , followed by an element-wise sigmoid function:t = σ (E • h [CLS]). 3 Similar to previous work #REF , we assume independence between all entity type in T .",
        "output": "{\"INFO\": [\"WordPiece tokens #TARGET_REF .\"], \"PERCEPT\": [\"We use pretrained BERT 2 #REF for the mention and context encoder. This BERT-based encoder accepts as input a token sequence formatted asx = [CLS] m [SEP] s [SEP],where the mention m and context s are chunked into\", \"We encode the whole sequence using BERT and use the hidden vector at the [CLS] token as the mention and context representation:h [CLS] = BERTENCODER(x).Type\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Modern",
                "search",
                "engines",
                "often",
                "attempt",
                "to",
                "provide",
                "structured",
                "search",
                "results",
                "that",
                "reveal",
                "more",
                "facets",
                "of",
                "the",
                "search",
                "query",
                "than",
                "explicitly",
                "requested.",
                "These",
                "results",
                "rely",
                "on",
                "knowledge",
                "bases",
                "that",
                "contain",
                "tuples",
                "of",
                "the",
                "form",
                "(entity,",
                "attribute,",
                "value).",
                "However,",
                "the",
                "number",
                "of",
                "known",
                "entities",
                "and",
                "attributes",
                "in",
                "these",
                "knowledge",
                "bases",
                "is",
                "limited",
                "and",
                "there",
                "is",
                "a",
                "long",
                "tail",
                "of",
                "both",
                "entities",
                "and",
                "attributes",
                "that",
                "is",
                "too",
                "large",
                "to",
                "be",
                "manually",
                "curated.",
                "The",
                "goal",
                "of",
                "automatic",
                "entityattribute",
                "extraction",
                "is",
                "to",
                "replace",
                "manual",
                "knowledge",
                "acquisition",
                "which",
                "is",
                "expensive",
                "and",
                "biased",
                "towards",
                "popular",
                "entities",
                "#TARGET_REF",
                ".",
                "Previous",
                "studies",
                "have",
                "proposed",
                "model-based",
                "approaches",
                "that",
                "use",
                "various",
                "NLP",
                "features,",
                "distant",
                "supervision",
                "and",
                "traditional",
                "machine",
                "learning",
                "methods",
                "for",
                "entity-attribute",
                "extraction",
                "but",
                "*",
                "Work",
                "done",
                "during",
                "an",
                "internship",
                "at",
                "Google.",
                "their",
                "precision",
                "has",
                "not",
                "been",
                "high",
                "enough",
                "to",
                "replace",
                "manually",
                "curated",
                "knowledge",
                "bases",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Modern search engines often attempt to provide structured search results that reveal more facets of the search query than explicitly requested. These results rely on knowledge bases that contain tuples of the form (entity, attribute, value). However, the number of known entities and attributes in these knowledge bases is limited and there is a long tail of both entities and attributes that is too large to be manually curated. The goal of automatic entityattribute extraction is to replace manual knowledge acquisition which is expensive and biased towards popular entities #TARGET_REF . Previous studies have proposed model-based approaches that use various NLP features, distant supervision and traditional machine learning methods for entity-attribute extraction but * Work done during an internship at Google. their precision has not been high enough to replace manually curated knowledge bases #REF .",
        "output": "{\"INFO\": [\"The goal of automatic entityattribute extraction is to replace manual knowledge acquisition which is expensive and biased towards popular entities #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Previous studies have proposed model-based approaches that use various NLP features, distant supervision and traditional machine learning methods for entity-attribute extraction but\", \"their precision has not been high enough to replace manually curated knowledge bases #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "First,",
                "there",
                "is",
                "no",
                "agreed-upon",
                "definition",
                "of",
                "bridging",
                "#TARGET_REF",
                ".",
                "Consequently,",
                "manual",
                "annotation",
                "of",
                "bridging",
                "relations,",
                "and",
                "the",
                "use",
                "of",
                "these",
                "annotations,",
                "requires",
                "substantial",
                "expertise",
                "and",
                "effort.",
                "In",
                "contrast,",
                "NP",
                "Enrichment",
                "is",
                "compactly",
                "defined,",
                "and",
                "is",
                "amenable",
                "to",
                "large-scale",
                "annotation",
                "after",
                "only",
                "a",
                "brief",
                "annotator",
                "training."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "First, there is no agreed-upon definition of bridging #TARGET_REF . Consequently, manual annotation of bridging relations, and the use of these annotations, requires substantial expertise and effort. In contrast, NP Enrichment is compactly defined, and is amenable to large-scale annotation after only a brief annotator training.",
        "output": "{\"INFO\": [\"bridging #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"First, there is no agreed-upon definition of\", \"Consequently, manual annotation of bridging relations, and the use of these annotations, requires substantial expertise and effort.\"]}"
    },
    {
        "gold": {
            "text": [
                "Hope",
                "and",
                "Keller",
                "(2013),",
                "for",
                "example,",
                "use",
                "a",
                "graph",
                "of",
                "co-occurrences",
                "for",
                "word",
                "sense",
                "induction.",
                "Later",
                "#TARGET_REF",
                "use",
                "a",
                "similar",
                "method",
                "to",
                "disambiguate",
                "word",
                "embedding",
                "models."
            ],
            "context": [
                3,
                3,
                3,
                3,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Hope and Keller (2013), for example, use a graph of co-occurrences for word sense induction. Later #TARGET_REF use a similar method to disambiguate word embedding models.",
        "output": "{\"INFO\": [\"Later #TARGET_REF use a similar method to disambiguate word embedding models.\"], \"PERCEPT\": [], \"BACK\": [\"Hope and Keller (2013),\", \"use a graph of co-occurrences for word sense induction.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "apply",
                "the",
                "proposed",
                "framework",
                "and",
                "quantify",
                "second-order",
                "robustness",
                "through",
                "two",
                "second-order",
                "attacks",
                "(",
                "§3).",
                "We",
                "experiment",
                "with",
                "English",
                "sentiment",
                "classification",
                "on",
                "the",
                "SST-2",
                "dataset",
                "#TARGET_REF",
                "across",
                "various",
                "model",
                "architectures.",
                "Surprisingly,",
                "although",
                "robustly",
                "trained",
                "CNN",
                "#REF",
                "and",
                "Transformer",
                "#REF",
                "can",
                "achieve",
                "high",
                "robustness",
                "under",
                "strong",
                "attacks",
                "#REF",
                ")",
                "(23.0%-71.6%",
                "success",
                "rates),",
                "for",
                "around",
                "96.0%",
                "of",
                "the",
                "test",
                "examples",
                "our",
                "attacks",
                "can",
                "find",
                "a",
                "vulnerable",
                "example",
                "by",
                "perturbing",
                "1.3",
                "words",
                "on",
                "average.",
                "This",
                "finding",
                "indicates",
                "that",
                "these",
                "robustly",
                "trained",
                "models,",
                "despite",
                "being",
                "first-order",
                "robust,",
                "are",
                "not",
                "second-order",
                "robust."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We apply the proposed framework and quantify second-order robustness through two second-order attacks ( §3). We experiment with English sentiment classification on the SST-2 dataset #TARGET_REF across various model architectures. Surprisingly, although robustly trained CNN #REF and Transformer #REF can achieve high robustness under strong attacks #REF ) (23.0%-71.6% success rates), for around 96.0% of the test examples our attacks can find a vulnerable example by perturbing 1.3 words on average. This finding indicates that these robustly trained models, despite being first-order robust, are not second-order robust.",
        "output": "{\"INFO\": [\"the SST-2 dataset #TARGET_REF\"], \"PERCEPT\": [\"We experiment with English sentiment classification on\", \"across various model architectures.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "For",
                "each",
                "task,",
                "we",
                "downloaded",
                "and",
                "directly",
                "used",
                "the",
                "vanilla",
                "Transformer",
                "code",
                "offered",
                "by",
                "the",
                "authors",
                "#TARGET_REF",
                "and",
                "compared",
                "the",
                "performance",
                "before",
                "and",
                "after",
                "replacing",
                "the",
                "multi-head",
                "attention",
                "layers",
                "with",
                "top-128",
                "attention,",
                "using",
                "identical",
                "hyperparameters",
                "for",
                "both",
                "cases",
                "(details",
                "in",
                "§A.1).",
                "2",
                "Test",
                "accuracy",
                "measured",
                "at",
                "the",
                "training",
                "checkpoint",
                "with",
                "the",
                "highest",
                "accuracy",
                "on",
                "the",
                "development",
                "set",
                "is",
                "reported",
                "in",
                "Table",
                "1",
                "and",
                "the",
                "learning",
                "curves",
                "on",
                "the",
                "development",
                "and",
                "test",
                "sets",
                "are",
                "shown",
                "in",
                "Fig.",
                "5.",
                "On",
                "IMDb",
                "and",
                "AAN,",
                "the",
                "performance",
                "of",
                "top-128",
                "is",
                "comparable",
                "or",
                "better",
                "than",
                "vanilla",
                "attention.",
                "For",
                "ListOps,",
                "there",
                "is",
                "a",
                "minor",
                "drop",
                "in",
                "performance",
                "(1.5",
                "points),",
                "but",
                "learning",
                "curves",
                "(Figure",
                "5a)",
                "exhibit",
                "similar",
                "behaviour."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "For each task, we downloaded and directly used the vanilla Transformer code offered by the authors #TARGET_REF and compared the performance before and after replacing the multi-head attention layers with top-128 attention, using identical hyperparameters for both cases (details in §A.1). 2 Test accuracy measured at the training checkpoint with the highest accuracy on the development set is reported in Table 1 and the learning curves on the development and test sets are shown in Fig. 5. On IMDb and AAN, the performance of top-128 is comparable or better than vanilla attention. For ListOps, there is a minor drop in performance (1.5 points), but learning curves (Figure 5a) exhibit similar behaviour.",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"For each task, we downloaded and directly used the vanilla Transformer code offered by the authors\", \"and compared the performance before and after replacing the multi-head attention layers with top-128 attention, using identical hyperparameters for both cases (details in \\u00a7A.1).\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Text-based",
                "Game",
                "Playing",
                "and",
                "Generation.",
                "Recent",
                "text",
                "game",
                "playing",
                "works",
                "have",
                "focused",
                "on",
                "tackling",
                "three",
                "primary",
                "challenges:",
                "(1)",
                "how",
                "to",
                "represent",
                "agent",
                "knowledge",
                "to",
                "effectively",
                "operate",
                "in",
                "partially",
                "observable",
                "environments",
                "#REF",
                ",",
                "(2)",
                "scaling",
                "RL",
                "algorithms",
                "to",
                "handle",
                "combinatorial",
                "natural",
                "language",
                "state-action",
                "spaces",
                "#TARGET_REF",
                ",",
                "and",
                "(3)",
                "giving",
                "agents",
                "commonsense",
                "priors",
                "to",
                "better",
                "reason",
                "about",
                "the",
                "world",
                "#REF",
                "On",
                "the",
                "flip",
                "side,",
                "we",
                "have",
                "procedural",
                "generation",
                "of",
                "games",
                "with",
                "works",
                "such",
                "as",
                "Short",
                "and",
                "Adams",
                "(2017),",
                "Risi",
                "and",
                "Togelius",
                "(2019),",
                "Khalifa",
                "et",
                "al."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Text-based Game Playing and Generation. Recent text game playing works have focused on tackling three primary challenges: (1) how to represent agent knowledge to effectively operate in partially observable environments #REF , (2) scaling RL algorithms to handle combinatorial natural language state-action spaces #TARGET_REF , and (3) giving agents commonsense priors to better reason about the world #REF On the flip side, we have procedural generation of games with works such as Short and Adams (2017), Risi and Togelius (2019), Khalifa et al.",
        "output": "{\"INFO\": [\"scaling RL algorithms to handle combinatorial natural language state-action spaces #TARGET_REF ,\"], \"PERCEPT\": [\"we have procedural generation of games with works such as Short and Adams (2017), Risi and Togelius (2019), Khalifa et al.\"], \"BACK\": [\"Recent text game playing works have focused on tackling three primary challenges: (1) how to represent agent knowledge to effectively operate in partially observable environments\", \"and (3) giving agents commonsense priors to better reason about the world #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "have",
                "started",
                "working",
                "on",
                "these",
                "issues,",
                "but",
                "none",
                "of",
                "it",
                "was",
                "finally",
                "used",
                "in",
                "our",
                "system,",
                "mainly",
                "due",
                "to",
                "the",
                "fact",
                "that",
                "no",
                "native",
                "speaker",
                "of",
                "the",
                "Arabic",
                "language",
                "was",
                "available.",
                "The",
                "submitted",
                "system",
                "was",
                "only",
                "retuned",
                "on",
                "the",
                "ASR",
                "1-best",
                "development",
                "data.",
                "Table",
                "5",
                "compares",
                "the",
                "BLEU",
                "score",
                "on",
                "various",
                "data",
                "sets",
                "of",
                "the",
                "text",
                "and",
                "ASR",
                "condition.",
                "We",
                "observe",
                "a",
                "degradation",
                "of",
                "about",
                "11%",
                "relative",
                "when",
                "translating",
                "the",
                "ASR",
                "output",
                "of",
                "Dev5",
                "and",
                "of",
                "16%",
                "for",
                "Dev6",
                "respectively.",
                "Unfortunately,",
                "translation",
                "of",
                "the",
                "ASR",
                "output",
                "did",
                "not",
                "work",
                "very",
                "well",
                "on",
                "this",
                "year's",
                "test",
                "data.",
                "High",
                "word",
                "error",
                "rates",
                "of",
                "the",
                "speech",
                "recognition",
                "module",
                "favor",
                "the",
                "translation",
                "of",
                "consensus",
                "networks",
                "#TARGET_REF",
                "since",
                "the",
                "oracle",
                "error",
                "rate",
                "of",
                "such",
                "data",
                "structures",
                "is",
                "usually",
                "two",
                "to",
                "three",
                "times",
                "smaller.",
                "However,",
                "this",
                "data",
                "structure",
                "is",
                "incompatible",
                "with",
                "SYSTRAN's",
                "tokenization",
                "that",
                "operates",
                "at",
                "the",
                "sentence",
                "level."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We have started working on these issues, but none of it was finally used in our system, mainly due to the fact that no native speaker of the Arabic language was available. The submitted system was only retuned on the ASR 1-best development data. Table 5 compares the BLEU score on various data sets of the text and ASR condition. We observe a degradation of about 11% relative when translating the ASR output of Dev5 and of 16% for Dev6 respectively. Unfortunately, translation of the ASR output did not work very well on this year's test data. High word error rates of the speech recognition module favor the translation of consensus networks #TARGET_REF since the oracle error rate of such data structures is usually two to three times smaller. However, this data structure is incompatible with SYSTRAN's tokenization that operates at the sentence level.",
        "output": "{\"INFO\": [\"translation of consensus networks #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"High word error rates of the speech recognition module favor the\", \"since the oracle error rate of such data structures is usually two to three times smaller.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "key",
                "hypothesis",
                "in",
                "the",
                "pursuit",
                "towards",
                "creating",
                "goal-driven",
                "natural",
                "language-based",
                "agents",
                "posits",
                "that",
                "interactivity",
                "and",
                "environment",
                "grounding",
                "is",
                "critical",
                "for",
                "effective",
                "language",
                "learning",
                "#TARGET_REF",
                ".",
                "Text",
                "games",
                "provide",
                "a",
                "platform",
                "on",
                "which",
                "to",
                "interactively",
                "train",
                "agents",
                "that",
                "can",
                "both",
                "act",
                "and",
                "speak",
                "in",
                "a",
                "situated",
                "manner-producing",
                "language",
                "that",
                "is",
                "both",
                "goal-driven",
                "and",
                "contextually",
                "relevant."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "A key hypothesis in the pursuit towards creating goal-driven natural language-based agents posits that interactivity and environment grounding is critical for effective language learning #TARGET_REF . Text games provide a platform on which to interactively train agents that can both act and speak in a situated manner-producing language that is both goal-driven and contextually relevant.",
        "output": "{\"INFO\": [\"A key hypothesis in the pursuit towards creating goal-driven natural language-based agents posits that interactivity and environment grounding is critical for effective language learning #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Text games provide a platform on which to interactively train agents that can both act and speak in a situated manner-producing language that is both goal-driven and contextually relevant.\"]}"
    },
    {
        "gold": {
            "text": [
                "Augmented",
                "Training",
                "Dataset:",
                "Another",
                "explored",
                "solution",
                "for",
                "the",
                "unbalance",
                "in",
                "subtask",
                "1a",
                "consists",
                "in",
                "augmenting",
                "the",
                "poorly",
                "represented",
                "class",
                "(the",
                "positive",
                "class).",
                "We",
                "leverage",
                "the",
                "predefined",
                "augmentation",
                "approaches",
                "integrated",
                "into",
                "the",
                "Tex-tAttack",
                "library",
                "#REF",
                ".",
                "New",
                "positive",
                "examples",
                "are",
                "generated",
                "by",
                "char",
                "swapping,",
                "by",
                "replacing",
                "words",
                "with",
                "synonyms",
                "from",
                "the",
                "Word-Net",
                "thesaurus",
                "#REF",
                ",",
                "and",
                "by",
                "using",
                "methods",
                "from",
                "the",
                "CheckList",
                "testing",
                "-i.e.,",
                "transformations",
                "like",
                "location",
                "replacement",
                "or",
                "number",
                "alteration",
                "#TARGET_REF",
                ".",
                "Five",
                "positive",
                "examples",
                "are",
                "automatically",
                "added",
                "for",
                "each",
                "initial",
                "positive",
                "sample,",
                "thus",
                "increasing",
                "the",
                "proportion",
                "of",
                "the",
                "poorly",
                "represented",
                "class",
                "from",
                "7%",
                "to",
                "almost",
                "45%."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Augmented Training Dataset: Another explored solution for the unbalance in subtask 1a consists in augmenting the poorly represented class (the positive class). We leverage the predefined augmentation approaches integrated into the Tex-tAttack library #REF . New positive examples are generated by char swapping, by replacing words with synonyms from the Word-Net thesaurus #REF , and by using methods from the CheckList testing -i.e., transformations like location replacement or number alteration #TARGET_REF . Five positive examples are automatically added for each initial positive sample, thus increasing the proportion of the poorly represented class from 7% to almost 45%.",
        "output": "{\"INFO\": [\"transformations like location replacement or number alteration #TARGET_REF\"], \"PERCEPT\": [\"New positive examples are generated\", \"by using methods from the CheckList testing\"], \"BACK\": [\"by char swapping, by replacing words with synonyms from the Word-Net thesaurus #REF , and\"]}"
    },
    {
        "gold": {
            "text": [
                "Pre-training",
                "We",
                "pre-trained",
                "two",
                "MT",
                "models",
                "with",
                "the",
                "Spanish-English",
                "language-pair",
                "in",
                "both",
                "directions.",
                "We",
                "did",
                "not",
                "include",
                "an",
                "agglutinative",
                "language",
                "like",
                "Finnish",
                "#TARGET_REF",
                "for",
                "two",
                "reasons:",
                "it",
                "is",
                "not",
                "a",
                "must",
                "to",
                "consider",
                "highly",
                "related",
                "languages",
                "for",
                "effective",
                "transfer",
                "learning",
                "(e.g.",
                "English-German",
                "to",
                "English-Tamil",
                "#REF",
                "),",
                "and",
                "we",
                "wanted",
                "to",
                "translate",
                "the",
                "English",
                "side",
                "of",
                "en-aym,",
                "en-quy",
                "and",
                "en-quz",
                "to",
                "augment",
                "their",
                "correspondent",
                "Spanish-paired",
                "datasets.",
                "The",
                "en→es",
                "and",
                "es→en",
                "models",
                "achieved",
                "34.4",
                "and",
                "32.3",
                "BLEU",
                "points,",
                "respectively,",
                "in",
                "the",
                "newsdev2013",
                "set."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Pre-training We pre-trained two MT models with the Spanish-English language-pair in both directions. We did not include an agglutinative language like Finnish #TARGET_REF for two reasons: it is not a must to consider highly related languages for effective transfer learning (e.g. English-German to English-Tamil #REF ), and we wanted to translate the English side of en-aym, en-quy and en-quz to augment their correspondent Spanish-paired datasets. The en→es and es→en models achieved 34.4 and 32.3 BLEU points, respectively, in the newsdev2013 set.",
        "output": "{\"INFO\": [\"an agglutinative language like Finnish #TARGET_REF\"], \"PERCEPT\": [\"We did not include\", \"for two reasons:\"], \"BACK\": [\"it is not a must to consider highly related languages for effective transfer learning\", \"and we wanted to translate the English side of en-aym, en-quy and en-quz to augment their correspondent Spanish-paired datasets.\"]}"
    },
    {
        "gold": {
            "text": [
                "the",
                "best",
                "performance",
                "is",
                "obtained",
                "when",
                "averaging",
                "the",
                "results",
                "from",
                "RoBERTa",
                "#REF",
                "facts",
                "to",
                "the",
                "question",
                "using",
                "BM25",
                "vectors",
                "and",
                "then",
                "update",
                "the",
                "query",
                "vector",
                "via",
                "a",
                "max",
                "operation.",
                "The",
                "iterative",
                "retrieval",
                "step",
                "is",
                "performed",
                "until",
                "a",
                "list",
                "of",
                "K",
                "=",
                "200",
                "facts",
                "is",
                "selected",
                "from",
                "the",
                "knowledge",
                "base.",
                "Subsequently,",
                "the",
                "top",
                "K",
                "explanation",
                "facts",
                "are",
                "re-ranked",
                "using",
                "language",
                "models.",
                "The",
                "best",
                "model",
                "consists",
                "of",
                "an",
                "ensemble",
                "of",
                "BERT",
                "#TARGET_REF",
                "and",
                "SciBERT",
                "#REF",
                ".",
                "These",
                "models",
                "are",
                "fine-tuned",
                "to",
                "predict",
                "the",
                "target",
                "explanatory",
                "relevance",
                "ratings",
                "using",
                "the",
                "following",
                "input:",
                "Question",
                "+",
                "Answer",
                "[SEP]",
                "Explanation.",
                "Specifically,",
                "the",
                "authors",
                "frame",
                "the",
                "problem",
                "as",
                "a",
                "regression",
                "via",
                "mean",
                "squared",
                "error",
                "loss.",
                "The",
                "ensemble",
                "is",
                "achieved",
                "by",
                "linearly",
                "combining",
                "the",
                "scores",
                "of",
                "the",
                "models.",
                "The",
                "authors",
                "reported",
                "two",
                "negative",
                "results",
                "obtained",
                "using",
                "a",
                "two-stage",
                "approach",
                "and",
                "different",
                "negative",
                "sampling",
                "techniques.",
                "In",
                "the",
                "two-stage",
                "approach,",
                "the",
                "facts",
                "were",
                "firstly",
                "categorized",
                "using",
                "binary",
                "scores",
                "to",
                "discriminate",
                "between",
                "relevant",
                "and",
                "irrelevant",
                "sentences,",
                "and",
                "then",
                "re-ranked",
                "predicting",
                "the",
                "target",
                "explanatory",
                "relevance",
                "rating.",
                "Regarding",
                "the",
                "negative",
                "sampling",
                "strategy,",
                "the",
                "authors",
                "noticed",
                "that",
                "highest",
                "percentage",
                "of",
                "errors",
                "occurring",
                "at",
                "inference",
                "time",
                "was",
                "due",
                "to",
                "irrelevant",
                "facts",
                "that",
                "are",
                "lexically",
                "close",
                "to",
                "highly",
                "relevant",
                "explanation",
                "sentences.",
                "They",
                "attempted",
                "to",
                "alleviate",
                "this",
                "problem",
                "by",
                "randomly",
                "sampling",
                "facts",
                "from",
                "the",
                "knowledge",
                "base",
                "and",
                "retrieving",
                "close",
                "negative",
                "examples",
                "during",
                "training.",
                "Neither",
                "of",
                "these",
                "two",
                "methods",
                "resulted",
                "in",
                "significant",
                "improvements."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                3,
                3,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "the best performance is obtained when averaging the results from RoBERTa #REF facts to the question using BM25 vectors and then update the query vector via a max operation. The iterative retrieval step is performed until a list of K = 200 facts is selected from the knowledge base. Subsequently, the top K explanation facts are re-ranked using language models. The best model consists of an ensemble of BERT #TARGET_REF and SciBERT #REF . These models are fine-tuned to predict the target explanatory relevance ratings using the following input: Question + Answer [SEP] Explanation. Specifically, the authors frame the problem as a regression via mean squared error loss. The ensemble is achieved by linearly combining the scores of the models. The authors reported two negative results obtained using a two-stage approach and different negative sampling techniques. In the two-stage approach, the facts were firstly categorized using binary scores to discriminate between relevant and irrelevant sentences, and then re-ranked predicting the target explanatory relevance rating. Regarding the negative sampling strategy, the authors noticed that highest percentage of errors occurring at inference time was due to irrelevant facts that are lexically close to highly relevant explanation sentences. They attempted to alleviate this problem by randomly sampling facts from the knowledge base and retrieving close negative examples during training. Neither of these two methods resulted in significant improvements.",
        "output": "{\"INFO\": [\"BERT #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The best model consists of an ensemble of\", \"and SciBERT\", \"These models are fine-tuned to predict the target explanatory relevance ratings using the following input: Question + Answer [SEP] Explanation.\"]}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "advantage",
                "is",
                "that",
                "it",
                "provides",
                "precomputed",
                "contextual",
                "word",
                "representations.",
                "QA",
                "models",
                "based",
                "on",
                "LSTMs",
                "are",
                "built",
                "on",
                "top",
                "of",
                "static",
                "word",
                "embeddings",
                "models",
                "such",
                "as",
                "GloVe",
                "#TARGET_REF",
                ".",
                "Even",
                "these",
                "models",
                "have",
                "up",
                "to",
                "40",
                "times",
                "fewer",
                "parameters",
                "than",
                "a",
                "BERT-based",
                "model,",
                "they",
                "rely",
                "on",
                "LSTM-based",
                "encoders",
                "to",
                "produce",
                "contextual",
                "embeddings",
                "which",
                "considerably",
                "lengthens",
                "the",
                "time",
                "required",
                "for",
                "training",
                "and",
                "makes",
                "the",
                "dependence",
                "on",
                "supervised",
                "data",
                "more",
                "important."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Another advantage is that it provides precomputed contextual word representations. QA models based on LSTMs are built on top of static word embeddings models such as GloVe #TARGET_REF . Even these models have up to 40 times fewer parameters than a BERT-based model, they rely on LSTM-based encoders to produce contextual embeddings which considerably lengthens the time required for training and makes the dependence on supervised data more important.",
        "output": "{\"INFO\": [\"GloVe #TARGET_REF .\"], \"PERCEPT\": [\"Another advantage is that it provides precomputed contextual word representations.\", \"Even these models have up to 40 times fewer parameters than a BERT-based model, they rely on LSTM-based encoders to produce contextual embeddings which considerably lengthens the time required for training and makes the dependence on supervised data more important.\"], \"BACK\": [\"QA models based on LSTMs are built on top of static word embeddings models such as\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "interaction",
                "layer",
                "is",
                "the",
                "core",
                "element",
                "of",
                "the",
                "architecture",
                "for",
                "which",
                "several",
                "kinds",
                "attention",
                "mechanisms",
                "has",
                "been",
                "developed",
                "to",
                "improve",
                "the",
                "QA",
                "matching",
                "process",
                "such",
                "as",
                "bi-attention",
                "#REF",
                ",",
                "co-attention",
                "#REF",
                "or",
                "re-attention",
                "#TARGET_REF",
                ",",
                "to",
                "name",
                "just",
                "a",
                "few."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The interaction layer is the core element of the architecture for which several kinds attention mechanisms has been developed to improve the QA matching process such as bi-attention #REF , co-attention #REF or re-attention #TARGET_REF , to name just a few.",
        "output": "{\"INFO\": [\"re-attention #TARGET_REF ,\"], \"PERCEPT\": [\"The interaction layer is the core element of the architecture for which several kinds attention mechanisms has been developed to improve the QA matching process such as\", \"to name just a few.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Early",
                "work",
                "in",
                "opinion",
                "question",
                "answering",
                "addressed",
                "separating",
                "facts",
                "from",
                "opinions",
                "#TARGET_REF",
                ",",
                "and",
                "the",
                "authors",
                "used",
                "a",
                "Naïve",
                "Bayes",
                "classifier",
                "to",
                "identify",
                "polarity",
                "of",
                "the",
                "opinions.",
                "#REF",
                "aimed",
                "at",
                "identifying",
                "the",
                "opinion",
                "holder",
                "of",
                "the",
                "opinions.",
                "#REF",
                "explained",
                "the",
                "differences",
                "between",
                "fact",
                "based",
                "and",
                "opinionated",
                "answers",
                "and",
                "how",
                "traditional",
                "QA",
                "systems",
                "will",
                "not",
                "be",
                "able",
                "to",
                "handle",
                "multiple",
                "perspectives",
                "for",
                "answers.",
                "Some",
                "works",
                "aimed",
                "at",
                "using",
                "community",
                "based",
                "question-answers",
                "to",
                "provide",
                "unique",
                "answers",
                "to",
                "questions",
                "#REF",
                ".",
                "#REF",
                "made",
                "use",
                "of",
                "online",
                "reviews",
                "to",
                "answer",
                "questions",
                "on",
                "aspects",
                "of",
                "a",
                "product.",
                "#REF",
                "and",
                "#REF",
                "used",
                "graphs",
                "and",
                "trees",
                "to",
                "answer",
                "opinion",
                "questions.",
                "#REF",
                "modeled",
                "ambiguity",
                "and",
                "subjectivity",
                "in",
                "opinion",
                "QA",
                "using",
                "statistical",
                "models.",
                "#REF",
                "give",
                "baselines",
                "for",
                "answer",
                "generation",
                "systems",
                "given",
                "the",
                "question",
                "and",
                "reviews.",
                "We",
                "use",
                "their",
                "results",
                "as",
                "the",
                "baseline",
                "for",
                "our",
                "evaluation.",
                "We",
                "also",
                "discuss",
                "the",
                "dataset",
                "from",
                "this",
                "paper",
                "in",
                "4.2.",
                "While",
                "most",
                "systems",
                "used",
                "in",
                "the",
                "works",
                "described",
                "above",
                "are",
                "supervised",
                "learning",
                "models,",
                "our",
                "system",
                "used",
                "unsupervised",
                "learning",
                "to",
                "answer",
                "binary",
                "(yes/no)",
                "questions."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Early work in opinion question answering addressed separating facts from opinions #TARGET_REF , and the authors used a Naïve Bayes classifier to identify polarity of the opinions. #REF aimed at identifying the opinion holder of the opinions. #REF explained the differences between fact based and opinionated answers and how traditional QA systems will not be able to handle multiple perspectives for answers. Some works aimed at using community based question-answers to provide unique answers to questions #REF . #REF made use of online reviews to answer questions on aspects of a product. #REF and #REF used graphs and trees to answer opinion questions. #REF modeled ambiguity and subjectivity in opinion QA using statistical models. #REF give baselines for answer generation systems given the question and reviews. We use their results as the baseline for our evaluation. We also discuss the dataset from this paper in 4.2. While most systems used in the works described above are supervised learning models, our system used unsupervised learning to answer binary (yes/no) questions.",
        "output": "{\"INFO\": [\"Early work in opinion question answering addressed separating facts from opinions #TARGET_REF , and the authors used a Na\\u00efve Bayes classifier to identify polarity of the opinions.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "approach",
                "consists",
                "of",
                "translating",
                "the",
                "QA",
                "triples",
                "of",
                "the",
                "target",
                "domain",
                "into",
                "the",
                "source",
                "domain,",
                "so",
                "the",
                "model",
                "trained",
                "on",
                "the",
                "source",
                "language",
                "can",
                "be",
                "directly",
                "applied",
                "on",
                "the",
                "translated",
                "target",
                "language",
                "testing",
                "data.",
                "As",
                "an",
                "exemple,",
                "#TARGET_REF",
                "'s",
                "method",
                "consisted",
                "of",
                "combining",
                "the",
                "alignment",
                "attention",
                "scores",
                "from",
                "a",
                "MT",
                "model",
                "with",
                "an",
                "English",
                "QA",
                "model",
                "to",
                "guide",
                "the",
                "answer",
                "extraction",
                "process."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Another approach consists of translating the QA triples of the target domain into the source domain, so the model trained on the source language can be directly applied on the translated target language testing data. As an exemple, #TARGET_REF 's method consisted of combining the alignment attention scores from a MT model with an English QA model to guide the answer extraction process.",
        "output": "{\"INFO\": [\"#TARGET_REF 's method consisted of combining the alignment attention scores from a MT model with an English QA model to guide the answer extraction process.\"], \"PERCEPT\": [\"As an exemple,\"], \"BACK\": [\"Another approach consists of translating the QA triples of the target domain into the source domain,\"]}"
    },
    {
        "gold": {
            "text": [
                "BERT-based",
                "models",
                "have",
                "the",
                "advantage",
                "that",
                "we",
                "can",
                "directly",
                "use",
                "the",
                "attention",
                "scores",
                "as",
                "explanations",
                "of",
                "model",
                "decisions.",
                "For",
                "models",
                "with",
                "other",
                "architectures,",
                "we",
                "can",
                "use",
                "explanation",
                "techniques",
                "such",
                "as",
                "LIME",
                "#REF",
                "or",
                "Path",
                "Integrated",
                "Gradient",
                "approaches",
                "#TARGET_REF",
                "to",
                "provide",
                "explanations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2
            ]
        },
        "input": "BERT-based models have the advantage that we can directly use the attention scores as explanations of model decisions. For models with other architectures, we can use explanation techniques such as LIME #REF or Path Integrated Gradient approaches #TARGET_REF to provide explanations.",
        "output": "{\"INFO\": [\"Path Integrated Gradient approaches #TARGET_REF\"], \"PERCEPT\": [\"For models with other architectures, we can use explanation techniques such as\", \"to provide explanations.\"], \"BACK\": [\"BERT-based models have the advantage that we can directly use the attention scores as explanations of model decisions.\", \"LIME #REF or\"]}"
    },
    {
        "gold": {
            "text": [
                "of",
                "clusters",
                "is",
                "not",
                "provided",
                "as",
                "input,",
                "but",
                "for",
                "correct",
                "sets",
                "R",
                "it",
                "holds",
                "that",
                "∀n",
                "j",
                "∈",
                "c(n",
                "j",
                "),(n",
                "i",
                ",",
                "prep,",
                "n",
                "j",
                ")",
                "∈",
                "R",
                "⇒",
                "(n",
                "i",
                ",",
                "prep,",
                "n",
                "j",
                ")",
                "∈",
                "R,",
                "where",
                "c(n",
                "j",
                ")",
                "∈",
                "C",
                "is",
                "the",
                "cluster",
                "containing",
                "n",
                "j",
                ".Completeness",
                "and",
                "Uniformity",
                "The",
                "kinds",
                "of",
                "preposition-mediated",
                "relations",
                "we",
                "cover",
                "originate",
                "from",
                "different",
                "linguistic",
                "or",
                "cognitive",
                "phenomena,",
                "and",
                "some",
                "of",
                "them",
                "can",
                "be",
                "resolved",
                "by",
                "employing",
                "different",
                "linguistic",
                "constructs.",
                "For",
                "example,",
                "some",
                "within-sentence",
                "relations",
                "can",
                "be",
                "extracted",
                "deterministically",
                "from",
                "dependency",
                "trees,",
                "for",
                "example,",
                "by",
                "following",
                "syntactic",
                "prepositional",
                "attachment.",
                "Other",
                "relations",
                "can",
                "be",
                "inferred",
                "based",
                "on",
                "pronominal",
                "coreference",
                "(e.g.,",
                "''his",
                "school",
                "[of",
                "Adam]''",
                "above",
                "can",
                "be",
                "resolved",
                "by",
                "first",
                "resolving",
                "''his''",
                "to",
                "''Adam's''",
                "via",
                "a",
                "coreference",
                "engine,",
                "and",
                "then",
                "normalizing",
                "''Adam's",
                "school''",
                "→",
                "''school",
                "of",
                "Adam'').",
                "Many",
                "others",
                "are",
                "substantially",
                "more",
                "involved.",
                "We",
                "deliberately",
                "chose",
                "not",
                "to",
                "distinguish",
                "between",
                "the",
                "different",
                "cases,",
                "and",
                "expose",
                "all",
                "the",
                "relations",
                "to",
                "the",
                "user",
                "(and",
                "to",
                "the",
                "annotators)",
                "via",
                "the",
                "same",
                "uniform",
                "interface.",
                "This",
                "approach",
                "also",
                "contributes",
                "to",
                "the",
                "practical",
                "usefulness",
                "of",
                "the",
                "task:",
                "Instead",
                "of",
                "running",
                "several",
                "different",
                "processes",
                "to",
                "recover",
                "different",
                "kinds",
                "of",
                "links,",
                "the",
                "end-user",
                "will",
                "have",
                "to",
                "run",
                "only",
                "one",
                "process",
                "to",
                "obtain",
                "them",
                "all."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "of clusters is not provided as input, but for correct sets R it holds that ∀n j ∈ c(n j ),(n i , prep, n j ) ∈ R ⇒ (n i , prep, n j ) ∈ R, where c(n j ) ∈ C is the cluster containing n j .Completeness and Uniformity The kinds of preposition-mediated relations we cover originate from different linguistic or cognitive phenomena, and some of them can be resolved by employing different linguistic constructs. For example, some within-sentence relations can be extracted deterministically from dependency trees, for example, by following syntactic prepositional attachment. Other relations can be inferred based on pronominal coreference (e.g., ''his school [of Adam]'' above can be resolved by first resolving ''his'' to ''Adam's'' via a coreference engine, and then normalizing ''Adam's school'' → ''school of Adam''). Many others are substantially more involved. We deliberately chose not to distinguish between the different cases, and expose all the relations to the user (and to the annotators) via the same uniform interface. This approach also contributes to the practical usefulness of the task: Instead of running several different processes to recover different kinds of links, the end-user will have to run only one process to obtain them all.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "All",
                "methods",
                "and",
                "materials",
                "discussed",
                "in",
                "this",
                "paper",
                "were",
                "tested",
                "on",
                "a",
                "fully",
                "functional",
                "machine",
                "translation",
                "system",
                "based",
                "on",
                "Apertium",
                "#REF",
                "and",
                "#TARGET_REF",
                ",",
                "an",
                "opensource",
                "RBMT",
                "toolkit."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "All methods and materials discussed in this paper were tested on a fully functional machine translation system based on Apertium #REF and #TARGET_REF , an opensource RBMT toolkit.",
        "output": "{\"INFO\": [\"#TARGET_REF , an opensource RBMT toolkit.\"], \"PERCEPT\": [\"All methods and materials discussed in this paper were tested on a fully functional machine translation system based on\"], \"BACK\": [\"Apertium #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "Model.",
                "The",
                "proposed",
                "method",
                "will",
                "be",
                "able",
                "to",
                "process",
                "several",
                "modalities",
                "that",
                "play",
                "a",
                "crucial",
                "role",
                "in",
                "communication,",
                "(i)",
                "Linguistic",
                "Information",
                "(at",
                "syntactic",
                "and",
                "semantic",
                "level),",
                "(ii)",
                "Situational",
                "Information,",
                "(iii)",
                "Prototypical",
                "Knowledge",
                "and",
                "Relations,",
                "and",
                "(iv)",
                "Speech-accompanying",
                "eye-movements",
                "of",
                "the",
                "speaker.",
                "The",
                "initial",
                "base",
                "model",
                "will",
                "focus",
                "on",
                "the",
                "first",
                "three",
                "capabilities",
                "by",
                "utilizing",
                "data-driven",
                "language",
                "models",
                "such",
                "as",
                "fasttext",
                "#REF",
                "and",
                "commonsense",
                "knowledge-bases",
                "like",
                "ConceptNet",
                "#REF",
                ".",
                "At",
                "the",
                "same",
                "time,",
                "two",
                "modules",
                "that",
                "(i)",
                "incorporate",
                "eye-movements",
                "and",
                "(ii)",
                "perform",
                "situation-specific",
                "feature",
                "adaptation",
                "will",
                "be",
                "developed",
                "from",
                "scratch.",
                "In",
                "brief,",
                "vocabulary",
                "obtained",
                "from",
                "the",
                "pre-trained",
                "embeddings",
                "is",
                "used",
                "as",
                "a",
                "bridge",
                "between",
                "the",
                "modalities.",
                "For",
                "each",
                "vocabulary",
                "item,",
                "multimodal",
                "embeddings",
                "will",
                "be",
                "created",
                "by",
                "processing",
                "every",
                "input",
                "channel,",
                "see",
                "Figure",
                "2.",
                "For",
                "each",
                "modality",
                "and",
                "their",
                "joint",
                "training,",
                "we",
                "will",
                "utilize",
                "an",
                "appropriate",
                "encoder,",
                "such",
                "as",
                "Fast-R-CNN",
                "#REF",
                "for",
                "images",
                "and",
                "attention-based",
                "bi-directional",
                "LSTMs",
                "(e.g.",
                "#TARGET_REF",
                ",",
                "for",
                "text",
                "and",
                "eye-movement",
                "data.",
                "A",
                "neural",
                "network",
                "ensemble",
                "model",
                "will",
                "be",
                "trained",
                "on",
                "the",
                "embeddings",
                "for",
                "the",
                "task",
                "of",
                "intended",
                "object",
                "or",
                "action",
                "prediction",
                "from",
                "situated",
                "settings",
                "with",
                "masked",
                "information."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Model. The proposed method will be able to process several modalities that play a crucial role in communication, (i) Linguistic Information (at syntactic and semantic level), (ii) Situational Information, (iii) Prototypical Knowledge and Relations, and (iv) Speech-accompanying eye-movements of the speaker. The initial base model will focus on the first three capabilities by utilizing data-driven language models such as fasttext #REF and commonsense knowledge-bases like ConceptNet #REF . At the same time, two modules that (i) incorporate eye-movements and (ii) perform situation-specific feature adaptation will be developed from scratch. In brief, vocabulary obtained from the pre-trained embeddings is used as a bridge between the modalities. For each vocabulary item, multimodal embeddings will be created by processing every input channel, see Figure 2. For each modality and their joint training, we will utilize an appropriate encoder, such as Fast-R-CNN #REF for images and attention-based bi-directional LSTMs (e.g. #TARGET_REF , for text and eye-movement data. A neural network ensemble model will be trained on the embeddings for the task of intended object or action prediction from situated settings with masked information.",
        "output": "{\"INFO\": [\"#TARGET_REF ,\"], \"PERCEPT\": [\"For each modality and their joint training, we will utilize an appropriate encoder, such as Fast-R-CNN #REF for images and attention-based bi-directional LSTMs\", \"for text and eye-movement data.\"], \"BACK\": [\"(e.g.\", \"A neural network ensemble model will be trained on the embeddings for the task of intended object or action prediction from situated settings with masked information.\"]}"
    },
    {
        "gold": {
            "text": [
                "text",
                "generation",
                "of",
                "CTERM-GAN",
                "with",
                "that",
                "of",
                "SeqGAN",
                "#REF",
                ",",
                "SentiGAN",
                "#REF",
                "and",
                "an",
                "RNNLM",
                "baseline",
                "#REF",
                ".",
                "Following",
                "the",
                "experiments",
                "carried",
                "out",
                "in",
                "#TARGET_REF",
                ",",
                "the",
                "conditioning",
                "has",
                "been",
                "performed",
                "based",
                "on",
                "only",
                "two",
                "sentiments,",
                "positive",
                "or",
                "negative.",
                "In",
                "this",
                "case,",
                "the",
                "conditioning",
                "vector,",
                "c,",
                "taken",
                "as",
                "input",
                "by",
                "CTERM-GAN",
                "is",
                "a",
                "one-hot",
                "binary",
                "variable",
                "representing",
                "the",
                "desired",
                "sentiment.",
                "The",
                "RNNLM",
                "and",
                "SeqGAN",
                "models",
                "have",
                "been",
                "trained",
                "separately",
                "on",
                "the",
                "two",
                "sentiments",
                "by",
                "treating",
                "positive",
                "and",
                "negative",
                "sentences",
                "as",
                "two",
                "separate",
                "datasets,",
                "while",
                "SentiGAN",
                "and",
                "the",
                "proposed",
                "model",
                "have",
                "been",
                "trained",
                "jointly.",
                "This",
                "procedure",
                "makes",
                "the",
                "results",
                "comparable",
                "although",
                "it",
                "is",
                "clear",
                "how",
                "the",
                "flexibility",
                "of",
                "SentiGAN",
                "and",
                "CTERM-GAN",
                "makes",
                "these",
                "models",
                "more",
                "general.",
                "Dataset",
                "We",
                "have",
                "used",
                "two",
                "datasets,",
                "Movie",
                "Reviews",
                "(MR)",
                "#REF",
                "and",
                "Customer",
                "Reviews",
                "(CR)",
                "#REF",
                ",",
                "where",
                "individual",
                "sentences",
                "are",
                "annotated",
                "as",
                "either",
                "positive",
                "or",
                "negative.",
                "The",
                "Movie",
                "Reviews",
                "dataset",
                "consists",
                "of",
                "user",
                "reviews",
                "of",
                "movies,",
                "with",
                "2,",
                "133",
                "positive",
                "and",
                "2,",
                "370",
                "negative",
                "sentences.",
                "The",
                "Customer",
                "Reviews",
                "dataset",
                "consists",
                "of",
                "1,",
                "500",
                "reviews",
                "of",
                "products",
                "sold",
                "online,",
                "with",
                "positive/negative",
                "annotation",
                "at",
                "sentence",
                "level.",
                "For",
                "this",
                "task,",
                "only",
                "sentences",
                "of",
                "length",
                "shorter",
                "than",
                "15",
                "words",
                "have",
                "been",
                "retained,",
                "to",
                "be",
                "able",
                "to",
                "use",
                "the",
                "same",
                "preprocessing",
                "as",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "text generation of CTERM-GAN with that of SeqGAN #REF , SentiGAN #REF and an RNNLM baseline #REF . Following the experiments carried out in #TARGET_REF , the conditioning has been performed based on only two sentiments, positive or negative. In this case, the conditioning vector, c, taken as input by CTERM-GAN is a one-hot binary variable representing the desired sentiment. The RNNLM and SeqGAN models have been trained separately on the two sentiments by treating positive and negative sentences as two separate datasets, while SentiGAN and the proposed model have been trained jointly. This procedure makes the results comparable although it is clear how the flexibility of SentiGAN and CTERM-GAN makes these models more general. Dataset We have used two datasets, Movie Reviews (MR) #REF and Customer Reviews (CR) #REF , where individual sentences are annotated as either positive or negative. The Movie Reviews dataset consists of user reviews of movies, with 2, 133 positive and 2, 370 negative sentences. The Customer Reviews dataset consists of 1, 500 reviews of products sold online, with positive/negative annotation at sentence level. For this task, only sentences of length shorter than 15 words have been retained, to be able to use the same preprocessing as #REF .",
        "output": "{\"INFO\": [\"SentiGAN\"], \"PERCEPT\": [\"Following the experiments carried out in #TARGET_REF , the conditioning has been performed based on only two sentiments, positive or negative.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "½",
                "•",
                "«",
                "½",
                "have",
                "cost",
                "3,",
                "«",
                "¿",
                "has",
                "cost",
                "6",
                "(3",
                "for",
                "the",
                "pattern",
                "tree",
                "«",
                "¿",
                ",",
                "and",
                "3",
                "for",
                "the",
                "left",
                "child",
                "as",
                "annotated",
                "in",
                "the",
                "previous",
                "step),",
                "«",
                "has",
                "cost",
                "5.",
                "As",
                "both",
                "«",
                "alternatives",
                "span",
                "the",
                "same",
                "subtree",
                "from",
                "this",
                "node",
                "down,",
                "and",
                "have",
                "the",
                "same",
                "return",
                "type",
                "(sub),",
                "it",
                "is",
                "possible",
                "to",
                "discard",
                "the",
                "annotation",
                "«",
                "¿",
                ",",
                "as",
                "it",
                "will",
                "always",
                "be",
                "cheaper",
                "to",
                "use",
                "«",
                "at",
                "this",
                "point,",
                "regardless",
                "of",
                "what",
                "happens",
                "further",
                "up",
                "the",
                "tree.",
                "At",
                "the",
                "next",
                "higher",
                "node,",
                "the",
                "annotations",
                "¬",
                "½",
                "•",
                "«",
                "½",
                "½",
                "and",
                "¬",
                "½",
                "•",
                "«",
                "½",
                "have",
                "cost",
                "6,",
                "and",
                "«",
                "¿",
                "has",
                "cost",
                "8.",
                "Finally,",
                "at",
                "the",
                "top",
                "Ë",
                "node,",
                "«",
                "¾",
                "has",
                "cost",
                "13",
                "(5",
                "for",
                "the",
                "pattern",
                "tree,",
                "8",
                "for",
                "the",
                "left",
                "child:",
                "as",
                "the",
                "pattern",
                "tree",
                "can",
                "only",
                "accept",
                "an",
                "initial",
                "tree",
                "as",
                "the",
                "left",
                "child,",
                "only",
                "«",
                "¿",
                "is",
                "a",
                "suitable",
                "candidate),",
                "but",
                "«",
                "½",
                "has",
                "cost",
                "10",
                "(4",
                "for",
                "the",
                "pattern",
                "tree,",
                "6",
                "for",
                "the",
                "intervening",
                "auxiliary",
                "trees).",
                "The",
                "algorithm",
                "in",
                "Figure",
                "8",
                "is",
                "modified",
                "so",
                "that",
                "any",
                "annotation",
                "in",
                "an",
                "annotation",
                "set",
                "with",
                "the",
                "same",
                "type",
                "but",
                "non-minimal",
                "cost",
                "is",
                "discarded.",
                "Thus",
                "the",
                "derivation",
                "of",
                "the",
                "optimal",
                "tree",
                "parse,",
                "top-down,",
                "would",
                "be",
                "«",
                "½",
                "with",
                "an",
                "adjunction",
                "of",
                "¬",
                "½",
                "which",
                "in",
                "turn",
                "has",
                "an",
                "adjunction",
                "of",
                "¬",
                "½",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "½ • « ½ have cost 3, « ¿ has cost 6 (3 for the pattern tree « ¿ , and 3 for the left child as annotated in the previous step), « has cost 5. As both « alternatives span the same subtree from this node down, and have the same return type (sub), it is possible to discard the annotation « ¿ , as it will always be cheaper to use « at this point, regardless of what happens further up the tree. At the next higher node, the annotations ¬ ½ • « ½ ½ and ¬ ½ • « ½ have cost 6, and « ¿ has cost 8. Finally, at the top Ë node, « ¾ has cost 13 (5 for the pattern tree, 8 for the left child: as the pattern tree can only accept an initial tree as the left child, only « ¿ is a suitable candidate), but « ½ has cost 10 (4 for the pattern tree, 6 for the intervening auxiliary trees). The algorithm in Figure 8 is modified so that any annotation in an annotation set with the same type but non-minimal cost is discarded. Thus the derivation of the optimal tree parse, top-down, would be « ½ with an adjunction of ¬ ½ which in turn has an adjunction of ¬ ½ .",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Among",
                "the",
                "EC",
                "projects",
                "working",
                "in",
                "this",
                "direction",
                "we",
                "mention",
                "LE",
                "SPARKLE",
                "(Shallow",
                "PARsing",
                "and",
                "Knowledge",
                "extraction",
                "for",
                "Language",
                "Engineering",
                "2",
                "),",
                "combining",
                "shallow",
                "parsing",
                "and",
                "lexical",
                "acquisition",
                "techniques",
                "capable",
                "of",
                "learning",
                "(from",
                "large",
                "corpora)",
                "aspects",
                "of",
                "word",
                "knowledge",
                "required",
                "for",
                "LE",
                "applications",
                "#TARGET_REF",
                ".",
                "The",
                "project",
                "(http://www.ilc.pi.cnr.it/sparkle.html)",
                "is",
                "positioned",
                "as",
                "research",
                "on",
                "the",
                "development",
                "of",
                "methodologies",
                "and",
                "techniques",
                "for",
                "application-or",
                "domaindependent",
                "lexical",
                "resources",
                "to",
                "be",
                "acquired",
                "(semi)automatically",
                "from",
                "texts,",
                "an",
                "area",
                "which",
                "is",
                "crucial",
                "to",
                "most",
                "NLP",
                "applications.",
                "Economically",
                "feasible",
                "development",
                "of",
                "language",
                "models",
                "and",
                "of",
                "substantial",
                "lexical",
                "resources",
                "for",
                "real-world",
                "NLP",
                "applications",
                "needs",
                "to",
                "be",
                "based",
                "on",
                "substantially",
                "(semi)-automated",
                "techniques",
                "and",
                "flexible",
                "tools",
                "for",
                "analysing",
                "and",
                "extracting",
                "lexical",
                "information",
                "from",
                "textual",
                "corpora,",
                "otherwise",
                "coverage",
                "and/or",
                "accuracy",
                "will",
                "remain",
                "inadequate."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Among the EC projects working in this direction we mention LE SPARKLE (Shallow PARsing and Knowledge extraction for Language Engineering 2 ), combining shallow parsing and lexical acquisition techniques capable of learning (from large corpora) aspects of word knowledge required for LE applications #TARGET_REF . The project (http://www.ilc.pi.cnr.it/sparkle.html) is positioned as research on the development of methodologies and techniques for application-or domaindependent lexical resources to be acquired (semi)automatically from texts, an area which is crucial to most NLP applications. Economically feasible development of language models and of substantial lexical resources for real-world NLP applications needs to be based on substantially (semi)-automated techniques and flexible tools for analysing and extracting lexical information from textual corpora, otherwise coverage and/or accuracy will remain inadequate.",
        "output": "{\"INFO\": [\"LE SPARKLE (Shallow PARsing and Knowledge extraction for Language Engineering 2 ), combining shallow parsing and lexical acquisition techniques capable of learning (from large corpora) aspects of word knowledge required for LE applications #TARGET_REF .\"], \"PERCEPT\": [\"Among the EC projects working in this direction we mention\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Specifically,",
                "for",
                "the",
                "document",
                "retrieval",
                "step,",
                "we",
                "narrow",
                "the",
                "search",
                "space",
                "with",
                "an",
                "information",
                "retrieval",
                "model",
                "DRQA",
                "#TARGET_REF",
                "and",
                "then",
                "rerank",
                "the",
                "retrieved",
                "pages.",
                "For",
                "the",
                "evidence",
                "retrieval",
                "step,",
                "we",
                "design",
                "a",
                "multi-turn",
                "cell",
                "selector",
                "to",
                "extract",
                "sentence",
                "evidence",
                "and",
                "table",
                "evidence",
                "respectively,",
                "and",
                "select",
                "evidence",
                "cells",
                "from",
                "tables.",
                "Finally,",
                "we",
                "propose",
                "a",
                "Dual",
                "Channel",
                "Unified",
                "Format",
                "verification",
                "model",
                "(DCUF,",
                "shown",
                "in",
                "Figure",
                "2)",
                "for",
                "the",
                "verification",
                "step.",
                "DCUF",
                "converts",
                "evidence",
                "to",
                "a",
                "unified",
                "table/sentence",
                "format",
                "with",
                "carefully-designed",
                "evidence",
                "conversion",
                "and",
                "re-organization",
                "methods",
                "in",
                "each",
                "channel,",
                "and",
                "combine",
                "dual-channel",
                "encodings",
                "to",
                "make",
                "the",
                "final",
                "prediction."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Specifically, for the document retrieval step, we narrow the search space with an information retrieval model DRQA #TARGET_REF and then rerank the retrieved pages. For the evidence retrieval step, we design a multi-turn cell selector to extract sentence evidence and table evidence respectively, and select evidence cells from tables. Finally, we propose a Dual Channel Unified Format verification model (DCUF, shown in Figure 2) for the verification step. DCUF converts evidence to a unified table/sentence format with carefully-designed evidence conversion and re-organization methods in each channel, and combine dual-channel encodings to make the final prediction.",
        "output": "{\"INFO\": [\"an information retrieval model DRQA\"], \"PERCEPT\": [\"for the document retrieval step, we narrow the search space with\", \"and then rerank the retrieved pages. For the evidence retrieval step, we design a multi-turn cell selector to extract sentence evidence and table evidence respectively, and select evidence cells from tables.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "If",
                "there",
                "is",
                "no",
                "source",
                "text,",
                "the",
                "focus",
                "obviously",
                "falls",
                "upon",
                "the",
                "generation",
                "of",
                "the",
                "target",
                "text(s),",
                "a",
                "problem",
                "in",
                "MT",
                "which",
                "was",
                "for",
                "a",
                "long",
                "time",
                "seriously",
                "underestimated",
                "(cf.",
                "#REF",
                ").",
                "Our",
                "present",
                "approach",
                "has",
                "been",
                "influenced",
                "by",
                "the",
                "'phrasebook'",
                "approach",
                "to",
                "speech",
                "translation",
                "#TARGET_REF",
                ",",
                "in",
                "which",
                "set",
                "phrases",
                "are",
                "stored,",
                "as",
                "in",
                "a",
                "holidaymaker's",
                "phrasebook,",
                "and",
                "retrieved",
                "by",
                "the",
                "fairly",
                "crude,",
                "though",
                "effective,",
                "technique",
                "of",
                "recognising",
                "keywords",
                "in",
                "a",
                "particular",
                "order",
                "in",
                "the",
                "input",
                "speech",
                "signal.",
                "It",
                "also",
                "builds",
                "on",
                "research",
                "on",
                "interactive",
                "generation",
                "of",
                "stereotypical",
                "texts",
                "(",
                "#REF",
                "),",
                "where",
                "texts",
                "in",
                "certain",
                "restricted",
                "domains",
                "are",
                "stored",
                "and",
                "retrieved",
                "as",
                "appropriate",
                "through",
                "interaction",
                "with",
                "users,",
                "and",
                "are",
                "reformulated",
                "to",
                "fulfill",
                "the",
                "specific",
                "requirements",
                "expressed",
                "by",
                "them."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. #REF ). Our present approach has been influenced by the 'phrasebook' approach to speech translation #TARGET_REF , in which set phrases are stored, as in a holidaymaker's phrasebook, and retrieved by the fairly crude, though effective, technique of recognising keywords in a particular order in the input speech signal. It also builds on research on interactive generation of stereotypical texts ( #REF ), where texts in certain restricted domains are stored and retrieved as appropriate through interaction with users, and are reformulated to fulfill the specific requirements expressed by them.",
        "output": "{\"INFO\": [\"speech translation #TARGET_REF , in which set phrases are stored, as in a holidaymaker's phrasebook, and retrieved by the fairly crude, though effective, technique of recognising keywords in a particular order in the input speech signal. It also builds on research on interactive generation of stereotypical texts ( #REF ), where texts in certain restricted domains are stored and retrieved as appropriate through interaction with users, and are reformulated to fulfill the specific requirements expressed by them.\"], \"PERCEPT\": [\"Our present approach has been influenced by the 'phrasebook' approach to\"], \"BACK\": [\"If there is no source text, the focus obviously falls upon the generation of the target text(s), a problem in MT which was for a long time seriously underestimated (cf. #REF ).\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "design",
                "a",
                "memory",
                "component",
                "to",
                "identify",
                "the",
                "salient",
                "words",
                "of",
                "system",
                "utterances",
                "in",
                "terms",
                "of",
                "modeling",
                "state",
                "transitions",
                "(Sec.",
                "3.2).",
                "To",
                "further",
                "boost",
                "the",
                "memory's",
                "capability",
                "in",
                "learning",
                "compact",
                "natural",
                "language",
                "actions,",
                "we",
                "propose",
                "a",
                "novel",
                "auxiliary",
                "task",
                "to",
                "identify",
                "salient",
                "words",
                "of",
                "dialogue",
                "context",
                "in",
                "a",
                "supervised",
                "setting",
                "#TARGET_REF",
                ".",
                "Furthermore,we",
                "propose",
                "to",
                "take",
                "more",
                "advantage",
                "from",
                "the",
                "action",
                "learning",
                "phase",
                "by",
                "reusing",
                "the",
                "memory",
                "component",
                "for",
                "conditioned",
                "response",
                "generation",
                "(Sec.",
                "3.4)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We design a memory component to identify the salient words of system utterances in terms of modeling state transitions (Sec. 3.2). To further boost the memory's capability in learning compact natural language actions, we propose a novel auxiliary task to identify salient words of dialogue context in a supervised setting #TARGET_REF . Furthermore,we propose to take more advantage from the action learning phase by reusing the memory component for conditioned response generation (Sec. 3.4).",
        "output": "{\"INFO\": [\"a novel auxiliary task to identify salient words of dialogue context in a supervised setting #TARGET_REF .\"], \"PERCEPT\": [\"we propose\"], \"BACK\": [\"To further boost the memory's capability in learning compact natural language actions,\"]}"
    },
    {
        "gold": {
            "text": [
                "BoW",
                "+",
                "BERT",
                "As",
                "a",
                "baseline,",
                "we",
                "consider",
                "the",
                "retrieve-and-rerank",
                "approach",
                "originally",
                "proposed",
                "by",
                "#TARGET_REF",
                ",",
                "which",
                "has",
                "emerged",
                "as",
                "the",
                "standard",
                "architecture",
                "for",
                "applying",
                "pretrained",
                "transformers",
                "to",
                "ranking.",
                "We",
                "notate",
                "a",
                "specific",
                "configuration",
                "of",
                "this",
                "design",
                "as",
                "BoW(k",
                "0",
                ")",
                "+",
                "BERT,",
                "where",
                "k",
                "0",
                "denotes",
                "the",
                "number",
                "of",
                "candidates",
                "from",
                "bag-of-words",
                "retrieval",
                "that",
                "are",
                "then",
                "reranked",
                "by",
                "BERT.",
                "A",
                "commonly",
                "used",
                "default",
                "is",
                "BoW(1000)",
                "+",
                "BERT",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "BoW + BERT As a baseline, we consider the retrieve-and-rerank approach originally proposed by #TARGET_REF , which has emerged as the standard architecture for applying pretrained transformers to ranking. We notate a specific configuration of this design as BoW(k 0 ) + BERT, where k 0 denotes the number of candidates from bag-of-words retrieval that are then reranked by BERT. A commonly used default is BoW(1000) + BERT #REF .",
        "output": "{\"INFO\": [\"the retrieve-and-rerank approach originally proposed by #TARGET_REF\"], \"PERCEPT\": [\"As a baseline, we consider\", \"which has emerged as the standard architecture for applying pretrained transformers to ranking. We notate a specific configuration of this design as BoW(k 0 ) + BERT, where k 0 denotes the number of candidates from bag-of-words retrieval that are then reranked by BERT.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "As",
                "shown",
                "in",
                "Table",
                "1,",
                "the",
                "size",
                "of",
                "the",
                "'in-domain'",
                "TED",
                "training",
                "data",
                "is",
                "much",
                "smaller",
                "than",
                "the",
                "'out-of-domain'",
                "Multi-UN",
                "training",
                "data.",
                "Since",
                "adding",
                "a",
                "significant",
                "amount",
                "of",
                "out-ofdomain",
                "data",
                "to",
                "an",
                "in-domain",
                "corpus",
                "reduces",
                "the",
                "quality",
                "of",
                "translation",
                "for",
                "in-domain",
                "sentences",
                "#TARGET_REF",
                ",",
                "we",
                "decided",
                "to",
                "use",
                "only",
                "a",
                "part",
                "of",
                "the",
                "out-of-domain",
                "data",
                "to",
                "enhance",
                "the",
                "translation",
                "quality.",
                "In",
                "order",
                "to",
                "achieve",
                "this,",
                "we",
                "constructed",
                "a",
                "language",
                "model",
                "on",
                "the",
                "TED",
                "monolingual",
                "data",
                "and",
                "computed",
                "sentence-level",
                "perplexity",
                "score",
                "for",
                "all",
                "the",
                "sentences",
                "in",
                "Multi-UN,",
                "with",
                "respect",
                "to",
                "the",
                "TED",
                "language",
                "model.",
                "After",
                "sorting",
                "the",
                "sentences",
                "in",
                "the",
                "ascending",
                "order",
                "of",
                "the",
                "perplexity",
                "values,",
                "only",
                "sentences",
                "below",
                "a",
                "specific",
                "threshold",
                "were",
                "selected.",
                "This",
                "method",
                "provided",
                "us",
                "with",
                "the",
                "most",
                "'TED-like'",
                "sentences",
                "from",
                "the",
                "Multi-UN",
                "corpora."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "As shown in Table 1, the size of the 'in-domain' TED training data is much smaller than the 'out-of-domain' Multi-UN training data. Since adding a significant amount of out-ofdomain data to an in-domain corpus reduces the quality of translation for in-domain sentences #TARGET_REF , we decided to use only a part of the out-of-domain data to enhance the translation quality. In order to achieve this, we constructed a language model on the TED monolingual data and computed sentence-level perplexity score for all the sentences in Multi-UN, with respect to the TED language model. After sorting the sentences in the ascending order of the perplexity values, only sentences below a specific threshold were selected. This method provided us with the most 'TED-like' sentences from the Multi-UN corpora.",
        "output": "{\"INFO\": [\"adding a significant amount of out-ofdomain data to an in-domain corpus reduces the quality of translation for in-domain sentences #TARGET_REF ,\"], \"PERCEPT\": [\"Since\", \"we decided to use only a part of the out-of-domain data to enhance the translation quality.\"], \"BACK\": [\"the size of the 'in-domain' TED training data is much smaller than the 'out-of-domain' Multi-UN training data.\"]}"
    },
    {
        "gold": {
            "text": [
                "SemEval-2022",
                "task",
                "2b",
                "#TARGET_REF",
                "encourages",
                "the",
                "creation",
                "of",
                "better",
                "representations",
                "of",
                "idiomatic",
                "expressions",
                "across",
                "multiple",
                "languages",
                "by",
                "presenting",
                "a",
                "Semantic",
                "Text",
                "Similarity",
                "(STS)",
                "task",
                "in",
                "which",
                "correct",
                "STS",
                "scores",
                "are",
                "required",
                "whether",
                "or",
                "not",
                "either",
                "sentence",
                "contains",
                "an",
                "idiomatic",
                "expression.",
                "The",
                "sub-task",
                "requires",
                "the",
                "creation",
                "of",
                "a",
                "self-consistent",
                "model",
                "in",
                "which",
                "a",
                "sentence",
                "including",
                "an",
                "idiomatic",
                "expression",
                "and",
                "one",
                "containing",
                "its",
                "literal",
                "meaning",
                "('swan",
                "song'",
                "and",
                "'final",
                "performance')",
                "are",
                "exactly",
                "similar",
                "to",
                "each",
                "other",
                "and",
                "equally",
                "similar",
                "to",
                "any",
                "other",
                "sentence."
            ],
            "context": [
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "SemEval-2022 task 2b #TARGET_REF encourages the creation of better representations of idiomatic expressions across multiple languages by presenting a Semantic Text Similarity (STS) task in which correct STS scores are required whether or not either sentence contains an idiomatic expression. The sub-task requires the creation of a self-consistent model in which a sentence including an idiomatic expression and one containing its literal meaning ('swan song' and 'final performance') are exactly similar to each other and equally similar to any other sentence.",
        "output": "{\"INFO\": [\"SemEval-2022 task 2b\", \"encourages the creation of better representations of idiomatic expressions across multiple languages by presenting a Semantic Text Similarity (STS) task in which correct STS scores are required whether or not either sentence contains an idiomatic expression.\"], \"PERCEPT\": [\"The sub-task requires the creation of a self-consistent model in which a sentence including an idiomatic expression and one containing its literal meaning\", \"are exactly similar to each other and equally similar to any other sentence.\"], \"BACK\": [\"('swan song' and 'final performance')\"]}"
    },
    {
        "gold": {
            "text": [
                "Electro-/Magnetoencephalography",
                "(EEG/MEG),",
                "which",
                "measures",
                "neural",
                "activity",
                "at",
                "millisecond",
                "resolution,",
                "is",
                "a",
                "key",
                "neuroscientific",
                "method",
                "to",
                "assess",
                "how",
                "neural",
                "representations",
                "unfold",
                "dynamically",
                "in",
                "language",
                "processing.",
                "Early",
                "event",
                "related",
                "potential",
                "(ERP)",
                "studies",
                "that",
                "rely",
                "on",
                "averaging",
                "EEG",
                "activity",
                "across",
                "multiple",
                "trials",
                "have",
                "shown",
                "that",
                "EEG",
                "signal",
                "magnitude",
                "and",
                "topography",
                "depend",
                "on",
                "word",
                "length,",
                "frequency",
                "and",
                "open",
                "vs.",
                "closed",
                "class.",
                "Word",
                "length",
                "effects",
                "arose",
                "in",
                "EEG",
                "at",
                "about",
                "150",
                "ms,",
                "frequency",
                "effects",
                "at",
                "200",
                "ms",
                "and",
                "word",
                "class",
                "effects",
                "from",
                "400-700",
                "ms",
                "#REF",
                ".",
                "Recent",
                "studies",
                "were",
                "able",
                "to",
                "predict",
                "these",
                "and",
                "other",
                "(e.g.",
                "semantic)",
                "aspects",
                "based",
                "on",
                "single",
                "trial",
                "multi-channel",
                "EEG/MEG",
                "activity",
                "#TARGET_REF",
                ".",
                "Importantly,",
                "the",
                "aim",
                "of",
                "cognitive",
                "neuroscience",
                "studies",
                "is",
                "to",
                "dissociate",
                "when",
                "(i.e.",
                "latency)",
                "and",
                "where",
                "(i.e."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Electro-/Magnetoencephalography (EEG/MEG), which measures neural activity at millisecond resolution, is a key neuroscientific method to assess how neural representations unfold dynamically in language processing. Early event related potential (ERP) studies that rely on averaging EEG activity across multiple trials have shown that EEG signal magnitude and topography depend on word length, frequency and open vs. closed class. Word length effects arose in EEG at about 150 ms, frequency effects at 200 ms and word class effects from 400-700 ms #REF . Recent studies were able to predict these and other (e.g. semantic) aspects based on single trial multi-channel EEG/MEG activity #TARGET_REF . Importantly, the aim of cognitive neuroscience studies is to dissociate when (i.e. latency) and where (i.e.",
        "output": "{\"INFO\": [\"Recent studies were able to predict these and other (e.g. semantic) aspects based on single trial multi-channel EEG/MEG activity #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"EEG signal magnitude and topography depend on word length, frequency and open vs. closed class.\"]}"
    },
    {
        "gold": {
            "text": [
                "Deep",
                "models",
                "such",
                "as",
                "Transformers",
                "rely",
                "heavily",
                "on",
                "the",
                "availability",
                "of",
                "a",
                "large",
                "amount",
                "of",
                "annotated",
                "data,",
                "which",
                "is",
                "available",
                "only",
                "for",
                "prominent",
                "languages",
                "like",
                "English,",
                "Russian,",
                "German",
                "or",
                "Spanish",
                "#REF",
                ".",
                "For",
                "a",
                "majority",
                "of",
                "other",
                "languages",
                "with",
                "a",
                "minimal",
                "number",
                "of",
                "annotations,",
                "cross-lingual",
                "transfer",
                "learning",
                "#TARGET_REF",
                "has",
                "been",
                "proposed",
                "as",
                "a",
                "possible",
                "solution.",
                "This",
                "approach",
                "can",
                "transfer",
                "knowledge",
                "from",
                "the",
                "annotation-rich",
                "source",
                "language",
                "to",
                "low-resource",
                "or",
                "zero-resource",
                "target",
                "languages.",
                "Furthermore,",
                "multilingual",
                "models",
                "#REF",
                "can",
                "be",
                "used",
                "to",
                "mitigate",
                "the",
                "data",
                "scarcity",
                "problem.",
                "For",
                "example,",
                "LASER",
                "#REF",
                ")",
                "used",
                "a",
                "bidirectional",
                "LSTM",
                "#REF",
                "encoder",
                "with",
                "a",
                "byte",
                "pair",
                "encoding",
                "vocabulary",
                "shared",
                "between",
                "languages.",
                "This",
                "work",
                "showed",
                "that",
                "joint",
                "training",
                "of",
                "multiple",
                "languages",
                "helped",
                "to",
                "improve",
                "the",
                "model",
                "performance",
                "for",
                "low-resource",
                "languages.",
                "LaBSE",
                "#REF",
                "used",
                "the",
                "mBERT",
                "#REF",
                "encoder",
                "pre-trained",
                "with",
                "masked",
                "language",
                "modelling",
                "and",
                "translation",
                "language",
                "modelling",
                "#REF",
                "tasks.",
                "It",
                "attempted",
                "to",
                "optimize",
                "the",
                "dual",
                "encoder",
                "translation",
                "ranking",
                "#REF",
                "loss",
                "during",
                "pre-training",
                "to",
                "achieve",
                "similar",
                "embedding",
                "for",
                "the",
                "same",
                "text",
                "in",
                "different",
                "languages."
            ],
            "context": [
                3,
                3,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Deep models such as Transformers rely heavily on the availability of a large amount of annotated data, which is available only for prominent languages like English, Russian, German or Spanish #REF . For a majority of other languages with a minimal number of annotations, cross-lingual transfer learning #TARGET_REF has been proposed as a possible solution. This approach can transfer knowledge from the annotation-rich source language to low-resource or zero-resource target languages. Furthermore, multilingual models #REF can be used to mitigate the data scarcity problem. For example, LASER #REF ) used a bidirectional LSTM #REF encoder with a byte pair encoding vocabulary shared between languages. This work showed that joint training of multiple languages helped to improve the model performance for low-resource languages. LaBSE #REF used the mBERT #REF encoder pre-trained with masked language modelling and translation language modelling #REF tasks. It attempted to optimize the dual encoder translation ranking #REF loss during pre-training to achieve similar embedding for the same text in different languages.",
        "output": "{\"INFO\": [\"cross-lingual transfer learning #TARGET_REF\", \"This approach can transfer knowledge from the annotation-rich source language to low-resource or zero-resource target languages.\"], \"PERCEPT\": [\"For a majority of other languages with a minimal number of annotations,\", \"has been proposed as a possible solution.\"], \"BACK\": [\"Deep models\", \"rely heavily on the availability of a large amount of annotated data, which is available only for prominent languages like English, Russian, German or Spanish #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "in",
                "return",
                "leads",
                "to",
                "hourly",
                "rate",
                "destabilization.",
                "Regardless",
                "of",
                "MT",
                "output",
                "quality,",
                "vendors",
                "tend",
                "to",
                "decline",
                "jobs",
                "due",
                "to",
                "the",
                "fact",
                "MT",
                "output",
                "is",
                "incorporated",
                "in",
                "pre-translated",
                "documents.",
                "This",
                "decrease",
                "of",
                "vendor",
                "involvement",
                "leads",
                "us",
                "to",
                "a",
                "conclusion",
                "that",
                "purely",
                "showing",
                "good",
                "MT",
                "results",
                "is",
                "not",
                "sufficient",
                "and",
                "more",
                "work",
                "is",
                "required",
                "to",
                "be",
                "done",
                "in",
                "order",
                "to",
                "start",
                "gaining",
                "investment",
                "back",
                "and",
                "increasing",
                "the",
                "ROI",
                "ratio.",
                "What",
                "we",
                "discovered",
                "on",
                "our",
                "own,",
                "stated",
                "additionally",
                "by",
                "#TARGET_REF",
                ",",
                "is",
                "that",
                "human",
                "translators'",
                "engagement",
                "is",
                "MT",
                "development",
                "is",
                "vital.",
                "People",
                "are",
                "the",
                "key",
                "factor",
                "of",
                "success",
                "of",
                "every",
                "business",
                "and",
                "winning",
                "strategies",
                "must",
                "actively",
                "involve",
                "employees",
                "on",
                "different",
                "organizational",
                "levels",
                "in",
                "technological",
                "(including",
                "MT)",
                "solution",
                "processes.",
                "In",
                "euroscript",
                "10",
                ",",
                "we",
                "regularly",
                "ask",
                "for",
                "in-house",
                "translators'",
                "MT",
                "evaluation",
                "feedback",
                "in",
                "terms",
                "of",
                "different",
                "categories",
                "of",
                "MT",
                "output",
                "errors.",
                "We",
                "devote",
                "time",
                "to",
                "correcting",
                "these",
                "mistakes,",
                "informing",
                "the",
                "in-house",
                "translators",
                "of",
                "the",
                "improvements",
                "made",
                "and",
                "engaging",
                "ourselves",
                "into",
                "increasing",
                "translators'",
                "satisfaction",
                "with",
                "working",
                "with",
                "MT.",
                "We",
                "consider",
                "different",
                "options",
                "of",
                "post-editing",
                "training",
                "focused",
                "on",
                "translators",
                "following",
                "the",
                "strategy",
                "of",
                "involving",
                "translators",
                "more",
                "with",
                "MT.",
                "This",
                "idea",
                "is",
                "also",
                "supported",
                "by:",
                "Hernández-Lasa",
                "(2011)",
                "and",
                "#REF",
                ".",
                "Our",
                "preliminary",
                "results",
                "show",
                "that",
                "roughly",
                "50%",
                "of",
                "our",
                "in-house",
                "translators,",
                "who",
                "work",
                "with",
                "MT,",
                "consider",
                "its",
                "understandability",
                "as",
                "good",
                "opposed",
                "to",
                "acceptable",
                "or",
                "bad",
                "(see",
                "#REF",
                "for",
                "MT",
                "features",
                "that",
                "influence",
                "MT",
                "understandability)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "in return leads to hourly rate destabilization. Regardless of MT output quality, vendors tend to decline jobs due to the fact MT output is incorporated in pre-translated documents. This decrease of vendor involvement leads us to a conclusion that purely showing good MT results is not sufficient and more work is required to be done in order to start gaining investment back and increasing the ROI ratio. What we discovered on our own, stated additionally by #TARGET_REF , is that human translators' engagement is MT development is vital. People are the key factor of success of every business and winning strategies must actively involve employees on different organizational levels in technological (including MT) solution processes. In euroscript 10 , we regularly ask for in-house translators' MT evaluation feedback in terms of different categories of MT output errors. We devote time to correcting these mistakes, informing the in-house translators of the improvements made and engaging ourselves into increasing translators' satisfaction with working with MT. We consider different options of post-editing training focused on translators following the strategy of involving translators more with MT. This idea is also supported by: Hernández-Lasa (2011) and #REF . Our preliminary results show that roughly 50% of our in-house translators, who work with MT, consider its understandability as good opposed to acceptable or bad (see #REF for MT features that influence MT understandability).",
        "output": "{\"INFO\": [\"#TARGET_REF ,\", \"human translators' engagement is MT development is vital.\"], \"PERCEPT\": [\"What we discovered on our own, stated additionally by\", \"is that\", \"People are the key factor of success of every business and winning strategies must actively involve employees on different organizational levels in technological (including MT) solution processes.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "deal",
                "with",
                "the",
                "absence",
                "of",
                "action",
                "annotations,",
                "latent",
                "action",
                "learning",
                "has",
                "been",
                "introduced",
                "#REF",
                ".",
                "System",
                "utterances",
                "are",
                "represented",
                "as",
                "low-dimensional",
                "latent",
                "variables",
                "by",
                "an",
                "auto-encoding",
                "task",
                "#TARGET_REF",
                ",",
                "and",
                "utterances",
                "with",
                "the",
                "same",
                "representations",
                "are",
                "considered",
                "to",
                "convey",
                "similar",
                "meanings.",
                "Such",
                "action",
                "representations",
                "might",
                "be",
                "prone",
                "to",
                "overdependence",
                "on",
                "the",
                "training",
                "data,",
                "which",
                "restricts",
                "the",
                "model",
                "generalization",
                "capability,",
                "especially",
                "when",
                "multiple",
                "domains",
                "are",
                "considered.",
                "This",
                "is",
                "because,",
                "without",
                "explicit",
                "supervision,",
                "the",
                "desired",
                "property",
                "of",
                "capturing",
                "the",
                "intentions",
                "of",
                "system",
                "utterances",
                "in",
                "the",
                "latent",
                "space",
                "cannot",
                "be",
                "enforced",
                "#REF",
                ",",
                "which",
                "in",
                "turn",
                "is",
                "due",
                "to",
                "the",
                "implicit",
                "nature",
                "of",
                "latent",
                "variables.",
                "For",
                "example,",
                "variational",
                "auto-encoder",
                "(VAE),",
                "which",
                "is",
                "often",
                "used",
                "for",
                "latent",
                "action",
                "learning,",
                "tends",
                "to",
                "produce",
                "a",
                "balanced",
                "distribution",
                "over",
                "the",
                "latent",
                "variables",
                "#REF",
                ",",
                "while",
                "the",
                "true",
                "distribution",
                "of",
                "system",
                "actions",
                "is",
                "highly",
                "imbalanced",
                "#REF",
                ".",
                "The",
                "resulting",
                "misaligned",
                "action",
                "representations",
                "would",
                "confuse",
                "the",
                "model",
                "of",
                "both",
                "steps",
                "and",
                "degenerate",
                "the",
                "sample",
                "efficiency",
                "in",
                "training."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To deal with the absence of action annotations, latent action learning has been introduced #REF . System utterances are represented as low-dimensional latent variables by an auto-encoding task #TARGET_REF , and utterances with the same representations are considered to convey similar meanings. Such action representations might be prone to overdependence on the training data, which restricts the model generalization capability, especially when multiple domains are considered. This is because, without explicit supervision, the desired property of capturing the intentions of system utterances in the latent space cannot be enforced #REF , which in turn is due to the implicit nature of latent variables. For example, variational auto-encoder (VAE), which is often used for latent action learning, tends to produce a balanced distribution over the latent variables #REF , while the true distribution of system actions is highly imbalanced #REF . The resulting misaligned action representations would confuse the model of both steps and degenerate the sample efficiency in training.",
        "output": "{\"INFO\": [\"by an auto-encoding task #TARGET_REF\"], \"PERCEPT\": [\"To deal with the absence of action annotations,\"], \"BACK\": [\"latent action learning has been introduced #REF\", \"System utterances are represented as low-dimensional latent variables\"]}"
    },
    {
        "gold": {
            "text": [
                "Quechua:",
                "with",
                "6+",
                "millions",
                "of",
                "speakers",
                "and",
                "several",
                "variants,",
                "it",
                "is",
                "the",
                "most",
                "widespread",
                "indigenous",
                "language",
                "in",
                "Peru.",
                "AmericasNLP",
                "provides",
                "evaluation",
                "sets",
                "in",
                "the",
                "standard",
                "Southern",
                "Quechua,",
                "which",
                "is",
                "based",
                "mostly",
                "on",
                "the",
                "Quechua",
                "Ayacucho",
                "(quy)",
                "variant.",
                "There",
                "is",
                "parallel",
                "data",
                "from",
                "dictionaries",
                "and",
                "Jehovah",
                "Witnesses",
                "#REF",
                ".",
                "There",
                "is",
                "parallel",
                "corpus",
                "aligned",
                "with",
                "English",
                "too.",
                "We",
                "also",
                "include",
                "the",
                "close",
                "variant",
                "of",
                "Quechua",
                "Cusco",
                "(quz)",
                "to",
                "support",
                "the",
                "multilingual",
                "learning.",
                "•",
                "Aymara",
                "(aym):",
                "with",
                "1.7",
                "million",
                "of",
                "speakers",
                "(mostly",
                "in",
                "Bolivia).",
                "The",
                "parallel",
                "and",
                "monolingual",
                "data",
                "is",
                "extracted",
                "from",
                "a",
                "news",
                "website",
                "(Global",
                "Voices)",
                "and",
                "distributed",
                "by",
                "OPUS",
                "#REF",
                ".",
                "There",
                "are",
                "aligned",
                "data",
                "with",
                "English",
                "too.",
                "•",
                "Shipibo-Konibo",
                "(shp):",
                "a",
                "Panoan",
                "language",
                "with",
                "almost",
                "30,000",
                "speakers",
                "in",
                "the",
                "Amazonian",
                "region.",
                "There",
                "are",
                "parallel",
                "data",
                "from",
                "dictionaries,",
                "educational",
                "material",
                "#REF",
                ",",
                "language",
                "learning",
                "flashcards",
                "(Gómez",
                "#REF",
                ",",
                "plus",
                "monolingual",
                "data",
                "from",
                "educational",
                "books",
                "#TARGET_REF",
                ".",
                "•",
                "Ashaninka",
                "(cni):",
                "an",
                "Arawakan",
                "language",
                "with",
                "45,000",
                "speakers",
                "in",
                "the",
                "Amazon.",
                "There",
                "is",
                "parallel",
                "data",
                "from",
                "dictionaries,",
                "laws",
                "and",
                "books",
                "#REF",
                ",",
                "plus",
                "monolingual",
                "corpus",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Quechua: with 6+ millions of speakers and several variants, it is the most widespread indigenous language in Peru. AmericasNLP provides evaluation sets in the standard Southern Quechua, which is based mostly on the Quechua Ayacucho (quy) variant. There is parallel data from dictionaries and Jehovah Witnesses #REF . There is parallel corpus aligned with English too. We also include the close variant of Quechua Cusco (quz) to support the multilingual learning. • Aymara (aym): with 1.7 million of speakers (mostly in Bolivia). The parallel and monolingual data is extracted from a news website (Global Voices) and distributed by OPUS #REF . There are aligned data with English too. • Shipibo-Konibo (shp): a Panoan language with almost 30,000 speakers in the Amazonian region. There are parallel data from dictionaries, educational material #REF , language learning flashcards (Gómez #REF , plus monolingual data from educational books #TARGET_REF . • Ashaninka (cni): an Arawakan language with 45,000 speakers in the Amazon. There is parallel data from dictionaries, laws and books #REF , plus monolingual corpus #REF .",
        "output": "{\"INFO\": [\"monolingual data from educational books #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"There are parallel data from dictionaries, educational material #REF , language learning flashcards (G\\u00f3mez #REF , plus\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "viable",
                "approach",
                "to",
                "sentiment",
                "analysis",
                "of",
                "newspaper",
                "headlines",
                "has",
                "been",
                "developed",
                "by",
                "using",
                "linguistic",
                "techniques",
                "and",
                "a",
                "broad-coverage",
                "lexicon",
                "#TARGET_REF",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "A viable approach to sentiment analysis of newspaper headlines has been developed by using linguistic techniques and a broad-coverage lexicon #TARGET_REF .",
        "output": "{\"INFO\": [\"A viable approach to sentiment analysis of newspaper headlines has been developed by using linguistic techniques and a broad-coverage lexicon #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "These",
                "items",
                "are",
                "like",
                "those",
                "proposed",
                "for",
                "the",
                "tabulation",
                "of",
                "linear",
                "indexed",
                "automata",
                "#TARGET_REF",
                "LCYK",
                "=",
                "{",
                "[A,",
                ",y,i,j",
                "I",
                "B,",
                "p,q]",
                "I",
                "A,",
                "B",
                "E",
                "VN,",
                "'Y",
                "E",
                "Vi,",
                "0",
                "::,",
                "i::,",
                "j,",
                "(p,q)",
                "::,",
                "(i,",
                "j)",
                "}",
                "11.cYK",
                "=",
                "{",
                "[",
                "a,",
                "i",
                "-1,",
                "i]",
                "I",
                "a",
                "=",
                "ai,",
                "lJ",
                "::,",
                "i",
                "::,",
                "n",
                "}",
                "v",
                "scan",
                "-",
                "[a,j,",
                "j",
                "+",
                "1]",
                "A[",
                "]",
                "➔",
                "a",
                "E",
                "p",
                "CYK",
                "-[A",
                ".",
                ".",
                "1",
                "1",
                "]",
                ",",
                "-,",
                "1",
                ",",
                "1+",
                "-,",
                "-,",
                "-I",
                "[B,-,",
                "i,",
                "k",
                "1",
                "-,",
                "-,",
                "-],",
                "1)[00-y](",
                "](oo]",
                "_",
                "[C,",
                "17",
                ",k,j",
                "I",
                "D,"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "These items are like those proposed for the tabulation of linear indexed automata #TARGET_REF LCYK = { [A, ,y,i,j I B, p,q] I A, B E VN, 'Y E Vi, 0 ::, i::, j, (p,q) ::, (i, j) } 11.cYK = { [ a, i -1, i] I a = ai, lJ ::, i ::, n } v scan - [a,j, j + 1] A[ ] ➔ a E p CYK -[A . . 1 1 ] , -, 1 , 1+ -, -, -I [B,-, i, k 1 -, -, -], 1)[00-y]( ](oo] _ [C, 17 ,k,j I D,",
        "output": "{\"INFO\": [\"the tabulation of linear indexed automata #TARGET_REF LCYK = { [A, ,y,i,j I B, p,q] I A, B E VN, 'Y E Vi, 0 ::, i::, j, (p,q) ::, (i, j) } 11.cYK = { [ a, i -1, i] I a = ai, lJ ::, i ::, n } v scan - [a,j, j + 1] A[ ] \\u2794 a E p CYK -[A . . 1 1 ] , -, 1 , 1+ -, -, -I [B,-, i, k 1 -, -, -], 1)[00-y]( ](oo] _ [C, 17 ,k,j I D,\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Sentences",
                "are",
                "represented",
                "with",
                "their",
                "shortest",
                "dependency",
                "path",
                "between",
                "two",
                "candidates,",
                "as",
                "proposed",
                "in",
                "#TARGET_REF",
                ".",
                "The",
                "bottom",
                "of",
                "Figure",
                "1",
                "shows",
                "an",
                "example",
                "of",
                "the",
                "shortest",
                "path",
                "between",
                "an",
                "entity",
                "and",
                "attribute",
                "for",
                "one",
                "sentence.",
                "We",
                "converts",
                "each",
                "sentence",
                "from",
                "a",
                "string",
                "to",
                "a",
                "list",
                "of",
                "terms,",
                "where",
                "the",
                "first",
                "and",
                "last",
                "term",
                "is",
                "either",
                "the",
                "entity",
                "or",
                "the",
                "attribute.",
                "Each",
                "term",
                "in",
                "the",
                "dependency",
                "path",
                "is",
                "represented",
                "by",
                "the",
                "lemma",
                "of",
                "the",
                "term,",
                "the",
                "part-of-speech",
                "tag,",
                "the",
                "dependency",
                "label,",
                "the",
                "direction",
                "of",
                "the",
                "dependency",
                "path",
                "to",
                "the",
                "parent",
                "(left,",
                "right",
                "or",
                "root).",
                "Each",
                "of",
                "these",
                "features",
                "is",
                "embedded",
                "and",
                "concatenated",
                "to",
                "produce",
                "a",
                "sequence",
                "of",
                "vectors",
                "that",
                "represents",
                "the",
                "dependency",
                "path.",
                "The",
                "concatenation",
                "is",
                "the",
                "edge",
                "representation−",
                "→",
                "v",
                "edge",
                "=",
                "[",
                "−",
                "→",
                "v",
                "lemma",
                ",",
                "−",
                "→",
                "v",
                "pos",
                ",",
                "−",
                "→",
                "v",
                "dep",
                ",",
                "−",
                "→",
                "v",
                "dir",
                "]The",
                "sequence",
                "of",
                "terms",
                "in",
                "each",
                "path",
                "is",
                "input",
                "into",
                "an",
                "LSTM",
                "to",
                "produce",
                "a",
                "single",
                "vector",
                "representation",
                "for",
                "the",
                "sentence,",
                "−",
                "→",
                "v",
                "s",
                ".",
                "This",
                "is",
                "repeated",
                "for",
                "each",
                "sentence",
                "producing",
                "one",
                "vector",
                "per",
                "sentence.",
                "The",
                "sentences",
                "are",
                "aggregated",
                "with",
                "a",
                "weighted",
                "mean",
                "of",
                "the",
                "sentence",
                "representations",
                "to",
                "form",
                "a",
                "representation",
                "of",
                "the",
                "multiset",
                "of",
                "sentences,",
                "−",
                "→",
                "v",
                "sents(e,a)",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Sentences are represented with their shortest dependency path between two candidates, as proposed in #TARGET_REF . The bottom of Figure 1 shows an example of the shortest path between an entity and attribute for one sentence. We converts each sentence from a string to a list of terms, where the first and last term is either the entity or the attribute. Each term in the dependency path is represented by the lemma of the term, the part-of-speech tag, the dependency label, the direction of the dependency path to the parent (left, right or root). Each of these features is embedded and concatenated to produce a sequence of vectors that represents the dependency path. The concatenation is the edge representation− → v edge = [ − → v lemma , − → v pos , − → v dep , − → v dir ]The sequence of terms in each path is input into an LSTM to produce a single vector representation for the sentence, − → v s . This is repeated for each sentence producing one vector per sentence. The sentences are aggregated with a weighted mean of the sentence representations to form a representation of the multiset of sentences, − → v sents(e,a) .",
        "output": "{\"INFO\": [\"Sentences are represented with their shortest dependency path between two candidates, as proposed in #TARGET_REF .\"], \"PERCEPT\": [\"We converts each sentence from a string to a list of terms, where the first and last term is either the entity or the attribute.\"], \"BACK\": [\"The bottom of Figure 1 shows an example of the shortest path between an entity and attribute for one sentence.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "exponential",
                "growth",
                "of",
                "published",
                "articles",
                "may",
                "exceeds",
                "many",
                "readers'",
                "ability",
                "to",
                "keep",
                "track",
                "of",
                "the",
                "development",
                "of",
                "their",
                "field",
                "of",
                "interest.",
                "Hence,",
                "automatic",
                "reading",
                "comprehension",
                "of",
                "scientific",
                "documents",
                "has",
                "attracted",
                "the",
                "attention",
                "of",
                "researchers",
                "across",
                "various",
                "domains",
                "such",
                "as",
                "Drug",
                "Discovery,",
                "Knowledge",
                "Base",
                "Construction,",
                "and",
                "Natural",
                "Language",
                "Processing.",
                "A",
                "crucial",
                "aspect",
                "of",
                "understanding",
                "scientific",
                "literature",
                "is",
                "understanding",
                "terminologies",
                "and",
                "formulae",
                "because",
                "they",
                "offer",
                "an",
                "explicit",
                "and",
                "precise",
                "interface",
                "to",
                "present",
                "the",
                "relation",
                "between",
                "scientific",
                "concepts",
                "#TARGET_REF",
                ".",
                "As",
                "such,",
                "a",
                "reading",
                "comprehension",
                "machine",
                "needs",
                "to",
                "(i)",
                "identify",
                "their",
                "descriptions",
                "and",
                "formulae,",
                "(ii)",
                "segment",
                "them",
                "into",
                "primitive",
                "terms",
                "and",
                "symbols,",
                "and",
                "(iii)",
                "link",
                "the",
                "associated",
                "terms",
                "and",
                "corresponding",
                "symbols."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The exponential growth of published articles may exceeds many readers' ability to keep track of the development of their field of interest. Hence, automatic reading comprehension of scientific documents has attracted the attention of researchers across various domains such as Drug Discovery, Knowledge Base Construction, and Natural Language Processing. A crucial aspect of understanding scientific literature is understanding terminologies and formulae because they offer an explicit and precise interface to present the relation between scientific concepts #TARGET_REF . As such, a reading comprehension machine needs to (i) identify their descriptions and formulae, (ii) segment them into primitive terms and symbols, and (iii) link the associated terms and corresponding symbols.",
        "output": "{\"INFO\": [\"A crucial aspect of understanding scientific literature is understanding terminologies and formulae because they offer an explicit and precise interface to present the relation between scientific concepts #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"As such, a reading comprehension machine needs to (i) identify their descriptions and formulae, (ii) segment them into primitive terms and symbols, and (iii) link the associated terms and corresponding symbols.\"]}"
    },
    {
        "gold": {
            "text": [
                "Curriculum",
                "Diversity.",
                "The",
                "variations",
                "in",
                "the",
                "combinations",
                "of",
                "quests",
                "and",
                "worlds",
                "themselves",
                "seen",
                "at",
                "training",
                "time",
                "has",
                "potential",
                "to",
                "effect",
                "zero-shot",
                "performance",
                "#TARGET_REF",
                ".",
                "We",
                "introduce",
                "two",
                "baselines",
                "that",
                "change",
                "the",
                "relative",
                "diversities",
                "of",
                "resulting",
                "quests",
                "in",
                "the",
                "curriculums,",
                "to",
                "contrast",
                "with",
                "our",
                "proposed",
                "procedural",
                "generation",
                "pipeline.",
                "Generated",
                "quest",
                "details",
                "are",
                "found",
                "in",
                "Appendix",
                "A.5."
            ],
            "context": [
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Curriculum Diversity. The variations in the combinations of quests and worlds themselves seen at training time has potential to effect zero-shot performance #TARGET_REF . We introduce two baselines that change the relative diversities of resulting quests in the curriculums, to contrast with our proposed procedural generation pipeline. Generated quest details are found in Appendix A.5.",
        "output": "{\"INFO\": [\"The variations in the combinations of quests and worlds themselves seen at training time has potential to effect zero-shot performance #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "first",
                "compare",
                "RocketQA",
                "with",
                "the",
                "previous",
                "state-of-the-art",
                "approaches",
                "on",
                "passage",
                "retrieval.",
                "We",
                "consider",
                "both",
                "sparse",
                "and",
                "dense",
                "passage",
                "retriever",
                "baselines.",
                "The",
                "sparse",
                "retrievers",
                "include",
                "the",
                "traditional",
                "retriever",
                "BM25",
                "#REF",
                ",",
                "and",
                "four",
                "traditional",
                "retrievers",
                "enhanced",
                "by",
                "neural",
                "networks,",
                "including",
                "doc2query",
                "#REF",
                ",",
                "DeepCT",
                "#REF",
                ",",
                "docTTTT-Tquery",
                "#REF",
                "and",
                "GAR",
                "#TARGET_REF",
                ".",
                "Both",
                "doc2query",
                "and",
                "docTTTTTquery",
                "employ",
                "neural",
                "question",
                "generation",
                "to",
                "expand",
                "documents.",
                "In",
                "contrast,",
                "GAR",
                "employs",
                "neural",
                "generation",
                "models",
                "to",
                "expand",
                "questions.",
                "Different",
                "from",
                "them,",
                "DeepCT",
                "utilizes",
                "BERT",
                "to",
                "learn",
                "the",
                "term",
                "weight.",
                "The",
                "dense",
                "passage",
                "retrievers",
                "include",
                "DPR",
                "#REF",
                ",",
                "ME-BERT",
                "#REF",
                "and",
                "ANCE",
                "#REF",
                ".",
                "Both",
                "DRP",
                "and",
                "ME-BERT",
                "use",
                "in-batch",
                "random",
                "sampling",
                "and",
                "hard",
                "negative",
                "sampling",
                "from",
                "the",
                "results",
                "retrieved",
                "by",
                "BM25,",
                "while",
                "ANCE",
                "enhances",
                "the",
                "hard",
                "negative",
                "sampling",
                "by",
                "using",
                "the",
                "dense",
                "retriever."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We first compare RocketQA with the previous state-of-the-art approaches on passage retrieval. We consider both sparse and dense passage retriever baselines. The sparse retrievers include the traditional retriever BM25 #REF , and four traditional retrievers enhanced by neural networks, including doc2query #REF , DeepCT #REF , docTTTT-Tquery #REF and GAR #TARGET_REF . Both doc2query and docTTTTTquery employ neural question generation to expand documents. In contrast, GAR employs neural generation models to expand questions. Different from them, DeepCT utilizes BERT to learn the term weight. The dense passage retrievers include DPR #REF , ME-BERT #REF and ANCE #REF . Both DRP and ME-BERT use in-batch random sampling and hard negative sampling from the results retrieved by BM25, while ANCE enhances the hard negative sampling by using the dense retriever.",
        "output": "{\"INFO\": [\"GAR #TARGET_REF .\", \"GAR employs neural generation models to expand questions.\"], \"PERCEPT\": [], \"BACK\": [\"The sparse retrievers include the traditional retriever BM25 #REF , and four traditional retrievers enhanced by neural networks, including doc2query #REF , DeepCT #REF , docTTTT-Tquery #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "Since",
                "the",
                "removal",
                "of",
                "diacritics",
                "also",
                "clearly",
                "leads",
                "to",
                "a",
                "potential",
                "ambiguity",
                "as",
                "explained",
                "in",
                "Section",
                "(2.1)",
                "there",
                "has",
                "been",
                "some",
                "work",
                "on",
                "automatic",
                "diacritization",
                "of",
                "partially",
                "diacritized",
                "or",
                "undiacritized",
                "text",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Since the removal of diacritics also clearly leads to a potential ambiguity as explained in Section (2.1) there has been some work on automatic diacritization of partially diacritized or undiacritized text #TARGET_REF .",
        "output": "{\"INFO\": [\"there has been some work on automatic diacritization of partially diacritized or undiacritized text #TARGET_REF .\"], \"PERCEPT\": [\"Since the removal of diacritics also clearly leads to a potential ambiguity\"], \"BACK\": [\"as explained in Section (2.1)\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "evaluate",
                "our",
                "embedding",
                "approach",
                "on",
                "benchmark",
                "tasks",
                "for",
                "entity",
                "representations.",
                "We",
                "use",
                "coreference",
                "arc",
                "prediction",
                "(CAP)",
                "and",
                "named",
                "entity",
                "disambiguation",
                "on",
                "CoNLL-YAGO,",
                "two",
                "tasks",
                "in",
                "the",
                "EntEval",
                "suite",
                "#REF",
                ",",
                "as",
                "well",
                "as",
                "entity",
                "linking",
                "on",
                "WikilinksNED",
                "#TARGET_REF",
                ",",
                "which",
                "covers",
                "broader",
                "entities",
                "and",
                "writing",
                "styles.",
                "We",
                "compare",
                "our",
                "approach",
                "against",
                "entity",
                "representations",
                "produced",
                "directly",
                "by",
                "pre-trained",
                "models."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We evaluate our embedding approach on benchmark tasks for entity representations. We use coreference arc prediction (CAP) and named entity disambiguation on CoNLL-YAGO, two tasks in the EntEval suite #REF , as well as entity linking on WikilinksNED #TARGET_REF , which covers broader entities and writing styles. We compare our approach against entity representations produced directly by pre-trained models.",
        "output": "{\"INFO\": [\"entity linking on WikilinksNED #TARGET_REF\"], \"PERCEPT\": [\"We evaluate our embedding approach on benchmark tasks for entity representations. We use coreference arc prediction (CAP) and named entity disambiguation on CoNLL-YAGO, two tasks in the EntEval suite #REF , as well as\", \", which covers broader entities and writing styles.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Slot-gated",
                "#TARGET_REF",
                ")",
                "is",
                "an",
                "attentionbased",
                "BiLSTM",
                "model",
                "which",
                "builds",
                "on",
                "sepa-",
                "rate",
                "attended",
                "context",
                "for",
                "slot",
                "filling",
                "and",
                "intent",
                "classification",
                "while",
                "explicitly",
                "feeding",
                "the",
                "intent",
                "context",
                "into",
                "the",
                "process",
                "of",
                "slot",
                "filling",
                "via",
                "a",
                "gating",
                "mechanism.Metrics",
                "Model",
                "UCA",
                "U-F1(E)",
                "U-F1(I)",
                "U-F1(A)",
                "U-F1(O)",
                "T-F1",
                "T-F1(T)",
                "T-F1(S)",
                "T-F1(C)",
                "T-F1(D)",
                "T-F1(P)",
                "T-F1(O)",
                "JSA",
                "RNN-NLU",
                "(Liu•",
                "Inter-BiLSTM",
                "#REF",
                "combines",
                "two",
                "inter-connected",
                "BiLSTMs",
                "performing",
                "slot",
                "filling",
                "and",
                "intent",
                "classification",
                "respectively.",
                "The",
                "information",
                "flow",
                "between",
                "the",
                "two",
                "tasks",
                "occurs",
                "by",
                "passing",
                "the",
                "hidden",
                "states",
                "at",
                "each",
                "time",
                "step",
                "from",
                "each",
                "side",
                "to",
                "the",
                "other",
                "to",
                "support",
                "the",
                "decoding",
                "process."
            ],
            "context": [
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Slot-gated #TARGET_REF ) is an attentionbased BiLSTM model which builds on sepa- rate attended context for slot filling and intent classification while explicitly feeding the intent context into the process of slot filling via a gating mechanism.Metrics Model UCA U-F1(E) U-F1(I) U-F1(A) U-F1(O) T-F1 T-F1(T) T-F1(S) T-F1(C) T-F1(D) T-F1(P) T-F1(O) JSA RNN-NLU (Liu• Inter-BiLSTM #REF combines two inter-connected BiLSTMs performing slot filling and intent classification respectively. The information flow between the two tasks occurs by passing the hidden states at each time step from each side to the other to support the decoding process.",
        "output": "{\"INFO\": [\"is an attentionbased BiLSTM model which builds on sepa- rate attended context for slot filling and intent classification while explicitly feeding the intent context into the process of slot filling via a gating mechanism.Metrics Model UCA U-F1(E) U-F1(I) U-F1(A) U-F1(O) T-F1 T-F1(T) T-F1(S) T-F1(C) T-F1(D) T-F1(P) T-F1(O) JSA RNN-NLU\"], \"PERCEPT\": [], \"BACK\": [\"#REF combines two inter-connected BiLSTMs performing slot filling and intent classification respectively.\"]}"
    },
    {
        "gold": {
            "text": [
                "Visual",
                "Entailment",
                "(VE):",
                "VE",
                "task",
                "aims",
                "to",
                "predict",
                "whether",
                "an",
                "image",
                "semantically",
                "entails",
                "the",
                "text",
                "and",
                "requires",
                "fine-grained",
                "reasoning",
                "ability",
                "in",
                "a",
                "model.",
                "VE",
                "dataset",
                "is",
                "built",
                "upon",
                "SNLI",
                "#TARGET_REF",
                "and",
                "Flickr30k.",
                "Each",
                "image-text",
                "pair",
                "is",
                "assigned",
                "with",
                "one",
                "of",
                "three",
                "classes:",
                "entailment,",
                "neutral,",
                "contradiction.",
                "As",
                "in",
                "UNITER,",
                "we",
                "formulate",
                "it",
                "as",
                "3-way",
                "classification",
                "problem",
                "based",
                "on",
                "h",
                "cls",
                ".",
                "The",
                "batch",
                "size",
                "is",
                "32",
                "per",
                "GPU",
                "while",
                "other",
                "finetuning",
                "strategies",
                "are",
                "the",
                "same."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Visual Entailment (VE): VE task aims to predict whether an image semantically entails the text and requires fine-grained reasoning ability in a model. VE dataset is built upon SNLI #TARGET_REF and Flickr30k. Each image-text pair is assigned with one of three classes: entailment, neutral, contradiction. As in UNITER, we formulate it as 3-way classification problem based on h cls . The batch size is 32 per GPU while other finetuning strategies are the same.",
        "output": "{\"INFO\": [\"SNLI #TARGET_REF\"], \"PERCEPT\": [\"VE dataset is built upon\"], \"BACK\": [\"Visual Entailment (VE): VE task aims to predict whether an image semantically entails the text and requires fine-grained reasoning ability in a model.\", \"and Flickr30k.\"]}"
    },
    {
        "gold": {
            "text": [
                "aspects",
                "of",
                "the",
                "context",
                "that",
                "are",
                "otherwise",
                "not",
                "accessible",
                "through",
                "the",
                "linguistic",
                "content",
                "of",
                "the",
                "comment",
                "alone.",
                "Here,",
                "information",
                "may",
                "refer",
                "to",
                "demographic",
                "traits",
                "like",
                "age",
                "or",
                "gender,",
                "knowledge",
                "about",
                "linguistic",
                "behavior,",
                "location",
                "details,",
                "etc.",
                "Below",
                "we",
                "categorize",
                "and",
                "discuss",
                "the",
                "aspects",
                "of",
                "the",
                "context",
                "relevant",
                "to",
                "abusive",
                "language",
                "detection.",
                "Sociolinguistic",
                "norms.",
                "Sociolinguistics",
                "studies",
                "the",
                "effects",
                "of",
                "society",
                "on",
                "language",
                "and",
                "its",
                "usage.",
                "Researchers",
                "in",
                "the",
                "past",
                "have",
                "explored",
                "the",
                "links",
                "between",
                "the",
                "structures",
                "and",
                "norms",
                "of",
                "real-world",
                "communities",
                "and",
                "the",
                "linguistic",
                "practices",
                "of",
                "people",
                "(D'Arcy",
                "and",
                "#REF",
                ".",
                "As",
                "in",
                "the",
                "physical",
                "world,",
                "individuals",
                "and",
                "communities",
                "on",
                "online",
                "platforms",
                "also",
                "abide",
                "by",
                "certain",
                "norms,",
                "which",
                "may",
                "be",
                "guided",
                "by",
                "their",
                "cultural",
                "backgrounds",
                "and/or",
                "are",
                "based",
                "on",
                "the",
                "standards",
                "laid",
                "down",
                "by",
                "the",
                "platforms",
                "themselves.",
                "These",
                "norms",
                "and",
                "standards",
                "reflect",
                "expectations",
                "of",
                "respectful",
                "behavior,",
                "local",
                "customs",
                "and",
                "language",
                "patterns",
                "within",
                "a",
                "region,",
                "etc.",
                "#TARGET_REF",
                ".",
                "Consequently,",
                "the",
                "decision",
                "of",
                "what",
                "is",
                "considered",
                "abusive",
                "must",
                "be",
                "made",
                "taking",
                "into",
                "account",
                "the",
                "sociolinguistic",
                "norms.",
                "User",
                "and",
                "community",
                "information,",
                "when",
                "leveraged",
                "alongside",
                "linguistic",
                "features,",
                "helps",
                "capture",
                "the",
                "relevant",
                "sociolinguistic",
                "norms",
                "in",
                "a",
                "myriad",
                "of",
                "ways.",
                "For",
                "example,",
                "a",
                "comment",
                "may",
                "contain",
                "the",
                "n-word,",
                "but",
                "interpretation",
                "of",
                "its",
                "use",
                "and",
                "or",
                "the",
                "intent",
                "is",
                "greatly",
                "facilitated",
                "by",
                "the",
                "knowledge",
                "of",
                "the",
                "ethnicity",
                "of",
                "the",
                "user",
                "who",
                "wrote",
                "the",
                "comment",
                "and/or",
                "the",
                "ethnicity",
                "of",
                "the",
                "target",
                "user",
                "or",
                "community."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "aspects of the context that are otherwise not accessible through the linguistic content of the comment alone. Here, information may refer to demographic traits like age or gender, knowledge about linguistic behavior, location details, etc. Below we categorize and discuss the aspects of the context relevant to abusive language detection. Sociolinguistic norms. Sociolinguistics studies the effects of society on language and its usage. Researchers in the past have explored the links between the structures and norms of real-world communities and the linguistic practices of people (D'Arcy and #REF . As in the physical world, individuals and communities on online platforms also abide by certain norms, which may be guided by their cultural backgrounds and/or are based on the standards laid down by the platforms themselves. These norms and standards reflect expectations of respectful behavior, local customs and language patterns within a region, etc. #TARGET_REF . Consequently, the decision of what is considered abusive must be made taking into account the sociolinguistic norms. User and community information, when leveraged alongside linguistic features, helps capture the relevant sociolinguistic norms in a myriad of ways. For example, a comment may contain the n-word, but interpretation of its use and or the intent is greatly facilitated by the knowledge of the ethnicity of the user who wrote the comment and/or the ethnicity of the target user or community.",
        "output": "{\"INFO\": [\"certain norms, which may be guided by their cultural backgrounds and/or are based on the standards laid down by the platforms themselves. These norms and standards reflect expectations of respectful behavior, local customs and language patterns within a region, etc. #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"As in the physical world, individuals and communities on online platforms also abide by\"]}"
    },
    {
        "gold": {
            "text": [
                "SNAP",
                "provides",
                "four",
                "knowledge",
                "representation",
                "elements:",
                "node,",
                "link,",
                "node",
                "color",
                "and",
                "link",
                "value.",
                "#REF",
                ",",
                "Conceptual",
                "Graphs",
                "#REF",
                ",",
                "KODIAK",
                "#TARGET_REF",
                ",",
                "etc."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3
            ]
        },
        "input": "SNAP provides four knowledge representation elements: node, link, node color and link value. #REF , Conceptual Graphs #REF , KODIAK #TARGET_REF , etc.",
        "output": "{\"INFO\": [\"KODIAK #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"SNAP provides four knowledge representation elements: node, link, node color and link value. #REF , Conceptual Graphs #REF ,\", \"etc.\"]}"
    },
    {
        "gold": {
            "text": [
                "Similar",
                "to",
                "#TARGET_REF",
                ",",
                "we",
                "preprocess",
                "the",
                "data",
                "as",
                "follows:"
            ],
            "context": [
                2,
                2,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Similar to #TARGET_REF , we preprocess the data as follows:",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"Similar to\", \"we preprocess the data as follows:\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Researchers",
                "usually",
                "regard",
                "the",
                "sentence",
                "simplification",
                "task",
                "as",
                "a",
                "monolingual",
                "variant",
                "of",
                "machine",
                "translation",
                "(MT)",
                "#TARGET_REF",
                ".",
                "Benefiting",
                "from",
                "the",
                "advancement",
                "of",
                "neural",
                "machine",
                "translation,",
                "this",
                "task",
                "has",
                "also",
                "made",
                "great",
                "progress",
                "in",
                "recent",
                "years."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Researchers usually regard the sentence simplification task as a monolingual variant of machine translation (MT) #TARGET_REF . Benefiting from the advancement of neural machine translation, this task has also made great progress in recent years.",
        "output": "{\"INFO\": [\"monolingual variant of machine translation (MT) #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Researchers usually regard the sentence simplification task as a\", \"Benefiting from the advancement of neural machine translation, this task has also made great progress in recent years.\"]}"
    },
    {
        "gold": {
            "text": [
                "Parametrizing",
                "Curriculum",
                "Difficulty.",
                "Given",
                "the",
                "relative",
                "imbalance",
                "of",
                "this",
                "multinomial",
                "distribution,",
                "as",
                "seen",
                "in",
                "Figure",
                "3,",
                "we",
                "hypothesize",
                "that",
                "a",
                "LIGHT",
                "agent",
                "only",
                "learns",
                "to",
                "do",
                "well",
                "on",
                "certain",
                "types",
                "of",
                "objectives",
                "and",
                "not",
                "others-memorizing",
                "trajectories",
                "for",
                "less",
                "seen",
                "quest",
                "types,",
                "i.e.",
                "those",
                "found",
                "in",
                "the",
                "tail",
                "of",
                "the",
                "distribution.",
                "Preliminary",
                "evidence",
                "for",
                "this",
                "hypothesis",
                "is",
                "also",
                "seen",
                "in",
                "#TARGET_REF",
                ",",
                "where",
                "they",
                "show",
                "a",
                "positive",
                "correlation",
                "between",
                "the",
                "number",
                "of",
                "instances",
                "of",
                "a",
                "particular",
                "type",
                "of",
                "quest",
                "during",
                "training",
                "and",
                "the",
                "final",
                "test",
                "goal-achievement",
                "performance.",
                "Based",
                "on",
                "these",
                "observations",
                "and",
                "our",
                "initial",
                "hypothesis,",
                "we",
                "use",
                "this",
                "particular",
                "dimension",
                "to",
                "parametrize",
                "curriculum",
                "difficulty",
                "for",
                "training",
                "LIGHT",
                "agents-quest",
                "types",
                "that",
                "are",
                "rarer",
                "in",
                "the",
                "initial",
                "training",
                "data",
                "will",
                "be",
                "harder",
                "for",
                "the",
                "agent",
                "to",
                "generalize",
                "to",
                "in",
                "a",
                "zero-shot",
                "setting."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Parametrizing Curriculum Difficulty. Given the relative imbalance of this multinomial distribution, as seen in Figure 3, we hypothesize that a LIGHT agent only learns to do well on certain types of objectives and not others-memorizing trajectories for less seen quest types, i.e. those found in the tail of the distribution. Preliminary evidence for this hypothesis is also seen in #TARGET_REF , where they show a positive correlation between the number of instances of a particular type of quest during training and the final test goal-achievement performance. Based on these observations and our initial hypothesis, we use this particular dimension to parametrize curriculum difficulty for training LIGHT agents-quest types that are rarer in the initial training data will be harder for the agent to generalize to in a zero-shot setting.",
        "output": "{\"INFO\": [\"#TARGET_REF , where they show a positive correlation between the number of instances of a particular type of quest during training and the final test goal-achievement performance.\"], \"PERCEPT\": [\"Given the relative imbalance of this multinomial distribution,\", \"we hypothesize that a LIGHT agent only learns to do well on certain types of objectives and not others-memorizing trajectories for less seen quest types, i.e. those found in the tail of the distribution. Preliminary evidence for this hypothesis is also seen in\", \"Based on these observations and our initial hypothesis, we use this particular dimension to parametrize curriculum difficulty for training LIGHT agents-quest types\"], \"BACK\": [\"as seen in Figure 3,\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "are",
                "currently",
                "investigating",
                "whether",
                "our",
                "model",
                "is",
                "consistent",
                "with",
                "human",
                "language",
                "processing",
                "which",
                "has",
                "limited",
                "memory",
                "capacity",
                "#TARGET_REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1
            ]
        },
        "input": "We are currently investigating whether our model is consistent with human language processing which has limited memory capacity #TARGET_REF .",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"We are currently investigating whether our model is consistent with human language processing which has limited memory capacity\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Performance",
                "is",
                "plotted",
                "on",
                "the",
                "vertical",
                "axis",
                "and",
                "measured",
                "for",
                "different",
                "frequency",
                "bins.",
                "The",
                "Zipfian",
                "distribution",
                "of",
                "terms",
                "suggests",
                "assessing",
                "performance",
                "by",
                "frequency",
                "ranges",
                "growing",
                "by",
                "a",
                "constant",
                "factor",
                "#TARGET_REF",
                ",",
                "accordingly",
                "we",
                "used",
                "a",
                "logarithmic",
                "scale",
                "with",
                "base=3.",
                "The",
                "number",
                "of",
                "terms",
                "per",
                "bin",
                "is",
                "given",
                "in",
                "parentheses.",
                "Some",
                "of",
                "the",
                "previous",
                "work",
                "cited",
                "in",
                "Section",
                "2",
                "described",
                "performance",
                "for",
                "selected",
                "subsets",
                "of",
                "terms,",
                "typically",
                "high",
                "frequency",
                "terms",
                "that",
                "are",
                "easier",
                "to",
                "translate.",
                "We",
                "believe",
                "presenting",
                "translation",
                "accuracy",
                "as",
                "a",
                "function",
                "of",
                "source",
                "term",
                "frequency",
                "is",
                "more",
                "informative."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Performance is plotted on the vertical axis and measured for different frequency bins. The Zipfian distribution of terms suggests assessing performance by frequency ranges growing by a constant factor #TARGET_REF , accordingly we used a logarithmic scale with base=3. The number of terms per bin is given in parentheses. Some of the previous work cited in Section 2 described performance for selected subsets of terms, typically high frequency terms that are easier to translate. We believe presenting translation accuracy as a function of source term frequency is more informative.",
        "output": "{\"INFO\": [\"by a constant factor #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The Zipfian distribution of terms suggests assessing performance by frequency ranges growing\"]}"
    },
    {
        "gold": {
            "text": [
                "Recent",
                "read-write",
                "policies",
                "can",
                "be",
                "divided",
                "into",
                "two",
                "categories:",
                "fixed",
                "policies",
                "such",
                "as",
                "wait-k",
                "#REF",
                ",",
                "wait-if*",
                "#REF",
                ",",
                "and",
                "adaptive",
                "policies",
                "such",
                "as",
                "MoChA",
                "#REF",
                ",",
                "MILk",
                "#TARGET_REF",
                "and",
                "MU",
                "#REF",
                ".",
                "Fixed",
                "policies",
                "are",
                "simple",
                "to",
                "implement,",
                "but",
                "they",
                "neglect",
                "contextual",
                "information,",
                "which",
                "might",
                "result",
                "in",
                "quality",
                "reduction.",
                "Dynamic",
                "policies",
                "are",
                "more",
                "flexible,",
                "they",
                "can",
                "learn",
                "from",
                "data",
                "to",
                "achieve",
                "better",
                "quality/latency",
                "trade-offs,",
                "but",
                "accordingly",
                "difficult",
                "to",
                "train."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                0,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Recent read-write policies can be divided into two categories: fixed policies such as wait-k #REF , wait-if* #REF , and adaptive policies such as MoChA #REF , MILk #TARGET_REF and MU #REF . Fixed policies are simple to implement, but they neglect contextual information, which might result in quality reduction. Dynamic policies are more flexible, they can learn from data to achieve better quality/latency trade-offs, but accordingly difficult to train.",
        "output": "{\"INFO\": [\"Recent read-write policies can be divided into two categories:\", \"MILk #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"fixed policies such as wait-k #REF , wait-if* #REF , and adaptive policies such as MoChA #REF\", \"MU #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "an",
                "ever",
                "increasing",
                "need",
                "for",
                "labeled",
                "datasets",
                "for",
                "machine",
                "learning.",
                "This",
                "is",
                "true",
                "for",
                "English",
                "as",
                "well",
                "as",
                "other,",
                "often",
                "under-resourced,",
                "languages.",
                "We",
                "provide",
                "a",
                "cross-lingual",
                "fine-grained",
                "sentence-level",
                "emotion",
                "and",
                "sentiment",
                "dataset.",
                "The",
                "dataset",
                "consists",
                "of",
                "parallel",
                "manually",
                "annotated",
                "data",
                "for",
                "English",
                "and",
                "Finnish,",
                "with",
                "additional",
                "parallel",
                "datasets",
                "of",
                "varying",
                "sizes",
                "for",
                "a",
                "total",
                "of",
                "32",
                "languages",
                "created",
                "by",
                "annotation",
                "projection.",
                "We",
                "use",
                "Plutchik's",
                "Wheel",
                "of",
                "Emotions",
                "(anger,",
                "anticipation,",
                "disgust,",
                "fear,",
                "joy,",
                "sadness,",
                "surprise,",
                "trust)",
                "#TARGET_REF",
                "as",
                "our",
                "annotation",
                "scheme",
                "with",
                "the",
                "addition",
                "of",
                "neutral",
                "on",
                "movie",
                "subtitle",
                "data",
                "from",
                "OPUS",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "There is an ever increasing need for labeled datasets for machine learning. This is true for English as well as other, often under-resourced, languages. We provide a cross-lingual fine-grained sentence-level emotion and sentiment dataset. The dataset consists of parallel manually annotated data for English and Finnish, with additional parallel datasets of varying sizes for a total of 32 languages created by annotation projection. We use Plutchik's Wheel of Emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust) #TARGET_REF as our annotation scheme with the addition of neutral on movie subtitle data from OPUS #REF .",
        "output": "{\"INFO\": [\"Plutchik's Wheel of Emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, trust)\", \"as our annotation scheme with the addition of neutral on movie subtitle data from OPUS #REF .\"], \"PERCEPT\": [\"We use\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "extensively",
                "evaluate",
                "top-k",
                "attention",
                "on",
                "a",
                "wide",
                "range",
                "of",
                "tasks",
                "and",
                "demonstrate",
                "its",
                "mentioned",
                "advantages.",
                "Training",
                "from",
                "scratch,",
                "we",
                "show",
                "top-k",
                "attention",
                "performs",
                "as",
                "well",
                "as",
                "vanilla",
                "self-attention",
                "on",
                "Long",
                "Range",
                "Arena,",
                "a",
                "benchmark",
                "dedicated",
                "to",
                "evaluating",
                "the",
                "ability",
                "of",
                "transformers",
                "to",
                "handle",
                "long",
                "sequences,",
                "and",
                "in",
                "a",
                "language",
                "modeling",
                "task",
                "(WikiText-103).",
                "Second,",
                "we",
                "show",
                "top-k",
                "attention",
                "can",
                "be",
                "used",
                "as",
                "a",
                "drop-in",
                "replacement",
                "for",
                "vanilla",
                "attention",
                "at",
                "inference",
                "time",
                "without",
                "any",
                "additional",
                "training",
                "at",
                "the",
                "feed-forward",
                "layer",
                "of",
                "the",
                "UnifiedQA",
                "model",
                "#TARGET_REF",
                "on",
                "12",
                "different",
                "question",
                "answering",
                "(QA)",
                "datasets,",
                "reducing",
                "the",
                "number",
                "of",
                "keys",
                "used",
                "per",
                "query",
                "by",
                "more",
                "than",
                "99%.",
                "Last,",
                "we",
                "show",
                "top-k",
                "attention",
                "obtains",
                "similar",
                "performance",
                "to",
                "vanilla",
                "attention",
                "on",
                "a",
                "wide",
                "range",
                "of",
                "QA",
                "tasks",
                "when",
                "fine-tuning",
                "T5",
                "#REF",
                ",",
                "without",
                "the",
                "need",
                "for",
                "any",
                "corrective",
                "pre-training."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We extensively evaluate top-k attention on a wide range of tasks and demonstrate its mentioned advantages. Training from scratch, we show top-k attention performs as well as vanilla self-attention on Long Range Arena, a benchmark dedicated to evaluating the ability of transformers to handle long sequences, and in a language modeling task (WikiText-103). Second, we show top-k attention can be used as a drop-in replacement for vanilla attention at inference time without any additional training at the feed-forward layer of the UnifiedQA model #TARGET_REF on 12 different question answering (QA) datasets, reducing the number of keys used per query by more than 99%. Last, we show top-k attention obtains similar performance to vanilla attention on a wide range of QA tasks when fine-tuning T5 #REF , without the need for any corrective pre-training.",
        "output": "{\"INFO\": [\"the UnifiedQA model #TARGET_REF\"], \"PERCEPT\": [\"We extensively evaluate top-k attention on a wide range of tasks and demonstrate its mentioned advantages. Training from scratch, we show top-k attention performs as well as vanilla self-attention on Long Range Arena, a benchmark dedicated to evaluating the ability of transformers to handle long sequences, and in a language modeling task (WikiText-103). Second, we show top-k attention can be used as a drop-in replacement for vanilla attention at inference time without any additional training at the feed-forward layer of\", \"on 12 different question answering (QA) datasets, reducing the number of keys used per query by more than 99%.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "correct",
                "answer",
                "and",
                "at",
                "least",
                "50%",
                "were",
                "inspired",
                "by",
                "the",
                "accuracy",
                "@",
                "x%",
                "approach",
                "used",
                "by",
                "different",
                "authors",
                "working",
                "with",
                "the",
                "Amazon",
                "dataset",
                "and",
                "performing",
                "similar",
                "tasks",
                "#TARGET_REF",
                ".",
                "In",
                "accuracy",
                "@",
                "x%",
                "the",
                "commonly",
                "used",
                "measure",
                "is",
                "accuracy",
                "@",
                "50%.",
                "This",
                "approach",
                "helps",
                "in",
                "identifying",
                "the",
                "top",
                "answers",
                "crossing",
                "a",
                "threshold",
                "and",
                "has",
                "better",
                "relationship",
                "in",
                "real",
                "world",
                "applications",
                "#REF",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The correct answer and at least 50% were inspired by the accuracy @ x% approach used by different authors working with the Amazon dataset and performing similar tasks #TARGET_REF . In accuracy @ x% the commonly used measure is accuracy @ 50%. This approach helps in identifying the top answers crossing a threshold and has better relationship in real world applications #REF .",
        "output": "{\"INFO\": [\"The correct answer and at least 50% were inspired by the accuracy @ x% approach used by different authors working with the Amazon dataset and performing similar tasks #TARGET_REF .\"], \"PERCEPT\": [\"This approach helps in identifying the top answers crossing a threshold and has better relationship in real world applications #REF .\"], \"BACK\": [\"In accuracy @ x% the commonly used measure is accuracy @ 50%.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "distribution",
                "over",
                "the",
                "vocabulary",
                "of",
                "the",
                "next",
                "word",
                "is",
                "evaluated",
                "using",
                "the",
                "memory",
                "output",
                "o",
                "t",
                "as",
                "in",
                "Eq.",
                "3",
                "with",
                "a",
                "feed-forward",
                "layer.",
                "Then,",
                "the",
                "next",
                "soft",
                "word,",
                "ŷt",
                ",",
                "is",
                "sampled",
                "using",
                "the",
                "Gumbelsoftmax",
                "relaxation",
                "#TARGET_REF",
                "with",
                "temperature",
                "T",
                "(Eq.",
                "4).",
                "The",
                "temperature",
                "value",
                "greatly",
                "influences",
                "the",
                "quality-diversity",
                "trade-off,",
                "more",
                "details",
                "on",
                "these",
                "parameters",
                "are",
                "provided",
                "in",
                "Appendix",
                "D."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The distribution over the vocabulary of the next word is evaluated using the memory output o t as in Eq. 3 with a feed-forward layer. Then, the next soft word, ŷt , is sampled using the Gumbelsoftmax relaxation #TARGET_REF with temperature T (Eq. 4). The temperature value greatly influences the quality-diversity trade-off, more details on these parameters are provided in Appendix D.",
        "output": "{\"INFO\": [\"the Gumbelsoftmax relaxation #TARGET_REF with temperature T (Eq. 4).\"], \"PERCEPT\": [\"The temperature value greatly influences the quality-diversity trade-off, more details on these parameters are provided in Appendix D.\"], \"BACK\": [\"The distribution over the vocabulary of the next word is evaluated using the memory output o t as in Eq. 3 with a feed-forward layer. Then, the next soft word, \\u0177t , is sampled using\"]}"
    },
    {
        "gold": {
            "text": [
                "Lately,",
                "many",
                "works",
                "built",
                "upon",
                "the",
                "Seq2Seq",
                "MT",
                "model",
                "#TARGET_REF",
                "performed",
                "well.",
                "First",
                "attempted",
                "by",
                "#REF",
                ",",
                "the",
                "Seq2Seq",
                "models",
                "for",
                "this",
                "task",
                "are",
                "able",
                "to",
                "perform",
                "lexical",
                "simplification",
                "and",
                "content",
                "reduction",
                "simultaneously",
                "by",
                "training",
                "on",
                "complex-simple",
                "sentence",
                "pairs.",
                "This",
                "method",
                "was",
                "inherited",
                "and",
                "improved",
                "by",
                "many",
                "subsequent",
                "works,",
                "such",
                "as",
                "combining",
                "with",
                "the",
                "reinforcement",
                "learning",
                "method",
                "by",
                "setting",
                "a",
                "simplification",
                "reward",
                "#REF",
                ",",
                "augmenting",
                "memory",
                "capacities",
                "#REF",
                "or",
                "training",
                "with",
                "multitasking",
                "on",
                "entailment",
                "and",
                "paraphrase",
                "generation",
                "#REF",
                ".",
                "#REF",
                "proposed",
                "to",
                "prepend",
                "additional",
                "prompt",
                "tokens",
                "to",
                "source",
                "sentences",
                "at",
                "train",
                "time,",
                "which",
                "enables",
                "the",
                "end-users",
                "to",
                "condition",
                "the",
                "simplifications",
                "returned",
                "by",
                "the",
                "model",
                "on",
                "attributes",
                "like",
                "length,",
                "lexical",
                "complexity,",
                "and",
                "syntactic",
                "complexity.",
                "This",
                "controllable",
                "simplification",
                "system",
                "(called",
                "ACCESS)",
                "and",
                "its",
                "improved",
                "version",
                "MUSS",
                "#REF",
                "achieved",
                "SOTA",
                "results",
                "on",
                "the",
                "Turk",
                "corpus",
                "in",
                "terms",
                "of",
                "the",
                "SARI",
                "metric",
                "#REF",
                "."
            ],
            "context": [
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Lately, many works built upon the Seq2Seq MT model #TARGET_REF performed well. First attempted by #REF , the Seq2Seq models for this task are able to perform lexical simplification and content reduction simultaneously by training on complex-simple sentence pairs. This method was inherited and improved by many subsequent works, such as combining with the reinforcement learning method by setting a simplification reward #REF , augmenting memory capacities #REF or training with multitasking on entailment and paraphrase generation #REF . #REF proposed to prepend additional prompt tokens to source sentences at train time, which enables the end-users to condition the simplifications returned by the model on attributes like length, lexical complexity, and syntactic complexity. This controllable simplification system (called ACCESS) and its improved version MUSS #REF achieved SOTA results on the Turk corpus in terms of the SARI metric #REF .",
        "output": "{\"INFO\": [\"many works built upon the Seq2Seq MT model #TARGET_REF performed well.\"], \"PERCEPT\": [\"Lately,\", \"the Seq2Seq models for this task are able to perform lexical simplification and content reduction simultaneously by training on complex-simple sentence pairs. This method was inherited and improved by many subsequent works,\"], \"BACK\": [\"such as combining with the reinforcement learning method by setting a simplification reward #REF , augmenting memory capacities #REF or training with multitasking on entailment and paraphrase generation #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "where",
                "X",
                "∈",
                "{A,",
                "B,",
                "C,",
                "D}).",
                "We",
                "consider",
                "two",
                "settings",
                "where",
                "each",
                "generative",
                "factor",
                "is",
                "embedded",
                "in",
                "a",
                "single",
                "dimension",
                "(denoted",
                "by",
                "Ex.1),",
                "or",
                "two",
                "dimensions",
                "(denoted",
                "by",
                "Ex.2).",
                "In",
                "each",
                "setting",
                "we",
                "uniformly",
                "sample",
                "20",
                "values",
                "from",
                "-1",
                "to",
                "1",
                "to",
                "represent",
                "20",
                "assignments",
                "per",
                "factor",
                "and",
                "use",
                "them",
                "to",
                "allocate",
                "the",
                "assignments",
                "into",
                "distinctive",
                "bins",
                "per",
                "each",
                "corresponding",
                "dimension.",
                "By",
                "concatenating",
                "dimensions",
                "for",
                "each",
                "generative",
                "factor,",
                "we",
                "construct",
                "two",
                "ideal",
                "disentangled",
                "representations",
                "for",
                "data",
                "points",
                "in",
                "this",
                "toy",
                "dataset,",
                "amounting",
                "to",
                "4",
                "and",
                "8",
                "dimensional",
                "representations,",
                "respectively.",
                "Using",
                "these",
                "representations",
                "(skipping",
                "the",
                "encoding",
                "step),",
                "we",
                "measured",
                "the",
                "above",
                "metrics.",
                "Table",
                "1",
                "(Ex.1",
                "and",
                "Ex.2",
                "columns)",
                "summarises",
                "the",
                "results,",
                "illustrating",
                "that",
                "out",
                "of",
                "the",
                "6",
                "metrics,",
                "#REF",
                ",",
                "Ridgeway",
                "and",
                "Mozer",
                "(2018),",
                "#REF",
                "are",
                "the",
                "only",
                "ones",
                "that",
                "reach",
                "the",
                "potential",
                "maximum",
                "(i.e.,",
                "100),",
                "while",
                "#TARGET_REF",
                "exhibits",
                "its",
                "sensitivity",
                "towards",
                "completeness",
                "when",
                "we",
                "allocate",
                "two",
                "dimensions",
                "per",
                "factors."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "where X ∈ {A, B, C, D}). We consider two settings where each generative factor is embedded in a single dimension (denoted by Ex.1), or two dimensions (denoted by Ex.2). In each setting we uniformly sample 20 values from -1 to 1 to represent 20 assignments per factor and use them to allocate the assignments into distinctive bins per each corresponding dimension. By concatenating dimensions for each generative factor, we construct two ideal disentangled representations for data points in this toy dataset, amounting to 4 and 8 dimensional representations, respectively. Using these representations (skipping the encoding step), we measured the above metrics. Table 1 (Ex.1 and Ex.2 columns) summarises the results, illustrating that out of the 6 metrics, #REF , Ridgeway and Mozer (2018), #REF are the only ones that reach the potential maximum (i.e., 100), while #TARGET_REF exhibits its sensitivity towards completeness when we allocate two dimensions per factors.",
        "output": "{\"INFO\": [\"#TARGET_REF exhibits its sensitivity towards completeness\"], \"PERCEPT\": [\"while\", \"when we allocate two dimensions per factors.\"], \"BACK\": [\"Table 1 (Ex.1 and Ex.2 columns) summarises the results, illustrating that out of the 6 metrics, #REF , Ridgeway and Mozer (2018), #REF are the only ones that reach the potential maximum (i.e., 100),\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "#TARGET_REF",
                "showed,",
                "they",
                "might",
                "associate",
                "words",
                "that",
                "are",
                "not",
                "in",
                "a",
                "strong",
                "direct",
                "connection,",
                "but",
                "are",
                "only",
                "indirectly",
                "related",
                "(e.g.",
                "religion",
                "is",
                "not",
                "related",
                "to",
                "tree,",
                "but",
                "both",
                "are",
                "related",
                "to",
                "Christmas,",
                "therefore",
                "religion",
                "could",
                "be",
                "a",
                "clue",
                "for",
                "tree)."
            ],
            "context": [
                2,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "As #TARGET_REF showed, they might associate words that are not in a strong direct connection, but are only indirectly related (e.g. religion is not related to tree, but both are related to Christmas, therefore religion could be a clue for tree).",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [\"As\", \"showed, they might associate words that are not in a strong direct connection, but are only indirectly related\"], \"BACK\": [\"(e.g. religion is not related to tree, but both are related to Christmas, therefore religion could be a clue for tree).\"]}"
    },
    {
        "gold": {
            "text": [
                "where",
                "t",
                "i",
                "denotes",
                "the",
                "desired",
                "output,",
                "i.e.,",
                "the",
                "probability",
                "should",
                "be",
                "1.0",
                "for",
                "the",
                "next",
                "word",
                "in",
                "the",
                "training",
                "sentence",
                "and",
                "0.0",
                "for",
                "all",
                "the",
                "other",
                "ones.",
                "The",
                "first",
                "part",
                "of",
                "this",
                "equation",
                "is",
                "the",
                "cross-entropy",
                "between",
                "the",
                "output",
                "and",
                "the",
                "target",
                "probability",
                "distributions,",
                "and",
                "the",
                "second",
                "part",
                "is",
                "a",
                "regularization",
                "term",
                "that",
                "aims",
                "to",
                "prevent",
                "the",
                "neural",
                "network",
                "from",
                "over-fitting",
                "the",
                "training",
                "data",
                "(weight",
                "decay).",
                "The",
                "parameter",
                "β",
                "has",
                "to",
                "be",
                "determined",
                "experimentally.",
                "Training",
                "is",
                "done",
                "using",
                "a",
                "re-sampling",
                "algorithm",
                "as",
                "described",
                "in",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "where t i denotes the desired output, i.e., the probability should be 1.0 for the next word in the training sentence and 0.0 for all the other ones. The first part of this equation is the cross-entropy between the output and the target probability distributions, and the second part is a regularization term that aims to prevent the neural network from over-fitting the training data (weight decay). The parameter β has to be determined experimentally. Training is done using a re-sampling algorithm as described in #TARGET_REF .",
        "output": "{\"INFO\": [\"as described in #TARGET_REF .\"], \"PERCEPT\": [\"using a re-sampling algorithm\"], \"BACK\": [\"Training is done\"]}"
    },
    {
        "gold": {
            "text": [
                "Naturally,",
                "the",
                "WMT",
                "Metrics",
                "task,",
                "most",
                "recently",
                "run",
                "in",
                "2020",
                "#TARGET_REF",
                ")",
                "is",
                "one",
                "such",
                "forum",
                "for",
                "the",
                "evaluation",
                "of",
                "metrics.",
                "In",
                "this",
                "last",
                "iteration,",
                "metrics",
                "were",
                "evaluated",
                "based",
                "on",
                "their",
                "correlation",
                "with",
                "human",
                "judgment",
                "scores",
                "on",
                "the",
                "sentence,",
                "paragraph,",
                "and",
                "document",
                "level.",
                "BERTScore",
                "was",
                "not",
                "included",
                "even",
                "in",
                "the",
                "most",
                "recent",
                "iteration",
                "of",
                "the",
                "metrics",
                "task."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Naturally, the WMT Metrics task, most recently run in 2020 #TARGET_REF ) is one such forum for the evaluation of metrics. In this last iteration, metrics were evaluated based on their correlation with human judgment scores on the sentence, paragraph, and document level. BERTScore was not included even in the most recent iteration of the metrics task.",
        "output": "{\"INFO\": [\"the WMT Metrics task, most recently run in 2020 #TARGET_REF ) is one such forum for the evaluation of metrics.\"], \"PERCEPT\": [], \"BACK\": [\"In this last iteration, metrics were evaluated based on their correlation with human judgment scores on the sentence, paragraph, and document level. BERTScore was not included even in the most recent iteration of the metrics task.\"]}"
    },
    {
        "gold": {
            "text": [
                "Using",
                "CCG",
                "categories",
                "to",
                "label",
                "non-terminals",
                "in",
                "HPB",
                "rules",
                "can",
                "produce",
                "better",
                "translation",
                "quality",
                "and",
                "smaller",
                "trans-lation",
                "models",
                "in",
                "comparison",
                "with",
                "SAMT",
                "#TARGET_REF",
                ".",
                "CCG",
                "nonterminal",
                "labels",
                "are",
                "less",
                "sparse",
                "and",
                "represent",
                "richer",
                "and",
                "more",
                "accurate",
                "syntactic",
                "constraints",
                "compared",
                "to",
                "SAMT",
                "nonterminal",
                "labels",
                "#REF",
                "."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Using CCG categories to label non-terminals in HPB rules can produce better translation quality and smaller trans-lation models in comparison with SAMT #TARGET_REF . CCG nonterminal labels are less sparse and represent richer and more accurate syntactic constraints compared to SAMT nonterminal labels #REF .",
        "output": "{\"INFO\": [\"Using CCG categories to label non-terminals in HPB rules can produce better translation quality and smaller trans-lation models in comparison with SAMT #TARGET_REF .\"], \"PERCEPT\": [\"CCG nonterminal labels are less sparse and represent richer and more accurate syntactic constraints compared to SAMT nonterminal labels #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "axis",
                "of",
                "development",
                "concerns",
                "the",
                "use",
                "of",
                "neural",
                "architecture",
                "search",
                "#REF",
                "which",
                "allows",
                "to",
                "optimize",
                "a",
                "model",
                "by",
                "progressively",
                "modifying",
                "the",
                "design",
                "of",
                "the",
                "network",
                "through",
                "trial",
                "and",
                "error,",
                "eliminating",
                "insignificant",
                "operations.",
                "To",
                "avoid",
                "the",
                "unnecessary",
                "large",
                "number",
                "of",
                "parameters,",
                "adapters",
                "#TARGET_REF",
                "were",
                "introduced",
                "to",
                "allow",
                "fine-tuning",
                "of",
                "the",
                "set",
                "of",
                "parameters",
                "specific",
                "to",
                "the",
                "task",
                "of",
                "interest",
                "rather",
                "than",
                "the",
                "entire",
                "model."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Another axis of development concerns the use of neural architecture search #REF which allows to optimize a model by progressively modifying the design of the network through trial and error, eliminating insignificant operations. To avoid the unnecessary large number of parameters, adapters #TARGET_REF were introduced to allow fine-tuning of the set of parameters specific to the task of interest rather than the entire model.",
        "output": "{\"INFO\": [\"adapters #TARGET_REF were introduced to allow fine-tuning of the set of parameters specific to the task of interest rather than the entire model.\"], \"PERCEPT\": [], \"BACK\": [\"To avoid the unnecessary large number of parameters,\"]}"
    },
    {
        "gold": {
            "text": [
                "Previous",
                "experiments",
                "have",
                "shown",
                "the",
                "effectiveness",
                "of",
                "RocketQA",
                "on",
                "passage",
                "retrieval.",
                "Next,",
                "we",
                "verify",
                "whether",
                "the",
                "retrieval",
                "results",
                "of",
                "RocketQA",
                "can",
                "improve",
                "the",
                "performance",
                "of",
                "passage",
                "reading",
                "for",
                "extracting",
                "correct",
                "answers.",
                "We",
                "implement",
                "an",
                "end-to-end",
                "QA",
                "system",
                "in",
                "which",
                "we",
                "have",
                "an",
                "extractive",
                "reader",
                "stacked",
                "on",
                "our",
                "RocketQA",
                "retriever.",
                "For",
                "a",
                "fair",
                "comparison,",
                "we",
                "first",
                "re-use",
                "the",
                "released",
                "model",
                "6",
                "of",
                "the",
                "extractive",
                "reader",
                "in",
                "DPR",
                "#REF",
                ",",
                "and",
                "take",
                "100",
                "retrieved",
                "passages",
                "during",
                "inference",
                "(the",
                "same",
                "setting",
                "used",
                "in",
                "DPR).",
                "Besides,",
                "6",
                "https://github.com/facebookresearch/",
                "DPR",
                "Model",
                "EM",
                "BM25+BERT",
                "#REF",
                "26.5",
                "HardEM",
                "#REF",
                "28.1",
                "GraphRetriever",
                "#REF",
                "PathRetriever",
                "#REF",
                "32.6",
                "ORQA",
                "#REF",
                "33.3",
                "REALM",
                "#TARGET_REF",
                "40.4",
                "DPR",
                "#REF",
                "41.5",
                "GAR",
                "#REF",
                "41.6",
                "RocketQA",
                "+",
                "DPR",
                "reader",
                "42.0",
                "RocketQA",
                "+",
                "re-trained",
                "DPR",
                "reader",
                "42.8"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Previous experiments have shown the effectiveness of RocketQA on passage retrieval. Next, we verify whether the retrieval results of RocketQA can improve the performance of passage reading for extracting correct answers. We implement an end-to-end QA system in which we have an extractive reader stacked on our RocketQA retriever. For a fair comparison, we first re-use the released model 6 of the extractive reader in DPR #REF , and take 100 retrieved passages during inference (the same setting used in DPR). Besides, 6 https://github.com/facebookresearch/ DPR Model EM BM25+BERT #REF 26.5 HardEM #REF 28.1 GraphRetriever #REF PathRetriever #REF 32.6 ORQA #REF 33.3 REALM #TARGET_REF 40.4 DPR #REF 41.5 GAR #REF 41.6 RocketQA + DPR reader 42.0 RocketQA + re-trained DPR reader 42.8",
        "output": "{\"INFO\": [\"33.3 REALM #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"6 https://github.com/facebookresearch/ DPR Model EM BM25+BERT #REF 26.5 HardEM #REF 28.1 GraphRetriever #REF PathRetriever #REF 32.6 ORQA #REF\", \"40.4 DPR #REF 41.5 GAR #REF 41.6 RocketQA + DPR reader 42.0 RocketQA + re-trained DPR reader 42.8\"]}"
    },
    {
        "gold": {
            "text": [
                "Post-editing",
                "is",
                "the",
                "process",
                "whereby",
                "a",
                "human",
                "user",
                "corrects",
                "the",
                "output",
                "of",
                "a",
                "machine",
                "translation",
                "system.",
                "The",
                "use",
                "of",
                "basic",
                "post-editing",
                "tools",
                "by",
                "bilingual",
                "human",
                "translators",
                "has",
                "been",
                "shown",
                "to",
                "yield",
                "substantial",
                "increases",
                "in",
                "terms",
                "of",
                "productivity",
                "#REF",
                "as",
                "well",
                "as",
                "improvements",
                "in",
                "translation",
                "quality",
                "#REF",
                "when",
                "compared",
                "to",
                "bilingual",
                "human",
                "translators",
                "working",
                "without",
                "assistance",
                "from",
                "machine",
                "translation",
                "and",
                "post-editing",
                "tools.",
                "More",
                "sophisticated",
                "interactive",
                "interfaces",
                "#REF",
                "may",
                "also",
                "provide",
                "benefit",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Post-editing is the process whereby a human user corrects the output of a machine translation system. The use of basic post-editing tools by bilingual human translators has been shown to yield substantial increases in terms of productivity #REF as well as improvements in translation quality #REF when compared to bilingual human translators working without assistance from machine translation and post-editing tools. More sophisticated interactive interfaces #REF may also provide benefit #TARGET_REF .",
        "output": "{\"INFO\": [\"More sophisticated interactive interfaces #REF may also provide benefit #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"The use of basic post-editing tools by bilingual human translators has been shown to yield substantial increases in terms of productivity #REF as well as improvements in translation quality #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "(a)",
                "the",
                "back",
                "vowels",
                "a,",
                "u,",
                "o",
                "and",
                "the",
                "diphthong",
                "au,",
                "can",
                "be",
                "fronted",
                "#TARGET_REF"
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "(a) the back vowels a, u, o and the diphthong au, can be fronted #TARGET_REF",
        "output": "{\"INFO\": [\"the back vowels a, u, o and the diphthong au, can be fronted #TARGET_REF\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "French",
                "is",
                "a",
                "poorly",
                "endowed",
                "language",
                "since",
                "we",
                "do",
                "not",
                "have",
                "enough",
                "annotated",
                "data",
                "to",
                "train",
                "a",
                "deep",
                "learning",
                "model",
                "on",
                "QA",
                "tasks.",
                "Moreover,",
                "unlike",
                "the",
                "only",
                "two",
                "large",
                "monolingual",
                "French",
                "models:",
                "CamemBERT",
                "#REF",
                "and",
                "FlauBERT",
                "#TARGET_REF",
                ",",
                "the",
                "English",
                "BERT",
                "model",
                "has",
                "become",
                "a",
                "branching",
                "point",
                "from",
                "which",
                "a",
                "growing",
                "number",
                "of",
                "large",
                "and",
                "compact",
                "English",
                "pre-trained",
                "models",
                "have",
                "emerged.",
                "These",
                "French",
                "monolingual",
                "models,",
                "although",
                "they",
                "provide",
                "good",
                "performances,",
                "do",
                "not",
                "reflect",
                "the",
                "rapid",
                "evolution",
                "of",
                "the",
                "field."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "French is a poorly endowed language since we do not have enough annotated data to train a deep learning model on QA tasks. Moreover, unlike the only two large monolingual French models: CamemBERT #REF and FlauBERT #TARGET_REF , the English BERT model has become a branching point from which a growing number of large and compact English pre-trained models have emerged. These French monolingual models, although they provide good performances, do not reflect the rapid evolution of the field.",
        "output": "{\"INFO\": [\"FlauBERT #TARGET_REF ,\"], \"PERCEPT\": [\"Moreover, unlike the only two large monolingual French models:\", \"the English BERT model has become a branching point from which a growing number of large and compact English pre-trained models have emerged.\"], \"BACK\": [\"CamemBERT #REF and\", \"These French monolingual models, although they provide good performances, do not reflect the rapid evolution of the field.\"]}"
    },
    {
        "gold": {
            "text": [
                "our",
                "internal",
                "proofing",
                "costs",
                "do",
                "not",
                "change",
                "according",
                "to",
                "recent",
                "statistics.",
                "With",
                "time,",
                "these",
                "statistics",
                "can",
                "change",
                "and",
                "guide",
                "better",
                "pricing",
                "model",
                "development.",
                "Table",
                "4.",
                "shows",
                "the",
                "translation",
                "process",
                "investment",
                "costs",
                "when",
                "MT",
                "is",
                "developed",
                "internally",
                "on",
                "LSP",
                "premises.",
                "The",
                "document",
                "conversion,",
                "project",
                "coordination,",
                "additional",
                "services",
                "costs,",
                "along",
                "with",
                "the",
                "cost",
                "of",
                "terminology",
                "management,",
                "and",
                "resources,",
                "are",
                "identical",
                "and",
                "the",
                "same",
                "as",
                "in",
                "Scenario",
                "1.",
                "It",
                "is",
                "interesting",
                "to",
                "note",
                "the",
                "costs",
                "that",
                "accompany",
                "internal",
                "MT",
                "development.",
                "These",
                "costs",
                "include",
                "but",
                "are",
                "not",
                "restricted",
                "to",
                "customization,",
                "6",
                "equal",
                "to",
                "50%",
                "*Cosegm",
                "automation,",
                "software",
                "and",
                "hardware",
                "costs.",
                "A",
                "cost",
                "for",
                "trainings",
                "is",
                "introduced.",
                "It",
                "covers",
                "project",
                "coordinators",
                "MT",
                "training",
                "expenses.",
                "Additionally",
                "it",
                "includes",
                "MT",
                "specialist",
                "new",
                "methodology",
                "and",
                "approach",
                "trainings.",
                "These",
                "costs",
                "can",
                "be",
                "roughly",
                "estimated",
                "to",
                "the",
                "expenses",
                "incurred",
                "for",
                "the",
                "number",
                "of",
                "employees",
                "required",
                "per",
                "day.",
                "Depending",
                "of",
                "the",
                "scale",
                "of",
                "the",
                "MT",
                "projects,",
                "hardware",
                "costs",
                "for",
                "two",
                "servers",
                "allowing",
                "simultaneous",
                "translation",
                "requests",
                "can",
                "easily",
                "reach",
                "60K",
                "euros.",
                "The",
                "hardware",
                "cost",
                "is",
                "repetitive",
                "every",
                "year",
                "as",
                "more",
                "projects",
                "and",
                "users",
                "are",
                "expected",
                "to",
                "benefit",
                "from",
                "MT.",
                "The",
                "cost",
                "of",
                "customization",
                "and",
                "optimization",
                "include",
                "human",
                "development",
                "effort",
                "and",
                "is",
                "measured",
                "in",
                "man-hours.",
                "This",
                "cost",
                "is",
                "directly",
                "linked",
                "to",
                "the",
                "software",
                "licensing",
                "expenses",
                "as",
                "licensed",
                "tools",
                "are",
                "used",
                "to",
                "accelerate",
                "the",
                "MT",
                "specialists'",
                "development",
                "effort.",
                "More",
                "managerial",
                "tasks",
                "by",
                "human",
                "resources",
                "are",
                "required",
                "such",
                "as",
                "risk",
                "management",
                "monitoring",
                "and",
                "development",
                "of",
                "prevention",
                "plan",
                "strategies."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "our internal proofing costs do not change according to recent statistics. With time, these statistics can change and guide better pricing model development. Table 4. shows the translation process investment costs when MT is developed internally on LSP premises. The document conversion, project coordination, additional services costs, along with the cost of terminology management, and resources, are identical and the same as in Scenario 1. It is interesting to note the costs that accompany internal MT development. These costs include but are not restricted to customization, 6 equal to 50% *Cosegm automation, software and hardware costs. A cost for trainings is introduced. It covers project coordinators MT training expenses. Additionally it includes MT specialist new methodology and approach trainings. These costs can be roughly estimated to the expenses incurred for the number of employees required per day. Depending of the scale of the MT projects, hardware costs for two servers allowing simultaneous translation requests can easily reach 60K euros. The hardware cost is repetitive every year as more projects and users are expected to benefit from MT. The cost of customization and optimization include human development effort and is measured in man-hours. This cost is directly linked to the software licensing expenses as licensed tools are used to accelerate the MT specialists' development effort. More managerial tasks by human resources are required such as risk management monitoring and development of prevention plan strategies.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "anticipate",
                "exploring",
                "various",
                "extensions",
                "to",
                "and",
                "validations",
                "of",
                "this",
                "method",
                "in",
                "the",
                "future.",
                "Specifically,",
                "we",
                "would",
                "like",
                "to",
                "explore",
                "methods",
                "that",
                "might",
                "mitigate",
                "performance",
                "degradation",
                "due",
                "to",
                "a",
                "lack",
                "of",
                "word",
                "boundaries",
                "in",
                "our",
                "method.",
                "Subword",
                "tokenization",
                "techniques,",
                "such",
                "as",
                "Byte-Pair",
                "Encodings",
                "(BPE)",
                "#REF",
                ",",
                "or",
                "character-based",
                "word",
                "segmentation",
                "techniques",
                "might",
                "help",
                "in",
                "detecting",
                "and",
                "exploiting",
                "repeating",
                "patterns",
                "within",
                "the",
                "phonetic",
                "representation.",
                "Furthermore,",
                "the",
                "word",
                "embedding",
                "techniques",
                "used",
                "by",
                "#REF",
                "or",
                "#TARGET_REF",
                "have",
                "been",
                "shown",
                "to",
                "work",
                "well,",
                "and",
                "would",
                "be",
                "worth",
                "investigating",
                "how",
                "the",
                "removal",
                "of",
                "spacedelimited",
                "word",
                "boundaries",
                "would",
                "affect",
                "this."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We anticipate exploring various extensions to and validations of this method in the future. Specifically, we would like to explore methods that might mitigate performance degradation due to a lack of word boundaries in our method. Subword tokenization techniques, such as Byte-Pair Encodings (BPE) #REF , or character-based word segmentation techniques might help in detecting and exploiting repeating patterns within the phonetic representation. Furthermore, the word embedding techniques used by #REF or #TARGET_REF have been shown to work well, and would be worth investigating how the removal of spacedelimited word boundaries would affect this.",
        "output": "{\"INFO\": [\"the word embedding techniques used by\", \"#TARGET_REF\"], \"PERCEPT\": [\"have been shown to work well, and would be worth investigating how the removal of spacedelimited word boundaries would affect this.\"], \"BACK\": [\"#REF or\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "use",
                "DRQA",
                "#TARGET_REF",
                "to",
                "extract",
                "k",
                "sentences",
                "S",
                "=",
                "{s",
                "i",
                "}",
                "k",
                "i=1",
                "and",
                "n",
                "tables",
                "T",
                "=",
                "{t",
                "i",
                "}",
                "n",
                "i=1",
                "from",
                "the",
                "retrieved",
                "pages,",
                "respectively.",
                "Then",
                "we",
                "select",
                "cells",
                "from",
                "the",
                "extracted",
                "tables.",
                "Many",
                "instances",
                "in",
                "the",
                "FEVEROUS",
                "dataset",
                "require",
                "evidence",
                "cells",
                "from",
                "more",
                "than",
                "one",
                "table,",
                "and",
                "each",
                "retrieved",
                "table",
                "has",
                "different",
                "relevance",
                "score",
                "to",
                "the",
                "claim.",
                "However,",
                "the",
                "widely-used",
                "cell",
                "extractor",
                "#REF",
                "reserves",
                "cells",
                "from",
                "only",
                "one",
                "table",
                "in",
                "their",
                "implementation."
            ],
            "context": [
                2,
                2,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "We use DRQA #TARGET_REF to extract k sentences S = {s i } k i=1 and n tables T = {t i } n i=1 from the retrieved pages, respectively. Then we select cells from the extracted tables. Many instances in the FEVEROUS dataset require evidence cells from more than one table, and each retrieved table has different relevance score to the claim. However, the widely-used cell extractor #REF reserves cells from only one table in their implementation.",
        "output": "{\"INFO\": [\"DRQA #TARGET_REF\"], \"PERCEPT\": [\"We use\", \"to extract k sentences S = {s i } k i=1 and n tables T = {t i } n i=1 from the retrieved pages, respectively.\", \"we select cells from the extracted tables. Many instances in the FEVEROUS dataset require evidence cells from more than one table, and each retrieved table has different relevance score to the claim.\", \"the widely-used cell extractor #REF reserves cells from only one table in their implementation.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "sequential",
                "decision",
                "making",
                "problems",
                "in",
                "particular,",
                "this",
                "generalization",
                "gap",
                "is",
                "the",
                "result",
                "of",
                "an",
                "agent",
                "simply",
                "memorizing",
                "trajectories,",
                "e.g.",
                "the",
                "sequence",
                "of",
                "actions",
                "and",
                "dialogues",
                "required",
                "to",
                "finish",
                "a",
                "game,",
                "and",
                "thus",
                "being",
                "unable",
                "to",
                "react",
                "in",
                "novel",
                "scenarios-i.e.",
                "the",
                "agent",
                "learns",
                "from",
                "the",
                "head",
                "the",
                "training",
                "data",
                "and",
                "simply",
                "memorizes",
                "the",
                "long",
                "tail.",
                "One",
                "way",
                "of",
                "decreasing",
                "this",
                "generalization",
                "gap",
                "is",
                "by",
                "training",
                "agents",
                "on",
                "procedurally",
                "generated",
                "environments-wherein",
                "the",
                "agent",
                "learns",
                "a",
                "family",
                "of",
                "parametrized",
                "tasks",
                "with",
                "a",
                "significantly",
                "larger",
                "state-action",
                "spaces",
                "than",
                "singular",
                "environments,",
                "thus",
                "effectively",
                "making",
                "the",
                "memorization",
                "of",
                "trajectories",
                "impossible",
                "#TARGET_REF",
                ".",
                "Drawing",
                "inspiration",
                "from",
                "all",
                "of",
                "these",
                "ideas,",
                "we",
                "create",
                "a",
                "method",
                "that",
                "learns",
                "to",
                "create",
                "a",
                "training",
                "curriculum",
                "of",
                "increasingly",
                "more",
                "difficult",
                "novel",
                "procedurally",
                "generated",
                "environments."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In sequential decision making problems in particular, this generalization gap is the result of an agent simply memorizing trajectories, e.g. the sequence of actions and dialogues required to finish a game, and thus being unable to react in novel scenarios-i.e. the agent learns from the head the training data and simply memorizes the long tail. One way of decreasing this generalization gap is by training agents on procedurally generated environments-wherein the agent learns a family of parametrized tasks with a significantly larger state-action spaces than singular environments, thus effectively making the memorization of trajectories impossible #TARGET_REF . Drawing inspiration from all of these ideas, we create a method that learns to create a training curriculum of increasingly more difficult novel procedurally generated environments.",
        "output": "{\"INFO\": [\"training agents on procedurally generated environments-wherein the agent learns a family of parametrized tasks with a significantly larger state-action spaces than singular environments, thus effectively making the memorization of trajectories impossible #TARGET_REF .\"], \"PERCEPT\": [\"One way of decreasing this generalization gap is by\"], \"BACK\": [\"In sequential decision making problems in particular, this generalization gap is the result of an agent simply memorizing trajectories,\"]}"
    },
    {
        "gold": {
            "text": [
                "Besides,",
                "we",
                "also",
                "conduct",
                "a",
                "manual",
                "evaluation",
                "on",
                "the",
                "Chinese",
                "test",
                "set,",
                "and",
                "the",
                "results",
                "are",
                "listed",
                "in",
                "Table",
                "5.",
                "From",
                "the",
                "averaged",
                "scores,",
                "we",
                "observe",
                "that",
                "SimpDefiner",
                "outperforms",
                "MASS",
                "by",
                "0.2",
                "in",
                "terms",
                "of",
                "accuracy",
                "(more",
                "accurate)",
                "and",
                "0.18",
                "in",
                "terms",
                "of",
                "simplicity",
                "(more",
                "straightforward).",
                "On",
                "the",
                "accuracy",
                "score,",
                "all",
                "three",
                "annotators",
                "agree",
                "that",
                "SimpDefiner",
                "has",
                "higher",
                "accuracy",
                "than",
                "MASS,",
                "which",
                "shows",
                "the",
                "superiority",
                "of",
                "our",
                "framework.",
                "As",
                "expected,",
                "the",
                "golden",
                "definitions",
                "have",
                "the",
                "highest",
                "accuracy",
                "in",
                "the",
                "table,",
                "far",
                "exceeding",
                "the",
                "definitions",
                "generated",
                "by",
                "the",
                "two",
                "models.",
                "We",
                "believe",
                "this",
                "is",
                "caused",
                "by",
                "insufficient",
                "knowledge",
                "in",
                "the",
                "model,",
                "and",
                "this",
                "can",
                "be",
                "solved",
                "by",
                "using",
                "larger",
                "pretrained",
                "models,",
                "such",
                "as",
                "BART",
                "#TARGET_REF",
                ".",
                "On",
                "the",
                "simplicity",
                "score,",
                "three",
                "annotators",
                "agree",
                "that",
                "SimpDefiner",
                "generates",
                "simpler",
                "definitions",
                "than",
                "MASS,",
                "and",
                "two",
                "of",
                "three",
                "annotators",
                "think",
                "SimpDefiner",
                "generates",
                "simpler",
                "definitions",
                "than",
                "the",
                "golden",
                "ones."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Besides, we also conduct a manual evaluation on the Chinese test set, and the results are listed in Table 5. From the averaged scores, we observe that SimpDefiner outperforms MASS by 0.2 in terms of accuracy (more accurate) and 0.18 in terms of simplicity (more straightforward). On the accuracy score, all three annotators agree that SimpDefiner has higher accuracy than MASS, which shows the superiority of our framework. As expected, the golden definitions have the highest accuracy in the table, far exceeding the definitions generated by the two models. We believe this is caused by insufficient knowledge in the model, and this can be solved by using larger pretrained models, such as BART #TARGET_REF . On the simplicity score, three annotators agree that SimpDefiner generates simpler definitions than MASS, and two of three annotators think SimpDefiner generates simpler definitions than the golden ones.",
        "output": "{\"INFO\": [\"BART #TARGET_REF\"], \"PERCEPT\": [\"We believe this is caused by insufficient knowledge in the model, and this can be solved by using larger pretrained models, such as\"], \"BACK\": [\"the golden definitions have the highest accuracy in the table, far exceeding the definitions generated by the two models.\"]}"
    },
    {
        "gold": {
            "text": [
                "Ortega",
                "et",
                "al.",
                "(",
                "2020b)",
                "used",
                "morphological",
                "information,",
                "such",
                "as",
                "affixes,",
                "to",
                "guide",
                "the",
                "Byte-Pair-Encoding",
                "(BPE)",
                "segmentation",
                "algorithm",
                "#REF",
                "for",
                "Quechua.",
                "However,",
                "their",
                "improvement",
                "is",
                "not",
                "significant,",
                "and",
                "according",
                "to",
                "#REF",
                ",",
                "BPE",
                "tends",
                "to",
                "oversplit",
                "roots",
                "of",
                "infrequent",
                "words.",
                "They",
                "showed",
                "that",
                "a",
                "unigram",
                "language",
                "model",
                "#TARGET_REF",
                "seems",
                "like",
                "a",
                "better",
                "alternative",
                "to",
                "split",
                "affixes",
                "and",
                "preserve",
                "roots",
                "(in",
                "English",
                "and",
                "Japanese)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Ortega et al. ( 2020b) used morphological information, such as affixes, to guide the Byte-Pair-Encoding (BPE) segmentation algorithm #REF for Quechua. However, their improvement is not significant, and according to #REF , BPE tends to oversplit roots of infrequent words. They showed that a unigram language model #TARGET_REF seems like a better alternative to split affixes and preserve roots (in English and Japanese).",
        "output": "{\"INFO\": [\"a unigram language model #TARGET_REF\"], \"PERCEPT\": [\"They showed that\", \"seems like a better alternative to split affixes and preserve roots\"], \"BACK\": [\"according to #REF , BPE tends to oversplit roots of infrequent words.\", \"(in English and Japanese).\"]}"
    },
    {
        "gold": {
            "text": [
                "After",
                "the",
                "selection",
                "of",
                "documents",
                "for",
                "analysis,",
                "a",
                "list",
                "of",
                "keywords",
                "was",
                "prepared",
                "independently",
                "by",
                "the",
                "authors",
                "and",
                "then",
                "compiled.",
                "As",
                "traditionally",
                "held,",
                "an",
                "apology",
                "consists",
                "of",
                "five",
                "major",
                "parts",
                "#TARGET_REF",
                ".",
                "These",
                "are",
                "the",
                "following:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3
            ]
        },
        "input": "After the selection of documents for analysis, a list of keywords was prepared independently by the authors and then compiled. As traditionally held, an apology consists of five major parts #TARGET_REF . These are the following:",
        "output": "{\"INFO\": [\"an apology consists of five major parts #TARGET_REF .\"], \"PERCEPT\": [\"As traditionally held,\"], \"BACK\": [\"These are the following:\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "approach",
                "to",
                "text",
                "grammar",
                "taken",
                "here",
                "is",
                "in",
                "many",
                "ways",
                "similar",
                "to",
                "that",
                "of",
                "#TARGET_REF",
                ".",
                "However,",
                "he",
                "opts",
                "to",
                "treat",
                "punctuation",
                "marks",
                "as",
                "clitics",
                "on",
                "words",
                "which",
                "introduce",
                "additional",
                "featural",
                "information",
                "into",
                "standard",
                "syntactic",
                "rules.",
                "Thus,",
                "his",
                "grammar",
                "is",
                "thoroughly",
                "integrated",
                "and",
                "it",
                "would",
                "be",
                "harder",
                "to",
                "extract",
                "an",
                "independent",
                "text",
                "grammar",
                "or",
                "build",
                "a",
                "modular",
                "semantics.",
                "The",
                "coverage",
                "of",
                "the",
                "integrated",
                "version",
                "of",
                "the",
                "text",
                "grammar",
                "is",
                "described",
                "in",
                "more",
                "detail",
                "in",
                "#REF",
                ".",
                "#REF",
                "trained",
                "on",
                "text",
                "tagged",
                "with",
                "a",
                "slightly",
                "modified",
                "version",
                "of",
                "CLAWS-II",
                "labels",
                "#REF",
                ".",
                "#REF",
                "that",
                "in",
                "practice",
                "NL",
                "grammars",
                "do",
                "not",
                "evince",
                "worst-case",
                "parsing",
                "complexity."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The approach to text grammar taken here is in many ways similar to that of #TARGET_REF . However, he opts to treat punctuation marks as clitics on words which introduce additional featural information into standard syntactic rules. Thus, his grammar is thoroughly integrated and it would be harder to extract an independent text grammar or build a modular semantics. The coverage of the integrated version of the text grammar is described in more detail in #REF . #REF trained on text tagged with a slightly modified version of CLAWS-II labels #REF . #REF that in practice NL grammars do not evince worst-case parsing complexity.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"The approach to text grammar taken here is in many ways similar to that of\", \"he opts to treat punctuation marks as clitics on words which introduce additional featural information into standard syntactic rules.\", \"his grammar is thoroughly integrated and it would be harder to extract an independent text grammar or build a modular semantics.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Arabic",
                "being",
                "a",
                "morphologically",
                "rich",
                "language,",
                "has",
                "many",
                "different",
                "surface",
                "forms",
                "of",
                "words",
                "with",
                "same",
                "root.",
                "This",
                "phenomenon",
                "poses",
                "a",
                "data",
                "sparsity",
                "problem",
                "for",
                "SMT",
                "systems.",
                "In",
                "order",
                "to",
                "reduce",
                "data",
                "sparsity,",
                "we",
                "segment",
                "the",
                "Arabic",
                "data",
                "morphologically",
                "before",
                "training.",
                "The",
                "Arabic",
                "data",
                "is",
                "segmented",
                "according",
                "to",
                "the",
                "D3",
                "segmentation",
                "scheme",
                "using",
                "MADA",
                "(Morphological",
                "Analysis",
                "and",
                "Disambiguation",
                "for",
                "Arabic).",
                "5",
                "For",
                "all",
                "the",
                "available",
                "Chinese",
                "data,",
                "we",
                "segment",
                "the",
                "sentences",
                "to",
                "words",
                "using",
                "the",
                "Stanford",
                "Chinese",
                "Word",
                "Segmenter",
                "#TARGET_REF",
                ".",
                "English",
                "data",
                "is",
                "lower-cased",
                "and",
                "tokenized",
                "in",
                "the",
                "preprocessing",
                "step."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Arabic being a morphologically rich language, has many different surface forms of words with same root. This phenomenon poses a data sparsity problem for SMT systems. In order to reduce data sparsity, we segment the Arabic data morphologically before training. The Arabic data is segmented according to the D3 segmentation scheme using MADA (Morphological Analysis and Disambiguation for Arabic). 5 For all the available Chinese data, we segment the sentences to words using the Stanford Chinese Word Segmenter #TARGET_REF . English data is lower-cased and tokenized in the preprocessing step.",
        "output": "{\"INFO\": [\"Stanford Chinese Word Segmenter #TARGET_REF .\"], \"PERCEPT\": [\"For all the available Chinese data, we segment the sentences to words using the\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "initialize",
                "attribute",
                "embeddings",
                "with",
                "Glove",
                "#TARGET_REF",
                "word",
                "embeddings.",
                "For",
                "an",
                "entity,",
                "we",
                "take",
                "all",
                "the",
                "known",
                "attributes",
                "from",
                "K",
                "e",
                ".",
                "The",
                "representation",
                "of",
                "each",
                "entity",
                "is",
                "the",
                "weighted",
                "sum",
                "of",
                "the",
                "known",
                "attributes,",
                "with",
                "learned",
                "attention",
                "weights.",
                "The",
                "weights",
                "are",
                "shared",
                "between",
                "entities",
                "and",
                "attributes."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We initialize attribute embeddings with Glove #TARGET_REF word embeddings. For an entity, we take all the known attributes from K e . The representation of each entity is the weighted sum of the known attributes, with learned attention weights. The weights are shared between entities and attributes.",
        "output": "{\"INFO\": [\"Glove #TARGET_REF word embeddings.\"], \"PERCEPT\": [\"We initialize attribute embeddings with\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Once",
                "an",
                "agent",
                "acts",
                "or",
                "talks,",
                "the",
                "partner",
                "agent-in",
                "this",
                "case",
                "also",
                "a",
                "polyencoder",
                "#REF",
                "trained",
                "to",
                "react",
                "to",
                "agents",
                "with",
                "motivations-also",
                "acts",
                "or",
                "talks",
                "and",
                "this",
                "information",
                "is",
                "processed",
                "by",
                "the",
                "environment.",
                "As",
                "recommended",
                "by",
                "Prabhumoye",
                "et",
                "al.",
                "(",
                "2020),",
                "#REF",
                ",",
                "we",
                "keep",
                "the",
                "partner",
                "model",
                "fixed",
                "during",
                "the",
                "episodes",
                "where",
                "the",
                "LIGHT",
                "agent",
                "trains",
                "to",
                "ensure",
                "that",
                "it",
                "retains",
                "natural",
                "English",
                "semantics-avoiding",
                "the",
                "problem",
                "of",
                "language",
                "drift",
                "by",
                "learning",
                "an",
                "emergent",
                "language",
                "with",
                "that",
                "must",
                "agree",
                "with",
                "the",
                "partner's",
                "usage",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Once an agent acts or talks, the partner agent-in this case also a polyencoder #REF trained to react to agents with motivations-also acts or talks and this information is processed by the environment. As recommended by Prabhumoye et al. ( 2020), #REF , we keep the partner model fixed during the episodes where the LIGHT agent trains to ensure that it retains natural English semantics-avoiding the problem of language drift by learning an emergent language with that must agree with the partner's usage #TARGET_REF .",
        "output": "{\"INFO\": [\"semantics-avoiding the problem of language drift by learning an emergent language with that must agree with the partner's usage #TARGET_REF .\"], \"PERCEPT\": [\"we keep the partner model fixed during the episodes where the LIGHT agent trains to ensure that it retains natural English\"], \"BACK\": [\"Once an agent acts or talks, the partner agent-in\", \"motivations-also acts or talks and this information is processed by the environment.\"]}"
    },
    {
        "gold": {
            "text": [
                "Similar",
                "to",
                "other",
                "NLP",
                "applications,",
                "the",
                "most",
                "recent",
                "attention",
                "in",
                "this",
                "area",
                "has",
                "been",
                "on",
                "neural",
                "approaches.",
                "#TARGET_REF",
                "demonstrated",
                "an",
                "effective",
                "way",
                "of",
                "applying",
                "a",
                "Bi-LSTM",
                "to",
                "the",
                "POS",
                "tagging",
                "task,",
                "achieving",
                "97.4%",
                "on",
                "the",
                "English",
                "Penn",
                "Treebank.",
                "#REF",
                "used",
                "a",
                "Bi-LSTM",
                "in",
                "their",
                "work",
                "on",
                "Arabic",
                "POS",
                "tagging,",
                "achieving",
                "95.50%.",
                "#REF",
                "used",
                "the",
                "LSTM-RNN",
                "model",
                "on",
                "the",
                "Quranic",
                "Arabic",
                "Corpus",
                "(QAC).",
                "They",
                "reported",
                "accuracy",
                "of",
                "99.76%",
                "at",
                "the",
                "word",
                "level",
                "and",
                "99.18%",
                "at",
                "the",
                "morpheme",
                "level.",
                "They",
                "also",
                "compared",
                "their",
                "system",
                "against",
                "the",
                "Word2Vec",
                "POS",
                "tagger,",
                "for",
                "which",
                "they",
                "reported",
                "accuracy",
                "levels",
                "of",
                "97.33%",
                "and",
                "99.55%",
                "for",
                "words",
                "and",
                "morphemes",
                "respectively."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Similar to other NLP applications, the most recent attention in this area has been on neural approaches. #TARGET_REF demonstrated an effective way of applying a Bi-LSTM to the POS tagging task, achieving 97.4% on the English Penn Treebank. #REF used a Bi-LSTM in their work on Arabic POS tagging, achieving 95.50%. #REF used the LSTM-RNN model on the Quranic Arabic Corpus (QAC). They reported accuracy of 99.76% at the word level and 99.18% at the morpheme level. They also compared their system against the Word2Vec POS tagger, for which they reported accuracy levels of 97.33% and 99.55% for words and morphemes respectively.",
        "output": "{\"INFO\": [\"#TARGET_REF demonstrated an effective way of applying a Bi-LSTM to the POS tagging task, achieving 97.4% on the English Penn Treebank.\"], \"PERCEPT\": [], \"BACK\": [\"the most recent attention in this area has been on neural approaches.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "section",
                "describes",
                "how",
                "we",
                "prepare",
                "the",
                "collapsed",
                "single",
                "sequence",
                "composed",
                "of",
                "s",
                "i",
                "in",
                "Eq.",
                "(",
                "8).",
                "We",
                "explain",
                "this",
                "data",
                "preparation",
                "with",
                "both",
                "English",
                "(TED-LIUM",
                "release",
                "2",
                "(TEDLIUM2)",
                "#TARGET_REF",
                ")",
                "and",
                "Japanese",
                "(corpus",
                "of",
                "spontaneous",
                "Japanese",
                "(CSJ)",
                "#REF",
                "))",
                "data",
                "as",
                "an",
                "example.",
                "The",
                "sequence",
                "type",
                "includes",
                "the",
                "graphemic",
                "and",
                "phonemic",
                "transcripts",
                "1",
                ",",
                "as",
                "well",
                "as",
                "the",
                "POS",
                "tags."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "This section describes how we prepare the collapsed single sequence composed of s i in Eq. ( 8). We explain this data preparation with both English (TED-LIUM release 2 (TEDLIUM2) #TARGET_REF ) and Japanese (corpus of spontaneous Japanese (CSJ) #REF )) data as an example. The sequence type includes the graphemic and phonemic transcripts 1 , as well as the POS tags.",
        "output": "{\"INFO\": [\"(TED-LIUM release 2 (TEDLIUM2) #TARGET_REF )\"], \"PERCEPT\": [\"We explain this data preparation with both English\", \"as an example.\"], \"BACK\": [\"This section describes how we prepare the collapsed single sequence composed of s i in Eq. ( 8).\", \"and Japanese (corpus of spontaneous Japanese (CSJ) #REF )) data\", \"The sequence type includes the graphemic and phonemic transcripts 1 , as well as the POS tags.\"]}"
    }
]