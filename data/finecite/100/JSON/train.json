[
    {
        "gold": {
            "text": [
                "Following",
                "the",
                "previous",
                "editions",
                "of",
                "the",
                "shared",
                "task,",
                "we",
                "frame",
                "explanation",
                "generation",
                "as",
                "a",
                "ranking",
                "problem.",
                "Specifically,",
                "for",
                "a",
                "given",
                "science",
                "question,",
                "a",
                "model",
                "is",
                "supplied",
                "both",
                "the",
                "question",
                "and",
                "correct",
                "answer",
                "text,",
                "and",
                "must",
                "then",
                "selectively",
                "rank",
                "all",
                "the",
                "atomic",
                "scientific",
                "and",
                "world",
                "knowledge",
                "facts",
                "in",
                "the",
                "knowledge",
                "base",
                "such",
                "that",
                "those",
                "that",
                "were",
                "labelled",
                "as",
                "most",
                "relevant",
                "to",
                "building",
                "an",
                "explanation",
                "by",
                "a",
                "human",
                "annotator",
                "are",
                "ranked",
                "the",
                "highest.",
                "Additional",
                "details",
                "on",
                "the",
                "ranking",
                "problem",
                "are",
                "described",
                "in",
                "the",
                "2019",
                "shared",
                "task",
                "summary",
                "paper",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Following the previous editions of the shared task, we frame explanation generation as a ranking problem. Specifically, for a given science question, a model is supplied both the question and correct answer text, and must then selectively rank all the atomic scientific and world knowledge facts in the knowledge base such that those that were labelled as most relevant to building an explanation by a human annotator are ranked the highest. Additional details on the ranking problem are described in the 2019 shared task summary paper #TARGET_REF .",
        "output": "{\"INFO\": [\"2019 shared task summary paper #TARGET_REF .\"], \"PERCEPT\": [\"we frame explanation generation as a ranking problem. Specifically, for a given science question, a model is supplied both the question and correct answer text, and must then selectively rank all the atomic scientific and world knowledge facts in the knowledge base such that those that were labelled as most relevant to building an explanation by a human annotator are ranked the highest.\"], \"BACK\": [\"Additional details on the ranking problem are described in the\"]}"
    },
    {
        "gold": {
            "text": [
                "Technical",
                "Details",
                "All",
                "neural",
                "models",
                "are",
                "trained",
                "using",
                "cross-entropy",
                "loss",
                "and",
                "optimized",
                "with",
                "Adam",
                "(Kingma",
                "and",
                "Ba,",
                "2015),",
                "using",
                "the",
                "AllenNLP",
                "library",
                "#REF",
                ".",
                "We",
                "train",
                "using",
                "a",
                "1e",
                "−",
                "5",
                "learning",
                "rate",
                "for",
                "40",
                "epochs,",
                "with",
                "early",
                "stopping",
                "based",
                "the",
                "F1",
                "metric",
                "on",
                "the",
                "development",
                "set.",
                "We",
                "use",
                "SpanBERT",
                "#TARGET_REF",
                "as",
                "the",
                "pretrained",
                "MLM,",
                "as",
                "it",
                "was",
                "found",
                "to",
                "work",
                "well",
                "on",
                "span-based",
                "tasks",
                "with",
                "its",
                "base",
                "and",
                "the",
                "large",
                "variants.",
                "The",
                "anchor",
                "and",
                "complement",
                "encoding",
                "MLPs",
                "have",
                "one",
                "500-dim",
                "hidden",
                "layer",
                "and",
                "output",
                "500dim",
                "representations.",
                "The",
                "prediction",
                "MLPs",
                "have",
                "one",
                "100-dim",
                "hidden",
                "layer.",
                "All",
                "MLPs",
                "use",
                "the",
                "ReLU",
                "activation.",
                "We",
                "used",
                "the",
                "same",
                "hyperparameters",
                "for",
                "all",
                "baselines",
                "and",
                "did",
                "not",
                "tune",
                "them.",
                "18"
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Technical Details All neural models are trained using cross-entropy loss and optimized with Adam (Kingma and Ba, 2015), using the AllenNLP library #REF . We train using a 1e − 5 learning rate for 40 epochs, with early stopping based the F1 metric on the development set. We use SpanBERT #TARGET_REF as the pretrained MLM, as it was found to work well on span-based tasks with its base and the large variants. The anchor and complement encoding MLPs have one 500-dim hidden layer and output 500dim representations. The prediction MLPs have one 100-dim hidden layer. All MLPs use the ReLU activation. We used the same hyperparameters for all baselines and did not tune them. 18",
        "output": "{\"INFO\": [\"We use SpanBERT #TARGET_REF as the pretrained MLM, as it was found to work well on span-based tasks with its base and the large variants.\"], \"PERCEPT\": [], \"BACK\": [\"Technical Details All neural models are trained using cross-entropy loss and optimized with Adam (Kingma and Ba, 2015), using the AllenNLP library #REF . We train using a 1e \\u2212 5 learning rate for 40 epochs, with early stopping based the F1 metric on the development set.\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "will",
                "describe",
                "parsing",
                "algorithms",
                "using",
                "Parsing",
                "Schemata,",
                "a",
                "framework",
                "for",
                "high-level",
                "description",
                "of",
                "parsing",
                "algorithms",
                "#TARGET_REF",
                ".",
                "An",
                "interesting",
                "application",
                "of",
                "this",
                "framework",
                "is",
                "the",
                "analysis",
                "of",
                "the",
                "relations",
                "between",
                "different",
                "parsing",
                "algorithms",
                "by",
                "studying",
                "the",
                "formal",
                "relations",
                "between",
                "their",
                "underlying",
                "parsing",
                "schemata."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "We will describe parsing algorithms using Parsing Schemata, a framework for high-level description of parsing algorithms #TARGET_REF . An interesting application of this framework is the analysis of the relations between different parsing algorithms by studying the formal relations between their underlying parsing schemata.",
        "output": "{\"INFO\": [\"Parsing Schemata, a framework for high-level description of parsing algorithms #TARGET_REF\"], \"PERCEPT\": [\"An interesting application of this framework is\"], \"BACK\": [\"the analysis of the relations between different parsing algorithms by studying the formal relations between their underlying parsing schemata.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Champollion",
                "system",
                "was",
                "developed",
                "by",
                "#REF",
                "to",
                "specifically",
                "address",
                "translation",
                "of",
                "collocations,",
                "including",
                "non-compositional",
                "expressions.",
                "They",
                "used",
                "aligned",
                "sentences",
                "from",
                "the",
                "Canadian",
                "Hansards",
                "corpus",
                "(as",
                "did",
                "#REF",
                ".",
                "They",
                "used",
                "a",
                "tool",
                "they",
                "had",
                "previously",
                "developed",
                "(XTRACT)",
                "to",
                "identify",
                "collocations",
                "and",
                "they",
                "translated",
                "approximately",
                "900",
                "medium",
                "frequency",
                "English",
                "phrases",
                "to",
                "French.",
                "Manual",
                "evaluation",
                "by",
                "bilingual",
                "speakers",
                "revealed",
                "accuracies",
                "between",
                "65",
                "and",
                "78%.",
                "Champollion",
                "works",
                "by",
                "iteratively",
                "fusing",
                "together",
                "target",
                "language",
                "words",
                "that",
                "are",
                "strongly",
                "correlated",
                "to",
                "the",
                "source",
                "language",
                "collocation",
                "for",
                "which",
                "translation",
                "is",
                "attempted.",
                "Dice",
                "scores",
                "are",
                "used",
                "to",
                "filter",
                "out",
                "unlikely",
                "word",
                "combinations.",
                "#TARGET_REF",
                "ambitiously",
                "produce",
                "alignments",
                "from",
                "comparable",
                "corpora,",
                "corpora",
                "where",
                "exact",
                "translations",
                "may",
                "not",
                "be",
                "available,",
                "but",
                "in",
                "which",
                "the",
                "same",
                "topics",
                "or",
                "entities",
                "are",
                "being",
                "discussed",
                "such",
                "as",
                "contemporaneous",
                "newswire.",
                "They",
                "use",
                "suffix",
                "trees",
                "in",
                "both",
                "languages",
                "and",
                "a",
                "bilingual",
                "lexicon",
                "to",
                "provide",
                "points",
                "of",
                "correspondence",
                "between",
                "the",
                "two",
                "languages.",
                "Not",
                "only",
                "to",
                "they",
                "successfully",
                "create",
                "alignments",
                "in",
                "the",
                "comparable",
                "data,",
                "thus",
                "creating",
                "a",
                "parallel",
                "corpus,",
                "they",
                "create",
                "phrasal",
                "alignments",
                "of",
                "a",
                "restricted",
                "sort.",
                "Namely,",
                "their",
                "parallel",
                "phrases",
                "have",
                "the",
                "same",
                "number",
                "of",
                "tokens",
                "(i.e.,",
                "words)",
                "in",
                "each",
                "language",
                "and",
                "the",
                "word",
                "order",
                "of",
                "the",
                "source",
                "and",
                "target",
                "languages",
                "must",
                "be",
                "the",
                "same.",
                "Some",
                "examples",
                "of",
                "English/French",
                "alignments",
                "that",
                "they",
                "identified",
                "are:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The Champollion system was developed by #REF to specifically address translation of collocations, including non-compositional expressions. They used aligned sentences from the Canadian Hansards corpus (as did #REF . They used a tool they had previously developed (XTRACT) to identify collocations and they translated approximately 900 medium frequency English phrases to French. Manual evaluation by bilingual speakers revealed accuracies between 65 and 78%. Champollion works by iteratively fusing together target language words that are strongly correlated to the source language collocation for which translation is attempted. Dice scores are used to filter out unlikely word combinations. #TARGET_REF ambitiously produce alignments from comparable corpora, corpora where exact translations may not be available, but in which the same topics or entities are being discussed such as contemporaneous newswire. They use suffix trees in both languages and a bilingual lexicon to provide points of correspondence between the two languages. Not only to they successfully create alignments in the comparable data, thus creating a parallel corpus, they create phrasal alignments of a restricted sort. Namely, their parallel phrases have the same number of tokens (i.e., words) in each language and the word order of the source and target languages must be the same. Some examples of English/French alignments that they identified are:",
        "output": "{\"INFO\": [\"#TARGET_REF ambitiously produce alignments from comparable corpora, corpora where exact translations may not be available, but in which the same topics or entities are being discussed such as contemporaneous newswire. They use suffix trees in both languages and a bilingual lexicon to provide points of correspondence between the two languages. Not only to they successfully create alignments in the comparable data, thus creating a parallel corpus, they create phrasal alignments of a restricted sort. Namely, their parallel phrases have the same number of tokens\", \"in each language and the word order of the source and target languages must be the same. Some examples of English/French alignments that they identified are:\"], \"PERCEPT\": [], \"BACK\": [\"words)\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "achieve",
                "this",
                "goal,",
                "we",
                "investigate",
                "whether",
                "due",
                "to",
                "the",
                "similarity",
                "between",
                "idioms",
                "and",
                "rare-words",
                "Schick",
                "and",
                "Schütze's",
                "BERT",
                "for",
                "Attentive",
                "Mimicking",
                "#TARGET_REF",
                ")",
                "(BERTRAM)",
                "model,",
                "which",
                "was",
                "designed",
                "for",
                "use",
                "with",
                "rare-words,",
                "can",
                "be",
                "used",
                "to",
                "explicitly",
                "learn",
                "high-quality",
                "embeddings",
                "for",
                "idiomatic",
                "expressions.",
                "We",
                "also",
                "investigate",
                "how",
                "many",
                "examples",
                "of",
                "each",
                "idiom",
                "are",
                "required",
                "to",
                "create",
                "embeddings",
                "that",
                "perform",
                "well",
                "on",
                "the",
                "task,",
                "as",
                "well",
                "as",
                "how",
                "the",
                "quality",
                "of",
                "contexts",
                "fed",
                "to",
                "the",
                "BERTRAM",
                "model",
                "effects",
                "the",
                "representations",
                "and",
                "performance",
                "on",
                "the",
                "task."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To achieve this goal, we investigate whether due to the similarity between idioms and rare-words Schick and Schütze's BERT for Attentive Mimicking #TARGET_REF ) (BERTRAM) model, which was designed for use with rare-words, can be used to explicitly learn high-quality embeddings for idiomatic expressions. We also investigate how many examples of each idiom are required to create embeddings that perform well on the task, as well as how the quality of contexts fed to the BERTRAM model effects the representations and performance on the task.",
        "output": "{\"INFO\": [\"for Attentive Mimicking #TARGET_REF ) (BERTRAM) model, which was designed for use with rare-words, can be used to explicitly learn high-quality embeddings for idiomatic expressions.\"], \"PERCEPT\": [\"To achieve this goal, we investigate whether due to the similarity between idioms and rare-words Schick and Sch\\u00fctze's BERT\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "have",
                "established",
                "that",
                "the",
                "performance",
                "of",
                "top-k",
                "attention",
                "is",
                "comparable",
                "to",
                "vanilla",
                "attention",
                "when",
                "training",
                "the",
                "model",
                "from",
                "scratch.",
                "In",
                "this",
                "set-up,",
                "several",
                "recently-proposed",
                "approaches",
                "have",
                "also",
                "reported",
                "competitive",
                "performances",
                "#REF",
                ".",
                "Now,",
                "we",
                "consider",
                "a",
                "different",
                "and",
                "more",
                "practical",
                "setup,",
                "where",
                "the",
                "starting",
                "point",
                "is",
                "using",
                "an",
                "already",
                "pre-trained",
                "language",
                "model",
                "#TARGET_REF",
                ".",
                "As",
                "such",
                "models",
                "were",
                "trained",
                "using",
                "vanilla",
                "attention,",
                "replacing",
                "it",
                "with",
                "a",
                "new",
                "attention",
                "variant",
                "typically",
                "requires",
                "a",
                "corrective",
                "pretraining",
                "stage",
                "to",
                "allow",
                "the",
                "model",
                "weights",
                "to",
                "adjust",
                "to",
                "the",
                "new",
                "variant,",
                "which",
                "can",
                "be",
                "expensive",
                "for",
                "large",
                "models.",
                "For",
                "example,",
                "#REF",
                "have",
                "shown",
                "that",
                "using",
                "random",
                "features",
                "without",
                "corrective",
                "pre-training",
                "leads",
                "to",
                "high",
                "error",
                "rates",
                "in",
                "a",
                "language",
                "modeling",
                "task.",
                "Moreover,",
                "as",
                "explained",
                "in",
                "§2.1,",
                "most",
                "past",
                "methods",
                "are",
                "incompatible",
                "with",
                "feed-forward",
                "layers.",
                "In",
                "the",
                "subsequent",
                "experiments",
                "we",
                "show",
                "that",
                "it",
                "is",
                "possible",
                "to",
                "replace",
                "vanilla",
                "with",
                "top-k",
                "attention,",
                "at",
                "multi-head",
                "attention",
                "and",
                "feed-forward",
                "layers,",
                "and",
                "perform",
                "inference",
                "and",
                "fine-tuning",
                "without",
                "any",
                "need",
                "for",
                "such",
                "correction."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We have established that the performance of top-k attention is comparable to vanilla attention when training the model from scratch. In this set-up, several recently-proposed approaches have also reported competitive performances #REF . Now, we consider a different and more practical setup, where the starting point is using an already pre-trained language model #TARGET_REF . As such models were trained using vanilla attention, replacing it with a new attention variant typically requires a corrective pretraining stage to allow the model weights to adjust to the new variant, which can be expensive for large models. For example, #REF have shown that using random features without corrective pre-training leads to high error rates in a language modeling task. Moreover, as explained in §2.1, most past methods are incompatible with feed-forward layers. In the subsequent experiments we show that it is possible to replace vanilla with top-k attention, at multi-head attention and feed-forward layers, and perform inference and fine-tuning without any need for such correction.",
        "output": "{\"INFO\": [\"where the starting point is using an already pre-trained language model #TARGET_REF .\"], \"PERCEPT\": [\"we consider a different and more practical setup,\"], \"BACK\": [\"As such models were trained using vanilla attention, replacing it with a new attention variant typically requires a corrective pretraining stage to allow the model weights to adjust to the new variant, which can be expensive for large models.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "model",
                "the",
                "relational",
                "information",
                "in",
                "the",
                "commonsen",
                "KG,",
                "we",
                "employ",
                "the",
                "relational",
                "graph",
                "convolutional",
                "network",
                "(R-GCN)",
                "#TARGET_REF",
                "which",
                "generalizes",
                "GCN",
                "with",
                "relation",
                "specific",
                "weight",
                "matrices.",
                "We",
                "follow",
                "#REF",
                "and",
                "#REF",
                "to",
                "use",
                "a",
                "non-parametric",
                "compositional",
                "operation",
                "ϕ(•)",
                "to",
                "combine",
                "the",
                "concept",
                "node",
                "embedding",
                "and",
                "the",
                "relation",
                "embedding.",
                "Specifically,",
                "given",
                "the",
                "input",
                "subgraph",
                "G",
                "x",
                "=",
                "{V",
                "x",
                ",",
                "E",
                "x",
                "}",
                "and",
                "an",
                "R-GCN",
                "with",
                "L",
                "layers,",
                "we",
                "update",
                "the",
                "embedding",
                "of",
                "each",
                "node",
                "v",
                "∈",
                "V",
                "x",
                "at",
                "the",
                "(l+1)-th",
                "layer",
                "by",
                "aggregating",
                "information",
                "from",
                "the",
                "embeddings",
                "of",
                "its",
                "neighbours",
                "in",
                "N",
                "(v)",
                "at",
                "the",
                "l-th",
                "layer:"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To model the relational information in the commonsen KG, we employ the relational graph convolutional network (R-GCN) #TARGET_REF which generalizes GCN with relation specific weight matrices. We follow #REF and #REF to use a non-parametric compositional operation ϕ(•) to combine the concept node embedding and the relation embedding. Specifically, given the input subgraph G x = {V x , E x } and an R-GCN with L layers, we update the embedding of each node v ∈ V x at the (l+1)-th layer by aggregating information from the embeddings of its neighbours in N (v) at the l-th layer:",
        "output": "{\"INFO\": [\"the relational graph convolutional network (R-GCN) #TARGET_REF which generalizes GCN with relation specific weight matrices.\"], \"PERCEPT\": [\"To model the relational information in the commonsen KG, we employ\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Figure",
                "1",
                "shows",
                "an",
                "example",
                "in",
                "the",
                "commonsense",
                "explanation",
                "generation",
                "(ComVE)",
                "task.",
                "The",
                "dataset",
                "has",
                "collected",
                "explanations",
                "to",
                "counterfactual",
                "statements",
                "for",
                "sense-making",
                "from",
                "three",
                "annotators",
                "#TARGET_REF",
                ".",
                "From",
                "the",
                "annotations,",
                "we",
                "observed",
                "that",
                "different",
                "annotators",
                "gave",
                "explanations",
                "to",
                "the",
                "unreasonable",
                "statement",
                "from",
                "different",
                "perspectives",
                "to",
                "make",
                "them",
                "diverse",
                "in",
                "terms",
                "of",
                "content,",
                "e.g.,",
                "wrong",
                "effect",
                "and",
                "inappropriate",
                "usage."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Figure 1 shows an example in the commonsense explanation generation (ComVE) task. The dataset has collected explanations to counterfactual statements for sense-making from three annotators #TARGET_REF . From the annotations, we observed that different annotators gave explanations to the unreasonable statement from different perspectives to make them diverse in terms of content, e.g., wrong effect and inappropriate usage.",
        "output": "{\"INFO\": [\"The dataset has collected explanations to counterfactual statements for sense-making from three annotators #TARGET_REF .\"], \"PERCEPT\": [\"From the annotations, we observed that different annotators gave explanations to the unreasonable statement from different perspectives to make them diverse in terms of content,\"], \"BACK\": [\"Figure 1 shows an example in the commonsense explanation generation (ComVE) task.\", \"e.g., wrong effect and inappropriate usage.\"]}"
    },
    {
        "gold": {
            "text": [
                "Many",
                "of",
                "the",
                "lexical",
                "items",
                "classified",
                "into",
                "Levin's",
                "verb",
                "classes",
                "are",
                "listed",
                "as",
                "members",
                "of",
                "more",
                "than",
                "one",
                "semantic",
                "class",
                "#TARGET_REF",
                ".",
                "There",
                "are",
                "in",
                "fact",
                "3104",
                "verbs,",
                "but",
                "4194",
                "verb/class",
                "pairings,",
                "or",
                "verb",
                "senses,",
                "for",
                "an",
                "average",
                "of",
                "1.35",
                "senses",
                "per",
                "verb.",
                "Levin",
                "gives",
                "only",
                "a",
                "few",
                "informal",
                "indications",
                "about",
                "how",
                "to",
                "interpret",
                "a",
                "multiple",
                "listing",
                "for",
                "a",
                "verb.",
                "Sometimes",
                "the",
                "verb",
                "is",
                "listed",
                "in",
                "several",
                "classes",
                "because",
                "there",
                "is",
                "a",
                "systematic",
                "meaning",
                "relationship",
                "among",
                "them.",
                "Other",
                "times,",
                "the",
                "multiple",
                "categorization",
                "seems",
                "to",
                "be",
                "an",
                "idiosyncrasy",
                "involving",
                "two",
                "verbs",
                "that",
                "happen",
                "to",
                "have",
                "the",
                "same",
                "spelling,",
                "i.e.,",
                "homonyms.",
                "For",
                "example,",
                "the",
                "verb",
                "draw",
                "is",
                "listed",
                "as",
                "a",
                "remove",
                "verb",
                "(class",
                "10.1),",
                "as",
                "a",
                "scribble",
                "verb",
                "(class",
                "25.2)",
                "and",
                "as",
                "a",
                "performance",
                "verb",
                "(class",
                "26.7).",
                "While",
                "the",
                "latter",
                "two",
                "senses",
                "seem",
                "systematically",
                "related",
                "(both",
                "seem",
                "to",
                "be",
                "involved,",
                "for",
                "example,",
                "in",
                "a",
                "usage",
                "like",
                "draw",
                "a",
                "portrait)",
                "the",
                "remove",
                "sense",
                "(as",
                "in",
                "draw",
                "water",
                "from",
                "the",
                "well)",
                "is",
                "clearly",
                "distinct."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Many of the lexical items classified into Levin's verb classes are listed as members of more than one semantic class #TARGET_REF . There are in fact 3104 verbs, but 4194 verb/class pairings, or verb senses, for an average of 1.35 senses per verb. Levin gives only a few informal indications about how to interpret a multiple listing for a verb. Sometimes the verb is listed in several classes because there is a systematic meaning relationship among them. Other times, the multiple categorization seems to be an idiosyncrasy involving two verbs that happen to have the same spelling, i.e., homonyms. For example, the verb draw is listed as a remove verb (class 10.1), as a scribble verb (class 25.2) and as a performance verb (class 26.7). While the latter two senses seem systematically related (both seem to be involved, for example, in a usage like draw a portrait) the remove sense (as in draw water from the well) is clearly distinct.",
        "output": "{\"INFO\": [\"Many of the lexical items classified into Levin's verb classes are listed as members of more than one semantic class #TARGET_REF . There are\", \"3104 verbs, but 4194 verb/class pairings, or verb senses, for an average of 1.35 senses per verb.\"], \"PERCEPT\": [\"Levin gives only a few informal indications about how to interpret a multiple listing for a verb. Sometimes the verb is listed in several classes because there is a systematic meaning relationship among them. Other times, the multiple categorization seems to be an idiosyncrasy involving two verbs that happen to have the same spelling,\"], \"BACK\": [\"i.e., homonyms. For example, the verb draw is listed as a remove verb (class 10.1), as a scribble verb (class 25.2) and as a performance verb (class 26.7). While the latter two senses seem systematically related (both seem to be involved, for example, in a usage like draw a portrait) the remove sense (as in draw water from the well) is clearly distinct.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "original",
                "paper",
                "introducing",
                "BERTScore",
                "#TARGET_REF",
                "naturally",
                "compared",
                "BERTScore's",
                "correlations",
                "with",
                "human",
                "judgments",
                "to",
                "that",
                "of",
                "other",
                "metrics.",
                "However,",
                "various",
                "other",
                "surveys",
                "of",
                "MT",
                "metrics,",
                "as",
                "well",
                "as",
                "datasets",
                "and",
                "methodologies",
                "have",
                "been",
                "conducted,",
                "offering",
                "insights",
                "into",
                "how",
                "MT",
                "system",
                "and",
                "metric",
                "performance",
                "should",
                "be",
                "measured."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The original paper introducing BERTScore #TARGET_REF naturally compared BERTScore's correlations with human judgments to that of other metrics. However, various other surveys of MT metrics, as well as datasets and methodologies have been conducted, offering insights into how MT system and metric performance should be measured.",
        "output": "{\"INFO\": [\"The original paper introducing BERTScore #TARGET_REF naturally compared BERTScore's correlations with human judgments to that of other metrics.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Regarding",
                "the",
                "conversion",
                "process",
                "of",
                "text",
                "and",
                "audio",
                "data,",
                "we",
                "leverage",
                "recent",
                "advances",
                "to",
                "transliterate",
                "this",
                "data",
                "into",
                "corresponding",
                "sounds",
                "represented",
                "by",
                "IPA",
                "phonetic",
                "symbols.",
                "This",
                "transliteration",
                "is",
                "possible",
                "for",
                "speech/audio",
                "data",
                "using",
                "tools",
                "such",
                "as",
                "the",
                "Allosaurus",
                "universal",
                "phone",
                "recognizer,",
                "which",
                "can",
                "be",
                "applied",
                "without",
                "additional",
                "training",
                "to",
                "any",
                "language",
                "#REF",
                ",",
                "though",
                "it",
                "can",
                "benefit",
                "from",
                "fine-tuning",
                "#TARGET_REF",
                ".",
                "To",
                "convert",
                "text",
                "data",
                "to",
                "phonemes",
                "we",
                "can",
                "use",
                "tools",
                "such",
                "as",
                "the",
                "Epitran",
                "grapheme-to-phoneme",
                "converter",
                "#REF",
                ",",
                "which",
                "is",
                "specifically",
                "designed",
                "to",
                "provide",
                "precise",
                "phonetic",
                "transliterations",
                "in",
                "low-resource",
                "scenarios."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Regarding the conversion process of text and audio data, we leverage recent advances to transliterate this data into corresponding sounds represented by IPA phonetic symbols. This transliteration is possible for speech/audio data using tools such as the Allosaurus universal phone recognizer, which can be applied without additional training to any language #REF , though it can benefit from fine-tuning #TARGET_REF . To convert text data to phonemes we can use tools such as the Epitran grapheme-to-phoneme converter #REF , which is specifically designed to provide precise phonetic transliterations in low-resource scenarios.",
        "output": "{\"INFO\": [\"fine-tuning\"], \"PERCEPT\": [\"This transliteration is possible for speech/audio data using tools\", \"which can be applied without additional training to any language #REF , though it can benefit from\", \"To convert text data to phonemes we can use tools\"], \"BACK\": [\"Regarding the conversion process of text and audio data, we leverage recent advances to transliterate this data into corresponding sounds represented by IPA phonetic symbols.\", \"such as the Allosaurus universal phone recognizer,\", \"such as the Epitran grapheme-to-phoneme converter\"]}"
    },
    {
        "gold": {
            "text": [
                "Linguistic",
                "Embedding",
                "For",
                "the",
                "language",
                "D,",
                "we",
                "first",
                "tokenize",
                "the",
                "sentence",
                "into",
                "a",
                "sequence",
                "of",
                "word",
                "tokens",
                "using",
                "WordPiece",
                "#TARGET_REF",
                ",",
                "then",
                "encode",
                "them",
                "into",
                "word",
                "embeddings",
                "W",
                "=",
                "{w",
                "j",
                "}",
                "T",
                "j=1",
                "where",
                "w",
                "j",
                "∈",
                "R",
                "dw",
                "is",
                "the",
                "feature",
                "vector.",
                "Similarly,",
                "an",
                "index",
                "position",
                "#REF",
                "embedding",
                "is",
                "supplemented",
                "to",
                "each",
                "word",
                "embedding."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Linguistic Embedding For the language D, we first tokenize the sentence into a sequence of word tokens using WordPiece #TARGET_REF , then encode them into word embeddings W = {w j } T j=1 where w j ∈ R dw is the feature vector. Similarly, an index position #REF embedding is supplemented to each word embedding.",
        "output": "{\"INFO\": [\"WordPiece #TARGET_REF ,\"], \"PERCEPT\": [\"we first tokenize the sentence into a sequence of word tokens using\", \"then encode them into word embeddings W = {w j } T j=1 where w j \\u2208 R dw is the feature vector.\"], \"BACK\": [\"Linguistic Embedding For the language D,\"]}"
    },
    {
        "gold": {
            "text": [
                "therefore",
                "increase",
                "the",
                "upper",
                "bound",
                "of",
                "the",
                "performance,",
                "in",
                "practice",
                "model",
                "performance",
                "may",
                "be",
                "lower",
                "if",
                "the",
                "beam",
                "width",
                "is",
                "too",
                "large.",
                "The",
                "reason",
                "for",
                "this",
                "phenomenon",
                "is",
                "closely",
                "related",
                "to",
                "the",
                "low",
                "sequence-level",
                "coordination",
                "of",
                "the",
                "generator.",
                "Specifically,",
                "increasing",
                "the",
                "beam",
                "width",
                "may",
                "introduce",
                "candidates",
                "with",
                "lower",
                "quality",
                "#TARGET_REF",
                ",",
                "and",
                "the",
                "generator",
                "may",
                "not",
                "be",
                "able",
                "to",
                "differentiate",
                "them",
                "from",
                "high-quality",
                "candidates.",
                "In",
                "Tab.",
                "5,",
                "we",
                "compare",
                "the",
                "performance",
                "of",
                "the",
                "pre-trained",
                "BART",
                "and",
                "our",
                "model",
                "(BRIO-Mul)",
                "with",
                "different",
                "beam",
                "widths",
                "used",
                "during",
                "inference.",
                "We",
                "observe",
                "that",
                "the",
                "performance",
                "of",
                "BART",
                "goes",
                "down",
                "as",
                "the",
                "beam",
                "width",
                "increases.",
                "On",
                "the",
                "other",
                "hand,",
                "our",
                "model",
                "is",
                "able",
                "to",
                "achieve",
                "better",
                "performance",
                "with",
                "a",
                "larger",
                "number",
                "of",
                "beams,",
                "demonstrating",
                "that",
                "our",
                "training",
                "method",
                "can",
                "improve",
                "the",
                "coordination",
                "of",
                "the",
                "model",
                "by",
                "encouraging",
                "the",
                "model",
                "to",
                "assign",
                "estimated",
                "probabilities",
                "to",
                "candidate",
                "summaries",
                "wellcorrelated",
                "with",
                "their",
                "quality.",
                "Training",
                "with",
                "Different",
                "Evaluation",
                "Metrics",
                "In",
                "the",
                "previous",
                "experiments,",
                "we",
                "used",
                "ROUGE",
                "as",
                "the",
                "evaluation",
                "metric",
                "to",
                "define",
                "the",
                "target",
                "ordering",
                "of",
                "the",
                "candidate",
                "summaries",
                "(Eq.7).",
                "To",
                "evaluate",
                "our",
                "method's",
                "performance",
                "beyond",
                "ROUGE,",
                "we",
                "use",
                "a",
                "model-based",
                "semantic",
                "similarity",
                "metric,",
                "BERTScore",
                "#REF",
                ",",
                "7",
                "as",
                "the",
                "evaluation",
                "metric",
                "M",
                "in",
                "Eq.7",
                "to",
                "compare",
                "the",
                "performance",
                "of",
                "different",
                "candidate",
                "summaries.",
                "Then,",
                "we",
                "trained",
                "another",
                "version",
                "of",
                "BRIO-Mul",
                "based",
                "on",
                "the",
                "order",
                "of",
                "candidate",
                "summaries",
                "calculated",
                "by",
                "BERTScore."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "therefore increase the upper bound of the performance, in practice model performance may be lower if the beam width is too large. The reason for this phenomenon is closely related to the low sequence-level coordination of the generator. Specifically, increasing the beam width may introduce candidates with lower quality #TARGET_REF , and the generator may not be able to differentiate them from high-quality candidates. In Tab. 5, we compare the performance of the pre-trained BART and our model (BRIO-Mul) with different beam widths used during inference. We observe that the performance of BART goes down as the beam width increases. On the other hand, our model is able to achieve better performance with a larger number of beams, demonstrating that our training method can improve the coordination of the model by encouraging the model to assign estimated probabilities to candidate summaries wellcorrelated with their quality. Training with Different Evaluation Metrics In the previous experiments, we used ROUGE as the evaluation metric to define the target ordering of the candidate summaries (Eq.7). To evaluate our method's performance beyond ROUGE, we use a model-based semantic similarity metric, BERTScore #REF , 7 as the evaluation metric M in Eq.7 to compare the performance of different candidate summaries. Then, we trained another version of BRIO-Mul based on the order of candidate summaries calculated by BERTScore.",
        "output": "{\"INFO\": [\"increasing the beam width may introduce candidates with lower quality #TARGET_REF\"], \"PERCEPT\": [\"and the generator may not be able to differentiate them from high-quality candidates.\", \"We observe that the performance of BART goes down as the beam width increases.\"], \"BACK\": [\"In Tab. 5, we compare the performance of the pre-trained BART and our model (BRIO-Mul) with different beam widths used during inference.\"]}"
    },
    {
        "gold": {
            "text": [
                "=",
                "{µ1,",
                "...,",
                "µn},",
                "and",
                "σ(.)",
                "is",
                "the",
                "standard",
                "deviation.",
                "catello",
                "et",
                "al.",
                "(",
                "2019)",
                "on",
                "image",
                "domain.",
                "In",
                "Table",
                "3",
                "(Top-3",
                "column)",
                "we",
                "report",
                "the",
                "number",
                "of",
                "appearances",
                "of",
                "a",
                "model",
                "among",
                "the",
                "top",
                "3",
                "highest",
                "scoring",
                "models",
                "on",
                "at",
                "least",
                "one",
                "disentanglement",
                "metric.",
                "The",
                "ranking",
                "suggests",
                "that",
                "β-VAE",
                "with",
                "smaller",
                "β",
                "values",
                "reach",
                "better",
                "disentangled",
                "representations,",
                "and",
                "MAT-VAE",
                "performing",
                "superior",
                "on",
                "YNOC",
                "and",
                "poorly",
                "on",
                "POS,",
                "highlighting",
                "its",
                "more",
                "challenging",
                "nature.",
                "For",
                "MAT-VAE",
                "we",
                "also",
                "observe",
                "an",
                "interesting",
                "correlation",
                "between",
                "sparsity",
                "and",
                "disentanglement:",
                "for",
                "instance",
                "on",
                "YNOC,",
                "MAT-VAE",
                "(β",
                "=",
                "0.01,",
                "λ",
                "=",
                "0.1)",
                "achieves",
                "the",
                "highest",
                "Hoyer",
                "(See",
                "Table",
                "4)",
                "and",
                "occurs",
                "7",
                "times",
                "among",
                "Top-3",
                "(see",
                "Table",
                "3).",
                "Interestingly,",
                "the",
                "success",
                "of",
                "MAT-VAE",
                "does",
                "not",
                "translate",
                "to",
                "POS",
                "dataset,",
                "where",
                "it",
                "underperforms",
                "AE.",
                "These",
                "two",
                "observations",
                "suggest",
                "that",
                "sparsity",
                "could",
                "be",
                "a",
                "facilitator",
                "for",
                "disentanglement,",
                "but",
                "achieving",
                "a",
                "stable",
                "level",
                "of",
                "sparsity",
                "remains",
                "as",
                "a",
                "challenge.",
                "The",
                "more",
                "recent",
                "development",
                "in",
                "the",
                "direction",
                "of",
                "sparsity,",
                "HSVAE",
                "#TARGET_REF",
                ",",
                "addresses",
                "the",
                "stability",
                "issue",
                "of",
                "MAT-VAE",
                "but",
                "we",
                "leave",
                "its",
                "exploration",
                "to",
                "future",
                "work."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "= {µ1, ..., µn}, and σ(.) is the standard deviation. catello et al. ( 2019) on image domain. In Table 3 (Top-3 column) we report the number of appearances of a model among the top 3 highest scoring models on at least one disentanglement metric. The ranking suggests that β-VAE with smaller β values reach better disentangled representations, and MAT-VAE performing superior on YNOC and poorly on POS, highlighting its more challenging nature. For MAT-VAE we also observe an interesting correlation between sparsity and disentanglement: for instance on YNOC, MAT-VAE (β = 0.01, λ = 0.1) achieves the highest Hoyer (See Table 4) and occurs 7 times among Top-3 (see Table 3). Interestingly, the success of MAT-VAE does not translate to POS dataset, where it underperforms AE. These two observations suggest that sparsity could be a facilitator for disentanglement, but achieving a stable level of sparsity remains as a challenge. The more recent development in the direction of sparsity, HSVAE #TARGET_REF , addresses the stability issue of MAT-VAE but we leave its exploration to future work.",
        "output": "{\"INFO\": [\"The more recent development in the direction of sparsity, HSVAE #TARGET_REF ,\"], \"PERCEPT\": [\"For MAT-VAE we also observe an interesting correlation between sparsity and disentanglement:\", \"Interestingly, the success of MAT-VAE does not translate to POS dataset, where it underperforms AE. These two observations suggest that sparsity could be a facilitator for disentanglement, but achieving a stable level of sparsity remains as a challenge.\", \"addresses the stability issue of MAT-VAE but we leave its exploration to future work.\"], \"BACK\": [\"for instance on YNOC, MAT-VAE (\\u03b2 = 0.01, \\u03bb = 0.1) achieves the highest Hoyer (See Table 4) and occurs 7 times among Top-3 (see Table 3).\"]}"
    },
    {
        "gold": {
            "text": [
                "Baselines",
                "We",
                "compare",
                "the",
                "SimpDefiner",
                "with",
                "generation-simplification",
                "pipelines.",
                "We",
                "first",
                "employ",
                "LOG-CaD",
                "#REF",
                "and",
                "MASS",
                "#REF",
                "models",
                "to",
                "generate",
                "definitions,",
                "and",
                "then",
                "employ",
                "ACCESS",
                "#TARGET_REF",
                "and",
                "MUSS",
                "#REF",
                "models",
                "to",
                "simplify",
                "them.",
                "Thus,",
                "we",
                "have",
                "four",
                "different",
                "pipeline",
                "baselines.",
                "Since",
                "these",
                "models",
                "are",
                "not",
                "available",
                "in",
                "Chinese,",
                "we",
                "only",
                "apply",
                "these",
                "pipelines",
                "to",
                "English",
                "datasets.",
                "For",
                "the",
                "Chinese",
                "SDG",
                "task,",
                "we",
                "specially",
                "pretrained",
                "a",
                "MASS-ZH",
                "model",
                "from",
                "scratch",
                "using",
                "the",
                "Chinese",
                "Gigaword",
                "Fifth",
                "Edition",
                "3",
                "corpus.",
                "Note",
                "that",
                "we",
                "set",
                "the",
                "learning",
                "rate",
                "to",
                "3e-4,",
                "warmup",
                "steps",
                "to",
                "500",
                "when",
                "fine-tuning",
                "both",
                "MASS",
                "and",
                "MASS-ZH."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                1,
                1,
                3,
                3,
                3,
                1,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Baselines We compare the SimpDefiner with generation-simplification pipelines. We first employ LOG-CaD #REF and MASS #REF models to generate definitions, and then employ ACCESS #TARGET_REF and MUSS #REF models to simplify them. Thus, we have four different pipeline baselines. Since these models are not available in Chinese, we only apply these pipelines to English datasets. For the Chinese SDG task, we specially pretrained a MASS-ZH model from scratch using the Chinese Gigaword Fifth Edition 3 corpus. Note that we set the learning rate to 3e-4, warmup steps to 500 when fine-tuning both MASS and MASS-ZH.",
        "output": "{\"INFO\": [\"ACCESS #TARGET_REF\", \"models\"], \"PERCEPT\": [\"We\", \"employ\", \"to simplify them.\"], \"BACK\": [\"We compare the SimpDefiner with generation-simplification pipelines.\", \"and MUSS #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "training",
                "data",
                "include",
                "two",
                "public",
                "datasets:",
                "MNLI",
                "#TARGET_REF"
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1
            ]
        },
        "input": "Our training data include two public datasets: MNLI #TARGET_REF",
        "output": "{\"INFO\": [\"MNLI #TARGET_REF\"], \"PERCEPT\": [\"Our training data include two public datasets:\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "#REF",
                ",",
                "a",
                "multilingual",
                "dataset",
                "was",
                "provided",
                "containing",
                "English,",
                "German,",
                "Spanish",
                "and",
                "French",
                "and",
                "there",
                "were",
                "two",
                "subtasks:",
                "binary",
                "classification",
                "and",
                "probabilistic",
                "classification.",
                "The",
                "submitted",
                "systems",
                "mainly",
                "use",
                "traditional",
                "machine",
                "learning",
                "classifiers(e.g.",
                "SVM,",
                "Random",
                "Forests)",
                "with",
                "features",
                "#REF",
                ",",
                "deep",
                "learning",
                "methods",
                "#TARGET_REF",
                "and",
                "ensemble",
                "methods",
                "#REF",
                ".",
                "More",
                "recently,",
                "#REF",
                "propose",
                "a",
                "new",
                "perspective",
                "by",
                "treating",
                "CWI",
                "as",
                "a",
                "sequence",
                "labeling",
                "task",
                "that",
                "can",
                "detect",
                "both",
                "complex",
                "words",
                "and",
                "phrases.",
                "All",
                "these",
                "methods",
                "are",
                "different",
                "from",
                "ours",
                "which",
                "utilizes",
                "heterogeneous",
                "PLMs",
                "with",
                "various",
                "training",
                "strategies."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In #REF , a multilingual dataset was provided containing English, German, Spanish and French and there were two subtasks: binary classification and probabilistic classification. The submitted systems mainly use traditional machine learning classifiers(e.g. SVM, Random Forests) with features #REF , deep learning methods #TARGET_REF and ensemble methods #REF . More recently, #REF propose a new perspective by treating CWI as a sequence labeling task that can detect both complex words and phrases. All these methods are different from ours which utilizes heterogeneous PLMs with various training strategies.",
        "output": "{\"INFO\": [\"deep learning methods #TARGET_REF\"], \"PERCEPT\": [\"The submitted systems mainly use traditional machine learning classifiers(e.g.\", \"with\"], \"BACK\": [\"SVM, Random Forests)\", \"features #REF ,\", \"and ensemble methods #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "Semantic",
                "Similarity",
                "In",
                "addition",
                "to",
                "the",
                "BLEU",
                "score,",
                "we",
                "use",
                "the",
                "sentence-transformers",
                "toolkit",
                "#TARGET_REF",
                "to",
                "convert",
                "the",
                "generated",
                "definitions",
                "and",
                "references",
                "into",
                "sentence",
                "vectors,",
                "and",
                "calculate",
                "cosine",
                "similarity",
                "between",
                "them."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Semantic Similarity In addition to the BLEU score, we use the sentence-transformers toolkit #TARGET_REF to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them.",
        "output": "{\"INFO\": [\"the sentence-transformers toolkit #TARGET_REF\"], \"PERCEPT\": [\"we use\", \"to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Some",
                "research",
                "adopted",
                "argumentation",
                "schemes",
                "as",
                "a",
                "framework,",
                "making",
                "comparisons",
                "with",
                "discourse",
                "relations",
                "#REF",
                "and",
                "collecting",
                "and",
                "leveraging",
                "data",
                "at",
                "varying",
                "degrees",
                "of",
                "granularity.",
                "At",
                "a",
                "coarse",
                "level,",
                "prior",
                "studies",
                "annotated",
                "the",
                "presence",
                "of",
                "particular",
                "argumentation",
                "schemes",
                "in",
                "text",
                "#REF",
                "and",
                "developed",
                "models",
                "to",
                "classify",
                "different",
                "schemes",
                "#TARGET_REF",
                ".",
                "However,",
                "each",
                "scheme",
                "often",
                "accommodates",
                "both",
                "support",
                "and",
                "attack",
                "relations",
                "between",
                "statements,",
                "so",
                "classifying",
                "those",
                "relations",
                "requires",
                "semantically",
                "richer",
                "information",
                "within",
                "the",
                "scheme",
                "than",
                "just",
                "its",
                "presence.",
                "To",
                "that",
                "end,",
                "#REF",
                "annotated",
                "individual",
                "components",
                "within",
                "schemes,",
                "particularly",
                "emphasizing",
                "argument",
                "from",
                "consequences.",
                "Based",
                "on",
                "the",
                "logic",
                "behind",
                "this",
                "scheme,",
                "#REF",
                "developed",
                "an",
                "unsupervised",
                "method",
                "to",
                "classify",
                "the",
                "support",
                "and",
                "attack",
                "relations",
                "using",
                "syntactic",
                "rules",
                "and",
                "lexicons.",
                "Our",
                "work",
                "extends",
                "these",
                "studies",
                "by",
                "including",
                "other",
                "normative",
                "schemes",
                "(practical",
                "reasoning",
                "and",
                "property-based",
                "reasoning)",
                "and",
                "annotating",
                "richer",
                "information."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Some research adopted argumentation schemes as a framework, making comparisons with discourse relations #REF and collecting and leveraging data at varying degrees of granularity. At a coarse level, prior studies annotated the presence of particular argumentation schemes in text #REF and developed models to classify different schemes #TARGET_REF . However, each scheme often accommodates both support and attack relations between statements, so classifying those relations requires semantically richer information within the scheme than just its presence. To that end, #REF annotated individual components within schemes, particularly emphasizing argument from consequences. Based on the logic behind this scheme, #REF developed an unsupervised method to classify the support and attack relations using syntactic rules and lexicons. Our work extends these studies by including other normative schemes (practical reasoning and property-based reasoning) and annotating richer information.",
        "output": "{\"INFO\": [\"developed models to classify different schemes #TARGET_REF .\"], \"PERCEPT\": [\"At a coarse level, prior studies annotated the presence of particular argumentation schemes in text #REF and\"], \"BACK\": [\"each scheme often accommodates both support and attack relations between statements, so classifying those relations requires semantically richer information within the scheme than just its presence.\"]}"
    },
    {
        "gold": {
            "text": [
                "DMSNAP",
                "complete",
                "parsing",
                "in",
                "the",
                "order",
                "of",
                "milliseconds.",
                "While",
                "actual",
                "SNAP",
                "hardware",
                "is",
                "now",
                "being",
                "assembled",
                "and",
                "to",
                "be",
                "fully",
                "operational",
                "by",
                "May",
                "1991,",
                "this",
                "section",
                "provides",
                "performance",
                "estimation",
                "with",
                "precise",
                "simulation",
                "of",
                "the",
                "SNAP",
                "machine.",
                "Simulations",
                "of",
                "the",
                "DMSNAP",
                "algorithm",
                "have",
                "been",
                "performed",
                "on",
                "a",
                "SUN",
                "3/280",
                "using",
                "the",
                "SNAP",
                "simulator",
                "which",
                "has",
                "been",
                "developed",
                "at",
                "USC",
                "#TARGET_REF",
                "].",
                "The",
                "simulator",
                "is",
                "implemented",
                "in",
                "both",
                "SUN",
                "Common",
                "LISP",
                "and",
                "C,",
                "and",
                "simulates",
                "the",
                "SNAP",
                "machine",
                "at",
                "the",
                "processor",
                "level.",
                "The",
                "LISP",
                "version",
                "of",
                "the",
                "simulators",
                "also",
                "provides",
                "information",
                "about",
                "the",
                "number",
                "of",
                "SNAP",
                "clock",
                "cycles",
                "required",
                "to",
                "perform",
                "the",
                "simulation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "DMSNAP complete parsing in the order of milliseconds. While actual SNAP hardware is now being assembled and to be fully operational by May 1991, this section provides performance estimation with precise simulation of the SNAP machine. Simulations of the DMSNAP algorithm have been performed on a SUN 3/280 using the SNAP simulator which has been developed at USC #TARGET_REF ]. The simulator is implemented in both SUN Common LISP and C, and simulates the SNAP machine at the processor level. The LISP version of the simulators also provides information about the number of SNAP clock cycles required to perform the simulation.",
        "output": "{\"INFO\": [\"the SNAP simulator which has been developed at USC #TARGET_REF ].\"], \"PERCEPT\": [\"Simulations of the DMSNAP algorithm have been performed on a SUN 3/280 using\"], \"BACK\": [\"The simulator is implemented in both SUN Common LISP and C, and simulates the SNAP machine at the processor level.\"]}"
    },
    {
        "gold": {
            "text": [
                "Each",
                "annotated",
                "document",
                "consists",
                "of",
                "a",
                "title",
                "and",
                "3",
                "paragraphs",
                "of",
                "text,",
                "and",
                "contains",
                "a",
                "list",
                "of",
                "non-pronominal",
                "base-NPs",
                "(most",
                "identified",
                "by",
                "SpaCy",
                "#TARGET_REF",
                "9",
                "but",
                "some",
                "added",
                "manually",
                "by",
                "the",
                "annotators),",
                "a",
                "list",
                "of",
                "coreference",
                "clusters",
                "over",
                "the",
                "NPs,",
                "and",
                "a",
                "list",
                "of",
                "NP-relations",
                "that",
                "hold",
                "in",
                "the",
                "text.",
                "Each",
                "relation",
                "is",
                "a",
                "triplet",
                "consisting",
                "of",
                "two",
                "NPs",
                "from",
                "the",
                "NP",
                "list,",
                "and",
                "a",
                "connecting",
                "element",
                "which",
                "is",
                "one",
                "of",
                "23",
                "prepositions",
                "(displayed",
                "in",
                "Table",
                "1)",
                "10",
                "or",
                "a",
                "''member(s)",
                "of''",
                "relation",
                "designating",
                "set-membership.",
                "The",
                "list",
                "of",
                "NP",
                "relations",
                "is",
                "exhaustive,",
                "and",
                "aims",
                "to",
                "cover",
                "all",
                "and",
                "only",
                "valid",
                "NP-NP",
                "relations",
                "in",
                "the",
                "document."
            ],
            "context": [
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Each annotated document consists of a title and 3 paragraphs of text, and contains a list of non-pronominal base-NPs (most identified by SpaCy #TARGET_REF 9 but some added manually by the annotators), a list of coreference clusters over the NPs, and a list of NP-relations that hold in the text. Each relation is a triplet consisting of two NPs from the NP list, and a connecting element which is one of 23 prepositions (displayed in Table 1) 10 or a ''member(s) of'' relation designating set-membership. The list of NP relations is exhaustive, and aims to cover all and only valid NP-NP relations in the document.",
        "output": "{\"INFO\": [\"SpaCy #TARGET_REF 9\"], \"PERCEPT\": [\"(most identified by\"], \"BACK\": [\"Each annotated document\", \"contains a list of non-pronominal base-NPs\", \"but some added manually by the annotators),\"]}"
    },
    {
        "gold": {
            "text": [
                "(2)",
                "The",
                "BAE",
                "attack",
                "#TARGET_REF",
                "generates",
                "coherent",
                "adversarial",
                "examples",
                "by",
                "masking",
                "and",
                "replacing",
                "words",
                "using",
                "BERT.",
                "For",
                "both",
                "methods",
                "we",
                "use",
                "the",
                "implementation",
                "provided",
                "by",
                "TextAttack",
                "#REF",
                "."
            ],
            "context": [
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "(2) The BAE attack #TARGET_REF generates coherent adversarial examples by masking and replacing words using BERT. For both methods we use the implementation provided by TextAttack #REF .",
        "output": "{\"INFO\": [\"The BAE attack #TARGET_REF generates coherent adversarial examples by masking and replacing words using BERT.\"], \"PERCEPT\": [\"For both methods we use the implementation provided by TextAttack #REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "exponential",
                "growth",
                "of",
                "published",
                "articles",
                "may",
                "exceeds",
                "many",
                "readers'",
                "ability",
                "to",
                "keep",
                "track",
                "of",
                "the",
                "development",
                "of",
                "their",
                "field",
                "of",
                "interest.",
                "Hence,",
                "automatic",
                "reading",
                "comprehension",
                "of",
                "scientific",
                "documents",
                "has",
                "attracted",
                "the",
                "attention",
                "of",
                "researchers",
                "across",
                "various",
                "domains",
                "such",
                "as",
                "Drug",
                "Discovery,",
                "Knowledge",
                "Base",
                "Construction,",
                "and",
                "Natural",
                "Language",
                "Processing.",
                "A",
                "crucial",
                "aspect",
                "of",
                "understanding",
                "scientific",
                "literature",
                "is",
                "understanding",
                "terminologies",
                "and",
                "formulae",
                "because",
                "they",
                "offer",
                "an",
                "explicit",
                "and",
                "precise",
                "interface",
                "to",
                "present",
                "the",
                "relation",
                "between",
                "scientific",
                "concepts",
                "#TARGET_REF",
                ".",
                "As",
                "such,",
                "a",
                "reading",
                "comprehension",
                "machine",
                "needs",
                "to",
                "(i)",
                "identify",
                "their",
                "descriptions",
                "and",
                "formulae,",
                "(ii)",
                "segment",
                "them",
                "into",
                "primitive",
                "terms",
                "and",
                "symbols,",
                "and",
                "(iii)",
                "link",
                "the",
                "associated",
                "terms",
                "and",
                "corresponding",
                "symbols."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "The exponential growth of published articles may exceeds many readers' ability to keep track of the development of their field of interest. Hence, automatic reading comprehension of scientific documents has attracted the attention of researchers across various domains such as Drug Discovery, Knowledge Base Construction, and Natural Language Processing. A crucial aspect of understanding scientific literature is understanding terminologies and formulae because they offer an explicit and precise interface to present the relation between scientific concepts #TARGET_REF . As such, a reading comprehension machine needs to (i) identify their descriptions and formulae, (ii) segment them into primitive terms and symbols, and (iii) link the associated terms and corresponding symbols.",
        "output": "{\"INFO\": [\"A crucial aspect of understanding scientific literature is understanding terminologies and formulae because they offer an explicit and precise interface to present the relation between scientific concepts #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"As such, a reading comprehension machine needs to (i) identify their descriptions and formulae, (ii) segment them into primitive terms and symbols, and (iii) link the associated terms and corresponding symbols.\"]}"
    },
    {
        "gold": {
            "text": [
                "Training",
                "Following",
                "#TARGET_REF",
                ",",
                "the",
                "loss",
                "is",
                "a",
                "sum",
                "of",
                "binary",
                "cross-entropy",
                "losses",
                "over",
                "all",
                "entity",
                "types",
                "T",
                "over",
                "all",
                "training",
                "examples",
                "D.",
                "That",
                "is,",
                "we",
                "treat",
                "each",
                "type",
                "prediction",
                "for",
                "each",
                "example",
                "as",
                "an",
                "independent",
                "binary",
                "decision,",
                "with",
                "shared",
                "parameters",
                "in",
                "the",
                "BERT",
                "encoder."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Training Following #TARGET_REF , the loss is a sum of binary cross-entropy losses over all entity types T over all training examples D. That is, we treat each type prediction for each example as an independent binary decision, with shared parameters in the BERT encoder.",
        "output": "{\"INFO\": [\"Training Following #TARGET_REF , the loss is a sum of binary cross-entropy losses over all entity types T over all training examples D.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Although",
                "many",
                "NLP",
                "methods",
                "have",
                "already",
                "been",
                "used",
                "to",
                "generate",
                "distance",
                "matrices,",
                "others",
                "are",
                "worth",
                "trying.",
                "Examples",
                "include",
                "graph",
                "embedding",
                "of",
                "associations",
                "#TARGET_REF",
                "and",
                "GraphGlove",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                0
            ]
        },
        "input": "Although many NLP methods have already been used to generate distance matrices, others are worth trying. Examples include graph embedding of associations #TARGET_REF and GraphGlove #REF .",
        "output": "{\"INFO\": [\"graph embedding of associations #TARGET_REF\"], \"PERCEPT\": [\"Although many NLP methods have already been used to generate distance matrices, others are worth trying. Examples include\"], \"BACK\": [\"and GraphGlove #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "examine",
                "the",
                "performance",
                "of",
                "these",
                "models",
                "on",
                "real-world",
                "downstream",
                "task",
                "setting,",
                "we",
                "consider",
                "the",
                "classification",
                "task.",
                "For",
                "our",
                "classification",
                "datasets,",
                "we",
                "use",
                "DBpedia",
                "(14",
                "classes)",
                "and",
                "Yahoo",
                "Question",
                "(10",
                "classes)",
                "#TARGET_REF",
                ".",
                "Each",
                "class",
                "of",
                "these",
                "two",
                "datasets",
                "has",
                "(10k,",
                "1k,",
                "1k)",
                "randomly",
                "chosen",
                "sentences",
                "in",
                "(train,",
                "dev,",
                "test)",
                "sets.",
                "We",
                "train",
                "Vanilla-VAE,",
                "β-VAE",
                "(β",
                "=",
                "0.2),",
                "CCI-VAE",
                "(C",
                "=",
                "10),",
                "and",
                "MAT-VAE",
                "(β",
                "=",
                "0.01,",
                "λ",
                "=",
                "0.1)",
                "from",
                "Table",
                "3",
                "on",
                "DBpedia",
                "and",
                "Yahoo",
                "(without",
                "the",
                "labels),",
                "then",
                "freeze",
                "the",
                "trained",
                "encoders",
                "and",
                "place",
                "a",
                "classifier",
                "on",
                "top",
                "to",
                "use",
                "the",
                "mean",
                "vector",
                "representations",
                "from",
                "the",
                "encoder",
                "as",
                "a",
                "feature",
                "to",
                "train",
                "a",
                "classifier."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To examine the performance of these models on real-world downstream task setting, we consider the classification task. For our classification datasets, we use DBpedia (14 classes) and Yahoo Question (10 classes) #TARGET_REF . Each class of these two datasets has (10k, 1k, 1k) randomly chosen sentences in (train, dev, test) sets. We train Vanilla-VAE, β-VAE (β = 0.2), CCI-VAE (C = 10), and MAT-VAE (β = 0.01, λ = 0.1) from Table 3 on DBpedia and Yahoo (without the labels), then freeze the trained encoders and place a classifier on top to use the mean vector representations from the encoder as a feature to train a classifier.",
        "output": "{\"INFO\": [\"DBpedia (14 classes) and Yahoo Question (10 classes) #TARGET_REF .\"], \"PERCEPT\": [\"For our classification datasets, we use\", \"Each class of these two datasets has (10k, 1k, 1k) randomly chosen sentences in (train, dev, test) sets.\"], \"BACK\": [\"To examine the performance of these models on real-world downstream task setting, we consider the classification task.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "our",
                "knowledge",
                "these",
                "are",
                "the",
                "first",
                "experiments",
                "which",
                "objectively",
                "demonstrate",
                "the",
                "utility",
                "of",
                "punctuation",
                "for",
                "resolving",
                "syntactic",
                "ambiguity",
                "and",
                "improving",
                "parser",
                "coverage.",
                "They",
                "extend",
                "work",
                "by",
                "#REF",
                "and",
                "#TARGET_REF",
                "by",
                "applying",
                "a",
                "wide-coverage",
                "text",
                "grammar",
                "to",
                "substantial",
                "quantities",
                "of",
                "naturally-punctuated",
                "text",
                "and",
                "by",
                "quantifying",
                "the",
                "contribution",
                "of",
                "punctuation",
                "to",
                "ambiguity",
                "resolution",
                "in",
                "a",
                "well-defined",
                "probabilistic",
                "parse",
                "selection",
                "model."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To our knowledge these are the first experiments which objectively demonstrate the utility of punctuation for resolving syntactic ambiguity and improving parser coverage. They extend work by #REF and #TARGET_REF by applying a wide-coverage text grammar to substantial quantities of naturally-punctuated text and by quantifying the contribution of punctuation to ambiguity resolution in a well-defined probabilistic parse selection model.",
        "output": "{\"INFO\": [\"#TARGET_REF by applying a wide-coverage text grammar to substantial quantities of naturally-punctuated text and by quantifying the contribution of punctuation to ambiguity resolution in a well-defined probabilistic parse selection model.\"], \"PERCEPT\": [\"To our knowledge these are the first experiments which objectively demonstrate the utility of punctuation for resolving syntactic ambiguity and improving parser coverage.\"], \"BACK\": [\"They extend work by #REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "recent",
                "years",
                "there",
                "has",
                "been",
                "some",
                "revival",
                "of",
                "interest",
                "in",
                "computational",
                "lexicography",
                "that",
                "has",
                "fulfilled",
                "some",
                "of",
                "MMB's",
                "hopes",
                "and",
                "dreams.",
                "It",
                "has",
                "been",
                "driven",
                "to",
                "some",
                "extent",
                "by",
                "the",
                "availability",
                "from",
                "publishers",
                "of",
                "machine-readable",
                "English",
                "dictionaries,",
                "such",
                "as",
                "Longman's",
                "dictionary",
                "of",
                "contemporary",
                "English",
                "(LDOCE)",
                "and",
                "Collins-Birmingham",
                "University",
                "International",
                "Language",
                "Database",
                "(COBUILD),",
                "with",
                "definitions",
                "written",
                "in",
                "a",
                "semi-formal",
                "way.",
                "This",
                "makes",
                "it",
                "much",
                "easier",
                "for",
                "a",
                "computational",
                "parser",
                "to",
                "extract",
                "information",
                "from",
                "them.",
                "But",
                "the",
                "initial",
                "work",
                "in",
                "the",
                "current",
                "wave",
                "was",
                "done",
                "by",
                "#TARGET_REF",
                "at",
                "Texas",
                "using",
                "Webster's,",
                "an",
                "oldfashioned",
                "dinosaur",
                "of",
                "a",
                "dictionary.",
                "He",
                "developed",
                "a",
                "notion",
                "of",
                "'tangled",
                "hierarchies'",
                "which",
                "captures",
                "the",
                "notion",
                "MMB",
                "promoted",
                "so",
                "as",
                "to",
                "get",
                "away",
                "from",
                "straightforward",
                "tree-like",
                "hierarchies."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "In recent years there has been some revival of interest in computational lexicography that has fulfilled some of MMB's hopes and dreams. It has been driven to some extent by the availability from publishers of machine-readable English dictionaries, such as Longman's dictionary of contemporary English (LDOCE) and Collins-Birmingham University International Language Database (COBUILD), with definitions written in a semi-formal way. This makes it much easier for a computational parser to extract information from them. But the initial work in the current wave was done by #TARGET_REF at Texas using Webster's, an oldfashioned dinosaur of a dictionary. He developed a notion of 'tangled hierarchies' which captures the notion MMB promoted so as to get away from straightforward tree-like hierarchies.",
        "output": "{\"INFO\": [\"at Texas using Webster's, an oldfashioned dinosaur of a dictionary. He developed a notion of 'tangled hierarchies' which captures the notion MMB promoted so as to get away from straightforward tree-like hierarchies.\"], \"PERCEPT\": [\"the initial work in the current wave was done by\"], \"BACK\": [\"In recent years there has been some revival of interest in computational lexicography that has fulfilled some of MMB's hopes and dreams.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "2021",
                "instantiation",
                "of",
                "the",
                "Shared",
                "Task",
                "on",
                "Explanation",
                "Regeneration",
                "focuses",
                "on",
                "the",
                "theme",
                "of",
                "determining",
                "relevance",
                "in",
                "large",
                "multi-hop",
                "explanations.",
                "To",
                "this",
                "end,",
                "participants",
                "were",
                "given",
                "access",
                "to",
                "a",
                "large",
                "pre-release",
                "dataset",
                "of",
                "approximately",
                "250k",
                "explanatory",
                "relevancy",
                "ratings",
                "that",
                "augment",
                "the",
                "2020",
                "shared",
                "task",
                "data",
                "#TARGET_REF",
                ",",
                "and",
                "were",
                "tasked",
                "with",
                "ranking",
                "the",
                "facts",
                "most",
                "critical",
                "to",
                "assembling",
                "large",
                "explanations",
                "for",
                "a",
                "given",
                "question",
                "highest.",
                "Similarly",
                "to",
                "the",
                "previous",
                "instances",
                "of",
                "our",
                "competition,",
                "the",
                "shared",
                "task",
                "has",
                "been",
                "organized",
                "on",
                "the",
                "CodaLab",
                "platform.",
                "1",
                "We",
                "released",
                "train",
                "and",
                "development",
                "datasets",
                "along",
                "with",
                "the",
                "baseline",
                "solution",
                "in",
                "advance",
                "to",
                "allow",
                "one",
                "to",
                "get",
                "to",
                "know",
                "the",
                "task",
                "specifics.",
                "2",
                "We",
                "ran",
                "the",
                "practice",
                "phase",
                "from",
                "February",
                "15",
                "till",
                "March",
                "9,",
                "2021.",
                "Then",
                "we",
                "released",
                "the",
                "test",
                "dataset",
                "without",
                "answers",
                "and",
                "ran",
                "the",
                "official",
                "evaluation",
                "phase",
                "from",
                "March",
                "10",
                "till",
                "March",
                "24,",
                "2021.",
                "After",
                "that",
                "we",
                "established",
                "postcompetition",
                "phase",
                "to",
                "enable",
                "long-term",
                "evaluation",
                "of",
                "the",
                "methods",
                "beyond",
                "our",
                "shared",
                "task.",
                "Participating",
                "systems",
                "substantially",
                "increased",
                "task",
                "performance",
                "compared",
                "to",
                "a",
                "supplied",
                "baseline",
                "system",
                "by",
                "32%,",
                "while",
                "achieving",
                "moderate",
                "overall",
                "absolute",
                "task",
                "performance",
                "-highlighting",
                "both",
                "the",
                "success",
                "of",
                "this",
                "shared",
                "task,",
                "as",
                "well",
                "as",
                "the",
                "continued",
                "challenge",
                "of",
                "determining",
                "relevancy",
                "in",
                "large",
                "multi-hop",
                "inference",
                "problems."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "This 2021 instantiation of the Shared Task on Explanation Regeneration focuses on the theme of determining relevance in large multi-hop explanations. To this end, participants were given access to a large pre-release dataset of approximately 250k explanatory relevancy ratings that augment the 2020 shared task data #TARGET_REF , and were tasked with ranking the facts most critical to assembling large explanations for a given question highest. Similarly to the previous instances of our competition, the shared task has been organized on the CodaLab platform. 1 We released train and development datasets along with the baseline solution in advance to allow one to get to know the task specifics. 2 We ran the practice phase from February 15 till March 9, 2021. Then we released the test dataset without answers and ran the official evaluation phase from March 10 till March 24, 2021. After that we established postcompetition phase to enable long-term evaluation of the methods beyond our shared task. Participating systems substantially increased task performance compared to a supplied baseline system by 32%, while achieving moderate overall absolute task performance -highlighting both the success of this shared task, as well as the continued challenge of determining relevancy in large multi-hop inference problems.",
        "output": "{\"INFO\": [\"2020 shared task data #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"participants were given access to a large pre-release dataset of approximately 250k explanatory relevancy ratings that augment the\", \"and were tasked with ranking the facts most critical to assembling large explanations for a given question highest.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "deal",
                "with",
                "the",
                "absence",
                "of",
                "action",
                "annotations,",
                "latent",
                "action",
                "learning",
                "has",
                "been",
                "introduced",
                "#REF",
                ".",
                "System",
                "utterances",
                "are",
                "represented",
                "as",
                "low-dimensional",
                "latent",
                "variables",
                "by",
                "an",
                "auto-encoding",
                "task",
                "#TARGET_REF",
                ",",
                "and",
                "utterances",
                "with",
                "the",
                "same",
                "representations",
                "are",
                "considered",
                "to",
                "convey",
                "similar",
                "meanings.",
                "Such",
                "action",
                "representations",
                "might",
                "be",
                "prone",
                "to",
                "overdependence",
                "on",
                "the",
                "training",
                "data,",
                "which",
                "restricts",
                "the",
                "model",
                "generalization",
                "capability,",
                "especially",
                "when",
                "multiple",
                "domains",
                "are",
                "considered.",
                "This",
                "is",
                "because,",
                "without",
                "explicit",
                "supervision,",
                "the",
                "desired",
                "property",
                "of",
                "capturing",
                "the",
                "intentions",
                "of",
                "system",
                "utterances",
                "in",
                "the",
                "latent",
                "space",
                "cannot",
                "be",
                "enforced",
                "#REF",
                ",",
                "which",
                "in",
                "turn",
                "is",
                "due",
                "to",
                "the",
                "implicit",
                "nature",
                "of",
                "latent",
                "variables.",
                "For",
                "example,",
                "variational",
                "auto-encoder",
                "(VAE),",
                "which",
                "is",
                "often",
                "used",
                "for",
                "latent",
                "action",
                "learning,",
                "tends",
                "to",
                "produce",
                "a",
                "balanced",
                "distribution",
                "over",
                "the",
                "latent",
                "variables",
                "#REF",
                ",",
                "while",
                "the",
                "true",
                "distribution",
                "of",
                "system",
                "actions",
                "is",
                "highly",
                "imbalanced",
                "#REF",
                ".",
                "The",
                "resulting",
                "misaligned",
                "action",
                "representations",
                "would",
                "confuse",
                "the",
                "model",
                "of",
                "both",
                "steps",
                "and",
                "degenerate",
                "the",
                "sample",
                "efficiency",
                "in",
                "training."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To deal with the absence of action annotations, latent action learning has been introduced #REF . System utterances are represented as low-dimensional latent variables by an auto-encoding task #TARGET_REF , and utterances with the same representations are considered to convey similar meanings. Such action representations might be prone to overdependence on the training data, which restricts the model generalization capability, especially when multiple domains are considered. This is because, without explicit supervision, the desired property of capturing the intentions of system utterances in the latent space cannot be enforced #REF , which in turn is due to the implicit nature of latent variables. For example, variational auto-encoder (VAE), which is often used for latent action learning, tends to produce a balanced distribution over the latent variables #REF , while the true distribution of system actions is highly imbalanced #REF . The resulting misaligned action representations would confuse the model of both steps and degenerate the sample efficiency in training.",
        "output": "{\"INFO\": [\"by an auto-encoding task #TARGET_REF\"], \"PERCEPT\": [\"To deal with the absence of action annotations,\"], \"BACK\": [\"latent action learning has been introduced #REF\", \"System utterances are represented as low-dimensional latent variables\"]}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "large",
                "body",
                "of",
                "work",
                "in",
                "the",
                "literature",
                "showing",
                "that",
                "a",
                "morphological",
                "decomposition",
                "of",
                "the",
                "Arabic",
                "words",
                "can",
                "improve",
                "the",
                "word",
                "coverage",
                "and",
                "by",
                "these",
                "means",
                "the",
                "translation",
                "quality,",
                "see",
                "for",
                "instance",
                "#TARGET_REF",
                ".",
                "This",
                "is",
                "in",
                "particular",
                "true",
                "for",
                "under-resourced",
                "tasks",
                "like",
                "this",
                "evaluation.",
                "Most",
                "of",
                "the",
                "published",
                "work",
                "is",
                "based",
                "on",
                "the",
                "freely",
                "available",
                "tools,",
                "like",
                "the",
                "Buckwalter",
                "transliterator",
                "and",
                "the",
                "MADA",
                "and",
                "TOKAN",
                "tools",
                "for",
                "morphological",
                "analysis",
                "from",
                "Columbia",
                "University."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "There is a large body of work in the literature showing that a morphological decomposition of the Arabic words can improve the word coverage and by these means the translation quality, see for instance #TARGET_REF . This is in particular true for under-resourced tasks like this evaluation. Most of the published work is based on the freely available tools, like the Buckwalter transliterator and the MADA and TOKAN tools for morphological analysis from Columbia University.",
        "output": "{\"INFO\": [\"a morphological decomposition of the Arabic words can improve the word coverage and by these means the translation quality,\"], \"PERCEPT\": [\"see for instance #TARGET_REF . This is in particular true for under-resourced tasks like this evaluation.\"], \"BACK\": [\"There is a large body of work in the literature showing that\", \"Most of the published work is based on the freely available tools, like the Buckwalter transliterator and the MADA and TOKAN tools for morphological analysis from Columbia University.\"]}"
    },
    {
        "gold": {
            "text": [
                "E",
                "q",
                "φ",
                "(z|x)",
                "[log",
                "p",
                "θ",
                "(x|z)]",
                "−",
                "βD",
                "KL",
                "(q",
                "φ",
                "(z|x),",
                "p(z))",
                "−λD",
                "M",
                "M",
                "D",
                "(q",
                "φ",
                "(z),",
                "p(z))where",
                "D",
                "M",
                "M",
                "D",
                "is",
                "computed",
                "using",
                "maximum",
                "mean",
                "discrepancy",
                "#REF",
                ",",
                "MMD)",
                "and",
                "λ",
                "is",
                "the",
                "scalar",
                "weight.",
                "This",
                "term",
                "regularises",
                "the",
                "aggregated",
                "posterior",
                "q",
                "φ",
                "(z)",
                "with",
                "a",
                "factorised",
                "spikeand-slab",
                "prior",
                "#TARGET_REF",
                ",",
                "which",
                "aims",
                "for",
                "disentanglement",
                "via",
                "clustering",
                "and",
                "sparsifying",
                "the",
                "representations",
                "of",
                "z."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "E q φ (z|x) [log p θ (x|z)] − βD KL (q φ (z|x), p(z)) −λD M M D (q φ (z), p(z))where D M M D is computed using maximum mean discrepancy #REF , MMD) and λ is the scalar weight. This term regularises the aggregated posterior q φ (z) with a factorised spikeand-slab prior #TARGET_REF , which aims for disentanglement via clustering and sparsifying the representations of z.",
        "output": "{\"INFO\": [\"prior #TARGET_REF\", \"which aims for disentanglement via clustering and sparsifying the representations of z.\"], \"PERCEPT\": [], \"BACK\": [\"This term regularises the aggregated posterior q \\u03c6 (z) with a factorised spikeand-slab\"]}"
    },
    {
        "gold": {
            "text": [
                "thing",
                "marking",
                "the",
                "difference",
                "between",
                "the",
                "two",
                "words.",
                "The",
                "alternative",
                "model",
                "is",
                "called",
                "Item",
                "&amp,",
                "Process",
                "(IP).",
                "In",
                "this",
                "model,",
                "word",
                "formation",
                "rules",
                "are",
                "processes",
                "applying",
                "to",
                "a",
                "base.",
                "In",
                "(1a),",
                "the",
                "process",
                "adds",
                "un",
                "to",
                "the",
                "left",
                "of",
                "the",
                "stem",
                "clear.",
                "In",
                "(2a),",
                "the",
                "process",
                "changes",
                "the",
                "stem",
                "vowel",
                "of",
                "sing.",
                "In",
                "IP",
                "there",
                "are",
                "no",
                "morphemes",
                "but",
                "only",
                "lexemes",
                "and",
                "processes.",
                "In",
                "modern",
                "morphological",
                "theories",
                "both",
                "are",
                "represented,",
                "e.g.",
                "#REF",
                "for",
                "IA",
                "and",
                "#REF",
                "for",
                "IP.",
                "An",
                "important",
                "difference",
                "for",
                "our",
                "purposes",
                "is",
                "that",
                "in",
                "IA",
                "we",
                "have",
                "a",
                "tree",
                "structure",
                "whereas",
                "in",
                "IP",
                "we",
                "have",
                "a",
                "derivation",
                "history.",
                "A",
                "tree",
                "structure",
                "represents",
                "the",
                "relationship",
                "between",
                "morphemes,",
                "e.g.",
                "(3).",
                "A",
                "derivation",
                "history",
                "lists",
                "the",
                "different",
                "stages",
                "rules",
                "applying,",
                "e.g.",
                "(",
                "4).",
                "It",
                "should",
                "be",
                "noted",
                "that",
                "there",
                "are",
                "many",
                "variants",
                "of",
                "IA",
                "and",
                "IP.",
                "The",
                "reason",
                "we",
                "are",
                "interested",
                "in",
                "word",
                "formation",
                "rules",
                "is",
                "their",
                "productivity.",
                "Productivity",
                "is",
                "a",
                "difficult",
                "and",
                "controversial",
                "concept,",
                "cf.",
                "#REF",
                ".",
                "Basically,",
                "a",
                "productive",
                "word",
                "formation",
                "rule",
                "can",
                "be",
                "used",
                "to",
                "produce",
                "new",
                "lexical",
                "items.",
                "When",
                "a",
                "speaker",
                "has",
                "a",
                "productive",
                "word",
                "formation",
                "rule",
                "at",
                "her",
                "disposal,",
                "she",
                "can",
                "use",
                "a",
                "word",
                "not",
                "in",
                "her",
                "mental",
                "lexicon",
                "and",
                "be",
                "understood",
                "as",
                "far",
                "as",
                "other",
                "speakers",
                "have",
                "the",
                "same",
                "word",
                "formation",
                "rule",
                "available.",
                "The",
                "productivity",
                "of",
                "word",
                "formation",
                "makes",
                "it",
                "impossible",
                "to",
                "cover",
                "the",
                "entire",
                "lexicon",
                "in",
                "a",
                "finite",
                "list."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "thing marking the difference between the two words. The alternative model is called Item &amp, Process (IP). In this model, word formation rules are processes applying to a base. In (1a), the process adds un to the left of the stem clear. In (2a), the process changes the stem vowel of sing. In IP there are no morphemes but only lexemes and processes. In modern morphological theories both are represented, e.g. #REF for IA and #REF for IP. An important difference for our purposes is that in IA we have a tree structure whereas in IP we have a derivation history. A tree structure represents the relationship between morphemes, e.g. (3). A derivation history lists the different stages rules applying, e.g. ( 4). It should be noted that there are many variants of IA and IP. The reason we are interested in word formation rules is their productivity. Productivity is a difficult and controversial concept, cf. #REF . Basically, a productive word formation rule can be used to produce new lexical items. When a speaker has a productive word formation rule at her disposal, she can use a word not in her mental lexicon and be understood as far as other speakers have the same word formation rule available. The productivity of word formation makes it impossible to cover the entire lexicon in a finite list.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "serve.",
                "Designers",
                "of",
                "the",
                "method.",
                "For",
                "the",
                "designers",
                "of",
                "the",
                "detection",
                "method,",
                "explainability",
                "can",
                "serve",
                "as",
                "a",
                "principled",
                "mechanism",
                "for",
                "understanding",
                "and",
                "reasoning",
                "about",
                "the",
                "behavior",
                "of",
                "their",
                "method,",
                "which",
                "is",
                "important",
                "for",
                "multiple",
                "reasons.",
                "Firstly,",
                "if",
                "the",
                "detection",
                "method",
                "exhibits",
                "all",
                "the",
                "four",
                "properties",
                "of",
                "explain-ability,",
                "then",
                "the",
                "designers",
                "can",
                "easily",
                "gain",
                "insights",
                "into",
                "the",
                "factors",
                "that",
                "contributed",
                "to",
                "the",
                "decision",
                "made",
                "by",
                "the",
                "method",
                "given",
                "a",
                "comment.",
                "This",
                "can",
                "allow",
                "the",
                "designers",
                "to",
                "recognize",
                "when",
                "the",
                "method",
                "may",
                "be",
                "overly",
                "relying",
                "on",
                "a",
                "specific",
                "factor,",
                "e.g.,",
                "the",
                "demographic",
                "traits.",
                "In",
                "the",
                "case",
                "of",
                "social",
                "feature",
                "engineering",
                "and",
                "user",
                "embeddings",
                "based",
                "methods,",
                "operationalization",
                "of",
                "explainability",
                "via",
                "feature",
                "attribution",
                "such",
                "as",
                "LIME",
                "#REF",
                "and",
                "Integrated",
                "Gradients",
                "#TARGET_REF",
                "can",
                "be",
                "effective",
                "in",
                "offering",
                "such",
                "insights.",
                "For",
                "social",
                "graph",
                "based",
                "methods",
                "that",
                "employ",
                "graph",
                "neural",
                "networks,",
                "attribution",
                "techniques",
                "like",
                "GNNExplainer",
                "#REF",
                "can",
                "be",
                "used",
                "instead.",
                "The",
                "second",
                "reason",
                "why",
                "explainability",
                "is",
                "important",
                "for",
                "the",
                "designers",
                "is",
                "because",
                "it",
                "can",
                "allow",
                "them",
                "to",
                "optimize",
                "the",
                "method",
                "by",
                "removing",
                "inputs",
                "that",
                "do",
                "not",
                "contribute",
                "significantly.",
                "Here",
                "again,",
                "explainability",
                "via",
                "feature",
                "attribution",
                "can",
                "be",
                "effective.",
                "Lastly,",
                "explainability",
                "is",
                "also",
                "important",
                "for",
                "the",
                "designers",
                "to",
                "understand",
                "how",
                "their",
                "method",
                "would",
                "perform",
                "in",
                "cases",
                "where",
                "a",
                "user",
                "may",
                "try",
                "obfuscate",
                "abusive",
                "language",
                "#REF",
                ".",
                "Counterfactual",
                "explanations",
                "can",
                "constitute",
                "an",
                "effective",
                "operationalization",
                "for",
                "the",
                "designers",
                "to",
                "identify",
                "the",
                "parts",
                "of",
                "their",
                "method",
                "that",
                "are",
                "most",
                "vulnerable",
                "to",
                "obfuscations."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "serve. Designers of the method. For the designers of the detection method, explainability can serve as a principled mechanism for understanding and reasoning about the behavior of their method, which is important for multiple reasons. Firstly, if the detection method exhibits all the four properties of explain-ability, then the designers can easily gain insights into the factors that contributed to the decision made by the method given a comment. This can allow the designers to recognize when the method may be overly relying on a specific factor, e.g., the demographic traits. In the case of social feature engineering and user embeddings based methods, operationalization of explainability via feature attribution such as LIME #REF and Integrated Gradients #TARGET_REF can be effective in offering such insights. For social graph based methods that employ graph neural networks, attribution techniques like GNNExplainer #REF can be used instead. The second reason why explainability is important for the designers is because it can allow them to optimize the method by removing inputs that do not contribute significantly. Here again, explainability via feature attribution can be effective. Lastly, explainability is also important for the designers to understand how their method would perform in cases where a user may try obfuscate abusive language #REF . Counterfactual explanations can constitute an effective operationalization for the designers to identify the parts of their method that are most vulnerable to obfuscations.",
        "output": "{\"INFO\": [\"Integrated Gradients #TARGET_REF\"], \"PERCEPT\": [\"can be effective in offering such insights.\"], \"BACK\": [\"operationalization of explainability via feature attribution such as LIME #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "perform",
                "evaluations",
                "with",
                "fine-tuned",
                "cased",
                "multilingual",
                "and",
                "language",
                "specific",
                "BERT",
                "(Bidirectional",
                "Encoder",
                "Representations",
                "from",
                "Transformers)",
                "models",
                "#TARGET_REF",
                ",",
                "as",
                "well",
                "as",
                "Suport",
                "Vector",
                "Machines",
                "(SVMs).",
                "Our",
                "evaluations",
                "show",
                "that",
                "the",
                "human-annotated",
                "datasets",
                "behave",
                "on",
                "par",
                "with",
                "comparable",
                "state-of-the-art",
                "datasets",
                "such",
                "as",
                "the",
                "GoEmotions",
                "dataset",
                "#REF",
                ".",
                "Furthermore,",
                "the",
                "projected",
                "datasets",
                "have",
                "accuracies",
                "that",
                "closely",
                "resemble",
                "human-annotated",
                "data",
                "with",
                "macro",
                "f1",
                "scores",
                "of",
                "0.51",
                "for",
                "the",
                "human",
                "annotated",
                "Finnish",
                "data",
                "and",
                "0.45",
                "for",
                "the",
                "projected",
                "Finnish",
                "data",
                "when",
                "evaluating",
                "with",
                "FinBERT",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We perform evaluations with fine-tuned cased multilingual and language specific BERT (Bidirectional Encoder Representations from Transformers) models #TARGET_REF , as well as Suport Vector Machines (SVMs). Our evaluations show that the human-annotated datasets behave on par with comparable state-of-the-art datasets such as the GoEmotions dataset #REF . Furthermore, the projected datasets have accuracies that closely resemble human-annotated data with macro f1 scores of 0.51 for the human annotated Finnish data and 0.45 for the projected Finnish data when evaluating with FinBERT #REF .",
        "output": "{\"INFO\": [\"BERT (Bidirectional Encoder Representations from Transformers) models #TARGET_REF ,\"], \"PERCEPT\": [\"We perform evaluations with fine-tuned cased multilingual and language specific\", \"as well as Suport Vector Machines (SVMs).\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Our",
                "main",
                "contribution",
                "is",
                "to",
                "change",
                "the",
                "target",
                "distribution",
                "of",
                "abstractive",
                "models",
                "from",
                "a",
                "one-point",
                "deterministic",
                "distribution",
                "assumed",
                "by",
                "MLE",
                "training",
                "to",
                "a",
                "non-deterministic",
                "distribution",
                "in",
                "which",
                "candidate",
                "summaries",
                "are",
                "also",
                "assigned",
                "probability",
                "mass",
                "according",
                "to",
                "their",
                "quality.",
                "The",
                "new",
                "SOTA",
                "performance",
                "on",
                "#REF",
                "and",
                "XSum",
                "#TARGET_REF",
                "datasets",
                "demonstrated",
                "the",
                "effectiveness",
                "of",
                "our",
                "method.",
                "Our",
                "in-depth",
                "analysis",
                "also",
                "found",
                "that",
                "the",
                "abstractive",
                "models",
                "trained",
                "using",
                "our",
                "method",
                "can",
                "estimate",
                "the",
                "candidate",
                "summary",
                "quality",
                "more",
                "accurately,",
                "in",
                "concert",
                "with",
                "the",
                "the",
                "objective",
                "of",
                "our",
                "training",
                "paradigm."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Our main contribution is to change the target distribution of abstractive models from a one-point deterministic distribution assumed by MLE training to a non-deterministic distribution in which candidate summaries are also assigned probability mass according to their quality. The new SOTA performance on #REF and XSum #TARGET_REF datasets demonstrated the effectiveness of our method. Our in-depth analysis also found that the abstractive models trained using our method can estimate the candidate summary quality more accurately, in concert with the the objective of our training paradigm.",
        "output": "{\"INFO\": [\"XSum #TARGET_REF datasets\"], \"PERCEPT\": [\"The new SOTA performance on\", \"demonstrated the effectiveness of our method.\"], \"BACK\": [\"#REF and\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "built",
                "our",
                "HPB",
                "baseline",
                "using",
                "the",
                "Moses",
                "Chart",
                "Decoder",
                "#TARGET_REF",
                ".",
                "Continuous",
                "phrases",
                "are",
                "extracted",
                "according",
                "to",
                "the",
                "phrase",
                "based",
                "system",
                "settings",
                "explained",
                "in",
                "Section",
                "3.1.",
                "Maximum",
                "phrase",
                "length",
                "and",
                "maximum",
                "rule",
                "span",
                "are",
                "both",
                "set",
                "to",
                "12",
                "words.",
                "The",
                "maximum",
                "span",
                "for",
                "the",
                "chart",
                "during",
                "decoding",
                "is",
                "set",
                "to",
                "20",
                "words,",
                "above",
                "which",
                "only",
                "monotone",
                "concatenation",
                "of",
                "phrases",
                "is",
                "used.",
                "Rules",
                "extracted",
                "contain",
                "up",
                "to",
                "2",
                "non-terminals.",
                "Adjacent",
                "non-terminals",
                "on",
                "the",
                "source",
                "side",
                "are",
                "not",
                "allowed."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We built our HPB baseline using the Moses Chart Decoder #TARGET_REF . Continuous phrases are extracted according to the phrase based system settings explained in Section 3.1. Maximum phrase length and maximum rule span are both set to 12 words. The maximum span for the chart during decoding is set to 20 words, above which only monotone concatenation of phrases is used. Rules extracted contain up to 2 non-terminals. Adjacent non-terminals on the source side are not allowed.",
        "output": "{\"INFO\": [\"the Moses Chart Decoder #TARGET_REF\"], \"PERCEPT\": [\"We built our HPB baseline using\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "After",
                "obtaining",
                "natural",
                "language",
                "actions,",
                "we",
                "enrich",
                "the",
                "dialogues",
                "as",
                "{(c",
                "t",
                ",",
                "l(x",
                "t",
                "),",
                "x",
                "t",
                ")|1",
                "≤",
                "t",
                "≤",
                "n",
                "d",
                "},",
                "where",
                "l(x",
                "t",
                ")",
                "is",
                "the",
                "natural",
                "language",
                "action",
                "of",
                "utterance",
                "x",
                "t",
                ".",
                "We",
                "could",
                "then",
                "run",
                "conditioned",
                "response",
                "generation",
                "to",
                "train",
                "content",
                "planning",
                "and",
                "language",
                "generation",
                "models",
                "as",
                "Eqn.",
                "1-3.",
                "The",
                "learning",
                "efficiency",
                "can",
                "be",
                "improved",
                "by",
                "the",
                "more",
                "compact",
                "and",
                "noise-free",
                "action",
                "space.",
                "Moreover,",
                "the",
                "natural",
                "language",
                "actions",
                "present",
                "abundant",
                "information",
                "of",
                "correlations",
                "among",
                "actions,",
                "which",
                "allows",
                "for",
                "better",
                "generalization",
                "over",
                "actions",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "After obtaining natural language actions, we enrich the dialogues as {(c t , l(x t ), x t )|1 ≤ t ≤ n d }, where l(x t ) is the natural language action of utterance x t . We could then run conditioned response generation to train content planning and language generation models as Eqn. 1-3. The learning efficiency can be improved by the more compact and noise-free action space. Moreover, the natural language actions present abundant information of correlations among actions, which allows for better generalization over actions #TARGET_REF .",
        "output": "{\"INFO\": [\"the natural language actions present abundant information of correlations among actions, which allows for better generalization over actions #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "train",
                "two",
                "BART",
                "#TARGET_REF",
                ")",
                "models",
                "that",
                "encodes",
                "input",
                "information",
                "via",
                "a",
                "bidirectional",
                "transformer",
                "encoder",
                "and",
                "decodes",
                "autoregressively:",
                "the",
                "first",
                "takes",
                "as",
                "input",
                "character",
                "and",
                "location",
                "information",
                "and",
                "produces",
                "a",
                "short",
                "motivation",
                "(Section",
                "2),",
                "the",
                "second",
                "takes",
                "as",
                "input",
                "character,",
                "location",
                "information,",
                "short",
                "motivation",
                "and",
                "produces",
                "the",
                "sequence",
                "of",
                "LIGHT",
                "game",
                "engine",
                "executable",
                "actions",
                "needed",
                "to",
                "achieve",
                "the",
                "motivation.",
                "This",
                "sequence",
                "of",
                "actions",
                "is",
                "provided",
                "by",
                "the",
                "human",
                "expert",
                "demonstrations",
                "as",
                "mentioned",
                "in",
                "Section",
                "2."
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We train two BART #TARGET_REF ) models that encodes input information via a bidirectional transformer encoder and decodes autoregressively: the first takes as input character and location information and produces a short motivation (Section 2), the second takes as input character, location information, short motivation and produces the sequence of LIGHT game engine executable actions needed to achieve the motivation. This sequence of actions is provided by the human expert demonstrations as mentioned in Section 2.",
        "output": "{\"INFO\": [\"BART #TARGET_REF ) models\"], \"PERCEPT\": [\"We train two\", \"that encodes input information via a bidirectional transformer encoder and decodes autoregressively:\"], \"BACK\": [\"the first takes as input character and location information and produces a short motivation (Section 2), the second takes as input character, location information, short motivation and produces the sequence of LIGHT game engine executable actions needed to achieve the motivation.\"]}"
    },
    {
        "gold": {
            "text": [
                "As",
                "discussed",
                "elsewhere,",
                "e.g.,",
                "by",
                "#REF",
                ",",
                "Arabic",
                "is",
                "rich",
                "morphology",
                "language",
                "with",
                "complex",
                "grammar",
                "structure",
                "which",
                "poses",
                "extra",
                "challenges",
                "to",
                "systems",
                "when",
                "considering",
                "Arabic",
                "text",
                "as",
                "input.",
                "#REF",
                "discussed",
                "the",
                "script",
                "differences",
                "such",
                "as",
                "letter",
                "shaping,",
                "script",
                "direction",
                "(right",
                "to",
                "left)",
                "and",
                "obligatory",
                "ligatures.",
                "Also",
                "#REF",
                "discussed",
                "the",
                "lack",
                "of",
                "standard",
                "orthographies:",
                "e.g.,",
                "and",
                "both",
                "mean",
                "(gram).",
                "One",
                "of",
                "the",
                "major",
                "challenges",
                "in",
                "Arabic",
                "NER",
                "is",
                "the",
                "lack",
                "of",
                "capitalization",
                "#REF",
                ".",
                "#TARGET_REF",
                "also",
                "discussed",
                "the",
                "agglutinative",
                "nature",
                "of",
                "the",
                "Arabic",
                "language",
                "where",
                "new",
                "words",
                "and",
                "sometimes",
                "even",
                "sentences",
                "can",
                "be",
                "derived",
                "by",
                "adding",
                "affixes",
                "and",
                "clitics",
                "to",
                "Arabic",
                "words,",
                "making",
                "Arabic",
                "a",
                "morphologically",
                "rich",
                "language."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "As discussed elsewhere, e.g., by #REF , Arabic is rich morphology language with complex grammar structure which poses extra challenges to systems when considering Arabic text as input. #REF discussed the script differences such as letter shaping, script direction (right to left) and obligatory ligatures. Also #REF discussed the lack of standard orthographies: e.g., and both mean (gram). One of the major challenges in Arabic NER is the lack of capitalization #REF . #TARGET_REF also discussed the agglutinative nature of the Arabic language where new words and sometimes even sentences can be derived by adding affixes and clitics to Arabic words, making Arabic a morphologically rich language.",
        "output": "{\"INFO\": [\"#TARGET_REF also discussed the agglutinative nature of the Arabic language where new words and sometimes even sentences can be derived by adding affixes and clitics to Arabic words, making Arabic a morphologically rich language.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "Localized",
                "Narratives",
                "dataset",
                "#TARGET_REF",
                ",",
                "the",
                "annotators",
                "describe",
                "the",
                "image",
                "while",
                "drawing",
                "the",
                "traces",
                "of",
                "their",
                "attention",
                "movement,",
                "which",
                "presents",
                "a",
                "spatial",
                "alignment",
                "between",
                "visual",
                "objects",
                "and",
                "caption",
                "tokens",
                "as",
                "well",
                "as",
                "a",
                "temporal",
                "alignment",
                "between",
                "user",
                "intention(by",
                "trace)",
                "and",
                "caption",
                "sentences.",
                "From",
                "Figure",
                "1,",
                "we",
                "see",
                "that",
                "the",
                "caption",
                "tokens,",
                "e.g.",
                "\"person\",",
                "\"horse\",",
                "\"trees\"",
                "can",
                "be",
                "grounded",
                "to",
                "the",
                "visual",
                "objects",
                "spatially,",
                "and",
                "the",
                "order",
                "of",
                "caption",
                "sentences",
                "can",
                "be",
                "arranged",
                "to",
                "align",
                "to",
                "the",
                "order",
                "of",
                "traces",
                "temporally.",
                "Although",
                "it",
                "is",
                "easy",
                "for",
                "humans",
                "to",
                "recognize",
                "which",
                "visual",
                "object",
                "is",
                "indicated",
                "by",
                "the",
                "traces,",
                "it",
                "is",
                "a",
                "challenge",
                "for",
                "the",
                "agent",
                "to",
                "recognize,",
                "emphasize",
                "and",
                "arrange",
                "visual",
                "semantics",
                "solely",
                "based",
                "on",
                "several",
                "tracepoints'",
                "coordinates.",
                "Thereby,",
                "we",
                "mainly",
                "devote",
                "our",
                "effort",
                "to",
                "the",
                "spatial",
                "grounding",
                "and",
                "temporal",
                "controllability",
                "of",
                "image",
                "captioning."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the Localized Narratives dataset #TARGET_REF , the annotators describe the image while drawing the traces of their attention movement, which presents a spatial alignment between visual objects and caption tokens as well as a temporal alignment between user intention(by trace) and caption sentences. From Figure 1, we see that the caption tokens, e.g. \"person\", \"horse\", \"trees\" can be grounded to the visual objects spatially, and the order of caption sentences can be arranged to align to the order of traces temporally. Although it is easy for humans to recognize which visual object is indicated by the traces, it is a challenge for the agent to recognize, emphasize and arrange visual semantics solely based on several tracepoints' coordinates. Thereby, we mainly devote our effort to the spatial grounding and temporal controllability of image captioning.",
        "output": "{\"INFO\": [\"In the Localized Narratives dataset #TARGET_REF , the annotators describe the image while drawing the traces of their attention movement, which presents a spatial alignment between visual objects and caption tokens as well as a temporal alignment between user intention(by trace) and caption sentences.\"], \"PERCEPT\": [\"From Figure 1, we see that the caption tokens,\", \"can be grounded to the visual objects spatially, and the order of caption sentences can be arranged to align to the order of traces temporally.\"], \"BACK\": [\"\\\"person\\\", \\\"horse\\\", \\\"trees\\\"\"]}"
    },
    {
        "gold": {
            "text": [
                "Post-editing",
                "is",
                "the",
                "process",
                "whereby",
                "a",
                "human",
                "user",
                "corrects",
                "the",
                "output",
                "of",
                "a",
                "machine",
                "translation",
                "system.",
                "The",
                "use",
                "of",
                "basic",
                "post-editing",
                "tools",
                "by",
                "bilingual",
                "human",
                "translators",
                "has",
                "been",
                "shown",
                "to",
                "yield",
                "substantial",
                "increases",
                "in",
                "terms",
                "of",
                "productivity",
                "#REF",
                "as",
                "well",
                "as",
                "improvements",
                "in",
                "translation",
                "quality",
                "#REF",
                "when",
                "compared",
                "to",
                "bilingual",
                "human",
                "translators",
                "working",
                "without",
                "assistance",
                "from",
                "machine",
                "translation",
                "and",
                "post-editing",
                "tools.",
                "More",
                "sophisticated",
                "interactive",
                "interfaces",
                "#REF",
                "may",
                "also",
                "provide",
                "benefit",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "Post-editing is the process whereby a human user corrects the output of a machine translation system. The use of basic post-editing tools by bilingual human translators has been shown to yield substantial increases in terms of productivity #REF as well as improvements in translation quality #REF when compared to bilingual human translators working without assistance from machine translation and post-editing tools. More sophisticated interactive interfaces #REF may also provide benefit #TARGET_REF .",
        "output": "{\"INFO\": [\"More sophisticated interactive interfaces #REF may also provide benefit #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"The use of basic post-editing tools by bilingual human translators has been shown to yield substantial increases in terms of productivity #REF as well as improvements in translation quality #REF\"]}"
    },
    {
        "gold": {
            "text": [
                "in",
                "working",
                "with",
                "methods",
                "that",
                "incorporate",
                "user",
                "and",
                "community",
                "information",
                "is",
                "having",
                "datasets",
                "where",
                "comments",
                "come",
                "from",
                "users",
                "belonging",
                "to",
                "some",
                "limited",
                "demographics",
                "only.",
                "We",
                "refer",
                "to",
                "this",
                "as",
                "demographic",
                "bias.",
                "Datasets",
                "with",
                "demographic",
                "bias",
                "will",
                "cause",
                "the",
                "methods",
                "to",
                "overfit",
                "to",
                "linguistic",
                "practices",
                "and",
                "dialects",
                "of",
                "users",
                "and",
                "communities",
                "belonging",
                "to",
                "specific",
                "demographics",
                "#REF",
                ",",
                "hence",
                "diminishing",
                "the",
                "power",
                "of",
                "the",
                "methods",
                "to",
                "generalize.",
                "In",
                "fact,",
                "this",
                "bias",
                "is",
                "not",
                "only",
                "a",
                "problem",
                "for",
                "methods",
                "we",
                "discussed,",
                "but",
                "for",
                "any",
                "NLP",
                "method",
                "in",
                "general.",
                "When",
                "it",
                "comes",
                "to",
                "methods",
                "that",
                "incorporate",
                "user",
                "or",
                "community",
                "information",
                "specifically,",
                "there",
                "are",
                "two",
                "other",
                "biases",
                "that",
                "must",
                "be",
                "kept",
                "in",
                "mind",
                "when",
                "constructing",
                "datasets,",
                "we",
                "refer",
                "to",
                "them",
                "as",
                "comment",
                "distribution",
                "bias",
                "and",
                "label",
                "distribution",
                "bias.",
                "Comment",
                "distribution",
                "bias",
                "occurs",
                "when",
                "the",
                "majority",
                "of",
                "comments",
                "in",
                "the",
                "dataset",
                "come",
                "from",
                "a",
                "small",
                "number",
                "of",
                "unique",
                "users.",
                "Such",
                "datasets",
                "allow",
                "the",
                "methods",
                "to",
                "simply",
                "overfit",
                "to",
                "the",
                "linguistic",
                "or",
                "social",
                "behaviors",
                "and",
                "community",
                "roles",
                "of",
                "specific",
                "users",
                "#REF",
                ".",
                "Label",
                "distribution",
                "bias",
                "occurs",
                "when",
                "only",
                "the",
                "abusive",
                "comments",
                "of",
                "a",
                "user",
                "are",
                "included",
                "in",
                "the",
                "dataset.",
                "Abuse",
                "is",
                "a",
                "relatively",
                "infrequent",
                "phenomenon,",
                "even",
                "at",
                "an",
                "individual",
                "level",
                "#REF",
                ".",
                "Only",
                "getting",
                "abusive",
                "comments",
                "of",
                "a",
                "user",
                "can",
                "make",
                "the",
                "methods",
                "simply",
                "associate",
                "the",
                "identity",
                "of",
                "the",
                "user",
                "to",
                "abusiveness",
                "when",
                "including",
                "user",
                "information.",
                "Moreover,",
                "datasets",
                "with",
                "this",
                "bias",
                "can",
                "also",
                "make",
                "phenomena",
                "like",
                "homophily",
                "appear",
                "overly",
                "effective",
                "in",
                "the",
                "detection",
                "of",
                "abuse",
                "by",
                "sampling",
                "only",
                "abusive",
                "comments",
                "from",
                "users",
                "who",
                "are",
                "close",
                "in",
                "the",
                "social",
                "network."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "in working with methods that incorporate user and community information is having datasets where comments come from users belonging to some limited demographics only. We refer to this as demographic bias. Datasets with demographic bias will cause the methods to overfit to linguistic practices and dialects of users and communities belonging to specific demographics #REF , hence diminishing the power of the methods to generalize. In fact, this bias is not only a problem for methods we discussed, but for any NLP method in general. When it comes to methods that incorporate user or community information specifically, there are two other biases that must be kept in mind when constructing datasets, we refer to them as comment distribution bias and label distribution bias. Comment distribution bias occurs when the majority of comments in the dataset come from a small number of unique users. Such datasets allow the methods to simply overfit to the linguistic or social behaviors and community roles of specific users #REF . Label distribution bias occurs when only the abusive comments of a user are included in the dataset. Abuse is a relatively infrequent phenomenon, even at an individual level #REF . Only getting abusive comments of a user can make the methods simply associate the identity of the user to abusiveness when including user information. Moreover, datasets with this bias can also make phenomena like homophily appear overly effective in the detection of abuse by sampling only abusive comments from users who are close in the social network.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "10",
                "An",
                "example",
                "of",
                "this",
                "type",
                "of",
                "work",
                "is",
                "#TARGET_REF",
                ".",
                "In",
                "Arabic",
                "a",
                "root",
                "such",
                "as",
                "ktb",
                "is",
                "combined",
                "with",
                "a",
                "vowel",
                "pattern",
                "to",
                "produce",
                "words",
                "such",
                "as",
                "kitaab",
                "('book')",
                "and",
                "kutub",
                "('books').",
                "It",
                "is",
                "interesting",
                "to",
                "note",
                "that",
                "the",
                "traditional",
                "approach",
                "to",
                "Arabic",
                "roots",
                "results",
                "in",
                "approximately",
                "10,000",
                "different",
                "items.",
                "This",
                "number",
                "corresponds",
                "more",
                "closely",
                "to",
                "the",
                "number",
                "of",
                "simple",
                "lexemes",
                "to",
                "be",
                "expected",
                "in",
                "the",
                "lexicon",
                "of",
                "a",
                "language",
                "than",
                "to",
                "the",
                "number",
                "of",
                "lexemes.",
                "It",
                "is",
                "then",
                "not",
                "surprising",
                "to",
                "find",
                "items",
                "such",
                "as",
                "kaatib",
                "('writer'),",
                "kutib",
                "('be",
                "written')",
                "with",
                "the",
                "same",
                "root.",
                "11",
                "In",
                "principle",
                "we",
                "could",
                "of",
                "course",
                "reverse",
                "the",
                "entire",
                "system.",
                "Thus,",
                "languages",
                "such",
                "as",
                "Navajo,",
                "which",
                "use",
                "only",
                "prefixation,",
                "are",
                "not",
                "a",
                "major",
                "problem.",
                "12",
                "There",
                "is",
                "of",
                "course",
                "a",
                "different",
                "prefixation",
                "process",
                "attaching",
                "un-to",
                "a",
                "verb",
                "as",
                "in",
                "undo,",
                "but",
                "it",
                "would",
                "yield",
                "the",
                "wrong",
                "analysis",
                "for",
                "unacceptable.",
                "The",
                "word",
                "means",
                "'which",
                "cannot",
                "be",
                "accepted',",
                "not",
                "'which",
                "can",
                "be",
                "unaccepted'."
            ],
            "context": [
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "10 An example of this type of work is #TARGET_REF . In Arabic a root such as ktb is combined with a vowel pattern to produce words such as kitaab ('book') and kutub ('books'). It is interesting to note that the traditional approach to Arabic roots results in approximately 10,000 different items. This number corresponds more closely to the number of simple lexemes to be expected in the lexicon of a language than to the number of lexemes. It is then not surprising to find items such as kaatib ('writer'), kutib ('be written') with the same root. 11 In principle we could of course reverse the entire system. Thus, languages such as Navajo, which use only prefixation, are not a major problem. 12 There is of course a different prefixation process attaching un-to a verb as in undo, but it would yield the wrong analysis for unacceptable. The word means 'which cannot be accepted', not 'which can be unaccepted'.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"An example of this type of work is #TARGET_REF .\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "There",
                "is",
                "a",
                "growing",
                "trend",
                "in",
                "using",
                "adversarial",
                "models",
                "for",
                "data",
                "creation",
                "to",
                "make",
                "the",
                "dataset",
                "more",
                "challenging",
                "or",
                "discard",
                "examples",
                "that",
                "can",
                "be",
                "solved",
                "using",
                "surface",
                "cues",
                "#REF",
                ".",
                "Quoref",
                "is",
                "also",
                "created",
                "using",
                "an",
                "adversarial",
                "data",
                "collection",
                "method",
                "to",
                "discard",
                "examples",
                "that",
                "can",
                "be",
                "solved",
                "using",
                "simple",
                "lexical",
                "cues.",
                "The",
                "assumption",
                "is",
                "that",
                "it",
                "is",
                "hard",
                "to",
                "avoid",
                "simple",
                "lexical",
                "cues",
                "by",
                "which",
                "the",
                "model",
                "can",
                "answer",
                "questions",
                "without",
                "coreference",
                "reasoning.",
                "Therefore,",
                "an",
                "adversarial",
                "model",
                "(A)",
                "is",
                "used",
                "to",
                "discard",
                "examples",
                "that",
                "contain",
                "such",
                "lexical",
                "cues.",
                "While",
                "this",
                "adversarial",
                "filtering",
                "removes",
                "examples",
                "that",
                "are",
                "easy",
                "to",
                "solve",
                "by",
                "A,",
                "it",
                "does",
                "not",
                "ensure",
                "that",
                "the",
                "remaining",
                "examples",
                "do",
                "not",
                "contain",
                "shortcuts",
                "that",
                "are",
                "not",
                "explored",
                "by",
                "A.",
                "First,",
                "the",
                "adversarial",
                "model",
                "in",
                "Quoref",
                "is",
                "trained",
                "on",
                "another",
                "dataset,",
                "i.e.,",
                "SQuAD.",
                "Thus,",
                "the",
                "failure",
                "of",
                "A",
                "on",
                "Quoref",
                "examples",
                "may",
                "be",
                "due",
                "to",
                "(1)",
                "Quoref",
                "having",
                "different",
                "lexical",
                "cues",
                "than",
                "those",
                "in",
                "SQuAD,",
                "or",
                "(2)",
                "domain",
                "shift.",
                "Second,",
                "and",
                "more",
                "importantly,",
                "as",
                "argued",
                "by",
                "#TARGET_REF",
                ",",
                "making",
                "the",
                "task",
                "challenging",
                "by",
                "focusing",
                "on",
                "examples",
                "that",
                "are",
                "more",
                "difficult",
                "for",
                "existing",
                "models",
                "is",
                "not",
                "a",
                "solution",
                "for",
                "more",
                "useful",
                "reading",
                "comprehension.",
                "7",
                "We",
                "instead",
                "propose",
                "a",
                "methodology",
                "for",
                "creating",
                "question-answer",
                "pairs",
                "as",
                "follows:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0
            ]
        },
        "input": "There is a growing trend in using adversarial models for data creation to make the dataset more challenging or discard examples that can be solved using surface cues #REF . Quoref is also created using an adversarial data collection method to discard examples that can be solved using simple lexical cues. The assumption is that it is hard to avoid simple lexical cues by which the model can answer questions without coreference reasoning. Therefore, an adversarial model (A) is used to discard examples that contain such lexical cues. While this adversarial filtering removes examples that are easy to solve by A, it does not ensure that the remaining examples do not contain shortcuts that are not explored by A. First, the adversarial model in Quoref is trained on another dataset, i.e., SQuAD. Thus, the failure of A on Quoref examples may be due to (1) Quoref having different lexical cues than those in SQuAD, or (2) domain shift. Second, and more importantly, as argued by #TARGET_REF , making the task challenging by focusing on examples that are more difficult for existing models is not a solution for more useful reading comprehension. 7 We instead propose a methodology for creating question-answer pairs as follows:",
        "output": "{\"INFO\": [\"making the task challenging by focusing on examples that are more difficult for existing models is not a solution for more useful reading comprehension.\"], \"PERCEPT\": [\"as argued by #TARGET_REF ,\", \"We instead propose a methodology for creating question-answer pairs\"], \"BACK\": [\"While this adversarial filtering removes examples that are easy to solve by A, it does not ensure that the remaining examples do not contain shortcuts that are not explored by A.\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "semantics,",
                "the",
                "situation",
                "is",
                "even",
                "more",
                "complicated.",
                "While",
                "BERT's",
                "performance",
                "on",
                "natural",
                "language",
                "understanding",
                "tasks",
                "set",
                "a",
                "new",
                "state",
                "of",
                "the",
                "art,",
                "more",
                "targeted",
                "tests",
                "of",
                "its",
                "semantic",
                "abilities",
                "have",
                "yielded",
                "less",
                "positive",
                "results.",
                "BERT",
                "has",
                "limited",
                "knowledge",
                "of",
                "lexical",
                "semantic",
                "relations",
                "such",
                "as",
                "hypernymy",
                "#TARGET_REF",
                "and",
                "antonymy",
                "#REF",
                ".",
                "Moreover,",
                "it",
                "has",
                "fragile",
                "representations",
                "of",
                "named",
                "entities",
                "#REF",
                ",",
                "and",
                "imprecise",
                "representations",
                "of",
                "numbers",
                "#REF",
                ".",
                "These",
                "flaws",
                "comprise",
                "specific",
                "linguistic",
                "phenomena",
                "that",
                "BERTScore,",
                "due",
                "to",
                "its",
                "use",
                "of",
                "BERT,",
                "might",
                "be",
                "unable",
                "to",
                "handle,",
                "and",
                "thus",
                "merit",
                "investigation."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For semantics, the situation is even more complicated. While BERT's performance on natural language understanding tasks set a new state of the art, more targeted tests of its semantic abilities have yielded less positive results. BERT has limited knowledge of lexical semantic relations such as hypernymy #TARGET_REF and antonymy #REF . Moreover, it has fragile representations of named entities #REF , and imprecise representations of numbers #REF . These flaws comprise specific linguistic phenomena that BERTScore, due to its use of BERT, might be unable to handle, and thus merit investigation.",
        "output": "{\"INFO\": [\"BERT has limited knowledge of lexical semantic relations such as hypernymy #TARGET_REF\"], \"PERCEPT\": [\"might be unable to handle, and thus merit investigation.\"], \"BACK\": [\"and antonymy #REF . Moreover, it has fragile representations of named entities #REF , and imprecise representations of numbers #REF . These flaws comprise specific linguistic phenomena that BERTScore, due to its use of BERT,\"]}"
    },
    {
        "gold": {
            "text": [
                "Benchmarks",
                "for",
                "fact",
                "verification",
                "on",
                "structured",
                "evidence",
                "are",
                "built",
                "on",
                "tables",
                "collected",
                "from",
                "Wikipedia",
                "#REF",
                "or",
                "scientific",
                "articles",
                "#REF",
                ".",
                "Many",
                "previous",
                "works",
                "search",
                "latent",
                "programs",
                "as",
                "an",
                "intermediary",
                "to",
                "reason",
                "over",
                "the",
                "given",
                "table.",
                "They",
                "directly",
                "encode",
                "programs",
                "#REF",
                "or",
                "construct",
                "heterogeneous",
                "graphs",
                "#TARGET_REF",
                "with",
                "the",
                "claim,",
                "the",
                "table",
                "and",
                "the",
                "programs.",
                "Another",
                "way",
                "is",
                "to",
                "linearize",
                "the",
                "input",
                "table",
                "and",
                "perform",
                "table",
                "pre-training",
                "#REF",
                "and",
                "add",
                "additional",
                "table-aware",
                "embeddings",
                "#REF",
                "to",
                "enhance",
                "the",
                "table",
                "encoding.",
                "However,",
                "in",
                "these",
                "datasets,",
                "the",
                "evidence",
                "is",
                "only",
                "one",
                "given",
                "table,",
                "and",
                "models",
                "are",
                "not",
                "requested",
                "to",
                "find",
                "out",
                "the",
                "evidence",
                "cells",
                "explicitly."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Benchmarks for fact verification on structured evidence are built on tables collected from Wikipedia #REF or scientific articles #REF . Many previous works search latent programs as an intermediary to reason over the given table. They directly encode programs #REF or construct heterogeneous graphs #TARGET_REF with the claim, the table and the programs. Another way is to linearize the input table and perform table pre-training #REF and add additional table-aware embeddings #REF to enhance the table encoding. However, in these datasets, the evidence is only one given table, and models are not requested to find out the evidence cells explicitly.",
        "output": "{\"INFO\": [\"construct heterogeneous graphs #TARGET_REF with the claim, the table and the programs.\"], \"PERCEPT\": [\"They\"], \"BACK\": [\"Many previous works search latent programs as an intermediary to reason over the given table.\", \"directly encode programs #REF or\"]}"
    },
    {
        "gold": {
            "text": [
                "Turning",
                "our",
                "attention",
                "now",
                "to",
                "Arabic",
                "POS",
                "tagging,",
                "many",
                "approaches",
                "have",
                "also",
                "been",
                "adopted",
                "over",
                "the",
                "years",
                "including",
                "rule-based",
                "methods",
                "#TARGET_REF",
                ",",
                "statistical",
                "models",
                "#REF",
                ",",
                "hybrid",
                "models",
                "#REF",
                "and",
                "neural",
                "networks",
                "#REF",
                ".",
                "Performance",
                "is",
                "usually",
                "much",
                "higher",
                "for",
                "POS",
                "tagging",
                "than",
                "NER.",
                "#REF",
                "introduced",
                "a",
                "hybrid",
                "POS",
                "tagger",
                "(with",
                "33",
                "tags)",
                "which",
                "combined",
                "HMM",
                "with",
                "a",
                "rule-based",
                "tagger.",
                "They",
                "used",
                "the",
                "Holy",
                "Quran",
                "Corpus",
                "and",
                "achieved",
                "an",
                "accuracy",
                "rate",
                "of",
                "97.6%",
                "and",
                "96.8%",
                "respectively.",
                "Yousif",
                "and",
                "Sembok",
                "(2008)",
                "used",
                "the",
                "SVM",
                "approach",
                "and",
                "a",
                "corpus",
                "of",
                "177",
                "tagged",
                "words.",
                "#REF",
                "presented",
                "a",
                "probabilistic",
                "POS",
                "tagger",
                "for",
                "Arabic",
                "text",
                "based",
                "on",
                "HMM",
                "called",
                "Tree",
                "Tagger.",
                "The",
                "proposed",
                "tagger",
                "obtained",
                "accuracy",
                "rates",
                "of",
                "99.4%",
                "using",
                "Al-Mus'haf",
                "corpus."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Turning our attention now to Arabic POS tagging, many approaches have also been adopted over the years including rule-based methods #TARGET_REF , statistical models #REF , hybrid models #REF and neural networks #REF . Performance is usually much higher for POS tagging than NER. #REF introduced a hybrid POS tagger (with 33 tags) which combined HMM with a rule-based tagger. They used the Holy Quran Corpus and achieved an accuracy rate of 97.6% and 96.8% respectively. Yousif and Sembok (2008) used the SVM approach and a corpus of 177 tagged words. #REF presented a probabilistic POS tagger for Arabic text based on HMM called Tree Tagger. The proposed tagger obtained accuracy rates of 99.4% using Al-Mus'haf corpus.",
        "output": "{\"INFO\": [\"rule-based methods #TARGET_REF\"], \"PERCEPT\": [\"Turning our attention now to Arabic POS tagging, many approaches have also been adopted over the years including\"], \"BACK\": [\", statistical models #REF , hybrid models #REF and neural networks #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Control",
                "is",
                "handled",
                "using",
                "the",
                "syntactic",
                "constraint",
                "network.",
                "Sentence",
                "s7",
                "is",
                "an",
                "example",
                "of",
                "sentence",
                "involving",
                "functional",
                "control",
                "#TARGET_REF",
                ".",
                "In",
                "s7,",
                "both",
                "subject",
                "control",
                "and",
                "object",
                "control",
                "exist",
                "-the",
                "subject",
                "of",
                "'persuade'",
                "should",
                "be",
                "the",
                "subject",
                "of",
                "'tried'",
                "(subject",
                "control),",
                "and",
                "the",
                "subject",
                "of",
                "'help'",
                "should",
                "be",
                "the",
                "object",
                "of",
                "'persuade'",
                "(object",
                "control).",
                "In",
                "this",
                "case,",
                "CSCS",
                "for",
                "infinitival",
                "complement",
                "has",
                "CSE",
                "without",
                "NEXT",
                "link.",
                "Such",
                "an",
                "CSE",
                "represents",
                "missing",
                "subject.",
                "There",
                "are",
                "SUBJ,",
                "OBJ,",
                "and",
                "OBJ2",
                "nodes",
                "(these",
                "are",
                "functional",
                "controller)",
                "in",
                "the",
                "syntactic",
                "constraints",
                "network",
                "each",
                "of",
                "which",
                "store",
                "pointer",
                "to",
                "the",
                "CI",
                "node",
                "for",
                "possible",
                "controllee.",
                "Syntactic",
                "constraint",
                "links",
                "from",
                "each",
                "lexical",
                "items",
                "of",
                "the",
                "verb",
                "determine",
                "which",
                "functional",
                "controller",
                "is",
                "active.",
                "Activated",
                "functional",
                "controller",
                "propagate",
                "a",
                "pointer",
                "to",
                "the",
                "CI",
                "node",
                "to",
                "unbound",
                "subject",
                "nodes",
                "of",
                "CSCs",
                "for",
                "infinitival",
                "complements.",
                "Basically,",
                "one",
                "set",
                "of",
                "nodes",
                "for",
                "functional",
                "controller",
                "handles",
                "deeply",
                "nested",
                "cases",
                "due",
                "to",
                "functional",
                "locality."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Control is handled using the syntactic constraint network. Sentence s7 is an example of sentence involving functional control #TARGET_REF . In s7, both subject control and object control exist -the subject of 'persuade' should be the subject of 'tried' (subject control), and the subject of 'help' should be the object of 'persuade' (object control). In this case, CSCS for infinitival complement has CSE without NEXT link. Such an CSE represents missing subject. There are SUBJ, OBJ, and OBJ2 nodes (these are functional controller) in the syntactic constraints network each of which store pointer to the CI node for possible controllee. Syntactic constraint links from each lexical items of the verb determine which functional controller is active. Activated functional controller propagate a pointer to the CI node to unbound subject nodes of CSCs for infinitival complements. Basically, one set of nodes for functional controller handles deeply nested cases due to functional locality.",
        "output": "{\"INFO\": [\"sentence involving functional control #TARGET_REF .\"], \"PERCEPT\": [\"Sentence s7 is an example of\"], \"BACK\": [\"Control is handled using the syntactic constraint network.\", \"In s7, both subject control and object control exist -the subject of 'persuade' should be the subject of 'tried' (subject control), and the subject of 'help' should be the object of 'persuade' (object control).\", \"There are SUBJ, OBJ, and OBJ2 nodes (these are functional controller) in the syntactic constraints network\", \"Syntactic constraint links from each lexical items of the verb determine which functional controller is active. Activated functional controller propagate a pointer to the CI node to unbound subject nodes of CSCs for infinitival complements. Basically, one set of nodes for functional controller handles deeply nested cases due to functional locality.\"]}"
    },
    {
        "gold": {
            "text": [
                "UFET",
                "This",
                "ultra-fine",
                "entity",
                "typing",
                "dataset",
                "is",
                "created",
                "by",
                "#TARGET_REF",
                ".",
                "This",
                "dataset",
                "consists",
                "of",
                "6k",
                "manually",
                "annotated",
                "examples.",
                "The",
                "entity",
                "mention",
                "spans",
                "could",
                "be",
                "named",
                "entities,",
                "nominal",
                "expressions,",
                "and",
                "pronouns",
                "while",
                "Wiki-based",
                "datasets",
                "mostly",
                "provide",
                "named",
                "entity",
                "mention",
                "spans.",
                "We",
                "use",
                "5.5k",
                "examples",
                "for",
                "training",
                "and",
                "500",
                "examples",
                "for",
                "validation.",
                "Note",
                "that",
                "because",
                "our",
                "goal",
                "in",
                "this",
                "work",
                "is",
                "downstream",
                "task",
                "performance,",
                "we",
                "deviate",
                "from",
                "the",
                "standard",
                "train/dev/test",
                "splits",
                "of",
                "2k/2k/2k",
                "in",
                "favor",
                "of",
                "higher",
                "performance."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "UFET This ultra-fine entity typing dataset is created by #TARGET_REF . This dataset consists of 6k manually annotated examples. The entity mention spans could be named entities, nominal expressions, and pronouns while Wiki-based datasets mostly provide named entity mention spans. We use 5.5k examples for training and 500 examples for validation. Note that because our goal in this work is downstream task performance, we deviate from the standard train/dev/test splits of 2k/2k/2k in favor of higher performance.",
        "output": "{\"INFO\": [\"UFET This ultra-fine entity typing dataset is created by #TARGET_REF . This dataset consists of 6k manually annotated examples. The entity mention spans could be named entities, nominal expressions, and pronouns while Wiki-based datasets mostly provide named entity mention spans.\"], \"PERCEPT\": [\"We use 5.5k examples for training and 500 examples for validation.\", \"our goal in this work is downstream task performance, we deviate from the standard train/dev/test splits of 2k/2k/2k in favor of higher performance.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "TNT",
                "tagger",
                "#TARGET_REF",
                ",",
                "which",
                "was",
                "used",
                "in",
                "the",
                "process,",
                "relies",
                "heavily",
                "on",
                "context",
                "to",
                "disambiguate",
                "ambiguities.",
                "In",
                "a",
                "word",
                "list",
                "each",
                "word",
                "is",
                "treated",
                "separately,",
                "there",
                "is",
                "no",
                "context,",
                "so",
                "the",
                "word",
                "tagging",
                "quality",
                "is",
                "lower",
                "than",
                "the",
                "values",
                "on",
                "running",
                "text."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The TNT tagger #TARGET_REF , which was used in the process, relies heavily on context to disambiguate ambiguities. In a word list each word is treated separately, there is no context, so the word tagging quality is lower than the values on running text.",
        "output": "{\"INFO\": [\"The TNT tagger #TARGET_REF ,\", \"relies\", \"on context to disambiguate ambiguities.\"], \"PERCEPT\": [\"heavily\"], \"BACK\": [\"which was used in the process,\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "word",
                "embeddings",
                "extracted",
                "from",
                "the",
                "first",
                "layer",
                "of",
                "the",
                "GPT2",
                "language",
                "model",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "• word embeddings extracted from the first layer of the GPT2 language model #TARGET_REF .",
        "output": "{\"INFO\": [\"GPT2 language model #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"word embeddings extracted from the first layer of the\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "generator",
                "is",
                "based",
                "on",
                "a",
                "Relational",
                "Memory",
                "with",
                "self-attention",
                "#TARGET_REF",
                ".",
                "This",
                "model",
                "updates",
                "its",
                "\"internal",
                "values\"",
                "and",
                "produces",
                "its",
                "final",
                "output",
                "by",
                "selecting",
                "from",
                "its",
                "memory",
                "cells",
                "with",
                "a",
                "self-attention",
                "mechanism.",
                "Leveraging",
                "an",
                "idea",
                "similar",
                "to",
                "that",
                "of",
                "image-based",
                "conditional",
                "GANs",
                "#REF",
                ",",
                "we",
                "introduce",
                "an",
                "external",
                "conditioning",
                "into",
                "the",
                "generator.",
                "First,",
                "given",
                "the",
                "conditioning",
                "input",
                "c",
                "2",
                "R",
                "d",
                ",",
                "the",
                "model",
                "computes",
                "an",
                "embedding",
                "t",
                "for",
                "c",
                "using",
                "functionf",
                "✓",
                ":",
                "R",
                "d",
                "!",
                "R",
                "m",
                ",",
                "with",
                "m",
                "&lt,",
                "d.Function",
                "f",
                "✓",
                "has",
                "been",
                "implemented",
                "using",
                "a",
                "feed-forward",
                "neural",
                "network",
                "with",
                "a",
                "self-attention",
                "layer.",
                "The",
                "conditioning",
                "vector",
                "c",
                "may",
                "originate",
                "from",
                "any",
                "type",
                "of",
                "different",
                "source",
                "as",
                "long",
                "as",
                "it",
                "remains",
                "consistent",
                "during",
                "the",
                "individual",
                "training.",
                "Depending",
                "on",
                "the",
                "required",
                "task,",
                "as",
                "shown",
                "in",
                "the",
                "experiment",
                "phase,",
                "it",
                "will",
                "change.",
                "This",
                "vector",
                "c",
                "is",
                "the",
                "only",
                "link",
                "between",
                "the",
                "conditioning",
                "and",
                "the",
                "generative",
                "model,",
                "its",
                "influence",
                "on",
                "the",
                "final",
                "output",
                "will",
                "be",
                "crucial",
                "for",
                "the",
                "conditioning",
                "of",
                "the",
                "generated",
                "sentence.",
                "f",
                "✓",
                "has",
                "been",
                "adopted",
                "to",
                "give",
                "the",
                "model",
                "the",
                "ability",
                "to",
                "learn",
                "the",
                "best",
                "manipulation",
                "of",
                "the",
                "conditioning",
                "vector",
                "to",
                "insert",
                "into",
                "the",
                "memory."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The generator is based on a Relational Memory with self-attention #TARGET_REF . This model updates its \"internal values\" and produces its final output by selecting from its memory cells with a self-attention mechanism. Leveraging an idea similar to that of image-based conditional GANs #REF , we introduce an external conditioning into the generator. First, given the conditioning input c 2 R d , the model computes an embedding t for c using functionf ✓ : R d ! R m , with m &lt, d.Function f ✓ has been implemented using a feed-forward neural network with a self-attention layer. The conditioning vector c may originate from any type of different source as long as it remains consistent during the individual training. Depending on the required task, as shown in the experiment phase, it will change. This vector c is the only link between the conditioning and the generative model, its influence on the final output will be crucial for the conditioning of the generated sentence. f ✓ has been adopted to give the model the ability to learn the best manipulation of the conditioning vector to insert into the memory.",
        "output": "{\"INFO\": [\"a Relational Memory with self-attention #TARGET_REF .\"], \"PERCEPT\": [\"The generator is based on\", \"This model updates its \\\"internal values\\\" and produces its final output by selecting from its memory cells with a self-attention mechanism.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Experimental",
                "details",
                "For",
                "all",
                "models,",
                "we",
                "benchmark",
                "by",
                "running",
                "a",
                "forward",
                "and",
                "backward",
                "pass",
                "over",
                "random",
                "inputs.",
                "Each",
                "measurement",
                "is",
                "an",
                "average",
                "over",
                "3",
                "runs",
                "on",
                "an",
                "Nvidia",
                "A100",
                "GPU",
                "and",
                "is",
                "discarded",
                "if",
                "memory",
                "usage",
                "exceeds",
                "30GiB.",
                "We",
                "use",
                "causal",
                "masking",
                "for",
                "self-attention",
                "layers",
                "to",
                "highlight",
                "the",
                "simplicity",
                "of",
                "our",
                "approach",
                "that",
                "can",
                "seamlessly",
                "handle",
                "arbitrary",
                "attention",
                "masks,",
                "unlike",
                "other",
                "methods",
                "#TARGET_REF",
                ",",
                "where",
                "implementing",
                "causal",
                "masking",
                "requires",
                "customized",
                "CUDA",
                "implementations.",
                "For",
                "Performer,",
                "we",
                "use",
                "256",
                "random",
                "features,",
                "and",
                "the",
                "CUDA",
                "implementation",
                "from",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Experimental details For all models, we benchmark by running a forward and backward pass over random inputs. Each measurement is an average over 3 runs on an Nvidia A100 GPU and is discarded if memory usage exceeds 30GiB. We use causal masking for self-attention layers to highlight the simplicity of our approach that can seamlessly handle arbitrary attention masks, unlike other methods #TARGET_REF , where implementing causal masking requires customized CUDA implementations. For Performer, we use 256 random features, and the CUDA implementation from #REF .",
        "output": "{\"INFO\": [\"implementing causal masking requires customized CUDA implementations.\"], \"PERCEPT\": [\"We use causal masking for self-attention layers to highlight the simplicity of our approach that can seamlessly handle arbitrary attention masks, unlike other methods #TARGET_REF , where\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Modern",
                "search",
                "engines",
                "often",
                "attempt",
                "to",
                "provide",
                "structured",
                "search",
                "results",
                "that",
                "reveal",
                "more",
                "facets",
                "of",
                "the",
                "search",
                "query",
                "than",
                "explicitly",
                "requested.",
                "These",
                "results",
                "rely",
                "on",
                "knowledge",
                "bases",
                "that",
                "contain",
                "tuples",
                "of",
                "the",
                "form",
                "(entity,",
                "attribute,",
                "value).",
                "However,",
                "the",
                "number",
                "of",
                "known",
                "entities",
                "and",
                "attributes",
                "in",
                "these",
                "knowledge",
                "bases",
                "is",
                "limited",
                "and",
                "there",
                "is",
                "a",
                "long",
                "tail",
                "of",
                "both",
                "entities",
                "and",
                "attributes",
                "that",
                "is",
                "too",
                "large",
                "to",
                "be",
                "manually",
                "curated.",
                "The",
                "goal",
                "of",
                "automatic",
                "entityattribute",
                "extraction",
                "is",
                "to",
                "replace",
                "manual",
                "knowledge",
                "acquisition",
                "which",
                "is",
                "expensive",
                "and",
                "biased",
                "towards",
                "popular",
                "entities",
                "#TARGET_REF",
                ".",
                "Previous",
                "studies",
                "have",
                "proposed",
                "model-based",
                "approaches",
                "that",
                "use",
                "various",
                "NLP",
                "features,",
                "distant",
                "supervision",
                "and",
                "traditional",
                "machine",
                "learning",
                "methods",
                "for",
                "entity-attribute",
                "extraction",
                "but",
                "*",
                "Work",
                "done",
                "during",
                "an",
                "internship",
                "at",
                "Google.",
                "their",
                "precision",
                "has",
                "not",
                "been",
                "high",
                "enough",
                "to",
                "replace",
                "manually",
                "curated",
                "knowledge",
                "bases",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Modern search engines often attempt to provide structured search results that reveal more facets of the search query than explicitly requested. These results rely on knowledge bases that contain tuples of the form (entity, attribute, value). However, the number of known entities and attributes in these knowledge bases is limited and there is a long tail of both entities and attributes that is too large to be manually curated. The goal of automatic entityattribute extraction is to replace manual knowledge acquisition which is expensive and biased towards popular entities #TARGET_REF . Previous studies have proposed model-based approaches that use various NLP features, distant supervision and traditional machine learning methods for entity-attribute extraction but * Work done during an internship at Google. their precision has not been high enough to replace manually curated knowledge bases #REF .",
        "output": "{\"INFO\": [\"The goal of automatic entityattribute extraction is to replace manual knowledge acquisition which is expensive and biased towards popular entities #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"Previous studies have proposed model-based approaches that use various NLP features, distant supervision and traditional machine learning methods for entity-attribute extraction but\", \"their precision has not been high enough to replace manually curated knowledge bases #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "compute",
                "our",
                "embeddings",
                "from",
                "an",
                "entity",
                "typing",
                "model",
                "trained",
                "on",
                "the",
                "UFET",
                "dataset",
                "#TARGET_REF",
                "for",
                "CAP",
                "(10k",
                "types).",
                "We",
                "choose",
                "this",
                "dataset",
                "because",
                "many",
                "of",
                "mention",
                "spans",
                "in",
                "the",
                "CAP",
                "examples",
                "are",
                "nominal",
                "expressions",
                "or",
                "pronouns,",
                "and",
                "the",
                "Wiki-Context",
                "dataset",
                "includes",
                "almost",
                "entirely",
                "mentions",
                "of",
                "proper",
                "nouns.",
                "To",
                "make",
                "a",
                "prediction",
                "if",
                "two",
                "mentions",
                "are",
                "coreferent,",
                "we",
                "compute",
                "sim",
                "cos",
                "(t",
                "1",
                ",",
                "t",
                "2",
                ")",
                "over",
                "the",
                "type",
                "vectors",
                "for",
                "each",
                "mention",
                "and",
                "check",
                "if",
                "this",
                "is",
                "greater",
                "than",
                "a",
                "threshold,",
                "which",
                "we",
                "set",
                "to",
                "0.5.",
                "Only",
                "our",
                "baselines",
                "use",
                "the",
                "CAP",
                "training",
                "set,",
                "our",
                "model",
                "does",
                "not",
                "train",
                "on",
                "this",
                "data.",
                "We",
                "compare",
                "our",
                "approach",
                "with",
                "the",
                "baselines",
                "described",
                "above",
                "as",
                "reported",
                "in",
                "#REF",
                ".",
                "Note",
                "that",
                "they",
                "use",
                "two",
                "different",
                "types",
                "of",
                "entity",
                "representations:",
                "one",
                "based",
                "on",
                "entity",
                "descriptions",
                "and",
                "another",
                "based",
                "on",
                "entity",
                "names",
                "only."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We compute our embeddings from an entity typing model trained on the UFET dataset #TARGET_REF for CAP (10k types). We choose this dataset because many of mention spans in the CAP examples are nominal expressions or pronouns, and the Wiki-Context dataset includes almost entirely mentions of proper nouns. To make a prediction if two mentions are coreferent, we compute sim cos (t 1 , t 2 ) over the type vectors for each mention and check if this is greater than a threshold, which we set to 0.5. Only our baselines use the CAP training set, our model does not train on this data. We compare our approach with the baselines described above as reported in #REF . Note that they use two different types of entity representations: one based on entity descriptions and another based on entity names only.",
        "output": "{\"INFO\": [\"the UFET dataset #TARGET_REF\"], \"PERCEPT\": [\"We compute our embeddings from an entity typing model trained on\", \"for CAP (10k types). We choose this dataset because many of mention spans in the CAP examples are nominal expressions or pronouns, and the Wiki-Context dataset includes almost entirely mentions of proper nouns.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "We",
                "hypothesize",
                "that",
                "any",
                "effects",
                "of",
                "word",
                "alignment",
                "visualization",
                "on",
                "post-editing",
                "may",
                "be",
                "dependent",
                "on",
                "the",
                "quality",
                "of",
                "the",
                "underlying",
                "machine",
                "translations",
                "displayed",
                "to",
                "the",
                "post-editors.",
                "Because",
                "we",
                "care",
                "about",
                "the",
                "adequacy",
                "of",
                "post-edited",
                "translations,",
                "we",
                "consider",
                "actual",
                "human",
                "judgements",
                "to",
                "be",
                "preferable",
                "to",
                "automated",
                "metrics",
                "such",
                "as",
                "BLEU",
                "#REF",
                ",",
                "which",
                "at",
                "best",
                "serve",
                "as",
                "a",
                "flawed",
                "proxy",
                "for",
                "human",
                "judgements.",
                "Instead,",
                "following",
                "#REF",
                "and",
                "#TARGET_REF",
                ",",
                "we",
                "therefore",
                "obtained",
                "human",
                "judgements",
                "of",
                "translation",
                "adequacy",
                "for",
                "the",
                "Russian-English",
                "and",
                "Spanish-English",
                "machine",
                "translations",
                "used",
                "in",
                "this",
                "study."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "We hypothesize that any effects of word alignment visualization on post-editing may be dependent on the quality of the underlying machine translations displayed to the post-editors. Because we care about the adequacy of post-edited translations, we consider actual human judgements to be preferable to automated metrics such as BLEU #REF , which at best serve as a flawed proxy for human judgements. Instead, following #REF and #TARGET_REF , we therefore obtained human judgements of translation adequacy for the Russian-English and Spanish-English machine translations used in this study.",
        "output": "{\"INFO\": [\"and #TARGET_REF ,\"], \"PERCEPT\": [\"we consider actual human judgements to be preferable to automated metrics such as BLEU #REF , which at best serve as a flawed proxy for human judgements.\"], \"BACK\": [\"Instead, following #REF\", \"we therefore obtained human judgements of translation adequacy for the Russian-English and Spanish-English machine translations used in this study.\"]}"
    },
    {
        "gold": {
            "text": [
                "This",
                "generation",
                "task",
                "adopts",
                "the",
                "traditional",
                "image",
                "captioning",
                "evaluation",
                "metric",
                "using",
                "the",
                "open-source",
                "tool",
                "2",
                "with",
                "a",
                "minor",
                "modification",
                "3",
                "to",
                "suit",
                "with",
                "LN-COCO,",
                "including",
                "BLEU",
                "#REF",
                ",",
                "METEOR",
                "#REF",
                ",",
                "ROUGE-L",
                "#TARGET_REF",
                ",",
                "ROUGE-1-F1(Pont-Tuset",
                "et",
                "al.,",
                "2020),",
                "and",
                "CIDEr-D",
                "#REF",
                "."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "This generation task adopts the traditional image captioning evaluation metric using the open-source tool 2 with a minor modification 3 to suit with LN-COCO, including BLEU #REF , METEOR #REF , ROUGE-L #TARGET_REF , ROUGE-1-F1(Pont-Tuset et al., 2020), and CIDEr-D #REF .",
        "output": "{\"INFO\": [\"ROUGE-L #TARGET_REF ,\"], \"PERCEPT\": [\"This generation task adopts the traditional image captioning evaluation metric using the open-source tool 2 with a minor modification 3 to suit with LN-COCO,\"], \"BACK\": [\"including BLEU #REF , METEOR #REF ,\", \"ROUGE-1-F1(Pont-Tuset et al., 2020), and CIDEr-D #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "For",
                "sake",
                "of",
                "comparison,",
                "we",
                "have",
                "computed",
                "BLEU",
                "at",
                "word",
                "level",
                "using",
                "BPE",
                "method",
                "#REF",
                ".",
                "We",
                "computed",
                "the",
                "subwords",
                "units",
                "in",
                "the",
                "output",
                "side",
                "of",
                "the",
                "neural",
                "network",
                "as",
                "done",
                "with",
                "Factored",
                "approach.",
                "We",
                "set",
                "the",
                "number",
                "of",
                "merge",
                "operations",
                "for",
                "the",
                "BPE",
                "algorithm,",
                "as",
                "explained",
                "in",
                "the",
                "paper",
                "#TARGET_REF",
                ",",
                "following",
                "equation",
                "12."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3
            ]
        },
        "input": "For sake of comparison, we have computed BLEU at word level using BPE method #REF . We computed the subwords units in the output side of the neural network as done with Factored approach. We set the number of merge operations for the BPE algorithm, as explained in the paper #TARGET_REF , following equation 12.",
        "output": "{\"INFO\": [\"the paper #TARGET_REF ,\"], \"PERCEPT\": [\"For sake of comparison, we have computed BLEU at word level using BPE method #REF . We computed the subwords units in the output side of the neural network as done with Factored approach. We set the number of merge operations for the BPE algorithm, as explained in\"], \"BACK\": [\"following equation 12.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "four",
                "languages",
                "are",
                "highly",
                "agglutinative",
                "or",
                "polysynthetic,",
                "meaning",
                "that",
                "they",
                "usually",
                "express",
                "a",
                "large",
                "amount",
                "of",
                "information",
                "in",
                "just",
                "one",
                "word",
                "with",
                "several",
                "joint",
                "morphemes.",
                "This",
                "is",
                "a",
                "real",
                "challenge",
                "for",
                "MT",
                "and",
                "subword",
                "segmentation",
                "methods,",
                "given",
                "the",
                "high",
                "probability",
                "of",
                "addressing",
                "a",
                "\"rare",
                "word\"",
                "for",
                "the",
                "system.",
                "We",
                "also",
                "note",
                "that",
                "each",
                "language",
                "belongs",
                "to",
                "a",
                "different",
                "language",
                "family,",
                "but",
                "that",
                "is",
                "not",
                "a",
                "problem",
                "for",
                "multilingual",
                "models,",
                "as",
                "usually",
                "the",
                "family-based",
                "clusters",
                "are",
                "not",
                "the",
                "most",
                "effective",
                "ones",
                "#TARGET_REF",
                "Pre-processing",
                "The",
                "datasets",
                "were",
                "noisy",
                "and",
                "not",
                "cleaned.",
                "Lines",
                "are",
                "reduced",
                "according",
                "to",
                "several",
                "heuristics:",
                "Arabic",
                "numbers",
                "or",
                "punctuation",
                "do",
                "not",
                "match",
                "in",
                "the",
                "parallel",
                "sentences,",
                "there",
                "are",
                "more",
                "symbols",
                "or",
                "numbers",
                "than",
                "words",
                "in",
                "a",
                "sentence,",
                "the",
                "ratio",
                "of",
                "words",
                "from",
                "one",
                "side",
                "is",
                "five",
                "times",
                "larger",
                "or",
                "shorter",
                "than",
                "the",
                "other,",
                "among",
                "others.",
                "Table",
                "5",
                "in",
                "the",
                "Appendix",
                "includes",
                "the",
                "original",
                "and",
                "cleaned",
                "data",
                "size",
                "per",
                "language-pair,",
                "whereas",
                "Table",
                "1",
                "presents",
                "the",
                "final",
                "sizes."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The four languages are highly agglutinative or polysynthetic, meaning that they usually express a large amount of information in just one word with several joint morphemes. This is a real challenge for MT and subword segmentation methods, given the high probability of addressing a \"rare word\" for the system. We also note that each language belongs to a different language family, but that is not a problem for multilingual models, as usually the family-based clusters are not the most effective ones #TARGET_REF Pre-processing The datasets were noisy and not cleaned. Lines are reduced according to several heuristics: Arabic numbers or punctuation do not match in the parallel sentences, there are more symbols or numbers than words in a sentence, the ratio of words from one side is five times larger or shorter than the other, among others. Table 5 in the Appendix includes the original and cleaned data size per language-pair, whereas Table 1 presents the final sizes.",
        "output": "{\"INFO\": [\"the family-based clusters are not the most effective ones #TARGET_REF\"], \"PERCEPT\": [\"We also note that each language belongs to a different language family, but that is not a problem for multilingual models, as usually\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "In",
                "SemEval",
                "2020-Task",
                "11",
                "#REF",
                ",",
                "the",
                "first",
                "sub-task",
                "-Span",
                "Identification",
                "-aims",
                "at",
                "detecting",
                "the",
                "beginning",
                "and",
                "the",
                "end",
                "offset",
                "for",
                "the",
                "propaganda",
                "spans",
                "in",
                "news",
                "articles.",
                "This",
                "sub-task",
                "is",
                "similar",
                "to",
                "SemEval",
                "2021-Task",
                "5.",
                "The",
                "proposed",
                "approaches",
                "for",
                "the",
                "sub-task",
                "can",
                "be",
                "broadly",
                "classified",
                "into",
                "Span",
                "Prediction",
                "or",
                "Token",
                "Classification.",
                "Most",
                "teams",
                "use",
                "multi-granular",
                "transformer-based",
                "systems",
                "for",
                "token",
                "classification/sequence",
                "tagging",
                "#REF",
                ".",
                "Inspired",
                "by",
                "#TARGET_REF",
                ",",
                "#REF",
                "use",
                "RoBERTa-CRF",
                "based",
                "systems.",
                "#REF",
                "use",
                "a",
                "variant",
                "of",
                "SpanBERT",
                "span",
                "prediction",
                "system."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In SemEval 2020-Task 11 #REF , the first sub-task -Span Identification -aims at detecting the beginning and the end offset for the propaganda spans in news articles. This sub-task is similar to SemEval 2021-Task 5. The proposed approaches for the sub-task can be broadly classified into Span Prediction or Token Classification. Most teams use multi-granular transformer-based systems for token classification/sequence tagging #REF . Inspired by #TARGET_REF , #REF use RoBERTa-CRF based systems. #REF use a variant of SpanBERT span prediction system.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"Inspired by #TARGET_REF , #REF use RoBERTa-CRF based systems.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "The",
                "Baseline",
                "method",
                "only",
                "takes",
                "image",
                "feature",
                "as",
                "input",
                "while",
                "the",
                "+Trace",
                "model",
                "take",
                "image",
                "feature",
                "and",
                "trace",
                "both",
                "as",
                "input.",
                "They",
                "employ",
                "the",
                "architecture",
                "in",
                "#TARGET_REF",
                "with",
                "a",
                "few",
                "minor",
                "differences.",
                "First,",
                "they",
                "set",
                "the",
                "number",
                "of",
                "Transformers'",
                "layers",
                "for",
                "both",
                "the",
                "encoder",
                "and",
                "the",
                "decoder",
                "to",
                "2",
                "instead",
                "of",
                "6.",
                "Second,",
                "their",
                "projection",
                "layers",
                "also",
                "consist",
                "of",
                "layer",
                "normalization",
                "#REF",
                ".",
                "Third,",
                "they",
                "set",
                "the",
                "maximum",
                "number",
                "of",
                "iterations",
                "to",
                "150k.",
                "Finally,",
                "they",
                "allow",
                "the",
                "maximum",
                "number",
                "of",
                "target",
                "captions",
                "to",
                "be",
                "as",
                "long",
                "as",
                "225",
                "to",
                "account",
                "for",
                "the",
                "narration's",
                "longer",
                "nature.",
                "LoopCAG",
                "methods",
                "Our",
                "model",
                "comprises",
                "of",
                "four",
                "components:",
                "1)",
                "the",
                "transformer",
                "encoderdecoder",
                "framework,",
                "2)",
                "the",
                "trace",
                "input,",
                "3)",
                "Attention",
                "Guidance(+AG",
                "for",
                "short)",
                "grounding",
                "loss,",
                "4)",
                "Contrastive",
                "constraints(+C",
                "for",
                "short)."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The Baseline method only takes image feature as input while the +Trace model take image feature and trace both as input. They employ the architecture in #TARGET_REF with a few minor differences. First, they set the number of Transformers' layers for both the encoder and the decoder to 2 instead of 6. Second, their projection layers also consist of layer normalization #REF . Third, they set the maximum number of iterations to 150k. Finally, they allow the maximum number of target captions to be as long as 225 to account for the narration's longer nature. LoopCAG methods Our model comprises of four components: 1) the transformer encoderdecoder framework, 2) the trace input, 3) Attention Guidance(+AG for short) grounding loss, 4) Contrastive constraints(+C for short).",
        "output": "{\"INFO\": [\"the number of Transformers' layers for both the encoder and the decoder to\", \"6.\", \"their projection layers also consist of layer normalization #REF .\"], \"PERCEPT\": [\"They employ the architecture in #TARGET_REF with a few minor differences. First, they set\", \"2 instead of\", \"Second,\", \"Third, they set the maximum number of iterations to 150k. Finally, they allow the maximum number of target captions to be as long as 225 to account for the narration's longer nature.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "As",
                "a",
                "first",
                "step,",
                "we",
                "consider",
                "only",
                "cases",
                "where",
                "at",
                "any",
                "node",
                "during",
                "the",
                "tree",
                "traversal",
                "in",
                "the",
                "BURS,",
                "there",
                "is",
                "only",
                "potentially",
                "one",
                "gNCN",
                "at",
                "a",
                "time:",
                "that",
                "is,",
                "it",
                "is",
                "not",
                "possible",
                "to",
                "embed",
                "or",
                "overlap",
                "these",
                "gNCNs.",
                "In",
                "order",
                "to",
                "explain",
                "this,",
                "consider",
                "first",
                "the",
                "example",
                "below.",
                "The",
                "input",
                "AST",
                "(ignoring",
                "the",
                "annotations",
                "on",
                "the",
                "nodes)",
                "is",
                "in",
                "Figure",
                "7,",
                "pattern",
                "trees,",
                "in",
                "the",
                "form",
                "of",
                "a",
                "TAG",
                "grammar",
                "(with",
                "associated",
                "costs",
                "still",
                "indicated",
                "by",
                "),",
                "are",
                "also",
                "in",
                "Figure",
                "7.",
                "The",
                "algorithm",
                "we",
                "use",
                "for",
                "bottom-up",
                "pattern",
                "matching,",
                "adapted",
                "from",
                "that",
                "of",
                "#TARGET_REF",
                ",",
                "is",
                "in",
                "Figure",
                "8."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "As a first step, we consider only cases where at any node during the tree traversal in the BURS, there is only potentially one gNCN at a time: that is, it is not possible to embed or overlap these gNCNs. In order to explain this, consider first the example below. The input AST (ignoring the annotations on the nodes) is in Figure 7, pattern trees, in the form of a TAG grammar (with associated costs still indicated by ), are also in Figure 7. The algorithm we use for bottom-up pattern matching, adapted from that of #TARGET_REF , is in Figure 8.",
        "output": "{\"INFO\": [\"The algorithm\", \"adapted from that of #TARGET_REF\"], \"PERCEPT\": [\"we use for bottom-up pattern matching,\", \", is in Figure 8.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "More",
                "recently,",
                "researchers",
                "have",
                "noted",
                "that",
                "the",
                "linguistic",
                "features",
                "of",
                "a",
                "comment",
                "alone",
                "may",
                "not",
                "be",
                "sufficient",
                "to",
                "classify",
                "it",
                "as",
                "abusive",
                "or",
                "not.",
                "Information",
                "of",
                "the",
                "user",
                "who",
                "posted",
                "the",
                "comment,",
                "and",
                "of",
                "the",
                "surrounding",
                "social",
                "community",
                "of",
                "that",
                "user,",
                "further",
                "provides",
                "valuable",
                "insights",
                "into",
                "the",
                "abusiveness",
                "of",
                "the",
                "comment.",
                "An",
                "example",
                "of",
                "this",
                "is",
                "the",
                "study",
                "by",
                "#TARGET_REF",
                ",",
                "which",
                "mapped",
                "the",
                "locations",
                "of",
                "racist",
                "tweets",
                "in",
                "response",
                "to",
                "President",
                "Obama's",
                "re-election",
                "to",
                "show",
                "that",
                "such",
                "tweets",
                "were",
                "not",
                "uniformly",
                "distributed",
                "across",
                "the",
                "United",
                "States",
                "but",
                "instead",
                "came",
                "from",
                "specific",
                "geographical",
                "communities",
                "of",
                "users.",
                "Other",
                "works",
                "have",
                "also",
                "shown",
                "how",
                "users",
                "on",
                "online",
                "platforms",
                "organize",
                "into",
                "communities",
                "based",
                "on",
                "factors",
                "such",
                "as",
                "shared",
                "beliefs,",
                "stereotypes,",
                "linguistic",
                "norms,",
                "or",
                "geographical",
                "propinquity",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "More recently, researchers have noted that the linguistic features of a comment alone may not be sufficient to classify it as abusive or not. Information of the user who posted the comment, and of the surrounding social community of that user, further provides valuable insights into the abusiveness of the comment. An example of this is the study by #TARGET_REF , which mapped the locations of racist tweets in response to President Obama's re-election to show that such tweets were not uniformly distributed across the United States but instead came from specific geographical communities of users. Other works have also shown how users on online platforms organize into communities based on factors such as shared beliefs, stereotypes, linguistic norms, or geographical propinquity #REF .",
        "output": "{\"INFO\": [\"An example of this is the study by #TARGET_REF , which mapped the locations of racist tweets in response to President Obama's re-election to show that such tweets were not uniformly distributed across the United States but instead came from specific geographical communities of users.\"], \"PERCEPT\": [\"researchers have noted that the linguistic features of a comment alone may not be sufficient to classify it as abusive or not. Information of the user who posted the comment, and of the surrounding social community of that user, further provides valuable insights into the abusiveness of the comment.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "take",
                "advantage",
                "of",
                "the",
                "potential",
                "lexical",
                "sharing",
                "of",
                "the",
                "languages",
                "(e.g.",
                "loanwords)",
                "and",
                "address",
                "the",
                "polysynthetic",
                "nature",
                "of",
                "the",
                "indigenous",
                "languages,",
                "we",
                "trained",
                "a",
                "unique",
                "multilingual",
                "segmentation",
                "model",
                "by",
                "sampling",
                "all",
                "languages",
                "with",
                "a",
                "uniform",
                "distribution.",
                "We",
                "used",
                "the",
                "unigram",
                "model",
                "implementation",
                "in",
                "SentencePiece",
                "#TARGET_REF",
                "with",
                "a",
                "vocabulary",
                "size",
                "of",
                "32,000."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "To take advantage of the potential lexical sharing of the languages (e.g. loanwords) and address the polysynthetic nature of the indigenous languages, we trained a unique multilingual segmentation model by sampling all languages with a uniform distribution. We used the unigram model implementation in SentencePiece #TARGET_REF with a vocabulary size of 32,000.",
        "output": "{\"INFO\": [\"in SentencePiece #TARGET_REF with a vocabulary size of 32,000.\"], \"PERCEPT\": [\"We used the unigram model implementation\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Neural",
                "Machine",
                "Translation",
                "(NMT)",
                "approach",
                "has",
                "been",
                "further",
                "developed",
                "in",
                "the",
                "last",
                "years",
                "#REF",
                ".",
                "In",
                "contrast",
                "to",
                "the",
                "traditional",
                "phrased-based",
                "statistical",
                "machine",
                "translation",
                "#REF",
                "that",
                "represents",
                "and",
                "translates",
                "the",
                "input",
                "sentence",
                "with",
                "a",
                "set",
                "of",
                "phrases,",
                "NMT",
                "uses",
                "the",
                "sequence",
                "to",
                "sequence",
                "learning",
                "architecture",
                "and",
                "the",
                "whole",
                "input",
                "sentence",
                "is",
                "considered",
                "as",
                "one",
                "unit",
                "for",
                "translation",
                "#TARGET_REF",
                ".",
                "Recently,",
                "NMT",
                "is",
                "gaining",
                "more",
                "and",
                "more",
                "interest",
                "and",
                "showing",
                "better",
                "accuracy",
                "than",
                "phrase-based",
                "system",
                "translating",
                "several",
                "language",
                "pairs.",
                "In",
                "spite",
                "of",
                "these",
                "recent",
                "improvements,",
                "the",
                "NMT",
                "systems",
                "still",
                "have",
                "some",
                "restrictions",
                "and",
                "difficulties",
                "to",
                "translate.",
                "One",
                "of",
                "them",
                "is",
                "the",
                "high",
                "computational",
                "of",
                "the",
                "softmax",
                "function",
                "which",
                "requires",
                "to",
                "normalize",
                "all",
                "the",
                "output",
                "vocabulary",
                "size."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Neural Machine Translation (NMT) approach has been further developed in the last years #REF . In contrast to the traditional phrased-based statistical machine translation #REF that represents and translates the input sentence with a set of phrases, NMT uses the sequence to sequence learning architecture and the whole input sentence is considered as one unit for translation #TARGET_REF . Recently, NMT is gaining more and more interest and showing better accuracy than phrase-based system translating several language pairs. In spite of these recent improvements, the NMT systems still have some restrictions and difficulties to translate. One of them is the high computational of the softmax function which requires to normalize all the output vocabulary size.",
        "output": "{\"INFO\": [\"NMT uses the sequence to sequence learning architecture and the whole input sentence is considered as one unit for translation #TARGET_REF\"], \"PERCEPT\": [\"In contrast to the traditional phrased-based statistical machine translation #REF\"], \"BACK\": [\"Neural Machine Translation (NMT) approach has been further developed in the last years #REF .\", \"that represents and translates the input sentence with a set of phrases,\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "central",
                "position",
                "in",
                "the",
                "bow-tie",
                "model",
                "is",
                "taken",
                "by",
                "the",
                "lexeme.",
                "The",
                "notion",
                "of",
                "lexeme",
                "in",
                "WM",
                "is",
                "similar",
                "to",
                "the",
                "one",
                "adopted",
                "by",
                "#REF",
                ",",
                "#TARGET_REF",
                "and",
                "others.",
                "A",
                "lexeme",
                "is",
                "a",
                "word",
                "considered",
                "as",
                "an",
                "inflectional",
                "paradigm.",
                "Fig.",
                "1",
                "highlights",
                "two",
                "mappings",
                "involving",
                "the",
                "lexeme:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The central position in the bow-tie model is taken by the lexeme. The notion of lexeme in WM is similar to the one adopted by #REF , #TARGET_REF and others. A lexeme is a word considered as an inflectional paradigm. Fig. 1 highlights two mappings involving the lexeme:",
        "output": "{\"INFO\": [\"#TARGET_REF\"], \"PERCEPT\": [], \"BACK\": [\"The notion of lexeme in WM is similar to the one adopted by #REF ,\", \"and others.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "section,",
                "we",
                "benchmark",
                "top-k",
                "attention",
                "in",
                "terms",
                "of",
                "time",
                "and",
                "memory,",
                "and",
                "compare",
                "it",
                "to",
                "vanilla",
                "attention,",
                "query-chunking",
                "without",
                "the",
                "top-k",
                "operation,",
                "and",
                "to",
                "Performer",
                "#TARGET_REF",
                ",",
                "as",
                "a",
                "representative",
                "of",
                "state-of-the-art",
                "linear",
                "attention",
                "variants.",
                "We",
                "separately",
                "benchmark",
                "(a)",
                "a",
                "single",
                "self-attention",
                "layer",
                "over",
                "long",
                "sequences,",
                "(b)",
                "a",
                "single",
                "feed-forward",
                "layer",
                "with",
                "a",
                "large",
                "feedforward",
                "dimension,",
                "and",
                "(c)",
                "a",
                "12-layer",
                "Transformer",
                "decoder",
                "with",
                "same",
                "architecture",
                "as",
                "BERT-base",
                "#REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this section, we benchmark top-k attention in terms of time and memory, and compare it to vanilla attention, query-chunking without the top-k operation, and to Performer #TARGET_REF , as a representative of state-of-the-art linear attention variants. We separately benchmark (a) a single self-attention layer over long sequences, (b) a single feed-forward layer with a large feedforward dimension, and (c) a 12-layer Transformer decoder with same architecture as BERT-base #REF .",
        "output": "{\"INFO\": [\"Performer #TARGET_REF ,\"], \"PERCEPT\": [\"we benchmark top-k attention in terms of time and memory, and compare it to vanilla attention, query-chunking without the top-k operation, and to\", \"as a representative of state-of-the-art linear attention variants.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Trained",
                "on",
                "20GB",
                "texts",
                "of",
                "both",
                "Vietnamese",
                "news",
                "and",
                "Vietnamese",
                "Wikipedia",
                "Bert4News",
                "#REF",
                "x",
                "Trained",
                "on",
                "more",
                "than",
                "20GB",
                "texts",
                "of",
                "Vietnamese",
                "news",
                "vElectra",
                "and",
                "ViBERT",
                "#REF",
                "x",
                "vElectra",
                "was",
                "trained",
                "on",
                "10GB",
                "texts,",
                "whereas",
                "ViBERT",
                "was",
                "trained",
                "on",
                "60GB",
                "texts",
                "of",
                "Vietnamese",
                "news",
                "VGG16",
                "#TARGET_REF",
                "x"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1
            ]
        },
        "input": "Trained on 20GB texts of both Vietnamese news and Vietnamese Wikipedia Bert4News #REF x Trained on more than 20GB texts of Vietnamese news vElectra and ViBERT #REF x vElectra was trained on 10GB texts, whereas ViBERT was trained on 60GB texts of Vietnamese news VGG16 #TARGET_REF x",
        "output": "{\"INFO\": [\"VGG16 #TARGET_REF x\"], \"PERCEPT\": [], \"BACK\": [\"ViBERT was trained on 60GB texts of Vietnamese news\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "step,",
                "we",
                "will",
                "extract",
                "both",
                "genuine",
                "tokens",
                "and",
                "shortcut",
                "tokens",
                "because",
                "they",
                "are",
                "both",
                "likely",
                "to",
                "affect",
                "a",
                "model's",
                "prediction.",
                "We",
                "rely",
                "on",
                "interpretability",
                "techniques",
                "to",
                "collect",
                "information",
                "on",
                "whether",
                "a",
                "certain",
                "input",
                "token",
                "is",
                "important",
                "to",
                "model's",
                "decision",
                "making.",
                "In",
                "this",
                "paper,",
                "we",
                "use",
                "the",
                "attention",
                "score",
                "in",
                "BERT-based",
                "models",
                "as",
                "an",
                "explanation",
                "of",
                "model",
                "predictions",
                "#REF",
                ",",
                "due",
                "to",
                "its",
                "simplicity",
                "and",
                "fast",
                "computation.",
                "Recent",
                "work",
                "#TARGET_REF",
                "also",
                "reveals",
                "that",
                "attention",
                "scores",
                "outperform",
                "other",
                "explanation",
                "techniques",
                "in",
                "regularizing",
                "redundant",
                "information.",
                "Other",
                "techniques",
                "#REF",
                "can",
                "also",
                "be",
                "used",
                "in",
                "this",
                "step.",
                "As",
                "an",
                "example,",
                "given",
                "a",
                "sentence",
                "\"Spielberg",
                "is",
                "a",
                "good",
                "director.\",",
                "assuming",
                "\"good\"",
                "is",
                "a",
                "genuine",
                "token",
                "and",
                "\"Spielberg\"",
                "is",
                "a",
                "shortcut",
                "token,",
                "we",
                "expect",
                "that",
                "in",
                "a",
                "BERT-based",
                "sentiment",
                "classification",
                "model,",
                "the",
                "attention",
                "scores",
                "for",
                "\"good\"",
                "and",
                "\"Spielberg\"",
                "are",
                "higher",
                "and",
                "thus",
                "will",
                "be",
                "extracted",
                "as",
                "important",
                "tokens.",
                "On",
                "the",
                "other",
                "hand,",
                "for",
                "\"is\",",
                "\"a\"",
                "and",
                "\"director\"",
                "the",
                "attention",
                "scores",
                "would",
                "be",
                "lower",
                "as",
                "they",
                "are",
                "relatively",
                "less",
                "useful",
                "to",
                "the",
                "model",
                "decision."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this step, we will extract both genuine tokens and shortcut tokens because they are both likely to affect a model's prediction. We rely on interpretability techniques to collect information on whether a certain input token is important to model's decision making. In this paper, we use the attention score in BERT-based models as an explanation of model predictions #REF , due to its simplicity and fast computation. Recent work #TARGET_REF also reveals that attention scores outperform other explanation techniques in regularizing redundant information. Other techniques #REF can also be used in this step. As an example, given a sentence \"Spielberg is a good director.\", assuming \"good\" is a genuine token and \"Spielberg\" is a shortcut token, we expect that in a BERT-based sentiment classification model, the attention scores for \"good\" and \"Spielberg\" are higher and thus will be extracted as important tokens. On the other hand, for \"is\", \"a\" and \"director\" the attention scores would be lower as they are relatively less useful to the model decision.",
        "output": "{\"INFO\": [\"Recent work #TARGET_REF also reveals that attention scores outperform other explanation techniques in regularizing redundant information.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "Mitigation",
                "Multiple",
                "approaches",
                "have",
                "been",
                "proposed",
                "to",
                "mitigate",
                "shortcut",
                "learning",
                "and",
                "data",
                "biases",
                "#REF",
                ",",
                "through",
                "data",
                "augmentation",
                "#REF",
                ",",
                "domain",
                "adaptation",
                "#REF",
                ",",
                "and",
                "multi-task",
                "learning",
                "#REF",
                ".",
                "#TARGET_REF",
                "proposes",
                "to",
                "mitigate",
                "shortcuts",
                "by",
                "suppressing",
                "model's",
                "prediction",
                "on",
                "examples",
                "with",
                "a",
                "large",
                "shortcut",
                "degree.",
                "Recent",
                "study",
                "has",
                "also",
                "shown",
                "removing",
                "spurious",
                "correlations",
                "can",
                "sometimes",
                "hurt",
                "model's",
                "accuracy",
                "#REF",
                ".",
                "Orthogonal",
                "to",
                "existing",
                "works,",
                "we",
                "propose",
                "to",
                "first",
                "identify",
                "unrobust",
                "correlations",
                "in",
                "an",
                "NLP",
                "model",
                "and",
                "then",
                "propose",
                "a",
                "targeted",
                "mitigation",
                "to",
                "encourage",
                "the",
                "model",
                "to",
                "rely",
                "less",
                "on",
                "those",
                "unrobust",
                "correlations."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Mitigation Multiple approaches have been proposed to mitigate shortcut learning and data biases #REF , through data augmentation #REF , domain adaptation #REF , and multi-task learning #REF . #TARGET_REF proposes to mitigate shortcuts by suppressing model's prediction on examples with a large shortcut degree. Recent study has also shown removing spurious correlations can sometimes hurt model's accuracy #REF . Orthogonal to existing works, we propose to first identify unrobust correlations in an NLP model and then propose a targeted mitigation to encourage the model to rely less on those unrobust correlations.",
        "output": "{\"INFO\": [\"proposes to mitigate shortcuts by suppressing model's prediction on examples with a large shortcut degree.\"], \"PERCEPT\": [], \"BACK\": [\"Mitigation Multiple approaches have been proposed to mitigate shortcut learning and data biases #REF , through data augmentation #REF , domain adaptation #REF , and multi-task learning #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "Linguistic",
                "variations.",
                "Another",
                "aspect",
                "comes",
                "from",
                "looking",
                "at",
                "implicit",
                "abuse,",
                "whereby",
                "a",
                "user",
                "may",
                "utilize",
                "novel",
                "slangs",
                "or",
                "conventional",
                "words",
                "in",
                "unconventional",
                "ways,",
                "e.g.,",
                "as",
                "a",
                "racial",
                "slur",
                "or",
                "as",
                "a",
                "name",
                "for",
                "some",
                "specific",
                "demographic",
                "#REF",
                ".",
                "Information",
                "about",
                "how",
                "a",
                "term",
                "is",
                "being",
                "used",
                "by",
                "other",
                "members",
                "of",
                "a",
                "user's",
                "community,",
                "e.g.,",
                "in",
                "abusive",
                "contexts",
                "or",
                "otherwise,",
                "can",
                "help",
                "decipher",
                "linguistic",
                "variations",
                "that",
                "come",
                "up",
                "from",
                "time",
                "to",
                "time.",
                "In",
                "fact,",
                "it",
                "is",
                "usually",
                "the",
                "users",
                "with",
                "strong",
                "ties",
                "who",
                "are",
                "responsible",
                "for",
                "popularizing",
                "language",
                "variations",
                "as",
                "well",
                "as",
                "for",
                "spreading",
                "hate",
                "speech",
                "#TARGET_REF",
                ".",
                "Therefore,",
                "having",
                "user",
                "and",
                "community",
                "information",
                "alongside",
                "linguistic",
                "features",
                "helps",
                "capture",
                "linguistic",
                "variations",
                "and",
                "their",
                "diffusion."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "Linguistic variations. Another aspect comes from looking at implicit abuse, whereby a user may utilize novel slangs or conventional words in unconventional ways, e.g., as a racial slur or as a name for some specific demographic #REF . Information about how a term is being used by other members of a user's community, e.g., in abusive contexts or otherwise, can help decipher linguistic variations that come up from time to time. In fact, it is usually the users with strong ties who are responsible for popularizing language variations as well as for spreading hate speech #TARGET_REF . Therefore, having user and community information alongside linguistic features helps capture linguistic variations and their diffusion.",
        "output": "{\"INFO\": [\"spreading hate speech\"], \"PERCEPT\": [\"it is usually the users with strong ties who are responsible for popularizing language variations as well as for\", \"having user and community information alongside linguistic features helps capture linguistic variations and their diffusion.\"], \"BACK\": [\"Linguistic variations. Another aspect comes from looking at implicit abuse, whereby a user may utilize novel slangs or conventional words in unconventional ways,\", \"Information about how a term is being used by other members of a user's community,\", \"can help decipher linguistic variations that come up from time to time.\"]}"
    },
    {
        "gold": {
            "text": [
                "Another",
                "graph,",
                "created",
                "as",
                "an",
                "alternative",
                "for",
                "word",
                "embeddings,",
                "is",
                "GraphGlove",
                "#REF",
                ",",
                "where",
                "the",
                "edges",
                "of",
                "the",
                "graph",
                "are",
                "optimized",
                "by",
                "the",
                "cost",
                "function",
                "of",
                "GloVe",
                "#TARGET_REF",
                ",",
                "so",
                "that",
                "the",
                "shortest",
                "path",
                "between",
                "two",
                "vertices",
                "gives",
                "the",
                "distance",
                "of",
                "the",
                "corresponding",
                "words."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Another graph, created as an alternative for word embeddings, is GraphGlove #REF , where the edges of the graph are optimized by the cost function of GloVe #TARGET_REF , so that the shortest path between two vertices gives the distance of the corresponding words.",
        "output": "{\"INFO\": [\"GloVe #TARGET_REF ,\"], \"PERCEPT\": [\"GraphGlove #REF , where the edges of the graph are optimized by the cost function of\"], \"BACK\": [\"so that the shortest path between two vertices gives the distance of the corresponding words.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "oddest",
                "feature",
                "of",
                "MMB's",
                "breath-group",
                "work,",
                "stretching",
                "as",
                "it",
                "did",
                "over",
                "many",
                "years",
                "was",
                "that",
                "it",
                "referred",
                "constantly",
                "to",
                "breathing,",
                "but",
                "nothing",
                "ever",
                "rested",
                "on",
                "that:",
                "partitions",
                "were",
                "always",
                "inserted",
                "into",
                "text",
                "intuitively",
                "in",
                "a",
                "way",
                "that,",
                "to",
                "me",
                "at",
                "least,",
                "corresponded",
                "more",
                "naturally",
                "to",
                "the",
                "criteria",
                "just",
                "listed",
                "#TARGET_REF",
                ".",
                "Finally,",
                "of",
                "course,",
                "it",
                "would",
                "be",
                "overbold",
                "to",
                "assert",
                "that",
                "there",
                "will",
                "never",
                "be",
                "applications",
                "of",
                "Greek",
                "rhetorical",
                "figures",
                "to",
                "the",
                "computer",
                "understanding",
                "of",
                "natural",
                "language,",
                "but",
                "none",
                "have",
                "as",
                "yet",
                "emerged,",
                "except",
                "their",
                "explicit",
                "and",
                "obvious",
                "use",
                "as",
                "forms",
                "of",
                "expression."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "The oddest feature of MMB's breath-group work, stretching as it did over many years was that it referred constantly to breathing, but nothing ever rested on that: partitions were always inserted into text intuitively in a way that, to me at least, corresponded more naturally to the criteria just listed #TARGET_REF . Finally, of course, it would be overbold to assert that there will never be applications of Greek rhetorical figures to the computer understanding of natural language, but none have as yet emerged, except their explicit and obvious use as forms of expression.",
        "output": "{\"INFO\": [\"#TARGET_REF .\"], \"PERCEPT\": [\"partitions were always inserted into text intuitively in a way that, to me at least, corresponded more naturally to the criteria just listed\"], \"BACK\": [\"The oddest feature of MMB's breath-group work, stretching as it did over many years was that it referred constantly to breathing, but nothing ever rested on that:\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "perplexities",
                "on",
                "the",
                "development",
                "data",
                "are",
                "summarized",
                "in",
                "Table",
                "2.",
                "It",
                "is",
                "not",
                "surprising",
                "to",
                "see",
                "that",
                "adding",
                "the",
                "development",
                "data",
                "of",
                "previous",
                "evaluations",
                "improves",
                "the",
                "perplexity",
                "since",
                "this",
                "more",
                "than",
                "doubles",
                "the",
                "amount",
                "of",
                "in-domain",
                "data.",
                "The",
                "small",
                "Gale",
                "as",
                "well",
                "as",
                "the",
                "large",
                "Gigaword",
                "corpus",
                "have",
                "also",
                "a",
                "noticeable",
                "effect.",
                "1",
                "The",
                "continuous",
                "space",
                "language",
                "model",
                "was",
                "trained",
                "on",
                "all",
                "the",
                "available",
                "data,",
                "including",
                "the",
                "large",
                "Gigaword",
                "corpus,",
                "using",
                "a",
                "resampling",
                "algorithm",
                "#REF",
                ".",
                "This",
                "approach",
                "achieved",
                "a",
                "reduction",
                "in",
                "perplexity",
                "of",
                "more",
                "than",
                "15%",
                "in",
                "comparison",
                "to",
                "the",
                "large",
                "back-off",
                "language",
                "model.",
                "This",
                "is",
                "inline",
                "with",
                "results",
                "obtained",
                "in",
                "previous",
                "IWSLT",
                "evaluations",
                "#TARGET_REF",
                ",",
                "but",
                "here",
                "both",
                "language",
                "models",
                "are",
                "trained",
                "on",
                "substantially",
                "more",
                "data."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The perplexities on the development data are summarized in Table 2. It is not surprising to see that adding the development data of previous evaluations improves the perplexity since this more than doubles the amount of in-domain data. The small Gale as well as the large Gigaword corpus have also a noticeable effect. 1 The continuous space language model was trained on all the available data, including the large Gigaword corpus, using a resampling algorithm #REF . This approach achieved a reduction in perplexity of more than 15% in comparison to the large back-off language model. This is inline with results obtained in previous IWSLT evaluations #TARGET_REF , but here both language models are trained on substantially more data.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"This is inline with results obtained in previous IWSLT evaluations #TARGET_REF , but here both language models are trained on substantially more data.\"], \"BACK\": [\"This approach achieved a reduction in perplexity of more than 15% in comparison to the large back-off language model.\"]}"
    },
    {
        "gold": {
            "text": [
                "model",
                "#REF",
                "which",
                "has",
                "6",
                "layers",
                "each",
                "in",
                "the",
                "three",
                "components:",
                "encoder",
                "self-attention",
                "(ES),",
                "encoderdecoder",
                "cross-attention",
                "(ED),",
                "and",
                "decoder",
                "selfattention",
                "(DS).",
                "In",
                "each",
                "layer",
                "of",
                "each",
                "of",
                "the",
                "three",
                "components,",
                "we",
                "have",
                "8",
                "attention",
                "heads,",
                "totalling",
                "to",
                "3",
                "×",
                "6",
                "×",
                "8",
                "=",
                "144",
                "attention",
                "heads.",
                "We",
                "train",
                "the",
                "mod-els",
                "with",
                "2.5",
                "million",
                "sentence",
                "pairs",
                "each",
                "from",
                "the",
                "WMT'14",
                "English-Russian",
                "(EN-RU)",
                "and",
                "English-German",
                "(EN-DE)",
                "datasets.",
                "We",
                "report",
                "BLEU",
                "scores",
                "on",
                "WMT's",
                "newstest2014.",
                "We",
                "use",
                "Adam",
                "optimizer",
                "(Kingma",
                "and",
                "Ba,",
                "2014)",
                "with",
                "parameters",
                "β",
                "1",
                "=",
                "0.9,",
                "β",
                "2",
                "=",
                "0.997,",
                "and",
                "=",
                "10",
                "−9",
                ".",
                "We",
                "vary",
                "the",
                "learning",
                "rate",
                "according",
                "to",
                "the",
                "formula",
                "described",
                "in",
                "#REF",
                "with",
                "warmup",
                "steps",
                "=",
                "16k.",
                "We",
                "use",
                "large",
                "batch",
                "sizes",
                "of",
                "32k",
                "and",
                "25k",
                "for",
                "EN-RU",
                "and",
                "EN-DE,",
                "respectively,",
                "as",
                "it",
                "has",
                "been",
                "established",
                "that",
                "large",
                "batch",
                "sizes",
                "are",
                "inherent",
                "to",
                "the",
                "performance",
                "of",
                "Transformers",
                "#TARGET_REF",
                ".",
                "We",
                "achieve",
                "effectively",
                "large",
                "batch",
                "sizes",
                "using",
                "the",
                "technique",
                "of",
                "gradient",
                "accumulation",
                "on",
                "single",
                "NVIDIA",
                "V100",
                "and",
                "1080Ti",
                "GPUs."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "model #REF which has 6 layers each in the three components: encoder self-attention (ES), encoderdecoder cross-attention (ED), and decoder selfattention (DS). In each layer of each of the three components, we have 8 attention heads, totalling to 3 × 6 × 8 = 144 attention heads. We train the mod-els with 2.5 million sentence pairs each from the WMT'14 English-Russian (EN-RU) and English-German (EN-DE) datasets. We report BLEU scores on WMT's newstest2014. We use Adam optimizer (Kingma and Ba, 2014) with parameters β 1 = 0.9, β 2 = 0.997, and = 10 −9 . We vary the learning rate according to the formula described in #REF with warmup steps = 16k. We use large batch sizes of 32k and 25k for EN-RU and EN-DE, respectively, as it has been established that large batch sizes are inherent to the performance of Transformers #TARGET_REF . We achieve effectively large batch sizes using the technique of gradient accumulation on single NVIDIA V100 and 1080Ti GPUs.",
        "output": "{\"INFO\": [\"large batch sizes are inherent to the performance of Transformers #TARGET_REF .\"], \"PERCEPT\": [\"We use large batch sizes of 32k and 25k for EN-RU and EN-DE, respectively, as it has been established that\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "der",
                "Goot",
                "(2022)",
                "(MaChAmp)",
                "proposed",
                "to",
                "pretrain",
                "a",
                "language",
                "model",
                "and",
                "re-finetune",
                "after",
                "multitask",
                "learning",
                "for",
                "a",
                "pre-defined",
                "set",
                "of",
                "semantically",
                "focused",
                "NLP",
                "tasks.",
                "They",
                "trained",
                "a",
                "multi-task",
                "model",
                "for",
                "all",
                "text-based",
                "SemEval",
                "tasks",
                "that",
                "include",
                "annotation",
                "on",
                "the",
                "word,",
                "sentence,",
                "or",
                "paragraph",
                "level.",
                "They",
                "compared",
                "the",
                "performance",
                "with",
                "models",
                "using",
                "mBERT",
                "#TARGET_REF",
                ".",
                "The",
                "pretrained",
                "multi-task",
                "embedding",
                "showed",
                "a",
                "consistent",
                "improvement",
                "across",
                "many",
                "tasks",
                "against",
                "the",
                "mBERT",
                "embedding."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "der Goot (2022) (MaChAmp) proposed to pretrain a language model and re-finetune after multitask learning for a pre-defined set of semantically focused NLP tasks. They trained a multi-task model for all text-based SemEval tasks that include annotation on the word, sentence, or paragraph level. They compared the performance with models using mBERT #TARGET_REF . The pretrained multi-task embedding showed a consistent improvement across many tasks against the mBERT embedding.",
        "output": "{\"INFO\": [\"mBERT #TARGET_REF .\"], \"PERCEPT\": [], \"BACK\": [\"der Goot (2022) (MaChAmp) proposed to pretrain a language model and re-finetune after multitask learning for a pre-defined set of semantically focused NLP tasks. They trained a multi-task model for all text-based SemEval tasks that include annotation on the word, sentence, or paragraph level. They compared the performance with models using\", \"The pretrained multi-task embedding showed a consistent improvement across many tasks against the mBERT embedding.\"]}"
    },
    {
        "gold": {
            "text": [
                "Simultaneous",
                "translation",
                "#TARGET_REF",
                "consists",
                "in",
                "generating",
                "a",
                "translation",
                "before",
                "the",
                "source",
                "speaker",
                "finishes",
                "speaking.",
                "It",
                "is",
                "widely",
                "used",
                "in",
                "many",
                "real-time",
                "scenarios",
                "such",
                "as",
                "international",
                "conferences,",
                "business",
                "negotiations",
                "and",
                "legal",
                "proceedings.",
                "The",
                "challenge",
                "of",
                "Simultaneous",
                "machine",
                "translation",
                "is",
                "to",
                "find",
                "a",
                "read-write",
                "policy",
                "that",
                "balances",
                "translation",
                "quality",
                "and",
                "latency.",
                "The",
                "translation",
                "quality",
                "will",
                "decline",
                "if",
                "the",
                "machine",
                "translation",
                "system",
                "reads",
                "insufficient",
                "source",
                "information.",
                "When",
                "reading",
                "wider",
                "source",
                "text,",
                "latency",
                "will",
                "increase."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Simultaneous translation #TARGET_REF consists in generating a translation before the source speaker finishes speaking. It is widely used in many real-time scenarios such as international conferences, business negotiations and legal proceedings. The challenge of Simultaneous machine translation is to find a read-write policy that balances translation quality and latency. The translation quality will decline if the machine translation system reads insufficient source information. When reading wider source text, latency will increase.",
        "output": "{\"INFO\": [\"Simultaneous translation #TARGET_REF consists in generating a translation before the source speaker finishes speaking.\"], \"PERCEPT\": [\"It is widely used in many real-time scenarios\", \"The challenge of Simultaneous machine translation is to find a read-write policy that balances translation quality and latency.\"], \"BACK\": [\"such as international conferences, business negotiations and legal proceedings.\", \"The translation quality will decline if the machine translation system reads insufficient source information.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "MOST",
                "FREQUENT",
                "baseline",
                "chooses",
                "the",
                "most",
                "frequently",
                "observed",
                "entity",
                "for",
                "a",
                "given",
                "mention",
                "as",
                "a",
                "prediction,",
                "based",
                "on",
                "a",
                "prior",
                "probability",
                "p",
                "prior",
                "computed",
                "from",
                "link",
                "counts",
                "on",
                "Wikipedia.",
                "All",
                "baselines",
                "except",
                "MOST",
                "FREQUENT",
                "combine",
                "the",
                "classifier",
                "output",
                "and",
                "the",
                "prior",
                "probability",
                "to",
                "make",
                "a",
                "prediction:",
                "arg",
                "max",
                "c",
                "p",
                "prior",
                "(c)",
                "+",
                "p",
                "classifier",
                "(c)",
                ".",
                "10",
                "data.",
                "Our",
                "approach",
                "outperforms",
                "all",
                "baselines,",
                "indicating",
                "that",
                "our",
                "entity",
                "representations",
                "include",
                "useful",
                "information",
                "about",
                "entities",
                "out-of-the-box.",
                "Such",
                "a",
                "performance",
                "gap",
                "is",
                "expected",
                "since",
                "our",
                "entity",
                "representations",
                "can",
                "directly",
                "encode",
                "some",
                "factual",
                "knowledge",
                "from",
                "Wikipedia.",
                "However,",
                "these",
                "results",
                "also",
                "imply",
                "that",
                "pre-trained",
                "LMs",
                "do",
                "not",
                "have",
                "enough",
                "factual",
                "information",
                "out-of-the-box,",
                "they",
                "may",
                "rely",
                "on",
                "in-domain",
                "fine-tuning",
                "to",
                "achieve",
                "high",
                "performance",
                "in",
                "the",
                "target",
                "domain,",
                "and",
                "often",
                "fail",
                "to",
                "generalize",
                "to",
                "new",
                "settings.",
                "Note",
                "that",
                "while",
                "these",
                "accuracies",
                "are",
                "significantly",
                "below",
                "the",
                "supervised",
                "state-of-the-art",
                "(95%),",
                "they",
                "are",
                "competitive",
                "with",
                "the",
                "\"zero-shot\"",
                "entity",
                "results",
                "from",
                "recent",
                "past",
                "work",
                "#TARGET_REF",
                "."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "The MOST FREQUENT baseline chooses the most frequently observed entity for a given mention as a prediction, based on a prior probability p prior computed from link counts on Wikipedia. All baselines except MOST FREQUENT combine the classifier output and the prior probability to make a prediction: arg max c p prior (c) + p classifier (c) . 10 data. Our approach outperforms all baselines, indicating that our entity representations include useful information about entities out-of-the-box. Such a performance gap is expected since our entity representations can directly encode some factual knowledge from Wikipedia. However, these results also imply that pre-trained LMs do not have enough factual information out-of-the-box, they may rely on in-domain fine-tuning to achieve high performance in the target domain, and often fail to generalize to new settings. Note that while these accuracies are significantly below the supervised state-of-the-art (95%), they are competitive with the \"zero-shot\" entity results from recent past work #TARGET_REF .",
        "output": "{\"INFO\": [\"recent past work #TARGET_REF .\"], \"PERCEPT\": [\"while these accuracies are significantly below the supervised state-of-the-art (95%), they are competitive with the \\\"zero-shot\\\" entity results from\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "To",
                "observe",
                "the",
                "effect",
                "of",
                "disentanglement",
                "in",
                "homotopy",
                "#TARGET_REF",
                "Additionally,",
                "to",
                "highlight",
                "the",
                "role",
                "of",
                "generative",
                "factor",
                "in",
                "generation,",
                "we",
                "conduct",
                "a",
                "dimensionwise",
                "homotopy,",
                "transitioning",
                "from",
                "the",
                "first",
                "to",
                "the",
                "last",
                "sentence",
                "by",
                "interpolating",
                "between",
                "the",
                "dimensions",
                "one-by-one.",
                "This",
                "is",
                "implemented",
                "as",
                "follows:",
                "(i)",
                "using",
                "prior",
                "distribution",
                "7",
                "we",
                "sample",
                "two",
                "latent",
                "codes",
                "denoted",
                "by",
                "z",
                "1",
                "=",
                "(z",
                "1,1",
                ",",
                "z",
                "1,2",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                "),",
                "z",
                "2",
                "=",
                "(z",
                "2,1",
                ",",
                "z",
                "2,2",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,n",
                "),",
                "(ii)",
                "for",
                "i-th",
                "dimension,",
                "using",
                "z",
                "1,i",
                "=",
                "(z",
                "2,1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,i−1",
                ",",
                "z",
                "1,i",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                ")",
                "as",
                "the",
                "start,",
                "we",
                "interpolate",
                "along",
                "the",
                "i-th",
                "dimension",
                "towards",
                "z",
                "2,i",
                "=",
                "(z",
                "2,1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "2,i",
                ",",
                "z",
                "1,i+1",
                ",",
                ".",
                ".",
                ".",
                ",",
                "z",
                "1,n",
                ").",
                "Table",
                "6",
                "illustrates",
                "this",
                "for",
                "a",
                "3D",
                "latent",
                "code",
                "example."
            ],
            "context": [
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "To observe the effect of disentanglement in homotopy #TARGET_REF Additionally, to highlight the role of generative factor in generation, we conduct a dimensionwise homotopy, transitioning from the first to the last sentence by interpolating between the dimensions one-by-one. This is implemented as follows: (i) using prior distribution 7 we sample two latent codes denoted by z 1 = (z 1,1 , z 1,2 , . . . , z 1,n ), z 2 = (z 2,1 , z 2,2 , . . . , z 2,n ), (ii) for i-th dimension, using z 1,i = (z 2,1 , . . . , z 2,i−1 , z 1,i , . . . , z 1,n ) as the start, we interpolate along the i-th dimension towards z 2,i = (z 2,1 , . . . , z 2,i , z 1,i+1 , . . . , z 1,n ). Table 6 illustrates this for a 3D latent code example.",
        "output": "{\"INFO\": [\"the effect of disentanglement in homotopy #TARGET_REF\"], \"PERCEPT\": [\"To observe\", \"to highlight the role of generative factor in generation, we conduct a dimensionwise homotopy, transitioning from the first to the last sentence by interpolating between the dimensions one-by-one.\"], \"BACK\": [\"This is implemented as follows: (i) using prior distribution 7 we sample two latent codes denoted by z 1 = (z 1,1 , z 1,2 , . . . , z 1,n ), z 2 = (z 2,1 , z 2,2 , . . . , z 2,n ), (ii) for i-th dimension, using z 1,i = (z 2,1 , . . . , z 2,i\\u22121 , z 1,i , . . . , z 1,n ) as the start, we interpolate along the i-th dimension towards z 2,i = (z 2,1 , . . . , z 2,i , z 1,i+1 , . . . , z 1,n ). Table 6 illustrates this for a 3D latent code example.\"]}"
    },
    {
        "gold": {
            "text": [
                "•",
                "Contrast",
                "set:",
                "the",
                "evaluation",
                "set",
                "by",
                "#TARGET_REF",
                "that",
                "is",
                "created",
                "based",
                "on",
                "the",
                "official",
                "Quoref",
                "test",
                "set.",
                "For",
                "creating",
                "this",
                "evaluation",
                "set,",
                "the",
                "authors",
                "manually",
                "performed",
                "small",
                "but",
                "meaningful",
                "perturbations",
                "to",
                "the",
                "test",
                "examples",
                "in",
                "a",
                "way",
                "that",
                "it",
                "changes",
                "the",
                "gold",
                "label.",
                "This",
                "dataset",
                "is",
                "constructed",
                "to",
                "evaluate",
                "whether",
                "models",
                "decision",
                "boundaries",
                "align",
                "to",
                "true",
                "decision",
                "boundaries",
                "when",
                "they",
                "are",
                "measured",
                "around",
                "the",
                "same",
                "point."
            ],
            "context": [
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "• Contrast set: the evaluation set by #TARGET_REF that is created based on the official Quoref test set. For creating this evaluation set, the authors manually performed small but meaningful perturbations to the test examples in a way that it changes the gold label. This dataset is constructed to evaluate whether models decision boundaries align to true decision boundaries when they are measured around the same point.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"the evaluation set by #TARGET_REF that is created based on the official Quoref test set.\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "fact,",
                "deploying",
                "ever-larger",
                "models",
                "raises",
                "questions",
                "and",
                "concerns",
                "about",
                "the",
                "increasing",
                "magnitude",
                "of",
                "the",
                "temporal,",
                "financial,",
                "and",
                "environmental",
                "cost",
                "of",
                "training",
                "and",
                "usability",
                "#REF",
                ".",
                "Typically,",
                "due",
                "to",
                "their",
                "resource",
                "requirements,",
                "these",
                "models",
                "are",
                "trained",
                "and",
                "deployed",
                "for",
                "industrial",
                "operations",
                "on",
                "remote",
                "servers.",
                "This",
                "leads",
                "to",
                "a",
                "high",
                "use",
                "of",
                "over-the-air",
                "communications,",
                "which",
                "are",
                "particularly",
                "resourceintensive",
                "#TARGET_REF",
                ".",
                "In",
                "particular,",
                "some",
                "NLP",
                "applications",
                "(speech",
                "recognition,",
                "speech",
                "to",
                "text,",
                "etc.)",
                "have",
                "some",
                "known",
                "problems",
                "related",
                "to",
                "network",
                "latency,",
                "transmission",
                "path",
                "difficulties,",
                "or",
                "privacy",
                "concerns.",
                "To",
                "reduce",
                "the",
                "impact",
                "of",
                "these",
                "communications,",
                "there",
                "is",
                "a",
                "solution",
                "that",
                "is",
                "to",
                "allow",
                "these",
                "models",
                "to",
                "run",
                "directly",
                "on",
                "peripheral",
                "or",
                "mobile",
                "devices,",
                "that",
                "is,",
                "in",
                "environments",
                "with",
                "limited",
                "resources",
                "that",
                "require",
                "lightweight,",
                "responsive",
                "models",
                "and",
                "energy",
                "efficiency.",
                "Reducing",
                "the",
                "size",
                "of",
                "the",
                "models",
                "is",
                "therefore",
                "one",
                "of",
                "the",
                "increasingly",
                "favoured",
                "avenues,",
                "especially",
                "for",
                "the",
                "reduction",
                "of",
                "memory",
                "resources",
                "and",
                "computation",
                "time",
                "involved",
                "in",
                "training",
                "and",
                "use."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In fact, deploying ever-larger models raises questions and concerns about the increasing magnitude of the temporal, financial, and environmental cost of training and usability #REF . Typically, due to their resource requirements, these models are trained and deployed for industrial operations on remote servers. This leads to a high use of over-the-air communications, which are particularly resourceintensive #TARGET_REF . In particular, some NLP applications (speech recognition, speech to text, etc.) have some known problems related to network latency, transmission path difficulties, or privacy concerns. To reduce the impact of these communications, there is a solution that is to allow these models to run directly on peripheral or mobile devices, that is, in environments with limited resources that require lightweight, responsive models and energy efficiency. Reducing the size of the models is therefore one of the increasingly favoured avenues, especially for the reduction of memory resources and computation time involved in training and use.",
        "output": "{\"INFO\": [\"This leads to a high use of over-the-air communications, which are particularly resourceintensive #TARGET_REF .\"], \"PERCEPT\": [\"Typically, due to their resource requirements, these models are trained and deployed for industrial operations on remote servers.\"], \"BACK\": [\"In particular, some NLP applications\", \"have some known problems related to network latency, transmission path difficulties, or privacy concerns.\"]}"
    },
    {
        "gold": {
            "text": [
                "The",
                "interaction",
                "layer",
                "is",
                "the",
                "core",
                "element",
                "of",
                "the",
                "architecture",
                "for",
                "which",
                "several",
                "kinds",
                "attention",
                "mechanisms",
                "has",
                "been",
                "developed",
                "to",
                "improve",
                "the",
                "QA",
                "matching",
                "process",
                "such",
                "as",
                "bi-attention",
                "#REF",
                ",",
                "co-attention",
                "#REF",
                "or",
                "re-attention",
                "#TARGET_REF",
                ",",
                "to",
                "name",
                "just",
                "a",
                "few."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "The interaction layer is the core element of the architecture for which several kinds attention mechanisms has been developed to improve the QA matching process such as bi-attention #REF , co-attention #REF or re-attention #TARGET_REF , to name just a few.",
        "output": "{\"INFO\": [\"re-attention #TARGET_REF ,\"], \"PERCEPT\": [\"The interaction layer is the core element of the architecture for which several kinds attention mechanisms has been developed to improve the QA matching process such as\", \"to name just a few.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "As",
                "shown",
                "in",
                "previous",
                "work",
                "#TARGET_REF",
                ",",
                "increasing",
                "the",
                "depth",
                "of",
                "the",
                "Transformer",
                "encoder",
                "can",
                "substantially",
                "improve",
                "model",
                "performance,",
                "therefore",
                "we",
                "train",
                "the",
                "Transformer",
                "with",
                "deep",
                "encoder",
                "to",
                "obtain",
                "a",
                "better",
                "source",
                "representation."
            ],
            "context": [
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1
            ]
        },
        "input": "As shown in previous work #TARGET_REF , increasing the depth of the Transformer encoder can substantially improve model performance, therefore we train the Transformer with deep encoder to obtain a better source representation.",
        "output": "{\"INFO\": [\"As shown in previous work #TARGET_REF\", \"increasing the depth of the Transformer encoder can substantially improve model performance, therefore we train the Transformer with deep encoder to obtain a better source representation.\"], \"PERCEPT\": [], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "For",
                "the",
                "cosine",
                "similarity",
                "calculation,we",
                "use",
                "word2vec",
                "to",
                "calculate",
                "the",
                "sentence",
                "vector",
                "as",
                "sum",
                "of",
                "the",
                "word",
                "vectors",
                "of",
                "the",
                "words",
                "in",
                "the",
                "sentence.",
                "The",
                "calculation",
                "of",
                "sentence",
                "vector",
                "was",
                "to",
                "take",
                "advantage",
                "of",
                "the",
                "compositionality",
                "property",
                "using",
                "word2vec",
                "#TARGET_REF",
                ".",
                "We",
                "used",
                "word",
                "vectors",
                "of",
                "dimension",
                "100",
                "trained",
                "on",
                "the",
                "2015",
                "wikidump."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "For the cosine similarity calculation,we use word2vec to calculate the sentence vector as sum of the word vectors of the words in the sentence. The calculation of sentence vector was to take advantage of the compositionality property using word2vec #TARGET_REF . We used word vectors of dimension 100 trained on the 2015 wikidump.",
        "output": "{\"INFO\": [\"The calculation of sentence vector was to take advantage of the compositionality property using word2vec #TARGET_REF .\"], \"PERCEPT\": [\"For the cosine similarity calculation,we use word2vec to calculate the sentence vector as sum of the word vectors of the words in the sentence.\", \"We used word vectors of dimension 100 trained on the 2015 wikidump.\"], \"BACK\": []}"
    },
    {
        "gold": {
            "text": [
                "As",
                "shown",
                "in",
                "Figure",
                "3,",
                "we",
                "organize",
                "the",
                "above",
                "three",
                "training",
                "strategies",
                "into",
                "an",
                "effective",
                "training",
                "pipeline",
                "for",
                "the",
                "dual-encoder.",
                "It",
                "makes",
                "an",
                "analogy",
                "to",
                "a",
                "multi-stage",
                "rocket,",
                "where",
                "the",
                "performance",
                "of",
                "the",
                "dual-encoder",
                "is",
                "consecutively",
                "improved",
                "at",
                "three",
                "steps",
                "(STEP",
                "1,",
                "3",
                "and",
                "4).",
                "That",
                "is",
                "why",
                "we",
                "call",
                "our",
                "approach",
                "RocketQA.",
                "Next,",
                "we",
                "will",
                "describe",
                "the",
                "details",
                "of",
                "the",
                "whole",
                "training",
                "procedure",
                "of",
                "RocketQA.",
                "D",
                "from",
                "C",
                "for",
                "each",
                "question",
                "q",
                "∈",
                "Q",
                "L",
                ".",
                "This",
                "design",
                "is",
                "to",
                "let",
                "the",
                "cross-encoder",
                "adjust",
                "to",
                "the",
                "distribution",
                "of",
                "the",
                "results",
                "retrieved",
                "by",
                "the",
                "dualencoder,",
                "since",
                "the",
                "cross-encoder",
                "will",
                "be",
                "used",
                "in",
                "the",
                "following",
                "two",
                "steps",
                "for",
                "optimizing",
                "the",
                "dualencoder.",
                "This",
                "design",
                "is",
                "important,",
                "and",
                "there",
                "is",
                "similar",
                "observation",
                "in",
                "Facebook",
                "Search",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1
            ]
        },
        "input": "As shown in Figure 3, we organize the above three training strategies into an effective training pipeline for the dual-encoder. It makes an analogy to a multi-stage rocket, where the performance of the dual-encoder is consecutively improved at three steps (STEP 1, 3 and 4). That is why we call our approach RocketQA. Next, we will describe the details of the whole training procedure of RocketQA. D from C for each question q ∈ Q L . This design is to let the cross-encoder adjust to the distribution of the results retrieved by the dualencoder, since the cross-encoder will be used in the following two steps for optimizing the dualencoder. This design is important, and there is similar observation in Facebook Search #TARGET_REF .",
        "output": "{\"INFO\": [\"Facebook Search #TARGET_REF .\"], \"PERCEPT\": [\"This design is important, and there is similar observation in\"], \"BACK\": [\"As shown in Figure 3, we organize the above three training strategies into an effective training pipeline for the dual-encoder. It makes an analogy to a multi-stage rocket, where the performance of the dual-encoder is consecutively improved at three steps (STEP 1, 3 and 4).\"]}"
    },
    {
        "gold": {
            "text": [
                "We",
                "achieved",
                "the",
                "best",
                "result",
                "with",
                "the",
                "Gradient",
                "Boosting",
                "classifier",
                "5",
                "using",
                "only",
                "10%",
                "of",
                "the",
                "prelabeled",
                "nodes",
                "i.e.,",
                "the",
                "classification",
                "does",
                "not",
                "improve",
                "after",
                "this",
                "percentage.",
                "Table",
                "3",
                "Besides",
                "our",
                "approach,",
                "we",
                "evaluated",
                "other",
                "graph",
                "models",
                "of",
                "different",
                "structures.",
                "First,",
                "we",
                "used",
                "the",
                "network",
                "graph",
                "developed",
                "by",
                "#REF",
                ".",
                "That",
                "graph",
                "does",
                "not",
                "use",
                "weight",
                "between",
                "the",
                "nodes.",
                "Second,",
                "we",
                "used",
                "the",
                "Term",
                "Frequency-Inverse",
                "Document",
                "Frequency",
                "(TF-IDF)",
                "as",
                "weight",
                "instead",
                "of",
                "the",
                "average",
                "of",
                "embeddings.",
                "Third,",
                "we",
                "used",
                "bigrams",
                "and",
                "trigrams",
                "as",
                "nodes",
                "rather",
                "than",
                "token",
                "nodes.",
                "Finally,",
                "we",
                "used",
                "the",
                "Pointwise",
                "Mutual",
                "Information",
                "(PMI)",
                "measure",
                "#TARGET_REF",
                "as",
                "the",
                "weight",
                "between",
                "the",
                "bi",
                "and",
                "trigrams",
                "nodes.",
                "For",
                "these",
                "approaches,",
                "we",
                "adopted",
                "the",
                "same",
                "regularization",
                "algorithm,",
                "ranging",
                "the",
                "pre-labeled",
                "nodes",
                "from",
                "5%",
                "to",
                "30%.",
                "In",
                "Table",
                "4,",
                "we",
                "present",
                "the",
                "bestachieved",
                "results.",
                "From",
                "this",
                "table,",
                "our",
                "graph",
                "modeling",
                "and",
                "the",
                "gradient",
                "boosting",
                "classifier",
                "achieved",
                "better",
                "results",
                "than",
                "these",
                "other",
                "graphs,",
                "as",
                "well",
                "as",
                "classifier",
                "variations.",
                "This,",
                "we",
                "think,",
                "is",
                "because",
                "of",
                "the",
                "embedding",
                "value",
                "among",
                "the",
                "graph",
                "nodes",
                "since",
                "it",
                "is",
                "able",
                "to",
                "capture",
                "morphological,",
                "syntactic,",
                "and",
                "semantic",
                "knowledge",
                "of",
                "a",
                "word.",
                "As",
                "we",
                "used",
                "the",
                "average",
                "word",
                "embedding",
                "value,",
                "it",
                "includes",
                "information",
                "from",
                "all",
                "of",
                "the",
                "individual",
                "vector",
                "values,",
                "working",
                "as",
                "an",
                "overall",
                "summary",
                "of",
                "all",
                "vector",
                "values."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                0,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "We achieved the best result with the Gradient Boosting classifier 5 using only 10% of the prelabeled nodes i.e., the classification does not improve after this percentage. Table 3 Besides our approach, we evaluated other graph models of different structures. First, we used the network graph developed by #REF . That graph does not use weight between the nodes. Second, we used the Term Frequency-Inverse Document Frequency (TF-IDF) as weight instead of the average of embeddings. Third, we used bigrams and trigrams as nodes rather than token nodes. Finally, we used the Pointwise Mutual Information (PMI) measure #TARGET_REF as the weight between the bi and trigrams nodes. For these approaches, we adopted the same regularization algorithm, ranging the pre-labeled nodes from 5% to 30%. In Table 4, we present the bestachieved results. From this table, our graph modeling and the gradient boosting classifier achieved better results than these other graphs, as well as classifier variations. This, we think, is because of the embedding value among the graph nodes since it is able to capture morphological, syntactic, and semantic knowledge of a word. As we used the average word embedding value, it includes information from all of the individual vector values, working as an overall summary of all vector values.",
        "output": "{\"INFO\": [\"the Pointwise Mutual Information (PMI) measure #TARGET_REF as the weight between the bi and trigrams nodes.\"], \"PERCEPT\": [\"we used\", \"we adopted\"], \"BACK\": [\"the same regularization algorithm, ranging the pre-labeled nodes from 5% to 30%.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "compare",
                "the",
                "linguistic",
                "annotation",
                "performance,",
                "we",
                "prepared",
                "a",
                "pipeline",
                "system,",
                "i.e.,",
                "ASR",
                "followed",
                "by",
                "an",
                "NLP-based",
                "linguistic",
                "annotation.",
                "In",
                "the",
                "pipeline",
                "system,",
                "the",
                "separated",
                "model",
                "of",
                "CTC+Transformer",
                "first",
                "predicts",
                "graphemic",
                "sequences.",
                "Then,",
                "the",
                "linear",
                "SVM",
                "with",
                "L2",
                "normalization,",
                "trained",
                "using",
                "KyTea",
                "#TARGET_REF",
                ",",
                "predicts",
                "word",
                "boundaries",
                "and",
                "linguistic",
                "annotation",
                "from",
                "the",
                "predicted",
                "sequences.",
                "To",
                "train",
                "KyTea,",
                "we",
                "only",
                "used",
                "the",
                "transcriptions",
                "in",
                "the",
                "ASR",
                "training",
                "set",
                "to",
                "perform",
                "a",
                "fair",
                "comparison",
                "to",
                "the",
                "proposed",
                "method."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2
            ]
        },
        "input": "To compare the linguistic annotation performance, we prepared a pipeline system, i.e., ASR followed by an NLP-based linguistic annotation. In the pipeline system, the separated model of CTC+Transformer first predicts graphemic sequences. Then, the linear SVM with L2 normalization, trained using KyTea #TARGET_REF , predicts word boundaries and linguistic annotation from the predicted sequences. To train KyTea, we only used the transcriptions in the ASR training set to perform a fair comparison to the proposed method.",
        "output": "{\"INFO\": [\"KyTea #TARGET_REF ,\"], \"PERCEPT\": [\"we only used the transcriptions in the ASR training set to perform a fair comparison to the proposed method.\"], \"BACK\": [\"the linear SVM with L2 normalization, trained using\", \"predicts word boundaries and linguistic annotation from the predicted sequences. To train KyTea,\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "this",
                "paper",
                "we",
                "have",
                "presented",
                "a",
                "more",
                "fine-grained",
                "analysis",
                "of",
                "the",
                "Levin",
                "classes",
                "which",
                "highlights",
                "the",
                "semantic",
                "components",
                "entailed",
                "by",
                "certain",
                "syntactic",
                "frames,",
                "and",
                "hence",
                "the",
                "semantic",
                "components",
                "of",
                "entire",
                "classes",
                "of",
                "verbs.",
                "We",
                "hypothesize",
                "that",
                "the",
                "semantic",
                "components",
                "we",
                "are",
                "identifying",
                "will",
                "be",
                "useful",
                "for",
                "cross-linguistic",
                "generalizations.",
                "An",
                "important",
                "avenue",
                "of",
                "future",
                "research",
                "which",
                "we",
                "intend",
                "to",
                "explore",
                "is",
                "the",
                "comparison",
                "of",
                "the",
                "translations",
                "of",
                "these",
                "classes",
                "to",
                "independently-defined",
                "classes",
                "in",
                "other",
                "languages,",
                "such",
                "as",
                "French",
                "verb",
                "classes",
                "#TARGET_REF",
                "or",
                "European",
                "WordNet.",
                "3",
                "These",
                "cross-linguistic",
                "generalizations",
                "will",
                "be",
                "equally",
                "valuable",
                "for",
                "both",
                "transfer-based",
                "and",
                "interlinguabased",
                "approaches",
                "to",
                "machine",
                "translation.",
                "Presumably",
                "both",
                "approaches",
                "need",
                "to",
                "be",
                "augmented",
                "with",
                "pragmatic",
                "information",
                "about",
                "tense",
                "and",
                "aspect",
                "and",
                "information",
                "structure,",
                "in",
                "particular",
                "coreference,",
                "in",
                "order",
                "to",
                "provide",
                "an",
                "adequate",
                "basis",
                "for",
                "translation",
                "in",
                "many",
                "circumstances.",
                "It",
                "could",
                "be",
                "argued",
                "that",
                "a",
                "language-specific",
                "predicate-argument",
                "structure",
                "will",
                "lend",
                "itself",
                "more",
                "readily",
                "to",
                "language-specific",
                "pragmatic",
                "annotation",
                "than",
                "a",
                "language-independent",
                "one,",
                "but",
                "it",
                "would",
                "still",
                "be",
                "necessary",
                "to",
                "ensure",
                "that",
                "the",
                "pragmatic",
                "annotation",
                "was",
                "meaningful",
                "in",
                "the",
                "target",
                "languages",
                "as",
                "well,",
                "i.e.,",
                "cross-linguistic.",
                "The",
                "discovery",
                "of",
                "cross-linguistic",
                "pragmatic",
                "features",
                "is",
                "an",
                "equally",
                "important",
                "area",
                "for",
                "future",
                "research."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In this paper we have presented a more fine-grained analysis of the Levin classes which highlights the semantic components entailed by certain syntactic frames, and hence the semantic components of entire classes of verbs. We hypothesize that the semantic components we are identifying will be useful for cross-linguistic generalizations. An important avenue of future research which we intend to explore is the comparison of the translations of these classes to independently-defined classes in other languages, such as French verb classes #TARGET_REF or European WordNet. 3 These cross-linguistic generalizations will be equally valuable for both transfer-based and interlinguabased approaches to machine translation. Presumably both approaches need to be augmented with pragmatic information about tense and aspect and information structure, in particular coreference, in order to provide an adequate basis for translation in many circumstances. It could be argued that a language-specific predicate-argument structure will lend itself more readily to language-specific pragmatic annotation than a language-independent one, but it would still be necessary to ensure that the pragmatic annotation was meaningful in the target languages as well, i.e., cross-linguistic. The discovery of cross-linguistic pragmatic features is an equally important area for future research.",
        "output": "{\"INFO\": [\"French verb classes #TARGET_REF\"], \"PERCEPT\": [\"An important avenue of future research\", \"is the comparison of the translations of these classes to independently-defined classes in other languages, such as\"], \"BACK\": [\"fine-grained analysis of the Levin classes\", \"which we intend to explore\", \"or European WordNet.\"]}"
    },
    {
        "gold": {
            "text": [
                "To",
                "address",
                "the",
                "above",
                "issues,",
                "we",
                "propose",
                "to",
                "learn",
                "natural",
                "language",
                "actions",
                "that",
                "represent",
                "system",
                "utterances",
                "as",
                "a",
                "span",
                "of",
                "words,",
                "which",
                "explicitly",
                "reveal",
                "the",
                "underlying",
                "intentions.",
                "Natural",
                "language",
                "provides",
                "unique",
                "compositional",
                "structure",
                "while",
                "retaining",
                "the",
                "representation",
                "flexibility.",
                "These",
                "properties",
                "promote",
                "model",
                "generalization",
                "and",
                "thus",
                "make",
                "natural",
                "language",
                "a",
                "flexible",
                "representation",
                "for",
                "capturing",
                "characteristics",
                "with",
                "minimal",
                "assumptions",
                "#TARGET_REF",
                ".",
                "Motivated",
                "by",
                "these",
                "advantages,",
                "we",
                "learn",
                "natural",
                "language",
                "actions",
                "by",
                "identifying",
                "salient",
                "words",
                "of",
                "system",
                "utterances.",
                "Salient",
                "refers",
                "to",
                "indicative",
                "for",
                "a",
                "prediction",
                "task",
                "(e.g.,",
                "sentiment",
                "analysis)",
                "that",
                "takes",
                "as",
                "input",
                "the",
                "original",
                "utterance.",
                "The",
                "main",
                "rationale",
                "is",
                "that",
                "the",
                "principal",
                "information",
                "that",
                "the",
                "task",
                "concerns",
                "can",
                "be",
                "preserved",
                "by",
                "just",
                "the",
                "salient",
                "words.",
                "For",
                "example,",
                "the",
                "sentiment",
                "of",
                "sentence",
                "\"The",
                "movie",
                "starts",
                "out",
                "as",
                "competent",
                "but",
                "turn",
                "bland\"",
                "can",
                "be",
                "revealed",
                "by",
                "the",
                "word",
                "\"bland\"",
                "when",
                "it",
                "is",
                "identified",
                "salient",
                "by",
                "considering",
                "the",
                "complete",
                "context.",
                "In",
                "our",
                "scenarios,",
                "we",
                "consider",
                "measuring",
                "word",
                "saliency",
                "in",
                "terms",
                "of",
                "state",
                "transitions.",
                "This",
                "is",
                "because",
                "state",
                "transitions",
                "reflect",
                "how",
                "the",
                "intentions",
                "of",
                "a",
                "system",
                "utterance",
                "influence",
                "the",
                "dialogue",
                "progress,",
                "and",
                "action",
                "representations",
                "that",
                "capture",
                "such",
                "influences",
                "can",
                "well",
                "reveal",
                "the",
                "intentions",
                "#REF",
                ".",
                "By",
                "considering",
                "salient",
                "words",
                "for",
                "state",
                "tracking",
                "tasks",
                "as",
                "actions,",
                "we",
                "obtain",
                "action",
                "representations",
                "that",
                "enjoy",
                "the",
                "merits",
                "of",
                "natural",
                "language",
                "and",
                "indeed",
                "capture",
                "the",
                "characteristics",
                "of",
                "interest,",
                "i.e.,",
                "intentions",
                "of",
                "system",
                "utterances."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "To address the above issues, we propose to learn natural language actions that represent system utterances as a span of words, which explicitly reveal the underlying intentions. Natural language provides unique compositional structure while retaining the representation flexibility. These properties promote model generalization and thus make natural language a flexible representation for capturing characteristics with minimal assumptions #TARGET_REF . Motivated by these advantages, we learn natural language actions by identifying salient words of system utterances. Salient refers to indicative for a prediction task (e.g., sentiment analysis) that takes as input the original utterance. The main rationale is that the principal information that the task concerns can be preserved by just the salient words. For example, the sentiment of sentence \"The movie starts out as competent but turn bland\" can be revealed by the word \"bland\" when it is identified salient by considering the complete context. In our scenarios, we consider measuring word saliency in terms of state transitions. This is because state transitions reflect how the intentions of a system utterance influence the dialogue progress, and action representations that capture such influences can well reveal the intentions #REF . By considering salient words for state tracking tasks as actions, we obtain action representations that enjoy the merits of natural language and indeed capture the characteristics of interest, i.e., intentions of system utterances.",
        "output": "{\"INFO\": [\"These properties promote model generalization and thus make natural language a flexible representation for capturing characteristics with minimal assumptions\"], \"PERCEPT\": [\"Motivated by these advantages, we learn natural language actions by identifying salient words of system utterances.\"], \"BACK\": [\"Natural language provides unique compositional structure while retaining the representation flexibility.\"]}"
    },
    {
        "gold": {
            "text": [
                "Generating",
                "Job",
                "Ads",
                "We",
                "use",
                "the",
                "OpenAI",
                "Davinci",
                "GPT-3",
                "model",
                "which",
                "has",
                "been",
                "adapted",
                "for",
                "natural",
                "language",
                "requests.",
                "We",
                "use",
                "default",
                "parameters",
                "values",
                "and",
                "500",
                "maximum",
                "tokens",
                "per",
                "completion",
                "(see",
                "Appendix",
                "B",
                "for",
                "hyperparameter",
                "details).",
                "Keeping",
                "default",
                "parameters",
                "better",
                "reflects",
                "when",
                "non-technical",
                "users",
                "apply",
                "large-scale",
                "generative",
                "models",
                "\"out-of-the-box\"",
                "#TARGET_REF",
                "."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                0
            ]
        },
        "input": "Generating Job Ads We use the OpenAI Davinci GPT-3 model which has been adapted for natural language requests. We use default parameters values and 500 maximum tokens per completion (see Appendix B for hyperparameter details). Keeping default parameters better reflects when non-technical users apply large-scale generative models \"out-of-the-box\" #TARGET_REF .",
        "output": "{\"INFO\": [\"Keeping default parameters better reflects when non-technical users apply large-scale generative models \\\"out-of-the-box\\\" #TARGET_REF\"], \"PERCEPT\": [\"We use default parameters values and 500 maximum tokens per completion\"], \"BACK\": [\"Generating Job Ads We use the OpenAI Davinci GPT-3 model\", \"(see Appendix B for hyperparameter details).\"]}"
    },
    {
        "gold": {
            "text": [
                "Corpus",
                "diversity",
                "(⇑).",
                "Distinct-k",
                "#TARGET_REF",
                "measures",
                "the",
                "total",
                "number",
                "of",
                "unique",
                "k-grams",
                "normalized",
                "by",
                "the",
                "total",
                "number",
                "of",
                "generated",
                "k-gram",
                "tokens",
                "to",
                "avoid",
                "favoring",
                "long",
                "sentences.",
                "Entropyk",
                "#REF",
                "reflects",
                "how",
                "evenly",
                "the",
                "empirical",
                "k-gram",
                "distribution",
                "is",
                "for",
                "a",
                "given",
                "sentence",
                "when",
                "word",
                "frequency",
                "is",
                "considered.",
                "Human",
                "6.62",
                "0.0",
                "12.43",
                "0.0",
                "10.36",
                "0.0",
                "6.04",
                "0.0",
                "53.57",
                "0.0",
                "10.84",
                "0.0",
                "100.0",
                "0.0",
                "100.0",
                "0.0",
                "*",
                "Metrics:",
                "SB-3/4:",
                "Self-BLEU-3/4",
                "(⇓),",
                "D-2:",
                "Distinct-2",
                "(⇑),",
                "E-4:",
                "Entropy-4",
                "(⇑),",
                "B-4:",
                "BLEU-4",
                "(⇑),",
                "R-L:",
                "ROUGE-L",
                "(⇑)#Uni.C(⇑)",
                "Jaccard",
                "(⇓)",
                "SB-3",
                "(⇓)",
                "SB-4",
                "(⇓)",
                "D-2(⇑)",
                "E-4(⇑)",
                "B-4",
                "(⇑)",
                "R-L",
                "(⇑)",
                "CVAE",
                "z",
                "="
            ],
            "context": [
                0,
                0,
                0,
                1,
                0,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "Corpus diversity (⇑). Distinct-k #TARGET_REF measures the total number of unique k-grams normalized by the total number of generated k-gram tokens to avoid favoring long sentences. Entropyk #REF reflects how evenly the empirical k-gram distribution is for a given sentence when word frequency is considered. Human 6.62 0.0 12.43 0.0 10.36 0.0 6.04 0.0 53.57 0.0 10.84 0.0 100.0 0.0 100.0 0.0 * Metrics: SB-3/4: Self-BLEU-3/4 (⇓), D-2: Distinct-2 (⇑), E-4: Entropy-4 (⇑), B-4: BLEU-4 (⇑), R-L: ROUGE-L (⇑)#Uni.C(⇑) Jaccard (⇓) SB-3 (⇓) SB-4 (⇓) D-2(⇑) E-4(⇑) B-4 (⇑) R-L (⇑) CVAE z =",
        "output": "{\"INFO\": [\"Distinct-k\", \"measures the total number of unique k-grams normalized by the total number of generated k-gram tokens to avoid favoring long sentences.\"], \"PERCEPT\": [], \"BACK\": [\"Entropyk #REF reflects how evenly the empirical k-gram distribution is for a given sentence when word frequency is considered.\"]}"
    },
    {
        "gold": {
            "text": [
                "complexity,",
                "robustness",
                "to",
                "atypical",
                "input,",
                "utilization",
                "of",
                "off-the-shelf",
                "language",
                "models,",
                "conceptual",
                "simplicity)",
                "while",
                "also",
                "having",
                "a",
                "degree",
                "of",
                "compositionality,",
                "traditionally",
                "a",
                "property",
                "of",
                "grammar-based",
                "systems.",
                "Specifically,",
                "our",
                "system",
                "learns",
                "to",
                "assign",
                "each",
                "token",
                "of",
                "an",
                "utterance",
                "one",
                "of",
                "a",
                "finite",
                "set",
                "of",
                "abstract",
                "meaning",
                "fragments",
                "that",
                "are",
                "deterministically",
                "combined",
                "to",
                "give",
                "the",
                "meaning",
                "of",
                "the",
                "whole",
                "utterance.",
                "While",
                "our",
                "system",
                "may",
                "not",
                "fulfill",
                "all",
                "criteria",
                "of",
                "compositionality",
                "according",
                "to",
                "some",
                "definitions,",
                "it",
                "can",
                "arguably",
                "reap",
                "some",
                "of",
                "compositionality's",
                "benefits,",
                "which",
                "make",
                "it",
                "suitable",
                "for",
                "use",
                "in",
                "semi-automatic",
                "annotation",
                "workflows.",
                "We",
                "discuss",
                "this",
                "further",
                "in",
                "Section",
                "5.",
                "Previous",
                "work",
                "has",
                "introduced",
                "trainable",
                "compositional",
                "semantic",
                "parsers",
                "for",
                "AMR",
                "#TARGET_REF",
                "and",
                "DRS",
                "#REF",
                ".",
                "In",
                "this",
                "paper,",
                "we",
                "improve",
                "upon",
                "the",
                "latter",
                "parser",
                "using",
                "a",
                "novel",
                "way",
                "to",
                "encode",
                "anchored",
                "DRSs",
                "as",
                "sequences,",
                "and",
                "thereby",
                "cast",
                "DRS",
                "parsing",
                "simply",
                "as",
                "a",
                "sequence",
                "labeling",
                "task",
                "(",
                "§2).",
                "We",
                "use",
                "a",
                "standard",
                "transformer-based",
                "model",
                "to",
                "learn",
                "this",
                "task,",
                "followed",
                "by",
                "post-processing",
                "to",
                "ensure",
                "well-formed",
                "DRSs",
                "(",
                "§3).",
                "We",
                "use",
                "training",
                "data",
                "from",
                "the",
                "Parallel",
                "Meaning",
                "Bank",
                "(",
                "§4).",
                "The",
                "accuracy",
                "of",
                "our",
                "model",
                "approaches",
                "the",
                "state",
                "of",
                "the",
                "art",
                "with",
                "the",
                "additional",
                "benefit",
                "of",
                "being,",
                "to",
                "a",
                "degree,",
                "compositional",
                "(",
                "§5).",
                "We",
                "give",
                "an",
                "error",
                "analysis",
                "in",
                "§6",
                "and",
                "conclude",
                "in",
                "§7."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "complexity, robustness to atypical input, utilization of off-the-shelf language models, conceptual simplicity) while also having a degree of compositionality, traditionally a property of grammar-based systems. Specifically, our system learns to assign each token of an utterance one of a finite set of abstract meaning fragments that are deterministically combined to give the meaning of the whole utterance. While our system may not fulfill all criteria of compositionality according to some definitions, it can arguably reap some of compositionality's benefits, which make it suitable for use in semi-automatic annotation workflows. We discuss this further in Section 5. Previous work has introduced trainable compositional semantic parsers for AMR #TARGET_REF and DRS #REF . In this paper, we improve upon the latter parser using a novel way to encode anchored DRSs as sequences, and thereby cast DRS parsing simply as a sequence labeling task ( §2). We use a standard transformer-based model to learn this task, followed by post-processing to ensure well-formed DRSs ( §3). We use training data from the Parallel Meaning Bank ( §4). The accuracy of our model approaches the state of the art with the additional benefit of being, to a degree, compositional ( §5). We give an error analysis in §6 and conclude in §7.",
        "output": "{\"INFO\": [\"for AMR #TARGET_REF\"], \"PERCEPT\": [\"While our system may not fulfill all criteria of compositionality according to some definitions, it can arguably reap some of compositionality's benefits, which make it suitable for use in semi-automatic annotation workflows.\"], \"BACK\": [\"Previous work has introduced trainable compositional semantic parsers\", \"and DRS #REF .\"]}"
    },
    {
        "gold": {
            "text": [
                "One",
                "frequently",
                "used",
                "NN",
                "architecture",
                "#TARGET_REF",
                ")",
                "that",
                "maximizes",
                "Eq.",
                "(",
                "3)",
                "is",
                "the",
                "O2M",
                "model",
                "trained",
                "with",
                "multi-task",
                "learning.",
                "Fig.",
                "1(a)",
                "shows",
                "the",
                "architecture",
                "of",
                "the",
                "model.",
                "The",
                "O2M",
                "model",
                "outputs",
                "several",
                "types",
                "of",
                "sequences",
                "independently.",
                "In",
                "other",
                "words,",
                "multi-task",
                "learning",
                "is",
                "derived",
                "by",
                "assuming",
                "conditional",
                "independence",
                "of",
                "output",
                "token",
                "types",
                "for",
                "Eq.",
                "(",
                "3),",
                "as",
                "follows:"
            ],
            "context": [
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "One frequently used NN architecture #TARGET_REF ) that maximizes Eq. ( 3) is the O2M model trained with multi-task learning. Fig. 1(a) shows the architecture of the model. The O2M model outputs several types of sequences independently. In other words, multi-task learning is derived by assuming conditional independence of output token types for Eq. ( 3), as follows:",
        "output": "{\"INFO\": [\"NN architecture #TARGET_REF )\"], \"PERCEPT\": [\"One frequently used\", \"that maximizes Eq. ( 3) is the O2M model trained with multi-task learning.\"], \"BACK\": [\"Fig. 1(a) shows the architecture of the model.\"]}"
    },
    {
        "gold": {
            "text": [
                "Simple",
                "definition",
                "in",
                "OALD",
                "a",
                "notice",
                "or",
                "announcement",
                "in",
                "a",
                "public",
                "medium",
                "promoting",
                "a",
                "product,",
                "service,",
                "or",
                "event",
                "or",
                "publicizing",
                "a",
                "job",
                "vacancy.",
                "current",
                "context",
                "because",
                "of",
                "the",
                "cognitively",
                "inaccurate",
                "nature",
                "of",
                "discrete",
                "sense",
                "boundaries",
                "#REF",
                ".",
                "Secondly,",
                "the",
                "predefined",
                "inventories",
                "need",
                "to",
                "be",
                "updated",
                "manually",
                "by",
                "lexicographers,",
                "which",
                "is",
                "time-consuming",
                "and",
                "causes",
                "dictionaries",
                "to",
                "lag",
                "behind",
                "the",
                "ever-changing",
                "language",
                "usage.",
                "Different",
                "from",
                "previous",
                "work",
                "#TARGET_REF",
                "that",
                "focused",
                "only",
                "on",
                "how",
                "to",
                "generate",
                "definitions,",
                "we",
                "further",
                "propose",
                "a",
                "novel",
                "task",
                "of",
                "Simple",
                "Definition",
                "Generation",
                "(SDG).",
                "Making",
                "the",
                "definitions",
                "easier",
                "to",
                "read",
                "and",
                "understand",
                "could",
                "benefit",
                "the",
                "language",
                "learners,",
                "low",
                "literacy",
                "readers,",
                "as",
                "well",
                "as",
                "helping",
                "people",
                "with",
                "aphasia",
                "or",
                "dyslexia.",
                "For",
                "example,",
                "compared",
                "with",
                "the",
                "Oxford",
                "Dictionary",
                "(OD),",
                "the",
                "Oxford",
                "Advanced",
                "Learner's",
                "Dictionary",
                "(OALD)",
                "has",
                "simpler",
                "definitions,",
                "which",
                "are",
                "specifically",
                "designed",
                "for",
                "language",
                "learners.",
                "As",
                "shown",
                "in",
                "Figure",
                "1,",
                "the",
                "definition",
                "of",
                "the",
                "word",
                "advertisement",
                "in",
                "OALD",
                "does",
                "not",
                "contain",
                "difficult",
                "words",
                "or",
                "phrases",
                "such",
                "as",
                "announcement",
                "and",
                "public",
                "medium."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                2,
                1,
                1,
                1,
                1,
                1,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "Simple definition in OALD a notice or announcement in a public medium promoting a product, service, or event or publicizing a job vacancy. current context because of the cognitively inaccurate nature of discrete sense boundaries #REF . Secondly, the predefined inventories need to be updated manually by lexicographers, which is time-consuming and causes dictionaries to lag behind the ever-changing language usage. Different from previous work #TARGET_REF that focused only on how to generate definitions, we further propose a novel task of Simple Definition Generation (SDG). Making the definitions easier to read and understand could benefit the language learners, low literacy readers, as well as helping people with aphasia or dyslexia. For example, compared with the Oxford Dictionary (OD), the Oxford Advanced Learner's Dictionary (OALD) has simpler definitions, which are specifically designed for language learners. As shown in Figure 1, the definition of the word advertisement in OALD does not contain difficult words or phrases such as announcement and public medium.",
        "output": "{\"INFO\": [\"#TARGET_REF that focused\", \"on how to generate definitions,\"], \"PERCEPT\": [\"Different from previous work\", \"only\", \"we further propose a novel task of Simple Definition Generation (SDG). Making the definitions easier to read and understand could benefit the language learners, low literacy readers, as well as helping people with aphasia or dyslexia.\"], \"BACK\": [\"For example, compared with the Oxford Dictionary (OD), the Oxford Advanced Learner's Dictionary (OALD) has simpler definitions, which are specifically designed for language learners. As shown in Figure 1, the definition of the word advertisement in OALD does not contain difficult words or phrases such as announcement and public medium.\"]}"
    },
    {
        "gold": {
            "text": [
                "DMSNAP",
                "is",
                "capable",
                "of",
                "resolving",
                "this",
                "lexical",
                "ambiguity",
                "through",
                "use",
                "of",
                "contextual",
                "priming",
                "using",
                "the",
                "contextual",
                "marker",
                "(C-Marker)",
                "#TARGET_REF",
                "and",
                "the",
                "cost-based",
                "disambiguation",
                "#REF",
                ".",
                "Sentence",
                "s3",
                "contains",
                "a",
                "word",
                "sense",
                "ambiguity",
                "in",
                "the",
                "interpretation",
                "of",
                "the",
                "word",
                "'paper''",
                "as",
                "either",
                "a",
                "technical",
                "document",
                "or",
                "a",
                "sheet",
                "of",
                "paper.",
                "Upon",
                "reading",
                "'paper',",
                "C-THESIS",
                "and",
                "C-PAPER",
                "are",
                "activated.",
                "At",
                "this",
                "time,",
                "C-THESIS",
                "has",
                "a",
                "C-MARKER.",
                "The",
                "C-MARKER",
                "comes",
                "from",
                "activation",
                "of",
                "C-IJCAI-91",
                "and",
                "C-CONFERENCE,",
                "in",
                "previous",
                "sentences,",
                "which",
                "has",
                "contextual",
                "links",
                "connecting",
                "concepts",
                "relevant",
                "to",
                "academic",
                "conference",
                "such",
                "as",
                "C-THESIS.",
                "The",
                "meaning",
                "hypothesis",
                "containing",
                "C-THESIS",
                "costs",
                "less",
                "than",
                "the",
                "one",
                "with",
                "C-PAPER",
                "so",
                "that",
                "it",
                "is",
                "selected",
                "as",
                "the",
                "best",
                "hypothesis."
            ],
            "context": [
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "DMSNAP is capable of resolving this lexical ambiguity through use of contextual priming using the contextual marker (C-Marker) #TARGET_REF and the cost-based disambiguation #REF . Sentence s3 contains a word sense ambiguity in the interpretation of the word 'paper'' as either a technical document or a sheet of paper. Upon reading 'paper', C-THESIS and C-PAPER are activated. At this time, C-THESIS has a C-MARKER. The C-MARKER comes from activation of C-IJCAI-91 and C-CONFERENCE, in previous sentences, which has contextual links connecting concepts relevant to academic conference such as C-THESIS. The meaning hypothesis containing C-THESIS costs less than the one with C-PAPER so that it is selected as the best hypothesis.",
        "output": "{\"INFO\": [\"the contextual marker (C-Marker) #TARGET_REF\"], \"PERCEPT\": [\"DMSNAP is capable of resolving this lexical ambiguity through use of contextual priming using\"], \"BACK\": [\"and the cost-based disambiguation #REF . Sentence s3 contains a word sense ambiguity in the interpretation of the word 'paper'' as either a technical document or a sheet of paper. Upon reading 'paper', C-THESIS and C-PAPER are activated. At this time, C-THESIS has a C-MARKER. The C-MARKER comes from activation of C-IJCAI-91 and C-CONFERENCE, in previous sentences, which has contextual links connecting concepts relevant to academic conference such as C-THESIS. The meaning hypothesis containing C-THESIS costs less than the one with C-PAPER so that it is selected as the best hypothesis.\"]}"
    },
    {
        "gold": {
            "text": [
                "A",
                "linear",
                "indexed",
                "grammar",
                "is",
                "a",
                "tuple",
                "(Vr,",
                "V",
                "N",
                ",",
                "Vi,",
                "P,",
                "S),",
                "where",
                "Vr",
                "is",
                "a",
                "finite",
                "set",
                "of",
                "terminals,",
                "V",
                "N",
                "a",
                "finite",
                "set",
                "of",
                "non-terminals,",
                "Vi",
                "is",
                "a",
                "finite",
                "set",
                "of",
                "indices,",
                "SE",
                "V",
                "N",
                "is",
                "the",
                "start",
                "symbol",
                "and",
                "Pisa",
                "finite",
                "set",
                "of",
                "productions.",
                "Following",
                "#TARGET_REF",
                "we",
                "consider",
                "productions",
                "in",
                "which",
                "at",
                "most",
                "one",
                "element",
                "can",
                "be",
                "pushed",
                "on",
                "or",
                "popped",
                "from",
                "a",
                "stack",
                "of",
                "indices",
                ":Ao",
                "[oo",
                "1",
                "]",
                "➔",
                "Ai",
                "[]",
                "...",
                "Ai",
                "-i",
                "l",
                "]",
                "Ai[oo,']",
                "Ai-i",
                "l",
                "]",
                "...",
                "Am",
                "[]",
                "Ao",
                "[",
                "]",
                "➔",
                "awhere",
                "m",
                "is",
                "the",
                "length",
                "of",
                "the",
                "production,",
                "A",
                "i",
                "E",
                "VN",
                "for",
                "each",
                "O",
                "-�",
                "j",
                "�",
                "m,",
                "Ai",
                "is",
                "the",
                "dependent",
                "child,",
                "oo",
                "is",
                "the",
                "part",
                "of",
                "the",
                "indices",
                "stack",
                "transmitted",
                "from",
                "the",
                "father",
                "to",
                "the",
                "dependent",
                "child,",
                ",",
                ",",
                ",'",
                "E",
                "Vi",
                "U",
                "{",
                "€}",
                "and",
                "for",
                "each",
                "production",
                "either",
                ",",
                "or",
                ",'",
                "or",
                "both",
                "must",
                "be",
                "€",
                "and",
                "a",
                "E",
                "VT",
                "U",
                "{",
                "€}."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "A linear indexed grammar is a tuple (Vr, V N , Vi, P, S), where Vr is a finite set of terminals, V N a finite set of non-terminals, Vi is a finite set of indices, SE V N is the start symbol and Pisa finite set of productions. Following #TARGET_REF we consider productions in which at most one element can be pushed on or popped from a stack of indices :Ao [oo 1 ] ➔ Ai [] ... Ai -i l ] Ai[oo,'] Ai-i l ] ... Am [] Ao [ ] ➔ awhere m is the length of the production, A i E VN for each O -� j � m, Ai is the dependent child, oo is the part of the indices stack transmitted from the father to the dependent child, , , ,' E Vi U { €} and for each production either , or ,' or both must be € and a E VT U { €}.",
        "output": "{\"INFO\": [], \"PERCEPT\": [\"Following #TARGET_REF we consider productions in which at most one element can be pushed on or popped from a stack of indices\"], \"BACK\": [\":Ao [oo 1 ] \\u2794 Ai [] ... Ai -i l ] Ai[oo,'] Ai-i l ] ... Am [] Ao [ ] \\u2794 awhere\"]}"
    },
    {
        "gold": {
            "text": [
                "In",
                "the",
                "past",
                "few",
                "years,",
                "Natural",
                "Language",
                "Processing",
                "(NLP)",
                "researchers",
                "have",
                "proposed",
                "several",
                "online",
                "game/community",
                "toxicity",
                "analysis",
                "frameworks",
                "Figure",
                "1:",
                "An",
                "example",
                "intent/slot",
                "annotation",
                "from",
                "the",
                "CONDA",
                "(CONtextual",
                "Dual-Annotated)",
                "dataset.",
                "#TARGET_REF",
                "and",
                "datasets",
                "#REF",
                ".",
                "However,",
                "existing",
                "datasets",
                "(1)",
                "focus",
                "only",
                "on",
                "the",
                "single",
                "utterance",
                "level",
                "without",
                "deeper",
                "understanding",
                "of",
                "context",
                "in",
                "the",
                "whole",
                "conversation/chat,",
                "and",
                "(2)",
                "do",
                "not",
                "explicitly",
                "use",
                "semantic",
                "clues",
                "from",
                "the",
                "words",
                "within",
                "the",
                "utterance."
            ],
            "context": [
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                3,
                3,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0
            ]
        },
        "input": "In the past few years, Natural Language Processing (NLP) researchers have proposed several online game/community toxicity analysis frameworks Figure 1: An example intent/slot annotation from the CONDA (CONtextual Dual-Annotated) dataset. #TARGET_REF and datasets #REF . However, existing datasets (1) focus only on the single utterance level without deeper understanding of context in the whole conversation/chat, and (2) do not explicitly use semantic clues from the words within the utterance.",
        "output": "{\"INFO\": [], \"PERCEPT\": [], \"BACK\": [\"In the past few years, Natural Language Processing (NLP) researchers have proposed several online game/community toxicity analysis frameworks\", \"and datasets\"]}"
    },
    {
        "gold": {
            "text": [
                "S",
                "j",
                "are",
                "two",
                "different",
                "candidate",
                "summaries",
                "and",
                "ROUGE(S",
                "i",
                ",",
                "S",
                "*",
                ")",
                "&gt,",
                "ROUGE(S",
                "j",
                ",",
                "S",
                "*",
                "),",
                "∀i,",
                "j,",
                "i",
                "&lt,",
                "j.",
                "λ",
                "ij",
                "is",
                "the",
                "margin",
                "multiplied",
                "by",
                "the",
                "difference",
                "in",
                "rank",
                "between",
                "the",
                "candidates,",
                "i.e.,λ",
                "ij",
                "=",
                "(j",
                "−",
                "i)",
                "*",
                "λ.",
                "f",
                "(S",
                "i",
                ")",
                "is",
                "the",
                "length-normalized",
                "estimated",
                "log-probability",
                "3",
                "f",
                "(S)",
                "=",
                "l",
                "t=1",
                "log",
                "p",
                "g",
                "θ",
                "(s",
                "t",
                "|D,",
                "S",
                "&lt,t",
                ",",
                "θ)",
                "|S|",
                "α",
                "(9)where",
                "α",
                "is",
                "the",
                "length",
                "penalty",
                "hyperparameter.",
                "This",
                "loss",
                "gives",
                "the",
                "abstractive",
                "model",
                "a",
                "dual",
                "purpose,",
                "first",
                "as",
                "a",
                "reference-free",
                "evaluation",
                "model,",
                "which",
                "can",
                "be",
                "used",
                "in",
                "a",
                "two-stage",
                "summarization",
                "pipeline,",
                "where",
                "it",
                "is",
                "used",
                "to",
                "score",
                "the",
                "candidates",
                "generated",
                "by",
                "a",
                "pre-trained",
                "generation",
                "model",
                "and",
                "select",
                "the",
                "final",
                "output",
                "from",
                "them.",
                "However,",
                "since",
                "the",
                "autoregressive",
                "generation",
                "depends",
                "on",
                "both",
                "the",
                "token-level",
                "prediction",
                "accuracy",
                "and",
                "sequencelevel",
                "coordination,",
                "the",
                "model",
                "fine-tuned",
                "with",
                "the",
                "contrastive",
                "loss",
                "alone",
                "can",
                "no",
                "longer",
                "be",
                "used",
                "as",
                "a",
                "generation",
                "model.",
                "Multi-task",
                "Fine-tuning",
                "Following",
                "#TARGET_REF",
                ",",
                "we",
                "combine",
                "the",
                "contrastive",
                "(Eq.",
                "8)",
                "and",
                "cross-entropy",
                "(Eq.",
                "3)",
                "losses",
                "to",
                "preserve",
                "the",
                "generation",
                "ability",
                "of",
                "the",
                "pre-trained",
                "abstractive",
                "model:"
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                1,
                1,
                1,
                1,
                1,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3,
                3
            ]
        },
        "input": "S j are two different candidate summaries and ROUGE(S i , S * ) &gt, ROUGE(S j , S * ), ∀i, j, i &lt, j. λ ij is the margin multiplied by the difference in rank between the candidates, i.e.,λ ij = (j − i) * λ. f (S i ) is the length-normalized estimated log-probability 3 f (S) = l t=1 log p g θ (s t |D, S &lt,t , θ) |S| α (9)where α is the length penalty hyperparameter. This loss gives the abstractive model a dual purpose, first as a reference-free evaluation model, which can be used in a two-stage summarization pipeline, where it is used to score the candidates generated by a pre-trained generation model and select the final output from them. However, since the autoregressive generation depends on both the token-level prediction accuracy and sequencelevel coordination, the model fine-tuned with the contrastive loss alone can no longer be used as a generation model. Multi-task Fine-tuning Following #TARGET_REF , we combine the contrastive (Eq. 8) and cross-entropy (Eq. 3) losses to preserve the generation ability of the pre-trained abstractive model:",
        "output": "{\"INFO\": [\"Multi-task Fine-tuning Following #TARGET_REF ,\"], \"PERCEPT\": [], \"BACK\": [\"we combine the contrastive (Eq. 8) and cross-entropy (Eq. 3) losses to preserve the generation ability of the pre-trained abstractive model:\"]}"
    },
    {
        "gold": {
            "text": [
                "Proximity-based",
                "features",
                "Traditional",
                "retrieval",
                "models",
                "assume",
                "terms",
                "are",
                "independent",
                "and",
                "ignore",
                "their",
                "relationships,",
                "but",
                "the",
                "proximity",
                "among",
                "query",
                "terms",
                "often",
                "serves",
                "as",
                "an",
                "important",
                "relevance",
                "signal.",
                "Thus,",
                "we",
                "include",
                "features",
                "that",
                "directly",
                "capture",
                "the",
                "proximity",
                "of",
                "query",
                "terms,",
                "such",
                "as",
                "the",
                "counts",
                "of",
                "ordered",
                "and",
                "unordered",
                "co-occurrence",
                "of",
                "bigrams",
                "within",
                "different",
                "window",
                "sizes.",
                "We",
                "compute",
                "the",
                "scores",
                "of",
                "proximity-based",
                "retrieval",
                "functions,",
                "such",
                "as",
                "SDM",
                "#REF",
                "and",
                "BM25-TP",
                "#TARGET_REF",
                ",",
                "as",
                "our",
                "features."
            ],
            "context": [
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                0,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                2,
                3,
                3,
                3,
                1,
                1,
                1,
                2,
                2,
                2
            ]
        },
        "input": "Proximity-based features Traditional retrieval models assume terms are independent and ignore their relationships, but the proximity among query terms often serves as an important relevance signal. Thus, we include features that directly capture the proximity of query terms, such as the counts of ordered and unordered co-occurrence of bigrams within different window sizes. We compute the scores of proximity-based retrieval functions, such as SDM #REF and BM25-TP #TARGET_REF , as our features.",
        "output": "{\"INFO\": [\"BM25-TP #TARGET_REF ,\"], \"PERCEPT\": [\"We compute the scores of proximity-based retrieval functions, such as\", \"as our features.\"], \"BACK\": [\"SDM #REF and\"]}"
    }
]