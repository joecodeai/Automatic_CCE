{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForTokenClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_id = \"FacebookAI/roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_df = pd.read_csv(\"./data/finecite/full_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the DataFrame\n",
    "results = []\n",
    "for index, row in cce_df.iterrows():\n",
    "    # Clean the paragraph by replacing <ref> tags with '[TREF]'\n",
    "    clean_paragraph = re.sub(r'<ref.*?>.*?</ref>', '[TREF]', row[\"paragraph\"])\n",
    "\n",
    "    # Split the cleaned paragraph into words using ';' as the delimiter\n",
    "    words = clean_paragraph.split(';')\n",
    "\n",
    "    # Process the context_location1 list\n",
    "    context_location1 = eval(row[\"context_location1\"])\n",
    "\n",
    "    # Check if the lengths match, and map the context_location1 to the words\n",
    "    if len(context_location1) == len(words):\n",
    "        # Aggregate the mapped results for the current row\n",
    "        mapped_result = list(zip(context_location1, words))\n",
    "        \n",
    "        # Separate the numbers and words into separate lists\n",
    "        numbers = [str(item[0]) for item in mapped_result]  # Convert numbers to strings\n",
    "        mapped_words = [item[1].strip() for item in mapped_result]  # Strip extra spaces from words\n",
    "        \n",
    "        results.append({\n",
    "            \"Paragraph\": ' '.join(mapped_words),\n",
    "            \"Scope\": numbers\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Paragraph\": \"Length of context_location1 and words don't match\",\n",
    "            \"Scope\": \"Mismatch\"\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Scope column elements to lists of integers\n",
    "def convert_scope_to_int(scope):\n",
    "    if isinstance(scope, str):\n",
    "        # Convert string representation of list to an actual list of integers\n",
    "        scope = eval(scope)\n",
    "    # Ensure all elements in the list are integers\n",
    "    return [int(i) for i in scope]\n",
    "\n",
    "# Apply the conversion to the Scope column\n",
    "df[\"Scope\"] = df[\"Scope\"].apply(convert_scope_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer for RoBERTa\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Check if the tokenizer has a pad_token and set it\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Tokenize and prepare dataset\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the paragraphs\n",
    "    tokens = tokenizer(examples[\"Paragraph\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    \n",
    "    # Process labels (Scope)\n",
    "    max_label_length = 512  # Same as max_length for consistency\n",
    "    padded_labels = []\n",
    "    \n",
    "    for label_list in examples[\"Scope\"]:\n",
    "        # Truncate if necessary\n",
    "        if len(label_list) > max_label_length:\n",
    "            label_list = label_list[:max_label_length]\n",
    "        \n",
    "        # Pad with -100\n",
    "        padded_label = label_list + [-100] * (max_label_length - len(label_list))\n",
    "        padded_labels.append(padded_label)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    tokens[\"labels\"] = torch.tensor(padded_labels, dtype=torch.long)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "train_ds, test_ds = train_test_split(df, test_size=0.2, random_state=96)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "train_ds = Dataset.from_pandas(train_ds)\n",
    "test_ds = Dataset.from_pandas(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990e92799a55441a98f5e8025d2ca9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/844 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a2fcc7ed56425d86f12b2cfc5e2772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the tokenization function to the dataset\n",
    "train_ds = train_ds.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=train_ds.column_names  # Remove all original columns\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    tokenize_function, \n",
    "    batched=True, \n",
    "    remove_columns=test_ds.column_names  # Remove all original columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747ef1b0aa0e469bad8a5daee6451545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model for token classification\n",
    "model = RobertaForTokenClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=4  # Adjust this number based on your specific task\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8440' max='8440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8440/8440 12:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.154600</td>\n",
       "      <td>1.282983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.425300</td>\n",
       "      <td>1.271016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.326300</td>\n",
       "      <td>1.275540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.356200</td>\n",
       "      <td>1.298682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.082800</td>\n",
       "      <td>1.284797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.441600</td>\n",
       "      <td>1.274678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.132900</td>\n",
       "      <td>1.272688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.338700</td>\n",
       "      <td>1.264350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.347200</td>\n",
       "      <td>1.259414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.242300</td>\n",
       "      <td>1.188549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8440, training_loss=1.2739387804863012, metrics={'train_runtime': 763.6066, 'train_samples_per_second': 11.053, 'train_steps_per_second': 11.053, 'total_flos': 2205384503623680.0, 'train_loss': 1.2739387804863012, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_Roberta/tokenizer_config.json',\n",
       " './trained_Roberta/special_tokens_map.json',\n",
       " './trained_Roberta/vocab.json',\n",
       " './trained_Roberta/merges.txt',\n",
       " './trained_Roberta/added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./trained_Roberta')\n",
    "tokenizer.save_pretrained('./trained_Roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference on a new paragraph\n",
    "def classify_paragraph(paragraph):\n",
    "    # Clean and tokenize the input paragraph\n",
    "    clean_paragraph = re.sub(r'<ref.*?>.*?</ref>', '[TREF]', paragraph)\n",
    "    tokens = tokenizer(clean_paragraph, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    tokens = {key: value.to(model.device) for key, value in tokens.items()}\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = model(**tokens)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Map predictions to scopes\n",
    "    predicted_scope = predictions[0].cpu().numpy().tolist()\n",
    "    \n",
    "    return predicted_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_scopes(true_scope, predicted_scope):\n",
    "    # Determine the maximum length\n",
    "    max_length = max(len(true_scope), len(predicted_scope))\n",
    "    \n",
    "    # Pad the shorter list with -1\n",
    "    true_scope_padded = true_scope + [-1] * (max_length - len(true_scope))\n",
    "    predicted_scope_padded = predicted_scope + [-1] * (max_length - len(predicted_scope))\n",
    "    \n",
    "    # Truncate the longer list to the length of the shorter list\n",
    "    min_length = min(len(true_scope_padded), len(predicted_scope_padded))\n",
    "    true_scope_padded = true_scope_padded[:min_length]\n",
    "    predicted_scope_padded = predicted_scope_padded[:min_length]\n",
    "    \n",
    "    # Compute the number of correct predictions\n",
    "    correct_predictions = sum(t == p for t, p in zip(true_scope_padded, predicted_scope_padded) if t != -1)\n",
    "    total_predictions = sum(1 for t in true_scope_padded if t != -1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0\n",
    "    \n",
    "    return correct_predictions, total_predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Scope: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True Scope: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Correct Predictions: 53/89\n",
      "Accuracy: 59.55%\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "new_paragraph = 'Neural Machine Translation (NMT) has opened several research directions to exploit as many and diverse data as possible. Massive multilingual NMT models, for instance, take advantage of several language-pair datasets in a single system [TREF] . This offers several advantages, such as a simple training process and enhanced performance of the language-pairs with little data (although sometimes detrimental to the high-resource language-pairs). However, massive models of dozens of languages are not necessarily the best outcome, as it is demonstrated that smaller clusters still offer the same benefits [TREF] .'\n",
    "\n",
    "# Get the predicted scope for the new paragraph\n",
    "predicted_scope = classify_paragraph(new_paragraph)\n",
    "print(\"Predicted Scope:\", predicted_scope)\n",
    "\n",
    "# df[\"Scope\"][0] is the true scope for comparison\n",
    "true_scope = df[\"Scope\"][0]\n",
    "print(\"True Scope:\", true_scope)\n",
    "\n",
    "# Compare scopes\n",
    "correct_predictions, total_predictions, accuracy = compare_scopes(true_scope, predicted_scope)\n",
    "print(f\"Correct Predictions: {correct_predictions}/{total_predictions}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse_automatic_cce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
