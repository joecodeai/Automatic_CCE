{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5bc7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_df = pd.read_csv(\"C:/Users/joelt/Downloads/full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97964da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                        087922a2-e3ce-415a-8149-d146175ee6de\n",
       "citing_title                               USST's System for AutoSimTrans 2022\n",
       "citing_pub_year                                                           2022\n",
       "citing_authors                                               Jiahui Zhu;Jun Yu\n",
       "cited_title                  ['unknown', 'Learning to translate in real-tim...\n",
       "cited_pub_year                                                ['2018', '2017']\n",
       "cited_authors                ['Mingbo Ma;Liang Huang;Hao Xiong;Renjie Zheng...\n",
       "citation_type                                                            group\n",
       "paragraph                    Simultaneous;translation;<ref type=\"group\">(Gu...\n",
       "target_reference_location                                                    2\n",
       "context_location1            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3...\n",
       "context_location2            [1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3...\n",
       "iaa_macro                                                                 0.85\n",
       "iaa_total                                                                 0.88\n",
       "iaa_inf                                                                    1.0\n",
       "iaa_perc                                                                   1.0\n",
       "iaa_back                                                                  0.56\n",
       "guideline_version                                                          2.1\n",
       "Name: 21, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_df.iloc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7dce59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simultaneous;translation;<ref type=\"group\">(Gu et al., 2017; Ma et al., 2018)</ref>;consists;in;generating;a;translation;before;the;source;speaker;finishes;speaking.;It;is;widely;used;in;many;real-time;scenarios;such;as;international;conferences,;business;negotiations;and;legal;proceedings.;The;challenge;of;Simultaneous;machine;translation;is;to;find;a;read-write;policy;that;balances;translation;quality;and;latency.;The;translation;quality;will;decline;if;the;machine;translation;system;reads;insufficient;source;information.;When;reading;wider;source;text,;latency;will;increase.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_df[\"paragraph\"][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a971e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,0,0,0,0,0,0,0,0]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cce_df[\"context_location1\"][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "868a1ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Scope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Machine Translation (NMT) has opened se...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As shown in Table 1, the size of the 'in-domai...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automatic extraction of events has gained siza...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The subject NP 'Bill' is coindexed with the tr...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-training [TREF] ) uses a source-to-target...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Paragraph  \\\n",
       "0  Neural Machine Translation (NMT) has opened se...   \n",
       "1  As shown in Table 1, the size of the 'in-domai...   \n",
       "2  Automatic extraction of events has gained siza...   \n",
       "3  The subject NP 'Bill' is coindexed with the tr...   \n",
       "4  Self-training [TREF] ) uses a source-to-target...   \n",
       "\n",
       "                                               Scope  \n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "1  [0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "2  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...  \n",
       "3  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for index, row in cce_df.iterrows():\n",
    "    # Clean the paragraph by replacing <ref> tags with '[TREF]'\n",
    "    clean_paragraph = re.sub(r'<ref.*?>.*?</ref>', '[TREF]', row[\"paragraph\"])\n",
    "\n",
    "    # Split the cleaned paragraph into words using ';' as the delimiter\n",
    "    words = clean_paragraph.split(';')\n",
    "\n",
    "    # Process the context_location1 list\n",
    "    context_location1 = eval(row[\"context_location1\"])\n",
    "\n",
    "    # Check if the lengths match, and map the context_location1 to the words\n",
    "    if len(context_location1) == len(words):\n",
    "        # Aggregate the mapped results for the current row\n",
    "        mapped_result = list(zip(context_location1, words))\n",
    "        \n",
    "        # Separate the numbers and words into separate lists\n",
    "        numbers = [item[0] for item in mapped_result]\n",
    "        mapped_words = [item[1].strip() for item in mapped_result]\n",
    "        \n",
    "        results.append({\n",
    "            \"Paragraph\": ' '.join(mapped_words),\n",
    "            \"Scope\": numbers\n",
    "        })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Paragraph\": \"Length of context_location1 and words don't match\",\n",
    "            \"Scope\": [\"Mismatch\"]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67658b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fcb2ec2fbd4814a6ee9e327d039323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1055 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the tokenizer for LLaMA 3\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "# Check if the tokenizer has an eos_token and set it as the padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define a function to tokenize the input text with the maximum length\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Paragraph'], padding=\"max_length\", truncation=True, max_length=786)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d822362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f20a9a2d14ecabc86d0a90cdcc972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1055 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to process the labels\n",
    "def process_labels(examples):\n",
    "    return {\"labels\": examples['Scope']}\n",
    "\n",
    "# Apply the label processing to the dataset\n",
    "labeled_dataset = tokenized_dataset.map(process_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9414a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained LLaMA 3 model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=labeled_dataset,\n",
    "    eval_dataset=labeled_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "trainer.save_model(\"./trained_llama_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4541ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for text classification\n",
    "classification_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "# Define your new input paragraph\n",
    "paragraph = \"Neural Machine Translation (NMT) has opened several research directions to exploit as many and diverse data as possible. Massive multilingual NMT models, for instance, take advantage of several language-pair datasets in a single system [TREF] . This offers several advantages, such as a simple training process and enhanced performance of the language-pairs with little data (although sometimes detrimental to the high-resource language-pairs). However, massive models of dozens of languages are not necessarily the best outcome, as it is demonstrated that smaller clusters still offer the same benefits [TREF] .\"\n",
    "\n",
    "# Split the paragraph into words\n",
    "words = paragraph.split()\n",
    "\n",
    "word_predictions = []\n",
    "\n",
    "# Iterate over each word in the paragraph\n",
    "for word in words:\n",
    "    # Tokenize the word and get the input tensors\n",
    "    tokenized_word = tokenizer(word, return_tensors='pt', truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_word)\n",
    "\n",
    "    # Get the logits and apply softmax to get probabilities\n",
    "    scores = torch.softmax(outputs.logits, dim=1).detach().numpy()\n",
    "\n",
    "    # Get the label with the highest score\n",
    "    max_score_idx = scores.argmax(axis=1)[0]\n",
    "    max_score = scores[0, max_score_idx]\n",
    "    label = f\"{max_score_idx}\"\n",
    "\n",
    "    word_predictions.append({'word': word, 'scope': label, 'score': max_score})\n",
    "\n",
    "for prediction in word_predictions:\n",
    "    print(f\"Word: {prediction['word']}, Predicted Scope: {prediction['scope']}, Score: {prediction['score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
