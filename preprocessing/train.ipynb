{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, Trainer, TrainingArguments\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from statistics import mean\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "#tokenizer.add_special_tokens({'additional_special_tokens':['<INFORMATION>','</INFORMATION>','<PERCEPTION>', '</PERCEPTION>', '<BACKGROUND>', '</BACKGROUND>']})\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_storage=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "# LMmodel = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     quantization_config = bnb_config,\n",
    "#     torch_dtype = torch.bfloat16,\n",
    "#     device_map = 'auto'\n",
    "# )\n",
    "# LMmodel.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# peft_config = LoraConfig(target_modules=[ \"v_proj\", \"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\" ], inference_mode=False, r=4, lora_alpha=32, lora_dropout=0.1)\n",
    "\n",
    "# LMmodel = get_peft_model(LMmodel, peft_config)\n",
    "\n",
    "# LMmodel.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "cce_df = pd.read_csv(\"../data/finecite/full_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Scope</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Machine Translation (NMT) has opened se...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>&lt;BACKGROUND&gt; Neural Machine Translation (NMT) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As shown in Table 1, the size of the 'in-domai...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>As shown in Table 1, &lt;BACKGROUND&gt; the size of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automatic extraction of events has gained siza...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>&lt;PERCEPTION&gt; Automatic extraction of events ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The subject NP 'Bill' is coindexed with the tr...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>&lt;BACKGROUND&gt; The subject NP 'Bill' is coindexe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-training [TREF] ) uses a source-to-target...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>&lt;INFORMATION&gt; Self-training [TREF] ) uses a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>Taking inspiration from gradient checkpointing...</td>\n",
       "      <td>[2, 2, 2, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>&lt;PERCEPTION&gt; Taking inspiration from &lt;/PERCEPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>• RNN-NLU [TREF] ) is an attention-based bi-di...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>• &lt;INFORMATION&gt; RNN-NLU [TREF] ) is an attenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>For the final-stage neural reranker, we experi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>For the final-stage neural reranker, we experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>Trained on 20GB texts of both Vietnamese news ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Trained on 20GB texts of both Vietnamese news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>Arabic being a morphologically rich language, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Arabic being a morphologically rich language, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Paragraph  \\\n",
       "0     Neural Machine Translation (NMT) has opened se...   \n",
       "1     As shown in Table 1, the size of the 'in-domai...   \n",
       "2     Automatic extraction of events has gained siza...   \n",
       "3     The subject NP 'Bill' is coindexed with the tr...   \n",
       "4     Self-training [TREF] ) uses a source-to-target...   \n",
       "...                                                 ...   \n",
       "1019  Taking inspiration from gradient checkpointing...   \n",
       "1020  • RNN-NLU [TREF] ) is an attention-based bi-di...   \n",
       "1021  For the final-stage neural reranker, we experi...   \n",
       "1022  Trained on 20GB texts of both Vietnamese news ...   \n",
       "1023  Arabic being a morphologically rich language, ...   \n",
       "\n",
       "                                                  Scope  \\\n",
       "0     [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1     [0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "2     [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "3     [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "1019  [2, 2, 2, 1, 1, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1020  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1021  [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, ...   \n",
       "1022  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1023  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                                 labels  \n",
       "0     <BACKGROUND> Neural Machine Translation (NMT) ...  \n",
       "1     As shown in Table 1, <BACKGROUND> the size of ...  \n",
       "2     <PERCEPTION> Automatic extraction of events ha...  \n",
       "3     <BACKGROUND> The subject NP 'Bill' is coindexe...  \n",
       "4     <INFORMATION> Self-training [TREF] ) uses a so...  \n",
       "...                                                 ...  \n",
       "1019  <PERCEPTION> Taking inspiration from </PERCEPT...  \n",
       "1020  • <INFORMATION> RNN-NLU [TREF] ) is an attenti...  \n",
       "1021  For the final-stage neural reranker, we experi...  \n",
       "1022  Trained on 20GB texts of both Vietnamese news ...  \n",
       "1023  Arabic being a morphologically rich language, ...  \n",
       "\n",
       "[1024 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean data\n",
    "def label_mapping(label):\n",
    "    if type(label) == int:\n",
    "        if label == 1: return 'INFORMATION'\n",
    "        if label == 2: return 'PERCEPTION'\n",
    "        if label == 3: return 'BACKGROUND'\n",
    "    else:\n",
    "        if label == 'INFORMATION': return 1\n",
    "        if label == 'PERCEPTION': return 2\n",
    "        if label == 'BACKGROUND': return 3\n",
    "    \n",
    "def replace_ref(word):\n",
    "    if re.match(r'single', word):\n",
    "        return '[REF]'\n",
    "    else:\n",
    "        return '[REF]'\n",
    "\n",
    "\n",
    "# Process the DataFrame\n",
    "results = []\n",
    "for index, row in cce_df.iterrows():\n",
    "    \n",
    "    #clean all ';' from references\n",
    "    clean_paragraph = re.sub(r'<ref.*?>.*?</ref>',lambda x: x.group().replace(';',','), row['paragraph'])\n",
    "    \n",
    "    #create word list of par\n",
    "    words_par = clean_paragraph.split(';')\n",
    "    \n",
    "    #replace (G)TREF\n",
    "    words_par[row['target_reference_location']] = '[TREF]' #if re.search(r'single', words_par[row['target_reference_location']]) else '[GTREF]'\n",
    "    \n",
    "    # Clean the paragraph by replacing <ref> tags with '[TREF]'\n",
    "    words_par = [replace_ref(word) if re.search(r'<ref.*?>.*?</ref>', word) else word for word in words_par]\n",
    "    \n",
    "\n",
    "    # Process the context_location1 list\n",
    "    context_location1 = eval(row[\"context_location1\"])\n",
    "\n",
    "    # check whether context label and word list are same length\n",
    "    assert len(context_location1) == len(words_par), f'The labels are of length {len(context_location1)}, while the word list is of length {len(words_par)}'\n",
    "    \n",
    "    # Aggregate the mapped results for the current row\n",
    "    mapped_result = list(zip(context_location1, words_par))\n",
    "    \n",
    "    # tokenize string to evaluate token length\n",
    "    tokenized_string = tokenizer.tokenize(' '.join(words_par))\n",
    "    \n",
    "    \n",
    "    max_len = 300\n",
    "    if len(tokenized_string) > max_len:\n",
    "        word_tokens = []\n",
    "        labels = []\n",
    "        word_id = []\n",
    "        for idx, (label, word) in enumerate(mapped_result):\n",
    "            tokens = tokenizer.tokenize(word)\n",
    "            word_tokens.extend(tokens)\n",
    "            labels.extend([labels] * len(tokens))\n",
    "            word_id.extend([idx] * len(tokens))\n",
    "        assert len(word_tokens) == len(labels), 'something went wrong in the tokenization process'\n",
    "        \n",
    "        excess_len = len(word_tokens) - max_len\n",
    "        zero_count_start = labels[:excess_len].count(0)\n",
    "        zero_count_end = labels[max_len:].count(0)\n",
    "        if zero_count_end > zero_count_start:\n",
    "            end_id = word_id[max_len]\n",
    "            mapped_result = list(zip(context_location1[:end_id -1], words_par[:end_id -1]))\n",
    "        else:\n",
    "            begin_id = word_id[excess_len-1]\n",
    "            mapped_result = list(zip(context_location1[begin_id +1:], words_par[begin_id +1:]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Separate the numbers and words into separate lists\n",
    "    numbers = [item[0] for item in mapped_result]  # Convert numbers to strings\n",
    "    mapped_words = [item[1].strip() for item in mapped_result]  # Strip extra spaces from words\n",
    "    \n",
    "    # skip entry if target reference is not present\n",
    "    if '[GTREF]' not in mapped_words and '[TREF]' not in mapped_words: continue\n",
    "\n",
    "    sem_structured_context = []\n",
    "    prev_label = 0\n",
    "    for label, word in mapped_result:\n",
    "        if label != prev_label:\n",
    "            if prev_label != 0:\n",
    "                sem_structured_context.append(f'</{label_mapping(prev_label)}>')\n",
    "            if label != 0:\n",
    "                sem_structured_context.append(f'<{label_mapping(label)}>')\n",
    "        sem_structured_context.append(word)\n",
    "        prev_label = label\n",
    "    if prev_label != 0:\n",
    "        sem_structured_context.append(f'</{label_mapping(prev_label)}>')      \n",
    "        \n",
    "    \n",
    "    \n",
    "    results.append({\n",
    "        \"Paragraph\": ' '.join(mapped_words),\n",
    "        \"Scope\": numbers,\n",
    "        \"labels\": ' '.join(sem_structured_context)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check input and output token length\n",
    "length_par = []\n",
    "length_labels = []\n",
    "for idx, row in df.iterrows():\n",
    "    length_par.append(len(tokenizer.tokenize(row['Paragraph'])))\n",
    "    \n",
    "    length_labels.append(len(tokenizer.tokenize(row['labels'])))\n",
    "    \n",
    "import seaborn as sns\n",
    "sns.histplot(data=length_par)\n",
    "sns.histplot(data=length_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_tune_prompt_xml( \n",
    "    input_str: str,\n",
    "    label_str: str,\n",
    "    tokenizer,\n",
    "    test: bool = False\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    usr_msg1 = \"You are given a excerpt from a scientific text with citations that are marked as [REF] or[TREF], and a list of context types\" \\\n",
    "        \"Your task is it to find the citation context of the targeted citation marked by [TREF]\" \\\n",
    "        \"To do this first find the targeted citation, \"\\\n",
    "        \"second, identify which part of the excerpt belongs to one of the context types, \"\\\n",
    "        \"third, annotate the context by adding XML tags (e.g. <INFORMATION> ... </INFORMATION>) to the input \"\\\n",
    "        \"Context types can occure multiple times. Some parts of the input might not belong to any context\"\\\n",
    "        \"Format all XML tags correctly, do not change the wording, do not exceed the input, do return anythig else that the input with added annotation\" \\\n",
    "        f\"\"\"\\n\\nList Context Types\\n\n",
    "        INFORMATION: includes the information that are cited from the cited article \\n\n",
    "        PERCEPTION: perception or use of the cited information in the citing paper \\n\n",
    "        BACKGROUND: backgound or further information on why the citation is included \\n\n",
    "        \"\"\"\\\n",
    "        \"\\n\\n\" \\\n",
    "        \"Are the instructions clear to you?\"\n",
    "    \n",
    "    asst_msg1 = \"Yes, the instructions are clear to me.\"\\\n",
    "                \"I will correctly identify the context of the as targeted marked citation ([TREF]) by adding the correct XML tags to the input. I will return anythig else that the input with added annotation\"\n",
    "    \n",
    "    usr_msg2 = \"Table 5: The experimental results of passage reading on NQ dataset. In this paper, we focus on extractive reader, while the recent generative readers [TREF] can also be applied here and may lead to better results.\"\n",
    "\n",
    "    asst_msg2 = \"Table 5: The experimental results of passage reading on NQ dataset. <BACKBROUND> In this paper, we focus on extractive reader, while </BACKBROUND><INFORMATION> the recent generative readers [TREF] </INFORMATION><PERCEPTION> can also be applied here and may lead to better results.</PERCEPTION>\"\n",
    "\n",
    "    usr_msg3 = \"Give a brief explanation of why your answer is correct.\"\n",
    "\n",
    "    asst_msg3 = \"The provided text discusses the advantages and limitations of massive multilingual NMT models.\" \\\n",
    "                \"The context type 'BACKGROUND' is used to explain the purpose of these models, which is to exploit as many and diverse data as possible.\"\\\n",
    "                \"The context type 'INFORMATION' is used to provide specific details about the massive multilingual NMT models, such as the fact that they take advantage of several language-pair datasets in a single system.\"\\\n",
    "                \"The reference marker [TREF] is used to cite the source of this information. The context type 'PERCEPTION' is not used in this text, as it refers to the perception or use of the cited content, and in this case, there is no explicit mention of how the information is being used or perceived\"\n",
    "    \n",
    "    usr_msg4 = \"Great! I am now going to give you another user utterance. Please detect the context types in it \" \\\n",
    "                \"according to the previous instructions. Do not include an explanation in your answer.\"\n",
    "    \n",
    "    asst_msg4 = \"Sure! Please give me the user utterance.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": usr_msg1},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg1},\n",
    "        {\"role\": \"user\", \"content\": usr_msg2},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg2},\n",
    "        # {\"role\": \"user\", \"content\": usr_msg3},\n",
    "        # {\"role\": \"assistant\", \"content\": asst_msg3},\n",
    "        # {\"role\": \"user\", \"content\": usr_msg4},\n",
    "        # {\"role\": \"assistant\", \"content\": asst_msg4},\n",
    "        {\"role\": \"user\", \"content\": input_str},\n",
    "    ]\n",
    "    if not test: messages.append({\"role\": \"assistant\", \"content\": label_str})\n",
    "    \n",
    "    encoded_input_ids = tokenizer.apply_chat_template(messages)\n",
    "\n",
    "    return {'input_ids': encoded_input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.utils import PaddingStrategy\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "@dataclass\n",
    "class CustomDataCollatorWithPadding:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        \n",
    "        # # Set loss mask for all pad tokens\n",
    "        # labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        # Compute loss mask for appropriate tokens only\n",
    "        for i in range(batch['input_ids'].shape[0]):\n",
    "            \n",
    "            # Decode the training input\n",
    "            text_content = self.tokenizer.decode(batch['input_ids'][i][1:])  # slicing from [1:] is important because tokenizer adds bos token\n",
    "            \n",
    "            # Extract substrings for prompt text in the training input\n",
    "            # The training input ends at the last user msg ending in [/INST]\n",
    "            prompt_gen_boundary = text_content.rfind(\"[/INST]\") + len(\"[/INST]\")\n",
    "            prompt_text = text_content[:prompt_gen_boundary]\n",
    "            \n",
    "            # print(f\"\"\"PROMPT TEXT:\\n{prompt_text}\"\"\")\n",
    "            \n",
    "            # retokenize the prompt text only\n",
    "            prompt_text_tokenized = self.tokenizer(\n",
    "                prompt_text,\n",
    "                return_overflowing_tokens=False,\n",
    "                return_length=False,\n",
    "            )\n",
    "            # compute index where prompt text ends in the training input\n",
    "            prompt_tok_idx = len(prompt_text_tokenized['input_ids'])\n",
    "            \n",
    "            # Set loss mask for all tokens in prompt text\n",
    "            labels[i][range(prompt_tok_idx)] = -100\n",
    "            \n",
    "                    \n",
    "        batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 819/819 [00:00<00:00, 1334.17 examples/s]\n",
      "Map: 100%|██████████| 9/9 [00:00<00:00, 1216.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# split data in train / test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=96, shuffle=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df[:9])\n",
    "\n",
    "#Apply the tokenization function to the dataset\n",
    "train_ds = train_ds.map(\n",
    "    lambda row: get_fine_tune_prompt_xml(row['Paragraph'], row['labels'], tokenizer), \n",
    "    batched=False, \n",
    "    remove_columns=train_ds.column_names  # Remove all original columns\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    lambda row: get_fine_tune_prompt_xml(row['Paragraph'], row['labels'], tokenizer, True), \n",
    "    batched=False, \n",
    "    remove_columns=test_ds.column_names  # Remove all original columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = []\n",
    "for item in train_ds:\n",
    "    length.append(len(item['input_ids']))\n",
    "sns.histplot(data=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "data_collator=CustomDataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, \n",
    "    padding=\"longest\", \n",
    "    max_length=max_seq_length, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "training_arguments = SFTConfig(\n",
    "    output_dir=\"./tmp\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    dataset_text_field=\"input_ids\",\n",
    "    max_seq_length=1024,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=LMmodel,\n",
    "    train_dataset=train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    # Using custom data collator inside SFTTrainer\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate untrained dataset\n",
    "def evaluate(model, test_ds, data_collator):\n",
    "    \n",
    "    #genreate answers\n",
    "    preds = []\n",
    "    trainer.model.to(DEVICE)\n",
    "    for input_data in tqdm(test_ds):\n",
    "        res = model.generate(data_collator([input_data])['input_ids'].to(DEVICE), max_new_tokens=512)\n",
    "        answ = tokenizer.decode(res[0]).split('[/INST]')[-1]\n",
    "        preds.append(answ)\n",
    "    \n",
    "    #get labels from marked text\n",
    "    answ_df = pd.DataFrame(columns=['answ_par', 'answ_labels'])\n",
    "    for answ in preds:\n",
    "        answ = answ.replace('</s>','')\n",
    "        answ = re.sub(r'\\s*(<\\/?(?:INFORMATION|PERCEPTION|BACKGROUND)+?>)\\s*',r' \\1 ', answ)\n",
    "        labels = []\n",
    "        paragraph = []\n",
    "        curr_label = 0\n",
    "        for word in re.split(r'\\s+|(?<=>)(?=<)', answ.strip()):\n",
    "            if word in ['<INFORMATION>','</INFORMATION>','<PERCEPTION>','</PERCEPTION>','<BACKGROUND>','</BACKGROUND>']:\n",
    "                new_label = re.findall(r'<([^\\/]*?)>', word)\n",
    "                if new_label: \n",
    "                    curr_label = label_mapping(new_label[0])\n",
    "                else:\n",
    "                    curr_label = 0\n",
    "            else:\n",
    "                labels.append(curr_label)\n",
    "                paragraph.append(word)\n",
    "        assert len(labels) == len(paragraph), f'The length of the labels and the length of the paragraph are not the same'\n",
    "        answ_df.loc[len(answ_df)] = [paragraph, labels]\n",
    "    return answ_df\n",
    "    \n",
    "def calculate_metrics(answ_df, test_df):\n",
    "        #assert len(answ_df) == len(test_df), 'The length of the answ_df is not the same with the length of the test_df'\n",
    "        eval_df = pd.concat([test_df, answ_df], axis=1)\n",
    "        f1_marcro = []\n",
    "        f1_total = [] \n",
    "        f1_inf = []\n",
    "        f1_perc = []\n",
    "        f1_back = []\n",
    "        error = []\n",
    "        def to_binary(arr, label):\n",
    "            if label == 0:\n",
    "                return [0 if no == 0 else 1 for no in arr]\n",
    "            else:\n",
    "                return [1 if no == label else 0 for no in arr]\n",
    "            \n",
    "        def repair_pred(pred, gold):\n",
    "            if len(pred) == len(gold): return pred, 0\n",
    "            if len(pred) > len(gold): return pred[:len(gold)], (len(pred) - len(gold)) / len(gold)\n",
    "            if len(pred) < len(gold): return pred + [0] * (len(gold) - len(pred)), (len(gold) - len(pred)) / len(gold)\n",
    "            \n",
    "        for idx, row in eval_df.iterrows():\n",
    "            gold = row['Scope']\n",
    "            pred = row['answ_labels']\n",
    "            pred, err = repair_pred(pred, gold)\n",
    "            error.append(err)\n",
    "            assert len(gold) == len(pred), f'{len(gold)}, {len(pred)}'\n",
    "            f1_marcro.append(f1_score(gold, pred, average='macro'))\n",
    "            f1_total.append(f1_score(to_binary(gold, 0), to_binary(pred, 0)))\n",
    "            f1_inf.append(f1_score(to_binary(gold, 1), to_binary(pred, 1)))\n",
    "            f1_perc.append(f1_score(to_binary(gold, 2), to_binary(pred, 2)))\n",
    "            f1_back.append(f1_score(to_binary(gold, 3), to_binary(pred, 3)))\n",
    "        return mean(error), mean(f1_marcro), mean(f1_total), mean(f1_inf), mean(f1_perc), mean(f1_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:19<02:33, 19.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 2/9 [00:36<02:06, 18.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 3/9 [00:57<01:56, 19.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 4/9 [01:18<01:40, 20.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 5/9 [01:55<01:45, 26.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 6/9 [02:07<01:04, 21.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 7/9 [02:21<00:38, 19.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 8/9 [02:32<00:16, 16.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 9/9 [02:54<00:00, 19.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answ_par</th>\n",
       "      <th>answ_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[To, reduce, the, deviation, caused, by, diffe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, memory-based, approach, is, expected, to...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[location,, and, object, retrieval, models, ar...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[We, have, established, that, the, performance...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[There, are, two, approaches, to, assessing, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Some, emotions, are, also, harder, to, detect...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Recent, work, has, identified, that, consecut...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Linguistic, Embedding, For, the, language, D,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[We, create, entity, representations, of, a, m...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            answ_par  \\\n",
       "0  [To, reduce, the, deviation, caused, by, diffe...   \n",
       "1  [The, memory-based, approach, is, expected, to...   \n",
       "2  [location,, and, object, retrieval, models, ar...   \n",
       "3  [We, have, established, that, the, performance...   \n",
       "4  [There, are, two, approaches, to, assessing, t...   \n",
       "5  [Some, emotions, are, also, harder, to, detect...   \n",
       "6  [Recent, work, has, identified, that, consecut...   \n",
       "7  [Linguistic, Embedding, For, the, language, D,...   \n",
       "8  [We, create, entity, representations, of, a, m...   \n",
       "\n",
       "                                         answ_labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, ...  \n",
       "6  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, ...  \n",
       "7  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df1 = evaluate(trainer.model, test_ds, data_collator)\n",
    "eval_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3185047163900566,\n",
       " np.float64(0.21382101149715482),\n",
       " np.float64(0.32205284218132313),\n",
       " np.float64(0.10810810810810811),\n",
       " np.float64(0.0),\n",
       " np.float64(0.22540957439089868))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(eval_df1, test_df[:len(eval_df1)])\n",
    "\n",
    "'''\n",
    "(0.3185047163900566,\n",
    " np.float64(0.21382101149715482),\n",
    " np.float64(0.32205284218132313),\n",
    " np.float64(0.10810810810810811),\n",
    " np.float64(0.0),\n",
    " np.float64(0.22540957439089868))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2457' max='2457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2457/2457 29:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2457, training_loss=0.050010033336945266, metrics={'train_runtime': 1758.9461, 'train_samples_per_second': 1.397, 'train_steps_per_second': 1.397, 'total_flos': 8.01173751431086e+16, 'train_loss': 0.050010033336945266, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 11%|█         | 1/9 [00:10<01:26, 10.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 22%|██▏       | 2/9 [00:51<03:19, 28.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 33%|███▎      | 3/9 [01:19<02:49, 28.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 44%|████▍     | 4/9 [01:39<02:04, 24.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 56%|█████▌    | 5/9 [02:20<02:02, 30.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 67%|██████▋   | 6/9 [03:01<01:42, 34.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 78%|███████▊  | 7/9 [03:14<00:54, 27.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 89%|████████▉ | 8/9 [03:23<00:21, 21.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 9/9 [03:40<00:00, 24.47s/it]\n",
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31645844944274265,\n",
       " np.float64(0.5611033454793029),\n",
       " np.float64(0.8073766632644296),\n",
       " np.float64(0.7161052455170103),\n",
       " np.float64(0.3969758871059333),\n",
       " np.float64(0.26680723276467955))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df2 =evaluate(trainer.model, test_ds, data_collator)\n",
    "calculate_metrics(eval_df2, test_df[:len(eval_df2)])\n",
    "'''\n",
    "(0.31645844944274265,\n",
    " np.float64(0.5611033454793029),\n",
    " np.float64(0.8073766632644296),\n",
    " np.float64(0.7161052455170103),\n",
    " np.float64(0.3969758871059333),\n",
    " np.float64(0.26680723276467955))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Some', 'emotions', 'are', 'also', 'harder', 'to', 'detect,', 'even', 'for', 'humans.', '[REF]', 'show', 'that', 'the', 'emotions', 'of', 'admiration,', 'approval,', 'annoyance,', 'gratitude', 'had', 'the', 'highest', 'interrater', 'correlations', 'at', 'around', '0.6,', 'and', 'grief,', 'relief,', 'pride,', 'nervousness,', 'embarrassment', 'had', 'the', 'lowest', 'interrater', 'correlations', 'between', '0-0.2,', 'with', 'a', 'vast', 'majority', 'of', 'emotions', 'falling', 'in', 'the', 'range', 'of', '0.3-0.5', 'for', 'interrater', 'correlation.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.']\n",
      "['Some', 'emotions', 'are', 'also', 'harder', 'to', 'detect,', 'even', 'for', 'humans.', '[REF]', 'show', 'that', 'the', 'emotions', 'of', 'admiration,', 'approval,', 'annoyance,', 'gratitude', 'had', 'the', 'highest', 'interrater', 'correlations', 'at', 'around', '0.6,', 'and', 'grief,', 'relief,', 'pride,', 'nervousness,', 'embarrassment', 'had', 'the', 'lowest', 'interrater', 'correlations', 'between', '0-0.2,', 'with', 'a', 'vast', 'majority', 'of', 'emotions', 'falling', 'in', 'the', 'range', 'of', '0.3-0.5', 'for', 'interrater', 'correlation.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also', 'expressed', 'differently', 'in', 'text', 'with', 'anger', 'and', 'disgust', 'expressed', 'explicitly,', 'and', 'surprise', 'in', 'context', '[TREF]', '.', 'Emotions', 'are', 'also']\n"
     ]
    }
   ],
   "source": [
    "#1, (4), 5, \n",
    "#i = -1\n",
    "#i += 1\n",
    "print(test_df.loc[i, 'Paragraph'].split())\n",
    "print(eval_df2.loc[i,'answ_par'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answ_df = pd.DataFrame(columns=['answ_par', 'answ_labels'])\n",
    "# for answ in pred:\n",
    "#     answ = answ.replace('</s>','')\n",
    "#     answ = re.sub(r'\\s*(<\\/?(?:INFORMATION|PERCEPTION|BACKGROUND)+?>)\\s*',r' \\1 ', answ)\n",
    "#     answ = re.sub('BACKBROUND','BACKGROUND',answ)\n",
    "#     print(answ)\n",
    "#     labels = []\n",
    "#     paragraph = []\n",
    "#     curr_label = 0\n",
    "#     for word in re.split(r'\\s+|(?<=>)(?=<)', answ.strip()):\n",
    "#         if word in ['<INFORMATION>','</INFORMATION>','<PERCEPTION>','</PERCEPTION>','<BACKGROUND>','</BACKGROUND>']:\n",
    "#             new_label = re.findall(r'<([^\\/]*?)>', word)\n",
    "#             if new_label: \n",
    "#                 curr_label = label_mapping(new_label[0])\n",
    "#             else:\n",
    "#                 curr_label = 0\n",
    "#         else:\n",
    "#             labels.append(curr_label)\n",
    "#             paragraph.append(word)\n",
    "#     assert len(labels) == len(paragraph), f'The length of the labels and the length of the paragraph are not the same'\n",
    "#     answ_df.loc[len(answ_df)] = [paragraph, labels]\n",
    "# #assert len(answ_df) == len(test_df.loc[:10]), 'The length of the answ_df is not the same with the length of the test_df'\n",
    "\n",
    "# eval_df = pd.concat([test_df.loc[:9], answ_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_marcro = []\n",
    "# f1_total = [] \n",
    "# f1_inf = []\n",
    "# f1_perc = []\n",
    "# f1_back = []\n",
    "# def to_binary(arr, label):\n",
    "#     if label == 0:\n",
    "#         return [0 if no == 0 else 1 for no in arr]\n",
    "#     else:\n",
    "#         return [1 if no == label else 0 for no in arr]\n",
    "    \n",
    "# def repair_pred(pred, gold):\n",
    "#     if len(pred) == len(gold): return pred\n",
    "#     if len(pred) > len(gold): return pred[:len(gold)]\n",
    "#     if len(pred) < len(gold): return pred + [0] * (len(gold) - len(pred))\n",
    "    \n",
    "# for idx, row in eval_df.iterrows():\n",
    "#     gold = row['Scope']\n",
    "#     pred = row['answ_labels']\n",
    "#     pred = repair_pred(pred, gold)\n",
    "#     assert len(gold) == len(pred), f'{len(gold)}, {len(pred)}'\n",
    "#     f1_marcro.append(f1_score(gold, pred, average='macro'))\n",
    "#     f1_total.append(f1_score(to_binary(gold, 0), to_binary(pred, 0)))\n",
    "#     f1_inf.append(f1_score(to_binary(gold, 1), to_binary(pred, 1)))\n",
    "#     f1_perc.append(f1_score(to_binary(gold, 2), to_binary(pred, 2)))\n",
    "#     f1_back.append(f1_score(to_binary(gold, 3), to_binary(pred, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.18181466785489436 0.3014459523848662 0.1063882063882064 0.0 0.18056841174965696\n",
    "#0.4924174473048213 0.589874943243401 0.4778282828282828 0.47370252585199735 0.0\n",
    "# print(mean(f1_marcro), mean(f1_total), mean(f1_inf), mean(f1_perc), mean(f1_back))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
