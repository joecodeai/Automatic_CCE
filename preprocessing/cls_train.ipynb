{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, Trainer, TrainingArguments\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from statistics import mean\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,485,760 || all params: 7,258,509,312 || trainable%: 0.1445\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "#tokenizer.add_special_tokens({'additional_special_tokens':['<INFORMATION>','</INFORMATION>','<PERCEPTION>', '</PERCEPTION>', '<BACKGROUND>', '</BACKGROUND>']})\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_storage=torch.bfloat16,\n",
    ")\n",
    "\n",
    "LMmodel = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bnb_config,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map = 'auto'\n",
    ")\n",
    "LMmodel.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "peft_config = LoraConfig(target_modules=[ \"v_proj\", \"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\" ], inference_mode=False, r=4, lora_alpha=32, lora_dropout=0.1)\n",
    "\n",
    "LMmodel = get_peft_model(LMmodel, peft_config)\n",
    "\n",
    "LMmodel.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/acl_arc/train_raw.txt',sep='\\t')\n",
    "test = pd.read_csv('../data/acl_arc/test_raw.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mapping(label):\n",
    "    if type(label) == int:\n",
    "        if label == 0: return 'BACKGROUND'\n",
    "        if label == 1: return 'USE'\n",
    "        if label == 2: return 'COMPARE_CONTRAST'\n",
    "        if label == 3: return 'MOTIVATION'\n",
    "        if label == 4: return 'EXTENSION'\n",
    "        if label == 5: return 'FUTURE'\n",
    "    else:\n",
    "        if label == 'BACKGROUND': return 0\n",
    "        if label == 'USE': return 1\n",
    "        if label == 'COMPARE_CONTRAST': return 2\n",
    "        if label == 'MOTIVATION': return 3\n",
    "        if label == 'EXTENSION': return 4\n",
    "        if label == 'FUTURE': return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fine_tune_prompt( \n",
    "    input_str: str,\n",
    "    label_str: str,\n",
    "    tokenizer,\n",
    "    test: bool = False\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    usr_msg1 = \"You are given a excerpt from a scientific text with one citation marked as #AUTHOR_TAG. Further you are given a list of citation functions.\" \\\n",
    "        \" Your task is it to find the citation function class of the marked citation.\"\\\n",
    "        ' To do this, first, find the marked citation, second, identify which function class fits the best for the marked citation by considering the surrounding words, third, reply with a short valid json only containing the label e.g.: {\"label\": \"USE\"}.'\\\n",
    "        ' Make sure the output is a valid jason with \"\" instead of \\'\\' '\\\n",
    "        f\"\"\"\\n\\nList Citation Function Types\\n\n",
    "        BACKGROUND: The cited paper provides relevant background information or is part of the body of literature. \\n\n",
    "        USE: The citing paper uses the methodology or tools created by the cited paper. \\n\n",
    "        COMPARE_CONTRAST: The citing paper expresses similarities to or or differences from, or disagrees with, the cited paper.\\n\n",
    "        MOTIVATION: The citing paper is directly motivated by the cited paper. \\n\n",
    "        EXTENSION: The citing paper extends the methods, tools, or data of the cited paper.\\n\n",
    "        FUTURE: The cited paper is a potential avenue for future work. \\n\n",
    "        \"\"\"\\\n",
    "        \"\\n\\n\" \\\n",
    "        \"Are the instructions clear to you?\"\n",
    "    \n",
    "    asst_msg1 = \"Yes, the instructions are clear to me. I will determine the citation function class of the marked citation (#AUTHOR_TAG) based on the provided citation function types and respond in json fromat.\"\n",
    "    \n",
    "    usr_msg2 = \"In a similar vain to #AUTHOR_TAG and Buchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures .\"\n",
    "\n",
    "    asst_msg2 = '{\"label\": \"COMPARE_CONTRAST\"}'\n",
    "\n",
    "    usr_msg3 = \"Give a brief explanation of why your answer is correct.\"\n",
    "\n",
    "    asst_msg3 = \"The marked citation (#AUTHOR_TAG) is compared to the method proposed in the citing paper and judged as similar.\"\\\n",
    "                \"Therefore, the citation function class is 'COMPARE_CONTRAST'\"\n",
    "    \n",
    "    usr_msg4 = \"Great! I am now going to give you another excerpt. Please detect the function class in it \" \\\n",
    "                \"according to the previous instructions. Do not include an explanation in your answer.\"\n",
    "    \n",
    "    asst_msg4 = \"Sure! Please give me the user utterance.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": usr_msg1},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg1},\n",
    "        {\"role\": \"user\", \"content\": usr_msg2},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg2},\n",
    "        {\"role\": \"user\", \"content\": usr_msg3},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg3},\n",
    "        {\"role\": \"user\", \"content\": usr_msg4},\n",
    "        {\"role\": \"assistant\", \"content\": asst_msg4},\n",
    "        {\"role\": \"user\", \"content\": input_str},\n",
    "    ]\n",
    "    if not test: messages.append({\"role\": \"assistant\", \"content\": label_str})\n",
    "    \n",
    "    encoded_input_ids = tokenizer.apply_chat_template(messages)\n",
    "\n",
    "    return {'input_ids': encoded_input_ids}\n",
    "\n",
    "# res = LMmodel.generate(torch.tensor([get_fine_tune_prompt('','',tokenizer)['input_ids']]), max_new_tokens=512)\n",
    "# tokenizer.decode(res[0]).split('[/INST]')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1646/1646 [00:01<00:00, 1346.52 examples/s]\n",
      "Map: 100%|██████████| 284/284 [00:00<00:00, 1461.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "def create_clean_data(df):\n",
    "    res_df = pd.DataFrame(columns=['par', 'label', 'json'])\n",
    "    for idx, row in df.iterrows():\n",
    "        par = ' '.join(eval(row['cite_context_paragraph']))\n",
    "        par_token = tokenizer.encode(par)\n",
    "        if len(par_token)>400:\n",
    "            if '#AUTHOR_TAG' in tokenizer.decode(par_token[:400]):\n",
    "                par = tokenizer.decode(par_token[:400])\n",
    "            elif '#AUTHOR_TAG' in tokenizer.decode(par_token[len(par_token)-400:]):\n",
    "                par = tokenizer.decode(par_token[len(par_token)-400:])\n",
    "            else: continue\n",
    "        label = row['citation_class_label']\n",
    "        json = '{\"label\": \"' + label_mapping(label) + '\"}'\n",
    "        res_df.loc[len(res_df)] = [par, label, json]\n",
    "    return res_df\n",
    "\n",
    "train_df = create_clean_data(train)\n",
    "test_df = create_clean_data(test)\n",
    "\n",
    "# Convert the DataFrame to a Dataset\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "#Apply the tokenization function to the dataset\n",
    "train_ds = train_ds.map(\n",
    "    lambda row: get_fine_tune_prompt(row['par'], row['json'], tokenizer), \n",
    "    batched=False, \n",
    "    remove_columns=train_ds.column_names  # Remove all original columns\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    lambda row: get_fine_tune_prompt(row['par'], row['json'], tokenizer, True), \n",
    "    batched=False, \n",
    "    remove_columns=test_ds.column_names  # Remove all original columns\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "length = []\n",
    "for item in train_ds:\n",
    "    length.append(len(item['input_ids']))\n",
    "sns.histplot(data=length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.utils import PaddingStrategy\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "@dataclass\n",
    "class CustomDataCollatorWithPadding:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        \n",
    "        # # Set loss mask for all pad tokens\n",
    "        # labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        # Compute loss mask for appropriate tokens only\n",
    "        for i in range(batch['input_ids'].shape[0]):\n",
    "            \n",
    "            # Decode the training input\n",
    "            text_content = self.tokenizer.decode(batch['input_ids'][i][1:])  # slicing from [1:] is important because tokenizer adds bos token\n",
    "            \n",
    "            # Extract substrings for prompt text in the training input\n",
    "            # The training input ends at the last user msg ending in [/INST]\n",
    "            prompt_gen_boundary = text_content.rfind(\"[/INST]\") + len(\"[/INST]\")\n",
    "            prompt_text = text_content[:prompt_gen_boundary]\n",
    "            \n",
    "            # print(f\"\"\"PROMPT TEXT:\\n{prompt_text}\"\"\")\n",
    "            \n",
    "            # retokenize the prompt text only\n",
    "            prompt_text_tokenized = self.tokenizer(\n",
    "                prompt_text,\n",
    "                return_overflowing_tokens=False,\n",
    "                return_length=False,\n",
    "            )\n",
    "            # compute index where prompt text ends in the training input\n",
    "            prompt_tok_idx = len(prompt_text_tokenized['input_ids'])\n",
    "            \n",
    "            # Set loss mask for all tokens in prompt text\n",
    "            labels[i][range(prompt_tok_idx)] = -100\n",
    "            \n",
    "                    \n",
    "        batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/explorer/anaconda3/envs/lasse/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:407: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "data_collator=CustomDataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, \n",
    "    padding=\"longest\", \n",
    "    max_length=max_seq_length, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "training_arguments = SFTConfig(\n",
    "    output_dir=\"./tmp\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    dataset_text_field=\"input_ids\",\n",
    "    max_seq_length=1024,\n",
    "    learning_rate=1e-4,\n",
    "    max_steps=2500,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=LMmodel,\n",
    "    train_dataset=train_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    # Using custom data collator inside SFTTrainer\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def is_json(myjson):\n",
    "  try:\n",
    "    json.loads(myjson)\n",
    "  except ValueError as e:\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(model, test_ds, data_collator):\n",
    "\n",
    "    eval_df = pd.DataFrame(columns=['pred', 'label_pred', 'is_valid_json'])\n",
    "    #generate response\n",
    "    for input_data in tqdm(test_ds):\n",
    "        res = model.generate(data_collator([input_data])['input_ids'].to(DEVICE), max_new_tokens=20)\n",
    "        answ = tokenizer.decode(res[0]).split('[/INST]')[-1]\n",
    "        clean_answ = re.sub('</s>', '', answ)\n",
    "        is_valid_json = is_json(clean_answ)\n",
    "        label = None\n",
    "        if is_valid_json: \n",
    "            label = int(label_mapping(json.loads(clean_answ)['label']))\n",
    "        eval_df.loc[len(eval_df)] = [clean_answ, label, is_valid_json]\n",
    "    \n",
    "    \n",
    "    #evaluate response\n",
    "    eval_df = pd.concat([test_df.loc[: len(eval_df) -1], eval_df], axis=1)\n",
    "    return eval_df\n",
    "\n",
    "def calculate_metrics(eval_df):\n",
    "    valid_json = sum(eval_df['is_valid_json']) / len(eval_df)\n",
    "    eval_df.dropna(inplace=True)\n",
    "    macro_f1 = f1_score([int(no) for no in eval_df['label']], [int(no) for no in eval_df['label_pred']], average='macro')\n",
    "    micro_f1 = f1_score([int(no) for no in eval_df['label']], [int(no) for no in eval_df['label_pred']], average='micro')\n",
    "    return valid_json, micro_f1, macro_f1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, np.float64(0.0), np.float64(0.0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par</th>\n",
       "      <th>label</th>\n",
       "      <th>json</th>\n",
       "      <th>pred</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>is_valid_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, a major obstacle to this approach is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"COMPARE_CONTRAST\"}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beside HTML markups, other criteria may also b...</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"label\": \"MOTIVATION\"}</td>\n",
       "      <td>{\"label\": \"FUTURE\"}</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The first system we have implemented with APE ...</td>\n",
       "      <td>5</td>\n",
       "      <td>{\"label\": \"FUTURE\"}</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2 See ( #AUTHOR_TAG ) for how MIMIC 's dialogu...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The strategies employed when MIMIC has only di...</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"label\": \"USE\"}</td>\n",
       "      <td>{\"label\": \"COMPARE_CONTRAST\"}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Previous work has argued that initiative affec...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"COMPARE_CONTRAST\"}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Previous work has argued that initiative affec...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"COMPARE_CONTRAST\"}</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 par  label  \\\n",
       "0  The parallel Web pages we collected from vario...      0   \n",
       "1  However, a major obstacle to this approach is ...      0   \n",
       "2  The parallel Web pages we collected from vario...      0   \n",
       "3  Beside HTML markups, other criteria may also b...      3   \n",
       "4  The parallel Web pages we collected from vario...      0   \n",
       "5  The first system we have implemented with APE ...      5   \n",
       "6  2 See ( #AUTHOR_TAG ) for how MIMIC 's dialogu...      0   \n",
       "7  The strategies employed when MIMIC has only di...      1   \n",
       "8  Previous work has argued that initiative affec...      0   \n",
       "9  Previous work has argued that initiative affec...      0   \n",
       "\n",
       "                      json                            pred  label_pred  \\\n",
       "0  {\"label\": \"BACKGROUND\"}                {\"label\": \"USE\"}           1   \n",
       "1  {\"label\": \"BACKGROUND\"}                {\"label\": \"USE\"}           1   \n",
       "2  {\"label\": \"BACKGROUND\"}   {\"label\": \"COMPARE_CONTRAST\"}           2   \n",
       "3  {\"label\": \"MOTIVATION\"}             {\"label\": \"FUTURE\"}           5   \n",
       "4  {\"label\": \"BACKGROUND\"}                {\"label\": \"USE\"}           1   \n",
       "5      {\"label\": \"FUTURE\"}                {\"label\": \"USE\"}           1   \n",
       "6  {\"label\": \"BACKGROUND\"}                {\"label\": \"USE\"}           1   \n",
       "7         {\"label\": \"USE\"}   {\"label\": \"COMPARE_CONTRAST\"}           2   \n",
       "8  {\"label\": \"BACKGROUND\"}   {\"label\": \"COMPARE_CONTRAST\"}           2   \n",
       "9  {\"label\": \"BACKGROUND\"}   {\"label\": \"COMPARE_CONTRAST\"}           2   \n",
       "\n",
       "   is_valid_json  \n",
       "0           True  \n",
       "1           True  \n",
       "2           True  \n",
       "3           True  \n",
       "4           True  \n",
       "5           True  \n",
       "6           True  \n",
       "7           True  \n",
       "8           True  \n",
       "9           True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = evaluate(trainer.model, test_ds, data_collator)\n",
    "metric_res = calculate_metrics(eval_df)\n",
    "print(metric_res)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 30:14, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.088800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.19527914581298828, metrics={'train_runtime': 1815.3721, 'train_samples_per_second': 1.377, 'train_steps_per_second': 1.377, 'total_flos': 7.70354066038702e+16, 'train_loss': 0.19527914581298828, 'epoch': 1.5188335358444713})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [04:21<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, np.float64(0.7676056338028169), np.float64(0.6428927883383747))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par</th>\n",
       "      <th>label</th>\n",
       "      <th>json</th>\n",
       "      <th>pred</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>is_valid_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, a major obstacle to this approach is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beside HTML markups, other criteria may also b...</td>\n",
       "      <td>3</td>\n",
       "      <td>{\"label\": \"MOTIVATION\"}</td>\n",
       "      <td>{\"label\": \"MOTIVATION\"}</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The parallel Web pages we collected from vario...</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>{\"label\": \"BACKGROUND\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 par  label  \\\n",
       "0  The parallel Web pages we collected from vario...      0   \n",
       "1  However, a major obstacle to this approach is ...      0   \n",
       "2  The parallel Web pages we collected from vario...      0   \n",
       "3  Beside HTML markups, other criteria may also b...      3   \n",
       "4  The parallel Web pages we collected from vario...      0   \n",
       "\n",
       "                      json                      pred  label_pred  \\\n",
       "0  {\"label\": \"BACKGROUND\"}   {\"label\": \"BACKGROUND\"}           0   \n",
       "1  {\"label\": \"BACKGROUND\"}   {\"label\": \"BACKGROUND\"}           0   \n",
       "2  {\"label\": \"BACKGROUND\"}   {\"label\": \"BACKGROUND\"}           0   \n",
       "3  {\"label\": \"MOTIVATION\"}   {\"label\": \"MOTIVATION\"}           3   \n",
       "4  {\"label\": \"BACKGROUND\"}   {\"label\": \"BACKGROUND\"}           0   \n",
       "\n",
       "   is_valid_json  \n",
       "0           True  \n",
       "1           True  \n",
       "2           True  \n",
       "3           True  \n",
       "4           True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = evaluate(trainer.model, test_ds, data_collator)\n",
    "metric_res = calculate_metrics(eval_df)\n",
    "print(metric_res)\n",
    "eval_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lasse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
